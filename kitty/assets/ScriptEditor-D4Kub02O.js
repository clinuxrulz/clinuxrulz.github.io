import{n as q,u as Y,t as J,K as $}from"./lib-oUuyS5Hd.js";import{O as R,c as G,Q,m,J as Z,N as v,Y as ee,q as ne}from"./dev-B9-ass9r.js";import"./index-XNH-lkY3.js";import"./dev-CC7pdsS5.js";const te=`import { Result } from 'control-flow-as-value';
import { Accessor, EffectFunction } from 'solid-js';
type ResultOkType<A> = A extends {
    type: "Ok";
    value: infer A2;
} ? A2 : never;
export declare class Cont<A> {
    private fn;
    private constructor();
    static of<A>(fn: (k: (a: A) => void) => void): Cont<A>;
    static readonly nop: Cont<void>;
    /**
     * Lifts a plain value into a Cont.
     * @param a the value to lift into a Cont.
     * @returns \`Cont<A>\`
     */
    static unit<A>(a: A): Cont<A>;
    /**
     * Lifts a promise into a Cont.
     * @param a the promise to lift into a Cont
     * @returns \`Cont<Result<A,any>>\`
     */
    static liftPromise<A>(a: Promise<A>): Cont<Result<A, any>>;
    /**
     * Lowers a Cont into a promise.
     * This method expects its generic type
     * to be a \`Result<..>\` type.
     * @returns \`Promise<ResultOkType<A>>\`
     */
    lowerPromise(): Promise<ResultOkType<A>>;
    /**
     * Lifts an accessor/memo into a Cont.
     * @param a the accessor/memo to lift into a Cont
     * @returns \`Cont<A>\`
     */
    static liftAccessor<A>(a: Accessor<A>): Cont<A>;
    /**
     * Lowers a Cont into an memo.
     * @returns \`Accessor<A | undefined>\`
     */
    lowerAccessor(): Accessor<A | undefined>;
    /**
     * Lowers a Cont into an memo.
     * @returns \`Accessor<A>\`
     */
    lowerAccessor(initValue: A): Accessor<A>;
    /**
     * Creates a computed and lifts it into a Cont.
     * @param fn the callback to use inside the computed, the callback returns what will be passed to the continuation.
     * @returns \`Cont<A>\`
     */
    static liftCC<A>(fn: EffectFunction<undefined | NoInfer<A>, A>): Cont<A>;
    /**
     * Creates a computed mapArray and lifts it into a Cont.
     * @param a the accessor of an array to feed to mapArray
     * @returns \`Cont<A>\`
     */
    static liftCCMA<A>(a: Accessor<A[]>): Cont<A>;
    static callCC<A>(fn: (k: (a: A) => Cont<never>) => Cont<A>): Cont<A>;
    map<B>(fn: (a: A) => B): Cont<B>;
    filter(cond: (a: A) => boolean): Cont<A>;
    filterNonNullable(): Cont<NonNullable<A>>;
    then<B>(fn: (a: A) => Cont<B>): Cont<B>;
    run(k?: (a: A) => void): void;
}
export {};
`,re=`import { Result } from './kitty-demo/Result';
import { Vec2 } from './math/Vec2';
export interface TypeSchemaMaybeUndefined<A> {
    type: "MaybeUndefined";
    element: TypeSchema<A>;
}
export interface TypeSchemaMaybeNull<A> {
    type: "MaybeNull";
    element: TypeSchema<A>;
}
export interface TypeSchemaBoolean {
    type: "Boolean";
}
export interface TypeSchemaNumber {
    type: "Number";
}
export interface TypeSchemaString {
    type: "String";
}
export interface TypeSchemaUnion<A extends {
    [K in Key]: unknown;
}, Key extends string = "type"> {
    type: "Union";
    selector: Key;
    parts: {
        [P in A[Key] & string]: TypeSchemaObject<Extract<A, {
            [Q in Key]: P;
        }>>["properties"];
    };
}
export interface TypeSchemaObject<A extends object> {
    type: "Object";
    properties: {
        [K in keyof A]: TypeSchema<A[K]>;
    };
}
export interface TypeSchemaArray<A> {
    type: "Array";
    element: TypeSchema<A>;
}
export interface TypeSchemaInvarant<A, B> {
    type: "Invarant";
    fromFn: (b: B) => A;
    toFn: (a: A) => B;
    inner: TypeSchema<B>;
}
export interface TypeSchemaDefault<A> {
    type: "Default";
    value: A;
    inner: TypeSchema<A>;
}
export interface TypeSchemaRecursive<A> {
    type: "Recursive";
    inner: () => TypeSchema<A>;
}
export interface TypeSchemaJson {
    type: "Json";
}
export type TypeSchema<A> = TypeSchemaMaybeUndefined<NonNullable<A>> | TypeSchemaMaybeNull<NonNullable<A>> | TypeSchemaBoolean | TypeSchemaNumber | TypeSchemaString | TypeSchemaUnion<Extract<A, Record<string, unknown>>, any> | TypeSchemaObject<Extract<A, object>> | TypeSchemaArray<any> | TypeSchemaInvarant<A, any> | TypeSchemaDefault<A> | TypeSchemaRecursive<A> | TypeSchemaJson;
export type TypeSchemaType<A> = A extends TypeSchemaMaybeUndefined<infer B> ? B | undefined : A extends TypeSchemaMaybeNull<infer B> ? B | null : A extends TypeSchemaBoolean ? boolean : A extends TypeSchemaNumber ? number : A extends TypeSchemaString ? string : A extends TypeSchemaUnion<infer B, any> ? B : A extends TypeSchemaObject<infer B> ? B : A extends TypeSchemaArray<infer B> ? B[] : A extends TypeSchemaInvarant<infer B, any> ? B : A extends TypeSchemaDefault<A> ? A : A extends TypeSchemaRecursive<A> ? A : A extends TypeSchemaJson ? any : never;
export declare function tsMaybeUndefined<TS>(element: TS): TypeSchemaMaybeUndefined<TypeSchemaType<TS>>;
export declare function tsMaybeNull<TS>(element: TS): TypeSchemaMaybeNull<TypeSchemaType<TS>>;
export declare function tsBoolean(): TypeSchemaBoolean;
export declare function tsNumber(): TypeSchemaNumber;
export declare function tsString(): TypeSchemaString;
type InferObjectSchema<T extends Record<string, TypeSchema<any>>> = {
    [K in keyof T]: TypeSchemaType<T[K]>;
};
export type UnionPart<T extends Record<string, Record<string, TypeSchema<any>>>, Key extends string> = {
    [P in keyof T]: P extends string ? {
        [Q in Key]: P;
    } & InferObjectSchema<T[P]> : never;
}[keyof T];
export declare function tsUnion<T extends {
    [K in keyof T]: Record<string, TypeSchema<any>>;
}, Key extends string = "type">(selector: Key, parts: T): TypeSchemaUnion<UnionPart<T, Key>, Key>;
export declare function tsObject<T>(properties: T): TypeSchemaObject<{
    [K in keyof T]: TypeSchemaType<T[K]>;
}>;
export declare function tsArray<TS>(element: TS): TypeSchemaArray<TypeSchemaType<TS>>;
export declare function tsInvarant<T, U>(fromFn: (u: U) => T, toFn: (t: T) => U, inner: TypeSchema<U>): TypeSchemaInvarant<T, U>;
export declare function tsDefault<A>(value: A, inner: TypeSchema<A>): TypeSchemaDefault<A>;
export declare function tsRecursive<A>(inner: () => TypeSchema<A>): TypeSchemaRecursive<A>;
export declare function tsJson(): TypeSchemaJson;
export declare const vec2TypeSchema: TypeSchemaInvarant<Vec2, {
    x: number;
    y: number;
}>;
export declare function loadFromJsonViaTypeSchema<A>(typeSchema: TypeSchema<A>, x: any): Result<A>;
export declare function makeDefaultViaTypeSchema<A>(typeSchema: TypeSchema<A>): A;
export declare function saveToJsonViaTypeSchema<A>(typeSchema: TypeSchema<A>, x: A): any;
export declare function equalsViaTypeSchema<A>(typeSchema: TypeSchema<A>, a: A, b: A): boolean;
export declare function createJsonProjectionViaTypeSchemaV2<A>(typeSchema: TypeSchema<A>, json: any, changeJson: (callback: (json: any) => void) => void): Result<A>;
export declare function createJsonProjectionViaTypeSchema<A extends object>(typeSchema: TypeSchema<A>, json: any, changeJson: (callback: (json: any) => void) => void): Result<A>;
export {};
`,oe=`import { EcsComponentType } from '../ecs/EcsComponent';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    textureAtlasFilename: string;
    animationName: string;
    frameIndex: number;
}>;
export type AnimatedState = TypeSchemaType<typeof typeSchema>;
export declare const animatedComponentType: EcsComponentType<{
    textureAtlasFilename: string;
    animationName: string;
    frameIndex: number;
}>;
export {};
`,ae=`import { EcsComponentType } from '../ecs/EcsComponent';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    targetEntity: string | undefined;
}>;
export type CameraState = TypeSchemaType<typeof typeSchema>;
export declare const cameraComponentType: EcsComponentType<{
    targetEntity: string | undefined;
}>;
export {};
`,ie=`import { EcsComponentType } from '../lib';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{}>;
export type FlipXState = TypeSchemaType<typeof typeSchema>;
export declare const flipXComponentType: EcsComponentType<{}>;
export {};
`,se=`import { EcsComponentType, TypeSchemaType } from '../lib';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    levelFilename: string;
}>;
export type LevelRefState = TypeSchemaType<typeof typeSchema>;
export declare const levelRefComponentType: EcsComponentType<{
    levelFilename: string;
}>;
export {};
`,le=`import { EcsComponentType } from '../lib';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{}>;
export type OnGroundState = TypeSchemaType<typeof typeSchema>;
export declare const onGroundComponentType: EcsComponentType<{}>;
export {};
`,de=`import { EcsComponentType } from '../ecs/EcsComponent';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    scale: number;
}>;
export type ScaleState = TypeSchemaType<typeof typeSchema>;
export declare const scaleComponentType: EcsComponentType<{
    scale: number;
}>;
export {};
`,pe=`import { EcsComponentType } from '../ecs/EcsComponent';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    textureAtlasFilename: string;
    frameName: string;
}>;
export type SpriteState = TypeSchemaType<typeof typeSchema>;
export declare const spriteComponentType: EcsComponentType<{
    textureAtlasFilename: string;
    frameName: string;
}>;
export {};
`,ce=`import { EcsComponentType } from '../ecs/EcsComponent';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    textureAtlasFilename: string;
    frameName: string;
    width: number;
    height: number;
    metaData: any;
}>;
export type TileCollisionState = TypeSchemaType<typeof typeSchema>;
export declare const tileCollisionComponentType: EcsComponentType<{
    textureAtlasFilename: string;
    frameName: string;
    width: number;
    height: number;
    metaData: any;
}>;
export {};
`,ue=`import { EcsComponentType } from '../ecs/EcsComponent';
import { Transform2D } from '../math/Transform2D';
import { TypeSchemaType } from '../TypeSchema';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    transform: Transform2D;
}>;
export type Transform2DState = TypeSchemaType<typeof typeSchema>;
export declare const transform2DComponentType: EcsComponentType<{
    transform: Transform2D;
}>;
export {};
`,me=`import { EcsComponentType, TypeSchemaType, Vec2 } from '../lib';
declare const typeSchema: import('../TypeSchema').TypeSchemaObject<{
    velocity: Vec2;
}>;
export type Velocity2DState = TypeSchemaType<typeof typeSchema>;
export declare const velocity2DComponentType: EcsComponentType<{
    velocity: Vec2;
}>;
export {};
`,he=`import { EcsRegistry } from '../ecs/EcsRegistry';
export declare const registry: EcsRegistry;
`,fe=`import { Cont } from './Cont';
/**
 * Do notation for Cont
 */
export declare function do_<A>(fn: () => A): Cont<A>;
/**
 * Adds an instruction to the computation for
 * the Cont do-notation block.
 * @param instr The instruction to add.
 */
export declare function exec(instr: Cont<void>): void;
/**
 * Utility to read a monadic handle to a value
 */
export declare function read<A>(a: Cont<A>, fn: (a: A) => Cont<void>): void;
/**
 * Similiar to \`exec\` but returns a monadic handle to a result.
 * @param instr The instruction to add that has a result.
 */
export declare function execR<A>(instr: Cont<A>): Cont<A>;
`,be=`import { Cont } from './Cont';
export declare const nop: Cont<void>;
export declare function callCC(fn: (k: Cont<void>) => void): void;
export type Label = () => Cont<void>;
export declare function provideNextFrame(nextFrame: (k: Cont<void>) => void): (cb: () => void) => void;
export declare function nextFrame(): void;
export declare function toPerFrameUpdateFn(cb: () => void): () => void;
export declare function makeLabel(): Label;
export declare function goto(label: Label): void;
export declare function while_(cond: Cont<boolean> | (() => boolean)): (body: () => void) => void;
export declare function sideEffect(cb: () => void): void;
`,ge=`import { SetStoreFunction, Store } from 'solid-js/store';
import { Result } from '../kitty-demo/Result';
import { TypeSchema } from '../TypeSchema';
import { Accessor } from 'solid-js';
export interface IsEcsComponentType {
    readonly typeName: string;
}
export interface IsEcsComponent {
    readonly type: IsEcsComponentType;
}
export declare class EcsComponentType<S extends object> implements IsEcsComponentType {
    readonly typeName: string;
    readonly typeSchema: TypeSchema<S>;
    constructor(params: {
        typeName: string;
        typeSchema: TypeSchema<S>;
    });
    create(s: S): EcsComponent<S>;
    createJsonProjectionV3(json: any, changeJson: (callback: (json: any) => void) => void): Result<EcsComponent<S>>;
    createJsonProjectionV2(json: any, changeJson: (callback: (json: any) => void) => void): Result<EcsComponent<S>>;
    createJsonProjection(json: Accessor<any>, setJson: (x: any) => void): Accessor<Result<EcsComponent<S>>>;
}
export declare class EcsComponent<S extends object> implements IsEcsComponent {
    readonly type: EcsComponentType<S>;
    state: Store<S>;
    setState: SetStoreFunction<S>;
    constructor(params: {
        type: EcsComponentType<S>;
        state: Store<S>;
        setState: SetStoreFunction<S>;
    });
}
`,ye=`import { IsEcsComponentType } from './EcsComponent';
export declare class EcsRegistry {
    componentTypes: IsEcsComponentType[];
    componentTypeMap: Map<string, IsEcsComponentType>;
    constructor(componentTypes: IsEcsComponentType[]);
}
`,xe=`import { EcsComponent, EcsComponentType, IsEcsComponent, IsEcsComponentType } from './EcsComponent';
import { Result } from '../kitty-demo/Result';
import { EcsRegistry } from './EcsRegistry';
import { IEcsWorld } from './IEcsWorld';
export declare class EcsWorld implements IEcsWorld {
    private entityMap;
    private componentTypeEntitiesMap;
    private componentTypeEntitiesMap_;
    constructor();
    entities(): string[];
    entitiesWithComponentType(componentType: IsEcsComponentType): string[];
    createEntityWithId(entityId: string, components: IsEcsComponent[]): void;
    createEntity(components: IsEcsComponent[]): string;
    destroyEntity(entityId: string): void;
    attachToParent(entityId: string, parentId: string): void;
    detactFromParent(entityId: string): void;
    getComponent<A extends object>(entityId: string, componentType: EcsComponentType<A>): EcsComponent<A> | undefined;
    getComponents(entityId: string): IsEcsComponent[];
    setComponent(entityId: string, component: IsEcsComponent): void;
    setComponents(entityId: string, components: IsEcsComponent[]): void;
    unsetComponent(entityId: string, componentType: IsEcsComponentType): void;
    unsetComponents(entityId: string, componentTypes: IsEcsComponentType[]): void;
    toJson(): any;
    static fromJson(registry: EcsRegistry, x: any): Result<EcsWorld>;
}
`,ve=`import { Doc, DocHandle } from '@automerge/automerge-repo';
import { IsEcsComponentType, IsEcsComponent, EcsComponentType, EcsComponent } from './EcsComponent';
import { IEcsWorld } from './IEcsWorld';
import { EcsRegistry } from './EcsRegistry';
import { Result } from '../kitty-demo/Result';
export declare class EcsWorldAutomergeProjection implements IEcsWorld {
    private registry;
    private docHandle;
    private doc;
    private keepAliveMap;
    constructor(registry: EcsRegistry, docHandle: DocHandle<any>, doc: Doc<any>);
    static create(registry: EcsRegistry, docHandle: DocHandle<any>): Result<EcsWorldAutomergeProjection>;
    private _entitiesCache;
    entities(): string[];
    private _entitiesWithComponentTypeCache;
    entitiesWithComponentType(componentType: IsEcsComponentType): string[];
    createEntityWithId(entityId: string, components: IsEcsComponent[]): void;
    createEntity(components: IsEcsComponent[]): string;
    destroyEntity(entityId: string): void;
    getComponent<A extends object>(entityId: string, componentType: EcsComponentType<A>): EcsComponent<A> | undefined;
    getComponents(entityId: string): IsEcsComponent[];
    setComponents(entityId: string, components: IsEcsComponent[]): void;
    unsetComponent(entityId: string, componentType: IsEcsComponentType): void;
    unsetComponents(entityId: string, componentTypes: IsEcsComponentType[]): void;
    debugInfo(): string;
}
`,Te=`import { EcsComponent, EcsComponentType, IsEcsComponent, IsEcsComponentType } from './EcsComponent';
export interface IEcsWorld {
    entities(): string[];
    entitiesWithComponentType(componentType: IsEcsComponentType): string[];
    createEntityWithId(entityId: string, components: IsEcsComponent[]): void;
    createEntity(components: IsEcsComponent[]): string;
    destroyEntity(entityId: string): void;
    getComponent<A extends object>(entityId: string, componentType: EcsComponentType<A>): EcsComponent<A> | undefined;
    getComponents(entityId: string): IsEcsComponent[];
    setComponents(entityId: string, components: IsEcsComponent[]): void;
    unsetComponent(entityId: string, componentType: IsEcsComponentType): void;
    unsetComponents(entityId: string, componentTypes: IsEcsComponentType[]): void;
    debugInfo?(): string;
}
`,Se=`import { TypeSchemaType } from '../../TypeSchema';
import { EcsComponentType } from '../EcsComponent';
declare const typeSchema: import('../../TypeSchema').TypeSchemaObject<{
    childIds: string[];
}>;
export type ChildrenState = TypeSchemaType<typeof typeSchema>;
export declare const childrenComponentType: EcsComponentType<{
    childIds: string[];
}>;
export {};
`,we=`import { TypeSchemaType } from '../../TypeSchema';
import { EcsComponentType } from '../EcsComponent';
declare const typeSchema: import('../../TypeSchema').TypeSchemaObject<{
    parentId: string;
}>;
export type ParentState = TypeSchemaType<typeof typeSchema>;
export declare const parentComponentType: EcsComponentType<{
    parentId: string;
}>;
export {};
`,_e=`import { TypeSchemaType } from '../../TypeSchema';
import { EcsComponentType } from '../EcsComponent';
declare const typeSchema: import('../../TypeSchema').TypeSchemaObject<{
    orderIndex: number;
}>;
export type SortOrderIndexState = TypeSchemaType<typeof typeSchema>;
export declare const sortOrderIndexComponentType: EcsComponentType<{
    orderIndex: number;
}>;
export {};
`,Ee=`import { EcsRegistry } from '../EcsRegistry';
export declare const registry: EcsRegistry;
`,Pe=`import { DocHandle } from '@automerge/automerge-repo';
import { EcsWorld } from '../EcsWorld';
import { EcsRegistry } from '../EcsRegistry';
import { Result } from '../../kitty-demo/Result';
export declare function createAutomergeEcsSyncSystem(params: {
    registry: EcsRegistry;
    world: EcsWorld;
    docHandle: DocHandle<any>;
}): Result<{
    dispose: () => void;
}>;
`,Ae=`export {}
`,Ce=`export {}
`,Re=`import { Accessor } from 'solid-js';
import { EcsWorld } from './lib';
import { AutomergeVfsFolder, AutomergeVirtualFileSystem } from 'solid-fs-automerge';
import { AsyncResult } from 'control-flow-as-value';
import { TextureAtlasState } from './level-builder/components/TextureAtlasComponent';
import { FrameState } from './level-builder/components/FrameComponent';
import { AnimationState } from './level-builder/components/AnimationComponent';
export * from './ecs/EcsComponent';
export * from './ecs/EcsRegistry';
export * from './ecs/EcsWorld';
export * from './ecs/components/ChildrenComponent';
export * from './ecs/components/ParentComponent';
export * from './ecs/components/SortOrderIndexComponent';
export * from './TypeSchema';
export { PixiRenderSystem } from './systems/PixiRenderSystem';
export { createGmeSystem } from './systems/GmeSystem';
export { createMonsterLogicSystem } from './systems/MonsterLogicSystem';
export { createSpawnSystem } from './systems/SpawnSystem';
export { createVirtualDPadSystem } from './systems/VirtualDPadSystem';
export { CollisionResolutionSystem, createCollisionResolutionSystem } from './systems/CollisionResolutionSystem';
export * from 'solid-js';
export * from './Cont';
export * from './cont-do';
export * from './coroutine-dsl';
declare let systems: {
    PixiRenderSystem: (params: {
        world: EcsWorld;
    }) => void;
    CollisionSystem: (params: {
        world: EcsWorld;
    }) => void;
    AnimationSystem: (params: {
        world: EcsWorld;
    }) => void;
};
export type SystemName = keyof typeof systems;
export declare function useSystem(systemName: SystemName): () => void;
export declare const REQUIRED_FOR_KEEPING_MANUAL_CHUNKS: () => undefined;
export declare function launch(): void;
export declare const createAutomergeVfs: () => Accessor<{
    type: "Pending";
} | {
    type: "Failed";
    message: string;
} | {
    type: "Success";
    value: AutomergeVirtualFileSystem;
}>;
export declare const libUrl: string;
export declare const world: EcsWorld;
export { type AnimatedState, animatedComponentType, } from './components/AnimatedComponent';
export { type CameraState, cameraComponentType, } from './components/CameraComponent';
export { type FlipXState, flipXComponentType, } from './components/FlipXComponent';
export { type LevelRefState, levelRefComponentType, } from './components/LevelRefComponent';
export { type OnGroundState, onGroundComponentType, } from './components/OnGroundComponent';
export { type ScaleState, scaleComponentType, } from './components/ScaleComponent';
export { type SpriteState, spriteComponentType, } from './components/SpriteComponent';
export { type TileCollisionState, tileCollisionComponentType, } from './components/TileCollisionComponent';
export { type Transform2DState, transform2DComponentType, } from './components/Transform2DComponent';
export { type Velocity2DState, velocity2DComponentType, } from './components/Velocity2DComponent';
export { registry } from './components/registry';
export { Complex } from './math/Complex';
export { Transform2D } from './math/Transform2D';
export { Vec2 } from './math/Vec2';
export declare function fixRelativeUrl(relativeUrl: string): string;
export declare const createGetRootFolder: () => Accessor<AsyncResult<AutomergeVfsFolder>>;
export declare const createGetLevelsFolder: () => Accessor<AsyncResult<AutomergeVfsFolder>>;
export declare const createTextureAtlasWithImageAndFramesList: () => Accessor<AsyncResult<{
    textureAtlasFilename: Accessor<string>;
    textureAtlas: TextureAtlasState;
    image: HTMLImageElement;
    frames: {
        frameId: string;
        frame: FrameState;
    }[];
    animations: {
        animationId: string;
        animation: AnimationState;
    }[];
}[]>>;
`,Ge=`import { Vec2 } from './Vec2';
export declare class Complex {
    readonly x: number;
    readonly y: number;
    static rot0: Complex;
    constructor(x: number, y: number);
    static xy(xy: Vec2): Complex;
    static fromAngle(angle: number): Complex;
    get u(): Vec2;
    get v(): Vec2;
    getLengthSquared(): number;
    getLength(): number;
    normalize(): Complex;
    times(rhs: Complex): Complex;
    conjugate(): Complex;
    rotate(p: Vec2): Vec2;
    getAngle(): number;
}
`,Me=`import { Vec2 } from './Vec2';
import { Complex } from './Complex';
export declare class Transform2D {
    readonly origin: Vec2;
    readonly orientation: Complex;
    static readonly identity: Transform2D;
    constructor(origin: Vec2, orientation: Complex);
    static create(origin: Vec2, orientation: Complex): Transform2D;
    get u(): Vec2;
    get v(): Vec2;
    pointFromSpace(p: Vec2): Vec2;
    pointToSpace(p: Vec2): Vec2;
    vectorFromSpace(v: Vec2): Vec2;
    vectorToSpace(v: Vec2): Vec2;
    transformFromSpace(a: Transform2D): Transform2D;
    transformToSpace(a: Transform2D): Transform2D;
}
`,ke=`export declare class Vec2 {
    readonly x: number;
    readonly y: number;
    private constructor();
    static create(x: number, y: number): Vec2;
    static readonly zero: Vec2;
    static readonly unitX: Vec2;
    static readonly unitY: Vec2;
    add(other: Vec2): Vec2;
    sub(other: Vec2): Vec2;
    multScalar(s: number): Vec2;
    cross(other: Vec2): number;
    distanceSquared(other: Vec2): number;
    distance(other: Vec2): number;
    lengthSquared(): number;
    length(): number;
    normalize(): Vec2;
}
`,Fe=`export {}
`,Oe=`export {}
`,Ie=`export {}
`,Le=`export {}
`,Be=`import { EcsWorld } from '../lib';
export declare class AnimationSystem {
    constructor(params: {
        world: EcsWorld;
    });
}
`,De=`import { EcsWorld, Vec2 } from '../lib';
export declare function createCollisionResolutionSystem(params: {
    world: EcsWorld;
    isSolidBlock: (meta: any) => boolean;
    isPlatform: (meta: any) => boolean;
    maxSpeed: Vec2;
}): {
    dispose: () => void;
    update: () => void;
};
export declare class CollisionResolutionSystem {
    update: () => void;
    constructor(params: {
        world: EcsWorld;
        isSolidBlock: (meta: any) => boolean;
        isPlatform: (meta: any) => boolean;
        maxSpeed: Vec2;
    });
}
`,Ue=`import { EcsWorld } from '../ecs/EcsWorld';
export declare class CollisionSystem {
    constructor(params: {
        world: EcsWorld;
    });
}
`,je=`export declare function createGmeSystem(params: {
    fileUrl: string;
    onReady?: () => void;
}): {
    playMusic: (subtune: number) => void;
    playSound: (subtune: number) => void;
    subtuneCount: () => number;
};
`,We=`import { Accessor } from 'solid-js';
import { EcsWorld, IsEcsComponentType } from '../lib';
export declare function createMonsterLogicSystem(params: {
    world: EcsWorld;
    monsterLogicList: Accessor<{
        componentType: IsEcsComponentType;
        logic: (entity: string) => void;
    }[]>;
}): {
    nextFrame: () => void;
    dispose: () => void;
};
`,He=`import { Application, Renderer } from 'pixi.js';
import { Accessor } from 'solid-js';
import { EcsWorld } from '../ecs/EcsWorld';
export declare class PixiRenderSystem {
    pixiApp: Accessor<Application<Renderer> | undefined>;
    constructor(params: {
        world: EcsWorld;
    });
}
`,Ve=`import { EcsWorld } from '../lib';
import { SpawnState } from '../level-builder/components/SpawnComponent';
export declare function createSpawnSystem(params: {
    world: EcsWorld;
    doSpawn: (params: {
        spawn: SpawnState;
    }) => string | undefined;
}): {
    dispose: () => void;
};
`,Ne=`import { Accessor } from 'solid-js';
export declare function createVirtualDPadSystem(): {
    dispose: () => void;
    leftPressed: Accessor<boolean>;
    rightPressed: Accessor<boolean>;
    upPressed: Accessor<boolean>;
    downPressed: Accessor<boolean>;
};
`,ze=`export type { JSX } from "./jsx.d.ts";
import type { JSX } from "./jsx.d.ts";
declare function Fragment(props: { children: JSX.Element }): JSX.Element;
declare function jsx(
  type: any,
  props: any
): () =>
  | (Node & {
      [key: string]: any;
    })
  | (Node & {
      [key: string]: any;
    })[];
export { jsx, jsx as jsxs, jsx as jsxDEV, Fragment };
`,Xe=`import * as csstype from "csstype";

/**
 * Based on JSX types for Surplus and Inferno and adapted for \`dom-expressions\`.
 *
 * https://github.com/adamhaile/surplus/blob/master/index.d.ts
 * https://github.com/infernojs/inferno/blob/master/packages/inferno/src/core/types.ts
 */
type DOMElement = Element;

export namespace JSX {
  type FunctionMaybe<T = unknown> = { (): T } | T;
  type Element =
    | Node
    | ArrayElement
    | FunctionElement
    | (string & {})
    | number
    | boolean
    | null
    | undefined;
  interface ArrayElement extends Array<Element> {}
  interface FunctionElement {
    (): Element;
  }
  interface ElementClass {
    // empty, libs can define requirements downstream
  }
  interface ElementAttributesProperty {
    // empty, libs can define requirements downstream
  }
  interface ElementChildrenAttribute {
    children: {};
  }
  interface EventHandler<T, E extends Event> {
    (
      e: E & {
        currentTarget: T;
        target: DOMElement;
      }
    ): void;
  }

  interface BoundEventHandler<T, E extends Event> {
    0: (
      data: any,
      e: E & {
        currentTarget: T;
        target: DOMElement;
      }
    ) => void;
    1: any;
  }
  type EventHandlerUnion<T, E extends Event> = EventHandler<T, E> | BoundEventHandler<T, E>;

  interface EventHandlerWithOptions<T, E extends Event> extends AddEventListenerOptions {
    handleEvent: (
      e: E & {
        currentTarget: T;
        target: Element;
      }
    ) => void;
  }

  type EventHandlerWithOptionsUnion<T, E extends Event> =
    | EventHandler<T, E>
    | EventHandlerWithOptions<T, E>;

  const SERIALIZABLE: unique symbol;
  interface SerializableAttributeValue {
    toString(): string;
    [SERIALIZABLE]: never;
  }

  interface IntrinsicAttributes {
    ref?: unknown | ((e: unknown) => void);
  }
  interface CustomAttributes<T> {
    ref?: T | ((el: T) => void);
    classList?: {
      [k: string]: boolean | undefined;
    };
    $ServerOnly?: boolean;
  }
  type Accessor<T> = () => T;
  interface Directives {}
  interface DirectiveFunctions {
    [x: string]: (el: Element, accessor: Accessor<any>) => void;
  }
  interface ExplicitProperties {}
  interface ExplicitAttributes {}
  interface ExplicitBoolAttributes {}
  interface CustomEvents {}
  /** @deprecated Replaced by CustomEvents */
  interface CustomCaptureEvents {}
  type DirectiveAttributes = {
    [Key in keyof Directives as \`use:\${Key}\`]?: Directives[Key];
  };
  type DirectiveFunctionAttributes<T> = {
    [K in keyof DirectiveFunctions as string extends K
      ? never
      : \`use:\${K}\`]?: DirectiveFunctions[K] extends (
      el: infer E, // will be unknown if not provided
      ...rest: infer R // use rest so that we can check whether it's provided or not
    ) => void
      ? T extends E // everything extends unknown if E is unknown
        ? R extends [infer A] // check if has accessor provided
          ? A extends Accessor<infer V>
            ? V // it's an accessor
            : never // it isn't, type error
          : true // no accessor provided
        : never // T is the wrong element
      : never; // it isn't a function
  };
  type PropAttributes = {
    [Key in keyof ExplicitProperties as \`prop:\${Key}\`]?: ExplicitProperties[Key];
  };
  type AttrAttributes = {
    [Key in keyof ExplicitAttributes as \`attr:\${Key}\`]?: ExplicitAttributes[Key];
  };
  type BoolAttributes = {
    [Key in keyof ExplicitBoolAttributes as \`bool:\${Key}\`]?: ExplicitBoolAttributes[Key];
  };
  type OnAttributes<T> = {
    [Key in keyof CustomEvents as \`on:\${Key}\`]?: EventHandlerWithOptionsUnion<T, CustomEvents[Key]>;
  };
  type OnCaptureAttributes<T> = {
    [Key in keyof CustomCaptureEvents as \`oncapture:\${Key}\`]?: EventHandler<
      T,
      CustomCaptureEvents[Key]
    >;
  };
  interface DOMAttributes<T>
    extends CustomAttributes<T>,
      DirectiveAttributes,
      DirectiveFunctionAttributes<T>,
      PropAttributes,
      AttrAttributes,
      BoolAttributes,
      OnAttributes<T>,
      OnCaptureAttributes<T>,
      CustomEventHandlersCamelCase<T>,
      CustomEventHandlersLowerCase<T>,
      CustomEventHandlersNamespaced<T> {
    children?: Element;
    innerHTML?: string;
    innerText?: string | number;
    textContent?: string | number;
    // camel case events
    onCopy?: EventHandlerUnion<T, ClipboardEvent>;
    onCut?: EventHandlerUnion<T, ClipboardEvent>;
    onPaste?: EventHandlerUnion<T, ClipboardEvent>;
    onCompositionEnd?: EventHandlerUnion<T, CompositionEvent>;
    onCompositionStart?: EventHandlerUnion<T, CompositionEvent>;
    onCompositionUpdate?: EventHandlerUnion<T, CompositionEvent>;
    onFocusOut?: EventHandlerUnion<T, FocusEvent>;
    onFocusIn?: EventHandlerUnion<T, FocusEvent>;
    onEncrypted?: EventHandlerUnion<T, Event>;
    onDragExit?: EventHandlerUnion<T, DragEvent>;
    // lower case events
    oncopy?: EventHandlerUnion<T, ClipboardEvent>;
    oncut?: EventHandlerUnion<T, ClipboardEvent>;
    onpaste?: EventHandlerUnion<T, ClipboardEvent>;
    oncompositionend?: EventHandlerUnion<T, CompositionEvent>;
    oncompositionstart?: EventHandlerUnion<T, CompositionEvent>;
    oncompositionupdate?: EventHandlerUnion<T, CompositionEvent>;
    onfocusout?: EventHandlerUnion<T, FocusEvent>;
    onfocusin?: EventHandlerUnion<T, FocusEvent>;
    onencrypted?: EventHandlerUnion<T, Event>;
    ondragexit?: EventHandlerUnion<T, DragEvent>;
    // namespaced events
    "on:copy"?: EventHandlerWithOptionsUnion<T, ClipboardEvent>;
    "on:cut"?: EventHandlerWithOptionsUnion<T, ClipboardEvent>;
    "on:paste"?: EventHandlerWithOptionsUnion<T, ClipboardEvent>;
    "on:compositionend"?: EventHandlerWithOptionsUnion<T, CompositionEvent>;
    "on:compositionstart"?: EventHandlerWithOptionsUnion<T, CompositionEvent>;
    "on:compositionupdate"?: EventHandlerWithOptionsUnion<T, CompositionEvent>;
    "on:focusout"?: EventHandlerWithOptionsUnion<T, FocusEvent>;
    "on:focusin"?: EventHandlerWithOptionsUnion<T, FocusEvent>;
    "on:encrypted"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:dragexit"?: EventHandlerWithOptionsUnion<T, DragEvent>;
  }
  interface CustomEventHandlersCamelCase<T> {
    onAbort?: EventHandlerUnion<T, Event>;
    onAnimationEnd?: EventHandlerUnion<T, AnimationEvent>;
    onAnimationIteration?: EventHandlerUnion<T, AnimationEvent>;
    onAnimationStart?: EventHandlerUnion<T, AnimationEvent>;
    onAuxClick?: EventHandlerUnion<T, MouseEvent>;
    onBeforeInput?: EventHandlerUnion<T, InputEvent>;
    onBeforeToggle?: EventHandlerUnion<T, ToggleEvent>;
    onBlur?: EventHandlerUnion<T, FocusEvent>;
    onCanPlay?: EventHandlerUnion<T, Event>;
    onCanPlayThrough?: EventHandlerUnion<T, Event>;
    onChange?: EventHandlerUnion<T, Event>;
    onClick?: EventHandlerUnion<T, MouseEvent>;
    onContextMenu?: EventHandlerUnion<T, MouseEvent>;
    onDblClick?: EventHandlerUnion<T, MouseEvent>;
    onDrag?: EventHandlerUnion<T, DragEvent>;
    onDragEnd?: EventHandlerUnion<T, DragEvent>;
    onDragEnter?: EventHandlerUnion<T, DragEvent>;
    onDragLeave?: EventHandlerUnion<T, DragEvent>;
    onDragOver?: EventHandlerUnion<T, DragEvent>;
    onDragStart?: EventHandlerUnion<T, DragEvent>;
    onDrop?: EventHandlerUnion<T, DragEvent>;
    onDurationChange?: EventHandlerUnion<T, Event>;
    onEmptied?: EventHandlerUnion<T, Event>;
    onEnded?: EventHandlerUnion<T, Event>;
    onError?: EventHandlerUnion<T, Event>;
    onFocus?: EventHandlerUnion<T, FocusEvent>;
    onGotPointerCapture?: EventHandlerUnion<T, PointerEvent>;
    onInput?: EventHandlerUnion<T, InputEvent>;
    onInvalid?: EventHandlerUnion<T, Event>;
    onKeyDown?: EventHandlerUnion<T, KeyboardEvent>;
    onKeyPress?: EventHandlerUnion<T, KeyboardEvent>;
    onKeyUp?: EventHandlerUnion<T, KeyboardEvent>;
    onLoad?: EventHandlerUnion<T, Event>;
    onLoadedData?: EventHandlerUnion<T, Event>;
    onLoadedMetadata?: EventHandlerUnion<T, Event>;
    onLoadStart?: EventHandlerUnion<T, Event>;
    onLostPointerCapture?: EventHandlerUnion<T, PointerEvent>;
    onMouseDown?: EventHandlerUnion<T, MouseEvent>;
    onMouseEnter?: EventHandlerUnion<T, MouseEvent>;
    onMouseLeave?: EventHandlerUnion<T, MouseEvent>;
    onMouseMove?: EventHandlerUnion<T, MouseEvent>;
    onMouseOut?: EventHandlerUnion<T, MouseEvent>;
    onMouseOver?: EventHandlerUnion<T, MouseEvent>;
    onMouseUp?: EventHandlerUnion<T, MouseEvent>;
    onPause?: EventHandlerUnion<T, Event>;
    onPlay?: EventHandlerUnion<T, Event>;
    onPlaying?: EventHandlerUnion<T, Event>;
    onPointerCancel?: EventHandlerUnion<T, PointerEvent>;
    onPointerDown?: EventHandlerUnion<T, PointerEvent>;
    onPointerEnter?: EventHandlerUnion<T, PointerEvent>;
    onPointerLeave?: EventHandlerUnion<T, PointerEvent>;
    onPointerMove?: EventHandlerUnion<T, PointerEvent>;
    onPointerOut?: EventHandlerUnion<T, PointerEvent>;
    onPointerOver?: EventHandlerUnion<T, PointerEvent>;
    onPointerUp?: EventHandlerUnion<T, PointerEvent>;
    onProgress?: EventHandlerUnion<T, Event>;
    onRateChange?: EventHandlerUnion<T, Event>;
    onReset?: EventHandlerUnion<T, Event>;
    onScroll?: EventHandlerUnion<T, Event>;
    onScrollEnd?: EventHandlerUnion<T, Event>;
    onSeeked?: EventHandlerUnion<T, Event>;
    onSeeking?: EventHandlerUnion<T, Event>;
    onSelect?: EventHandlerUnion<T, UIEvent>;
    onStalled?: EventHandlerUnion<T, Event>;
    onSubmit?: EventHandlerUnion<T, SubmitEvent>;
    onSuspend?: EventHandlerUnion<T, Event>;
    onTimeUpdate?: EventHandlerUnion<T, Event>;
    onToggle?: EventHandlerUnion<T, ToggleEvent>;
    onTouchCancel?: EventHandlerUnion<T, TouchEvent>;
    onTouchEnd?: EventHandlerUnion<T, TouchEvent>;
    onTouchMove?: EventHandlerUnion<T, TouchEvent>;
    onTouchStart?: EventHandlerUnion<T, TouchEvent>;
    onTransitionStart?: EventHandlerUnion<T, TransitionEvent>;
    onTransitionEnd?: EventHandlerUnion<T, TransitionEvent>;
    onTransitionRun?: EventHandlerUnion<T, TransitionEvent>;
    onTransitionCancel?: EventHandlerUnion<T, TransitionEvent>;
    onVolumeChange?: EventHandlerUnion<T, Event>;
    onWaiting?: EventHandlerUnion<T, Event>;
    onWheel?: EventHandlerUnion<T, WheelEvent>;
  }
  /** @type {GlobalEventHandlers} */
  interface CustomEventHandlersLowerCase<T> {
    onabort?: EventHandlerUnion<T, Event>;
    onanimationend?: EventHandlerUnion<T, AnimationEvent>;
    onanimationiteration?: EventHandlerUnion<T, AnimationEvent>;
    onanimationstart?: EventHandlerUnion<T, AnimationEvent>;
    onauxclick?: EventHandlerUnion<T, MouseEvent>;
    onbeforeinput?: EventHandlerUnion<T, InputEvent>;
    onbeforetoggle?: EventHandlerUnion<T, ToggleEvent>;
    onblur?: EventHandlerUnion<T, FocusEvent>;
    oncanplay?: EventHandlerUnion<T, Event>;
    oncanplaythrough?: EventHandlerUnion<T, Event>;
    onchange?: EventHandlerUnion<T, Event>;
    onclick?: EventHandlerUnion<T, MouseEvent>;
    oncontextmenu?: EventHandlerUnion<T, MouseEvent>;
    ondblclick?: EventHandlerUnion<T, MouseEvent>;
    ondrag?: EventHandlerUnion<T, DragEvent>;
    ondragend?: EventHandlerUnion<T, DragEvent>;
    ondragenter?: EventHandlerUnion<T, DragEvent>;
    ondragleave?: EventHandlerUnion<T, DragEvent>;
    ondragover?: EventHandlerUnion<T, DragEvent>;
    ondragstart?: EventHandlerUnion<T, DragEvent>;
    ondrop?: EventHandlerUnion<T, DragEvent>;
    ondurationchange?: EventHandlerUnion<T, Event>;
    onemptied?: EventHandlerUnion<T, Event>;
    onended?: EventHandlerUnion<T, Event>;
    onerror?: EventHandlerUnion<T, Event>;
    onfocus?: EventHandlerUnion<T, FocusEvent>;
    ongotpointercapture?: EventHandlerUnion<T, PointerEvent>;
    oninput?: EventHandlerUnion<T, InputEvent>;
    oninvalid?: EventHandlerUnion<T, Event>;
    onkeydown?: EventHandlerUnion<T, KeyboardEvent>;
    onkeypress?: EventHandlerUnion<T, KeyboardEvent>;
    onkeyup?: EventHandlerUnion<T, KeyboardEvent>;
    onload?: EventHandlerUnion<T, Event>;
    onloadeddata?: EventHandlerUnion<T, Event>;
    onloadedmetadata?: EventHandlerUnion<T, Event>;
    onloadstart?: EventHandlerUnion<T, Event>;
    onlostpointercapture?: EventHandlerUnion<T, PointerEvent>;
    onmousedown?: EventHandlerUnion<T, MouseEvent>;
    onmouseenter?: EventHandlerUnion<T, MouseEvent>;
    onmouseleave?: EventHandlerUnion<T, MouseEvent>;
    onmousemove?: EventHandlerUnion<T, MouseEvent>;
    onmouseout?: EventHandlerUnion<T, MouseEvent>;
    onmouseover?: EventHandlerUnion<T, MouseEvent>;
    onmouseup?: EventHandlerUnion<T, MouseEvent>;
    onpause?: EventHandlerUnion<T, Event>;
    onplay?: EventHandlerUnion<T, Event>;
    onplaying?: EventHandlerUnion<T, Event>;
    onpointercancel?: EventHandlerUnion<T, PointerEvent>;
    onpointerdown?: EventHandlerUnion<T, PointerEvent>;
    onpointerenter?: EventHandlerUnion<T, PointerEvent>;
    onpointerleave?: EventHandlerUnion<T, PointerEvent>;
    onpointermove?: EventHandlerUnion<T, PointerEvent>;
    onpointerout?: EventHandlerUnion<T, PointerEvent>;
    onpointerover?: EventHandlerUnion<T, PointerEvent>;
    onpointerup?: EventHandlerUnion<T, PointerEvent>;
    onprogress?: EventHandlerUnion<T, Event>;
    onratechange?: EventHandlerUnion<T, Event>;
    onreset?: EventHandlerUnion<T, Event>;
    onscroll?: EventHandlerUnion<T, Event>;
    onscrollend?: EventHandlerUnion<T, Event>;
    onseeked?: EventHandlerUnion<T, Event>;
    onseeking?: EventHandlerUnion<T, Event>;
    onselect?: EventHandlerUnion<T, UIEvent>;
    onstalled?: EventHandlerUnion<T, Event>;
    onsubmit?: EventHandlerUnion<T, SubmitEvent>;
    onsuspend?: EventHandlerUnion<T, Event>;
    ontimeupdate?: EventHandlerUnion<T, Event>;
    ontoggle?: EventHandlerUnion<T, ToggleEvent>;
    ontouchcancel?: EventHandlerUnion<T, TouchEvent>;
    ontouchend?: EventHandlerUnion<T, TouchEvent>;
    ontouchmove?: EventHandlerUnion<T, TouchEvent>;
    ontouchstart?: EventHandlerUnion<T, TouchEvent>;
    ontransitionstart?: EventHandlerUnion<T, TransitionEvent>;
    ontransitionend?: EventHandlerUnion<T, TransitionEvent>;
    ontransitionrun?: EventHandlerUnion<T, TransitionEvent>;
    ontransitioncancel?: EventHandlerUnion<T, TransitionEvent>;
    onvolumechange?: EventHandlerUnion<T, Event>;
    onwaiting?: EventHandlerUnion<T, Event>;
    onwheel?: EventHandlerUnion<T, WheelEvent>;
  }
  interface CustomEventHandlersNamespaced<T> {
    "on:abort"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:animationend"?: EventHandlerWithOptionsUnion<T, AnimationEvent>;
    "on:animationiteration"?: EventHandlerWithOptionsUnion<T, AnimationEvent>;
    "on:animationstart"?: EventHandlerWithOptionsUnion<T, AnimationEvent>;
    "on:auxclick"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:beforeinput"?: EventHandlerWithOptionsUnion<T, InputEvent>;
    "on:beforetoggle"?: EventHandlerWithOptionsUnion<T, ToggleEvent>;
    "on:blur"?: EventHandlerWithOptionsUnion<T, FocusEvent>;
    "on:canplay"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:canplaythrough"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:change"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:click"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:contextmenu"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:dblclick"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:drag"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:dragend"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:dragenter"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:dragleave"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:dragover"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:dragstart"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:drop"?: EventHandlerWithOptionsUnion<T, DragEvent>;
    "on:durationchange"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:emptied"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:ended"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:error"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:focus"?: EventHandlerWithOptionsUnion<T, FocusEvent>;
    "on:gotpointercapture"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:input"?: EventHandlerWithOptionsUnion<T, InputEvent>;
    "on:invalid"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:keydown"?: EventHandlerWithOptionsUnion<T, KeyboardEvent>;
    "on:keypress"?: EventHandlerWithOptionsUnion<T, KeyboardEvent>;
    "on:keyup"?: EventHandlerWithOptionsUnion<T, KeyboardEvent>;
    "on:load"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:loadeddata"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:loadedmetadata"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:loadstart"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:lostpointercapture"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:mousedown"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mouseenter"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mouseleave"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mousemove"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mouseout"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mouseover"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:mouseup"?: EventHandlerWithOptionsUnion<T, MouseEvent>;
    "on:pause"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:play"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:playing"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:pointercancel"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerdown"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerenter"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerleave"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointermove"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerout"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerover"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:pointerup"?: EventHandlerWithOptionsUnion<T, PointerEvent>;
    "on:progress"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:ratechange"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:reset"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:scroll"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:scrollend"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:seeked"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:seeking"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:select"?: EventHandlerWithOptionsUnion<T, UIEvent>;
    "on:stalled"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:submit"?: EventHandlerWithOptionsUnion<T, SubmitEvent>;
    "on:suspend"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:timeupdate"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:toggle"?: EventHandlerWithOptionsUnion<T, ToggleEvent>;
    "on:touchcancel"?: EventHandlerWithOptionsUnion<T, TouchEvent>;
    "on:touchend"?: EventHandlerWithOptionsUnion<T, TouchEvent>;
    "on:touchmove"?: EventHandlerWithOptionsUnion<T, TouchEvent>;
    "on:touchstart"?: EventHandlerWithOptionsUnion<T, TouchEvent>;
    "on:transitionstart"?: EventHandlerWithOptionsUnion<T, TransitionEvent>;
    "on:transitionend"?: EventHandlerWithOptionsUnion<T, TransitionEvent>;
    "on:transitionrun"?: EventHandlerWithOptionsUnion<T, TransitionEvent>;
    "on:transitioncancel"?: EventHandlerWithOptionsUnion<T, TransitionEvent>;
    "on:volumechange"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:waiting"?: EventHandlerWithOptionsUnion<T, Event>;
    "on:wheel"?: EventHandlerWithOptionsUnion<T, WheelEvent>;
  }

  interface CSSProperties extends csstype.PropertiesHyphen {
    // Override
    [key: \`-\${string}\`]: string | number | undefined;
  }

  type HTMLAutocapitalize = "off" | "none" | "on" | "sentences" | "words" | "characters";
  type HTMLDir = "ltr" | "rtl" | "auto";
  type HTMLFormEncType = "application/x-www-form-urlencoded" | "multipart/form-data" | "text/plain";
  type HTMLFormMethod = "post" | "get" | "dialog";
  type HTMLCrossorigin = "anonymous" | "use-credentials" | "";
  type HTMLReferrerPolicy =
    | "no-referrer"
    | "no-referrer-when-downgrade"
    | "origin"
    | "origin-when-cross-origin"
    | "same-origin"
    | "strict-origin"
    | "strict-origin-when-cross-origin"
    | "unsafe-url";
  type HTMLIframeSandbox =
    | "allow-downloads-without-user-activation"
    | "allow-downloads"
    | "allow-forms"
    | "allow-modals"
    | "allow-orientation-lock"
    | "allow-pointer-lock"
    | "allow-popups"
    | "allow-popups-to-escape-sandbox"
    | "allow-presentation"
    | "allow-same-origin"
    | "allow-scripts"
    | "allow-storage-access-by-user-activation"
    | "allow-top-navigation"
    | "allow-top-navigation-by-user-activation";
  type HTMLLinkAs =
    | "audio"
    | "document"
    | "embed"
    | "fetch"
    | "font"
    | "image"
    | "object"
    | "script"
    | "style"
    | "track"
    | "video"
    | "worker";

  // All the WAI-ARIA 1.1 attributes from https://www.w3.org/TR/wai-aria-1.1/
  interface AriaAttributes {
    /**
     * Identifies the currently active element when DOM focus is on a composite widget, textbox,
     * group, or application.
     */
    "aria-activedescendant"?: string;
    /**
     * Indicates whether assistive technologies will present all, or only parts of, the changed
     * region based on the change notifications defined by the aria-relevant attribute.
     */
    "aria-atomic"?: boolean | "false" | "true";
    /**
     * Indicates whether inputting text could trigger display of one or more predictions of the
     * user's intended value for an input and specifies how predictions would be presented if they
     * are made.
     */
    "aria-autocomplete"?: "none" | "inline" | "list" | "both";
    /**
     * Indicates an element is being modified and that assistive technologies MAY want to wait until
     * the modifications are complete before exposing them to the user.
     */
    "aria-busy"?: boolean | "false" | "true";
    /**
     * Indicates the current "checked" state of checkboxes, radio buttons, and other widgets.
     *
     * @see aria-pressed @see aria-selected.
     */
    "aria-checked"?: boolean | "false" | "mixed" | "true";
    /**
     * Defines the total number of columns in a table, grid, or treegrid.
     *
     * @see aria-colindex.
     */
    "aria-colcount"?: number | string;
    /**
     * Defines an element's column index or position with respect to the total number of columns
     * within a table, grid, or treegrid.
     *
     * @see aria-colcount @see aria-colspan.
     */
    "aria-colindex"?: number | string;
    /**
     * Defines the number of columns spanned by a cell or gridcell within a table, grid, or
     * treegrid.
     *
     * @see aria-colindex @see aria-rowspan.
     */
    "aria-colspan"?: number | string;
    /**
     * Identifies the element (or elements) whose contents or presence are controlled by the current
     * element.
     *
     * @see aria-owns.
     */
    "aria-controls"?: string;
    /**
     * Indicates the element that represents the current item within a container or set of related
     * elements.
     */
    "aria-current"?: boolean | "false" | "true" | "page" | "step" | "location" | "date" | "time";
    /**
     * Identifies the element (or elements) that describes the object.
     *
     * @see aria-labelledby
     */
    "aria-describedby"?: string;
    /**
     * Identifies the element that provides a detailed, extended description for the object.
     *
     * @see aria-describedby.
     */
    "aria-details"?: string;
    /**
     * Indicates that the element is perceivable but disabled, so it is not editable or otherwise
     * operable.
     *
     * @see aria-hidden @see aria-readonly.
     */
    "aria-disabled"?: boolean | "false" | "true";
    /**
     * Indicates what functions can be performed when a dragged object is released on the drop
     * target.
     *
     * @deprecated In ARIA 1.1
     */
    "aria-dropeffect"?: "none" | "copy" | "execute" | "link" | "move" | "popup";
    /**
     * Identifies the element that provides an error message for the object.
     *
     * @see aria-invalid @see aria-describedby.
     */
    "aria-errormessage"?: string;
    /**
     * Indicates whether the element, or another grouping element it controls, is currently expanded
     * or collapsed.
     */
    "aria-expanded"?: boolean | "false" | "true";
    /**
     * Identifies the next element (or elements) in an alternate reading order of content which, at
     * the user's discretion, allows assistive technology to override the general default of reading
     * in document source order.
     */
    "aria-flowto"?: string;
    /**
     * Indicates an element's "grabbed" state in a drag-and-drop operation.
     *
     * @deprecated In ARIA 1.1
     */
    "aria-grabbed"?: boolean | "false" | "true";
    /**
     * Indicates the availability and type of interactive popup element, such as menu or dialog,
     * that can be triggered by an element.
     */
    "aria-haspopup"?: boolean | "false" | "true" | "menu" | "listbox" | "tree" | "grid" | "dialog";
    /**
     * Indicates whether the element is exposed to an accessibility API.
     *
     * @see aria-disabled.
     */
    "aria-hidden"?: boolean | "false" | "true";
    /**
     * Indicates the entered value does not conform to the format expected by the application.
     *
     * @see aria-errormessage.
     */
    "aria-invalid"?: boolean | "false" | "true" | "grammar" | "spelling";
    /**
     * Indicates keyboard shortcuts that an author has implemented to activate or give focus to an
     * element.
     */
    "aria-keyshortcuts"?: string;
    /**
     * Defines a string value that labels the current element.
     *
     * @see aria-labelledby.
     */
    "aria-label"?: string;
    /**
     * Identifies the element (or elements) that labels the current element.
     *
     * @see aria-describedby.
     */
    "aria-labelledby"?: string;
    /** Defines the hierarchical level of an element within a structure. */
    "aria-level"?: number | string;
    /**
     * Indicates that an element will be updated, and describes the types of updates the user
     * agents, assistive technologies, and user can expect from the live region.
     */
    "aria-live"?: "off" | "assertive" | "polite";
    /** Indicates whether an element is modal when displayed. */
    "aria-modal"?: boolean | "false" | "true";
    /** Indicates whether a text box accepts multiple lines of input or only a single line. */
    "aria-multiline"?: boolean | "false" | "true";
    /**
     * Indicates that the user may select more than one item from the current selectable
     * descendants.
     */
    "aria-multiselectable"?: boolean | "false" | "true";
    /** Indicates whether the element's orientation is horizontal, vertical, or unknown/ambiguous. */
    "aria-orientation"?: "horizontal" | "vertical";
    /**
     * Identifies an element (or elements) in order to define a visual, functional, or contextual
     * parent/child relationship between DOM elements where the DOM hierarchy cannot be used to
     * represent the relationship.
     *
     * @see aria-controls.
     */
    "aria-owns"?: string;
    /**
     * Defines a short hint (a word or short phrase) intended to aid the user with data entry when
     * the control has no value. A hint could be a sample value or a brief description of the
     * expected format.
     */
    "aria-placeholder"?: string;
    /**
     * Defines an element's number or position in the current set of listitems or treeitems. Not
     * required if all elements in the set are present in the DOM.
     *
     * @see aria-setsize.
     */
    "aria-posinset"?: number | string;
    /**
     * Indicates the current "pressed" state of toggle buttons.
     *
     * @see aria-checked @see aria-selected.
     */
    "aria-pressed"?: boolean | "false" | "mixed" | "true";
    /**
     * Indicates that the element is not editable, but is otherwise operable.
     *
     * @see aria-disabled.
     */
    "aria-readonly"?: boolean | "false" | "true";
    /**
     * Indicates what notifications the user agent will trigger when the accessibility tree within a
     * live region is modified.
     *
     * @see aria-atomic.
     */
    "aria-relevant"?:
      | "additions"
      | "additions removals"
      | "additions text"
      | "all"
      | "removals"
      | "removals additions"
      | "removals text"
      | "text"
      | "text additions"
      | "text removals";
    /** Indicates that user input is required on the element before a form may be submitted. */
    "aria-required"?: boolean | "false" | "true";
    /** Defines a human-readable, author-localized description for the role of an element. */
    "aria-roledescription"?: string;
    /**
     * Defines the total number of rows in a table, grid, or treegrid.
     *
     * @see aria-rowindex.
     */
    "aria-rowcount"?: number | string;
    /**
     * Defines an element's row index or position with respect to the total number of rows within a
     * table, grid, or treegrid.
     *
     * @see aria-rowcount @see aria-rowspan.
     */
    "aria-rowindex"?: number | string;
    /**
     * Defines the number of rows spanned by a cell or gridcell within a table, grid, or treegrid.
     *
     * @see aria-rowindex @see aria-colspan.
     */
    "aria-rowspan"?: number | string;
    /**
     * Indicates the current "selected" state of various widgets.
     *
     * @see aria-checked @see aria-pressed.
     */
    "aria-selected"?: boolean | "false" | "true";
    /**
     * Defines the number of items in the current set of listitems or treeitems. Not required if all
     * elements in the set are present in the DOM.
     *
     * @see aria-posinset.
     */
    "aria-setsize"?: number | string;
    /** Indicates if items in a table or grid are sorted in ascending or descending order. */
    "aria-sort"?: "none" | "ascending" | "descending" | "other";
    /** Defines the maximum allowed value for a range widget. */
    "aria-valuemax"?: number | string;
    /** Defines the minimum allowed value for a range widget. */
    "aria-valuemin"?: number | string;
    /**
     * Defines the current value for a range widget.
     *
     * @see aria-valuetext.
     */
    "aria-valuenow"?: number | string;
    /** Defines the human readable text alternative of aria-valuenow for a range widget. */
    "aria-valuetext"?: string;
    role?: FunctionMaybe<
      | "alert"
      | "alertdialog"
      | "application"
      | "article"
      | "banner"
      | "button"
      | "cell"
      | "checkbox"
      | "columnheader"
      | "combobox"
      | "complementary"
      | "contentinfo"
      | "definition"
      | "dialog"
      | "directory"
      | "document"
      | "feed"
      | "figure"
      | "form"
      | "grid"
      | "gridcell"
      | "group"
      | "heading"
      | "img"
      | "link"
      | "list"
      | "listbox"
      | "listitem"
      | "log"
      | "main"
      | "marquee"
      | "math"
      | "menu"
      | "menubar"
      | "menuitem"
      | "menuitemcheckbox"
      | "menuitemradio"
      | "meter"
      | "navigation"
      | "none"
      | "note"
      | "option"
      | "presentation"
      | "progressbar"
      | "radio"
      | "radiogroup"
      | "region"
      | "row"
      | "rowgroup"
      | "rowheader"
      | "scrollbar"
      | "search"
      | "searchbox"
      | "separator"
      | "slider"
      | "spinbutton"
      | "status"
      | "switch"
      | "tab"
      | "table"
      | "tablist"
      | "tabpanel"
      | "term"
      | "textbox"
      | "timer"
      | "toolbar"
      | "tooltip"
      | "tree"
      | "treegrid"
      | "treeitem"
    >;
  }

  interface HTMLAttributes<T> extends AriaAttributes, DOMAttributes<T> {
    accessKey?: FunctionMaybe<string>;
    class?: FunctionMaybe<string> | undefined;
    contenteditable?: FunctionMaybe<boolean | "plaintext-only" | "inherit">;
    contextmenu?: FunctionMaybe<string>;
    dir?: FunctionMaybe<HTMLDir>;
    draggable?: FunctionMaybe<boolean>;
    hidden?: FunctionMaybe<boolean>;
    id?: FunctionMaybe<string>;
    lang?: FunctionMaybe<string>;
    spellcheck?: FunctionMaybe<boolean>;
    style?: FunctionMaybe<CSSProperties | string>;
    tabindex?: FunctionMaybe<number | string>;
    title?: FunctionMaybe<string>;
    translate?: FunctionMaybe<"yes" | "no">;
    about?: FunctionMaybe<string>;
    datatype?: FunctionMaybe<string>;
    inlist?: FunctionMaybe<any>;
    popover?: FunctionMaybe<boolean | "manual" | "auto">;
    prefix?: FunctionMaybe<string>;
    property?: FunctionMaybe<string>;
    resource?: FunctionMaybe<string>;
    typeof?: FunctionMaybe<string>;
    vocab?: FunctionMaybe<string>;
    autocapitalize?: FunctionMaybe<HTMLAutocapitalize>;
    slot?: FunctionMaybe<string>;
    color?: FunctionMaybe<string>;
    itemprop?: FunctionMaybe<string>;
    itemscope?: FunctionMaybe<boolean>;
    itemtype?: FunctionMaybe<string>;
    itemid?: FunctionMaybe<string>;
    itemref?: FunctionMaybe<string>;
    part?: FunctionMaybe<string>;
    exportparts?: FunctionMaybe<string>;
    inputmode?: FunctionMaybe<
      "none" | "text" | "tel" | "url" | "email" | "numeric" | "decimal" | "search"
    >;
    contentEditable?: FunctionMaybe<boolean | "plaintext-only" | "inherit">;
    contextMenu?: FunctionMaybe<string>;
    tabIndex?: FunctionMaybe<number | string>;
    autoCapitalize?: FunctionMaybe<HTMLAutocapitalize>;
    itemProp?: FunctionMaybe<string>;
    itemScope?: FunctionMaybe<boolean>;
    itemType?: FunctionMaybe<string>;
    itemId?: FunctionMaybe<string>;
    itemRef?: FunctionMaybe<string>;
    exportParts?: FunctionMaybe<string>;
    inputMode?: FunctionMaybe<
      "none" | "text" | "tel" | "url" | "email" | "numeric" | "decimal" | "search"
    >;
  }
  interface AnchorHTMLAttributes<T> extends HTMLAttributes<T> {
    download?: FunctionMaybe<any>;
    href?: FunctionMaybe<string>;
    hreflang?: FunctionMaybe<string>;
    media?: FunctionMaybe<string>;
    ping?: FunctionMaybe<string>;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    rel?: FunctionMaybe<string>;
    target?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
  }
  interface AudioHTMLAttributes<T> extends MediaHTMLAttributes<T> {}
  interface AreaHTMLAttributes<T> extends HTMLAttributes<T> {
    alt?: FunctionMaybe<string>;
    coords?: FunctionMaybe<string>;
    download?: FunctionMaybe<any>;
    href?: FunctionMaybe<string>;
    hreflang?: FunctionMaybe<string>;
    ping?: FunctionMaybe<string>;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    rel?: FunctionMaybe<string>;
    shape?: FunctionMaybe<"rect" | "circle" | "poly" | "default">;
    target?: FunctionMaybe<string>;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
  }
  interface BaseHTMLAttributes<T> extends HTMLAttributes<T> {
    href?: FunctionMaybe<string>;
    target?: FunctionMaybe<string>;
  }
  interface BlockquoteHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: FunctionMaybe<string>;
  }
  interface ButtonHTMLAttributes<T> extends HTMLAttributes<T> {
    autofocus?: FunctionMaybe<boolean>;
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    formaction?: FunctionMaybe<string | SerializableAttributeValue>;
    formenctype?: FunctionMaybe<HTMLFormEncType>;
    formmethod?: FunctionMaybe<HTMLFormMethod>;
    formnovalidate?: FunctionMaybe<boolean>;
    formtarget?: FunctionMaybe<string>;
    popovertarget?: FunctionMaybe<string>;
    popovertargetaction?: FunctionMaybe<"hide" | "show" | "toggle">;
    name?: FunctionMaybe<string>;
    type?: FunctionMaybe<"submit" | "reset" | "button">;
    value?: FunctionMaybe<string>;
    formAction?: FunctionMaybe<string | SerializableAttributeValue>;
    formEnctype?: FunctionMaybe<HTMLFormEncType>;
    formMethod?: FunctionMaybe<HTMLFormMethod>;
    formNoValidate?: FunctionMaybe<boolean>;
    formTarget?: FunctionMaybe<string>;
    popoverTarget?: FunctionMaybe<string>;
    popoverTargetAction?: FunctionMaybe<"hide" | "show" | "toggle">;
  }
  interface CanvasHTMLAttributes<T> extends HTMLAttributes<T> {
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
  }
  interface ColHTMLAttributes<T> extends HTMLAttributes<T> {
    span?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
  }
  interface ColgroupHTMLAttributes<T> extends HTMLAttributes<T> {
    span?: FunctionMaybe<number | string>;
  }
  interface DataHTMLAttributes<T> extends HTMLAttributes<T> {
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface DetailsHtmlAttributes<T> extends HTMLAttributes<T> {
    open?: FunctionMaybe<boolean>;
    onToggle?: EventHandlerUnion<T, Event>;
    ontoggle?: EventHandlerUnion<T, Event>;
  }
  interface DialogHtmlAttributes<T> extends HTMLAttributes<T> {
    open?: FunctionMaybe<boolean>;
  }
  interface EmbedHTMLAttributes<T> extends HTMLAttributes<T> {
    height?: FunctionMaybe<number | string>;
    src?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
  }
  interface FieldsetHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    name?: FunctionMaybe<string>;
  }
  interface FormHTMLAttributes<T> extends HTMLAttributes<T> {
    "accept-charset"?: FunctionMaybe<string>;
    action?: FunctionMaybe<string | SerializableAttributeValue>;
    autocomplete?: FunctionMaybe<string>;
    encoding?: FunctionMaybe<HTMLFormEncType>;
    enctype?: FunctionMaybe<HTMLFormEncType>;
    method?: FunctionMaybe<HTMLFormMethod>;
    name?: FunctionMaybe<string>;
    novalidate?: FunctionMaybe<boolean>;
    target?: FunctionMaybe<string>;
    noValidate?: FunctionMaybe<boolean>;
  }
  interface IframeHTMLAttributes<T> extends HTMLAttributes<T> {
    allow?: FunctionMaybe<string>;
    allowfullscreen?: FunctionMaybe<boolean>;
    height?: FunctionMaybe<number | string>;
    name?: FunctionMaybe<string>;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    sandbox?: HTMLIframeSandbox | string;
    src?: FunctionMaybe<string>;
    srcdoc?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
    loading?: FunctionMaybe<"eager" | "lazy">;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
  }
  interface ImgHTMLAttributes<T> extends HTMLAttributes<T> {
    alt?: FunctionMaybe<string>;
    crossorigin?: FunctionMaybe<HTMLCrossorigin>;
    decoding?: FunctionMaybe<"sync" | "async" | "auto">;
    height?: FunctionMaybe<number | string>;
    ismap?: FunctionMaybe<boolean>;
    isMap?: FunctionMaybe<boolean>;
    loading?: FunctionMaybe<"eager" | "lazy">;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    sizes?: FunctionMaybe<string>;
    src?: FunctionMaybe<string>;
    srcset?: FunctionMaybe<string>;
    srcSet?: FunctionMaybe<string>;
    usemap?: FunctionMaybe<string>;
    useMap?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
    crossOrigin?: FunctionMaybe<HTMLCrossorigin>;
  }
  interface InputHTMLAttributes<T> extends HTMLAttributes<T> {
    accept?: FunctionMaybe<string>;
    alt?: FunctionMaybe<string>;
    autocomplete?: FunctionMaybe<string>;
    autofocus?: FunctionMaybe<boolean>;
    capture?: FunctionMaybe<boolean | string>;
    checked?: FunctionMaybe<boolean>;
    crossorigin?: FunctionMaybe<HTMLCrossorigin>;
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    formaction?: FunctionMaybe<string | SerializableAttributeValue>;
    formenctype?: FunctionMaybe<HTMLFormEncType>;
    formmethod?: FunctionMaybe<HTMLFormMethod>;
    formnovalidate?: FunctionMaybe<boolean>;
    formtarget?: FunctionMaybe<string>;
    height?: FunctionMaybe<number | string>;
    list?: FunctionMaybe<string>;
    max?: FunctionMaybe<number | string>;
    maxlength?: FunctionMaybe<number | string>;
    min?: FunctionMaybe<number | string>;
    minlength?: FunctionMaybe<number | string>;
    multiple?: FunctionMaybe<boolean>;
    name?: FunctionMaybe<string>;
    pattern?: FunctionMaybe<string>;
    placeholder?: FunctionMaybe<string>;
    readonly?: FunctionMaybe<boolean>;
    required?: FunctionMaybe<boolean>;
    size?: FunctionMaybe<number | string>;
    src?: FunctionMaybe<string>;
    step?: FunctionMaybe<number | string>;
    type?: FunctionMaybe<string>;
    value?: FunctionMaybe<string | string[] | number>;
    width?: FunctionMaybe<number | string>;
    crossOrigin?: FunctionMaybe<HTMLCrossorigin>;
    formAction?: FunctionMaybe<string | SerializableAttributeValue>;
    formEnctype?: FunctionMaybe<HTMLFormEncType>;
    formMethod?: FunctionMaybe<HTMLFormMethod>;
    formNoValidate?: FunctionMaybe<boolean>;
    formTarget?: FunctionMaybe<string>;
    maxLength?: FunctionMaybe<number | string>;
    minLength?: FunctionMaybe<number | string>;
    readOnly?: FunctionMaybe<boolean>;
  }
  interface InsHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: FunctionMaybe<string>;
    dateTime?: FunctionMaybe<string>;
  }
  interface KeygenHTMLAttributes<T> extends HTMLAttributes<T> {
    autofocus?: FunctionMaybe<boolean>;
    challenge?: FunctionMaybe<string>;
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    keytype?: FunctionMaybe<string>;
    keyparams?: FunctionMaybe<string>;
    name?: FunctionMaybe<string>;
  }
  interface LabelHTMLAttributes<T> extends HTMLAttributes<T> {
    for?: FunctionMaybe<string>;
    form?: FunctionMaybe<string>;
  }
  interface LiHTMLAttributes<T> extends HTMLAttributes<T> {
    value?: FunctionMaybe<number | string>;
  }
  interface LinkHTMLAttributes<T> extends HTMLAttributes<T> {
    as?: FunctionMaybe<HTMLLinkAs>;
    crossorigin?: FunctionMaybe<HTMLCrossorigin>;
    disabled?: FunctionMaybe<boolean>;
    fetchpriority?: FunctionMaybe<"high" | "low" | "auto">;
    href?: FunctionMaybe<string>;
    hreflang?: FunctionMaybe<string>;
    imagesizes?: FunctionMaybe<string>;
    imagesrcset?: FunctionMaybe<string>;
    integrity?: FunctionMaybe<string>;
    media?: FunctionMaybe<string>;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    rel?: FunctionMaybe<string>;
    sizes?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    crossOrigin?: FunctionMaybe<HTMLCrossorigin>;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
  }
  interface MapHTMLAttributes<T> extends HTMLAttributes<T> {
    name?: FunctionMaybe<string>;
  }
  interface MediaHTMLAttributes<T> extends HTMLAttributes<T> {
    autoplay?: FunctionMaybe<boolean>;
    controls?: FunctionMaybe<boolean>;
    crossorigin?: FunctionMaybe<HTMLCrossorigin>;
    loop?: FunctionMaybe<boolean>;
    mediagroup?: FunctionMaybe<string>;
    muted?: FunctionMaybe<boolean>;
    preload?: FunctionMaybe<"none" | "metadata" | "auto" | "">;
    src?: FunctionMaybe<string>;
    crossOrigin?: FunctionMaybe<HTMLCrossorigin>;
    mediaGroup?: FunctionMaybe<string>;
  }
  interface MenuHTMLAttributes<T> extends HTMLAttributes<T> {
    label?: FunctionMaybe<string>;
    type?: FunctionMaybe<"context" | "toolbar">;
  }
  interface MetaHTMLAttributes<T> extends HTMLAttributes<T> {
    charset?: FunctionMaybe<string>;
    content?: FunctionMaybe<string>;
    "http-equiv"?: FunctionMaybe<string>;
    name?: FunctionMaybe<string>;
    media?: FunctionMaybe<string>;
  }
  interface MeterHTMLAttributes<T> extends HTMLAttributes<T> {
    form?: FunctionMaybe<string>;
    high?: FunctionMaybe<number | string>;
    low?: FunctionMaybe<number | string>;
    max?: FunctionMaybe<number | string>;
    min?: FunctionMaybe<number | string>;
    optimum?: FunctionMaybe<number | string>;
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface QuoteHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: FunctionMaybe<string>;
  }
  interface ObjectHTMLAttributes<T> extends HTMLAttributes<T> {
    data?: FunctionMaybe<string>;
    form?: FunctionMaybe<string>;
    height?: FunctionMaybe<number | string>;
    name?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    usemap?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
    useMap?: FunctionMaybe<string>;
  }
  interface OlHTMLAttributes<T> extends HTMLAttributes<T> {
    reversed?: FunctionMaybe<boolean>;
    start?: FunctionMaybe<number | string>;
    type?: FunctionMaybe<"1" | "a" | "A" | "i" | "I">;
  }
  interface OptgroupHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: FunctionMaybe<boolean>;
    label?: FunctionMaybe<string>;
  }
  interface OptionHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: FunctionMaybe<boolean>;
    label?: FunctionMaybe<string>;
    selected?: FunctionMaybe<boolean>;
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface OutputHTMLAttributes<T> extends HTMLAttributes<T> {
    form?: FunctionMaybe<string>;
    for?: FunctionMaybe<string>;
    name?: FunctionMaybe<string>;
  }
  interface ParamHTMLAttributes<T> extends HTMLAttributes<T> {
    name?: FunctionMaybe<string>;
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface ProgressHTMLAttributes<T> extends HTMLAttributes<T> {
    max?: FunctionMaybe<number | string>;
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface ScriptHTMLAttributes<T> extends HTMLAttributes<T> {
    async?: FunctionMaybe<boolean>;
    charset?: FunctionMaybe<string>;
    crossorigin?: FunctionMaybe<HTMLCrossorigin>;
    defer?: FunctionMaybe<boolean>;
    integrity?: FunctionMaybe<string>;
    nomodule?: FunctionMaybe<boolean>;
    nonce?: FunctionMaybe<string>;
    referrerpolicy?: FunctionMaybe<HTMLReferrerPolicy>;
    src?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    crossOrigin?: FunctionMaybe<HTMLCrossorigin>;
    noModule?: FunctionMaybe<boolean>;
    referrerPolicy?: FunctionMaybe<HTMLReferrerPolicy>;
  }
  interface SelectHTMLAttributes<T> extends HTMLAttributes<T> {
    autocomplete?: FunctionMaybe<string>;
    autofocus?: FunctionMaybe<boolean>;
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    multiple?: FunctionMaybe<boolean>;
    name?: FunctionMaybe<string>;
    required?: FunctionMaybe<boolean>;
    size?: FunctionMaybe<number | string>;
    value?: FunctionMaybe<string | string[] | number>;
  }
  interface HTMLSlotElementAttributes<T = HTMLSlotElement> extends HTMLAttributes<T> {
    name?: FunctionMaybe<string>;
  }
  interface SourceHTMLAttributes<T> extends HTMLAttributes<T> {
    media?: FunctionMaybe<string>;
    sizes?: FunctionMaybe<string>;
    src?: FunctionMaybe<string>;
    srcset?: FunctionMaybe<string>;
    type?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
  }
  interface StyleHTMLAttributes<T> extends HTMLAttributes<T> {
    media?: FunctionMaybe<string>;
    nonce?: FunctionMaybe<string>;
    scoped?: FunctionMaybe<boolean>;
    type?: FunctionMaybe<string>;
  }
  interface TdHTMLAttributes<T> extends HTMLAttributes<T> {
    colspan?: FunctionMaybe<number | string>;
    headers?: FunctionMaybe<string>;
    rowspan?: FunctionMaybe<number | string>;
    colSpan?: FunctionMaybe<number | string>;
    rowSpan?: FunctionMaybe<number | string>;
  }
  interface TemplateHTMLAttributes<T extends HTMLTemplateElement> extends HTMLAttributes<T> {
    content?: FunctionMaybe<DocumentFragment>;
  }
  interface TextareaHTMLAttributes<T> extends HTMLAttributes<T> {
    autocomplete?: FunctionMaybe<string>;
    autofocus?: FunctionMaybe<boolean>;
    cols?: FunctionMaybe<number | string>;
    dirname?: FunctionMaybe<string>;
    disabled?: FunctionMaybe<boolean>;
    form?: FunctionMaybe<string>;
    maxlength?: FunctionMaybe<number | string>;
    minlength?: FunctionMaybe<number | string>;
    name?: FunctionMaybe<string>;
    placeholder?: FunctionMaybe<string>;
    readonly?: FunctionMaybe<boolean>;
    required?: FunctionMaybe<boolean>;
    rows?: FunctionMaybe<number | string>;
    value?: FunctionMaybe<string | string[] | number>;
    wrap?: FunctionMaybe<"hard" | "soft" | "off">;
    maxLength?: FunctionMaybe<number | string>;
    minLength?: FunctionMaybe<number | string>;
    readOnly?: FunctionMaybe<boolean>;
  }
  interface ThHTMLAttributes<T> extends HTMLAttributes<T> {
    colspan?: FunctionMaybe<number | string>;
    headers?: FunctionMaybe<string>;
    rowspan?: FunctionMaybe<number | string>;
    colSpan?: FunctionMaybe<number | string>;
    rowSpan?: FunctionMaybe<number | string>;
    scope?: FunctionMaybe<"col" | "row" | "rowgroup" | "colgroup">;
  }
  interface TimeHTMLAttributes<T> extends HTMLAttributes<T> {
    datetime?: FunctionMaybe<string>;
    dateTime?: FunctionMaybe<string>;
  }
  interface TrackHTMLAttributes<T> extends HTMLAttributes<T> {
    default?: FunctionMaybe<boolean>;
    kind?: FunctionMaybe<"subtitles" | "captions" | "descriptions" | "chapters" | "metadata">;
    label?: FunctionMaybe<string>;
    src?: FunctionMaybe<string>;
    srclang?: FunctionMaybe<string>;
  }
  interface VideoHTMLAttributes<T> extends MediaHTMLAttributes<T> {
    height?: FunctionMaybe<number | string>;
    playsinline?: FunctionMaybe<boolean>;
    poster?: FunctionMaybe<string>;
    width?: FunctionMaybe<number | string>;
    disablepictureinpicture?: FunctionMaybe<boolean>;
  }
  type SVGPreserveAspectRatio =
    | "none"
    | "xMinYMin"
    | "xMidYMin"
    | "xMaxYMin"
    | "xMinYMid"
    | "xMidYMid"
    | "xMaxYMid"
    | "xMinYMax"
    | "xMidYMax"
    | "xMaxYMax"
    | "xMinYMin meet"
    | "xMidYMin meet"
    | "xMaxYMin meet"
    | "xMinYMid meet"
    | "xMidYMid meet"
    | "xMaxYMid meet"
    | "xMinYMax meet"
    | "xMidYMax meet"
    | "xMaxYMax meet"
    | "xMinYMin slice"
    | "xMidYMin slice"
    | "xMaxYMin slice"
    | "xMinYMid slice"
    | "xMidYMid slice"
    | "xMaxYMid slice"
    | "xMinYMax slice"
    | "xMidYMax slice"
    | "xMaxYMax slice";
  type ImagePreserveAspectRatio =
    | SVGPreserveAspectRatio
    | "defer none"
    | "defer xMinYMin"
    | "defer xMidYMin"
    | "defer xMaxYMin"
    | "defer xMinYMid"
    | "defer xMidYMid"
    | "defer xMaxYMid"
    | "defer xMinYMax"
    | "defer xMidYMax"
    | "defer xMaxYMax"
    | "defer xMinYMin meet"
    | "defer xMidYMin meet"
    | "defer xMaxYMin meet"
    | "defer xMinYMid meet"
    | "defer xMidYMid meet"
    | "defer xMaxYMid meet"
    | "defer xMinYMax meet"
    | "defer xMidYMax meet"
    | "defer xMaxYMax meet"
    | "defer xMinYMin slice"
    | "defer xMidYMin slice"
    | "defer xMaxYMin slice"
    | "defer xMinYMid slice"
    | "defer xMidYMid slice"
    | "defer xMaxYMid slice"
    | "defer xMinYMax slice"
    | "defer xMidYMax slice"
    | "defer xMaxYMax slice";
  type SVGUnits = "userSpaceOnUse" | "objectBoundingBox";
  interface CoreSVGAttributes<T> extends AriaAttributes, DOMAttributes<T> {
    id?: FunctionMaybe<string>;
    lang?: FunctionMaybe<string>;
    tabIndex?: FunctionMaybe<number | string>;
    tabindex?: FunctionMaybe<number | string>;
  }
  interface StylableSVGAttributes {
    class?: FunctionMaybe<string> | undefined;
    style?: FunctionMaybe<CSSProperties | string>;
  }
  interface TransformableSVGAttributes {
    transform?: FunctionMaybe<string>;
  }
  interface ConditionalProcessingSVGAttributes {
    requiredExtensions?: FunctionMaybe<string>;
    requiredFeatures?: FunctionMaybe<string>;
    systemLanguage?: FunctionMaybe<string>;
  }
  interface ExternalResourceSVGAttributes {
    externalResourcesRequired?: FunctionMaybe<"true" | "false">;
  }
  interface AnimationTimingSVGAttributes {
    begin?: FunctionMaybe<string>;
    dur?: FunctionMaybe<string>;
    end?: FunctionMaybe<string>;
    min?: FunctionMaybe<string>;
    max?: FunctionMaybe<string>;
    restart?: FunctionMaybe<"always" | "whenNotActive" | "never">;
    repeatCount?: FunctionMaybe<number | "indefinite">;
    repeatDur?: FunctionMaybe<string>;
    fill?: FunctionMaybe<"freeze" | "remove">;
  }
  interface AnimationValueSVGAttributes {
    calcMode?: FunctionMaybe<"discrete" | "linear" | "paced" | "spline">;
    values?: FunctionMaybe<string>;
    keyTimes?: FunctionMaybe<string>;
    keySplines?: FunctionMaybe<string>;
    from?: FunctionMaybe<number | string>;
    to?: FunctionMaybe<number | string>;
    by?: FunctionMaybe<number | string>;
  }
  interface AnimationAdditionSVGAttributes {
    attributeName?: FunctionMaybe<string>;
    additive?: FunctionMaybe<"replace" | "sum">;
    accumulate?: FunctionMaybe<"none" | "sum">;
  }
  interface AnimationAttributeTargetSVGAttributes {
    attributeName?: FunctionMaybe<string>;
    attributeType?: FunctionMaybe<"CSS" | "XML" | "auto">;
  }
  interface PresentationSVGAttributes {
    "alignment-baseline"?:
      | "auto"
      | "baseline"
      | "before-edge"
      | "text-before-edge"
      | "middle"
      | "central"
      | "after-edge"
      | "text-after-edge"
      | "ideographic"
      | "alphabetic"
      | "hanging"
      | "mathematical"
      | "inherit";
    "baseline-shift"?: FunctionMaybe<number | string>;
    clip?: FunctionMaybe<string>;
    "clip-path"?: FunctionMaybe<string>;
    "clip-rule"?: "nonzero" | "evenodd" | "inherit";
    color?: FunctionMaybe<string>;
    "color-interpolation"?: "auto" | "sRGB" | "linearRGB" | "inherit";
    "color-interpolation-filters"?: "auto" | "sRGB" | "linearRGB" | "inherit";
    "color-profile"?: FunctionMaybe<string>;
    "color-rendering"?: "auto" | "optimizeSpeed" | "optimizeQuality" | "inherit";
    cursor?: FunctionMaybe<string>;
    direction?: "ltr" | "rtl" | "inherit";
    display?: FunctionMaybe<string>;
    "dominant-baseline"?:
      | "auto"
      | "text-bottom"
      | "alphabetic"
      | "ideographic"
      | "middle"
      | "central"
      | "mathematical"
      | "hanging"
      | "text-top"
      | "inherit";
    "enable-background"?: FunctionMaybe<string>;
    fill?: FunctionMaybe<string>;
    "fill-opacity"?: FunctionMaybe<number | string | "inherit">;
    "fill-rule"?: FunctionMaybe<"nonzero" | "evenodd" | "inherit">;
    filter?: FunctionMaybe<string>;
    "flood-color"?: FunctionMaybe<string>;
    "flood-opacity"?: FunctionMaybe<number | string | "inherit">;
    "font-family"?: FunctionMaybe<string>;
    "font-size"?: FunctionMaybe<string>;
    "font-size-adjust"?: FunctionMaybe<number | string>;
    "font-stretch"?: FunctionMaybe<string>;
    "font-style"?: FunctionMaybe<"normal" | "italic" | "oblique" | "inherit">;
    "font-variant"?: FunctionMaybe<string>;
    "font-weight"?: FunctionMaybe<number | string>;
    "glyph-orientation-horizontal"?: FunctionMaybe<string>;
    "glyph-orientation-vertical"?: FunctionMaybe<string>;
    "image-rendering"?: FunctionMaybe<"auto" | "optimizeQuality" | "optimizeSpeed" | "inherit">;
    kerning?: FunctionMaybe<string>;
    "letter-spacing"?: FunctionMaybe<number | string>;
    "lighting-color"?: FunctionMaybe<string>;
    "marker-end"?: FunctionMaybe<string>;
    "marker-mid"?: FunctionMaybe<string>;
    "marker-start"?: FunctionMaybe<string>;
    mask?: FunctionMaybe<string>;
    opacity?: FunctionMaybe<number | string | "inherit">;
    overflow?: FunctionMaybe<"visible" | "hidden" | "scroll" | "auto" | "inherit">;
    pathLength?: FunctionMaybe<string | number>;
    "pointer-events"?: FunctionMaybe<
      | "bounding-box"
      | "visiblePainted"
      | "visibleFill"
      | "visibleStroke"
      | "visible"
      | "painted"
      | "color"
      | "fill"
      | "stroke"
      | "all"
      | "none"
      | "inherit"
    >;
    "shape-rendering"?: FunctionMaybe<
      "auto" | "optimizeSpeed" | "crispEdges" | "geometricPrecision" | "inherit"
    >;
    "stop-color"?: FunctionMaybe<string>;
    "stop-opacity"?: FunctionMaybe<number | string | "inherit">;
    stroke?: FunctionMaybe<string>;
    "stroke-dasharray"?: FunctionMaybe<string>;
    "stroke-dashoffset"?: FunctionMaybe<number | string>;
    "stroke-linecap"?: FunctionMaybe<"butt" | "round" | "square" | "inherit">;
    "stroke-linejoin"?: FunctionMaybe<
      "arcs" | "bevel" | "miter" | "miter-clip" | "round" | "inherit"
    >;
    "stroke-miterlimit"?: FunctionMaybe<number | string | "inherit">;
    "stroke-opacity"?: FunctionMaybe<number | string | "inherit">;
    "stroke-width"?: FunctionMaybe<number | string>;
    "text-anchor"?: FunctionMaybe<"start" | "middle" | "end" | "inherit">;
    "text-decoration"?: FunctionMaybe<
      "none" | "underline" | "overline" | "line-through" | "blink" | "inherit"
    >;
    "text-rendering"?: FunctionMaybe<
      "auto" | "optimizeSpeed" | "optimizeLegibility" | "geometricPrecision" | "inherit"
    >;
    "unicode-bidi"?: FunctionMaybe<string>;
    visibility?: FunctionMaybe<"visible" | "hidden" | "collapse" | "inherit">;
    "word-spacing"?: FunctionMaybe<number | string>;
    "writing-mode"?: FunctionMaybe<"lr-tb" | "rl-tb" | "tb-rl" | "lr" | "rl" | "tb" | "inherit">;
  }
  interface AnimationElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      ConditionalProcessingSVGAttributes {}
  interface ContainerElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "clip-path"
        | "mask"
        | "cursor"
        | "opacity"
        | "filter"
        | "enable-background"
        | "color-interpolation"
        | "color-rendering"
      > {}
  interface FilterPrimitiveElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<PresentationSVGAttributes, "color-interpolation-filters"> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    result?: FunctionMaybe<string>;
  }
  interface SingleInputFilterSVGAttributes {
    in?: FunctionMaybe<string>;
  }
  interface DoubleInputFilterSVGAttributes {
    in?: FunctionMaybe<string>;
    in2?: FunctionMaybe<string>;
  }
  interface FitToViewBoxSVGAttributes {
    viewBox?: FunctionMaybe<string>;
    preserveAspectRatio?: FunctionMaybe<SVGPreserveAspectRatio>;
  }
  interface GradientElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    gradientUnits?: FunctionMaybe<SVGUnits>;
    gradientTransform?: FunctionMaybe<string>;
    spreadMethod?: FunctionMaybe<"pad" | "reflect" | "repeat">;
    href?: FunctionMaybe<string>;
  }
  interface GraphicsElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "clip-rule"
        | "mask"
        | "pointer-events"
        | "cursor"
        | "opacity"
        | "filter"
        | "display"
        | "visibility"
        | "color-interpolation"
        | "color-rendering"
      > {}
  interface LightSourceElementSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface NewViewportSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    viewBox?: FunctionMaybe<string>;
  }
  interface ShapeElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "color"
        | "fill"
        | "fill-rule"
        | "fill-opacity"
        | "stroke"
        | "stroke-width"
        | "stroke-linecap"
        | "stroke-linejoin"
        | "stroke-miterlimit"
        | "stroke-dasharray"
        | "stroke-dashoffset"
        | "stroke-opacity"
        | "shape-rendering"
        | "pathLength"
      > {}
  interface TextContentElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "font-family"
        | "font-style"
        | "font-variant"
        | "font-weight"
        | "font-stretch"
        | "font-size"
        | "font-size-adjust"
        | "kerning"
        | "letter-spacing"
        | "word-spacing"
        | "text-decoration"
        | "glyph-orientation-horizontal"
        | "glyph-orientation-vertical"
        | "direction"
        | "unicode-bidi"
        | "text-anchor"
        | "dominant-baseline"
        | "color"
        | "fill"
        | "fill-rule"
        | "fill-opacity"
        | "stroke"
        | "stroke-width"
        | "stroke-linecap"
        | "stroke-linejoin"
        | "stroke-miterlimit"
        | "stroke-dasharray"
        | "stroke-dashoffset"
        | "stroke-opacity"
      > {}
  interface ZoomAndPanSVGAttributes {
    zoomAndPan?: FunctionMaybe<"disable" | "magnify">;
  }
  interface AnimateSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationAttributeTargetSVGAttributes,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes,
      Pick<PresentationSVGAttributes, "color-interpolation" | "color-rendering"> {}
  interface AnimateMotionSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes {
    path?: FunctionMaybe<string>;
    keyPoints?: FunctionMaybe<string>;
    rotate?: FunctionMaybe<number | string | "auto" | "auto-reverse">;
    origin?: FunctionMaybe<"default">;
  }
  interface AnimateTransformSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationAttributeTargetSVGAttributes,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes {
    type?: FunctionMaybe<"translate" | "scale" | "rotate" | "skewX" | "skewY">;
  }
  interface CircleSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    cx?: FunctionMaybe<number | string>;
    cy?: FunctionMaybe<number | string>;
    r?: FunctionMaybe<number | string>;
  }
  interface ClipPathSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "clip-path"> {
    clipPathUnits?: FunctionMaybe<SVGUnits>;
  }
  interface DefsSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {}
  interface DescSVGAttributes<T> extends CoreSVGAttributes<T>, StylableSVGAttributes {}
  interface EllipseSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    cx?: FunctionMaybe<number | string>;
    cy?: FunctionMaybe<number | string>;
    rx?: FunctionMaybe<number | string>;
    ry?: FunctionMaybe<number | string>;
  }
  interface FeBlendSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    mode?: FunctionMaybe<"normal" | "multiply" | "screen" | "darken" | "lighten">;
  }
  interface FeColorMatrixSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    type?: FunctionMaybe<"matrix" | "saturate" | "hueRotate" | "luminanceToAlpha">;
    values?: FunctionMaybe<string>;
  }
  interface FeComponentTransferSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {}
  interface FeCompositeSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    operator?: FunctionMaybe<"over" | "in" | "out" | "atop" | "xor" | "arithmetic">;
    k1?: FunctionMaybe<number | string>;
    k2?: FunctionMaybe<number | string>;
    k3?: FunctionMaybe<number | string>;
    k4?: FunctionMaybe<number | string>;
  }
  interface FeConvolveMatrixSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    order?: FunctionMaybe<number | string>;
    kernelMatrix?: FunctionMaybe<string>;
    divisor?: FunctionMaybe<number | string>;
    bias?: FunctionMaybe<number | string>;
    targetX?: FunctionMaybe<number | string>;
    targetY?: FunctionMaybe<number | string>;
    edgeMode?: FunctionMaybe<"duplicate" | "wrap" | "none">;
    kernelUnitLength?: FunctionMaybe<number | string>;
    preserveAlpha?: FunctionMaybe<"true" | "false">;
  }
  interface FeDiffuseLightingSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "lighting-color"> {
    surfaceScale?: FunctionMaybe<number | string>;
    diffuseConstant?: FunctionMaybe<number | string>;
    kernelUnitLength?: FunctionMaybe<number | string>;
  }
  interface FeDisplacementMapSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    scale?: FunctionMaybe<number | string>;
    xChannelSelector?: FunctionMaybe<"R" | "G" | "B" | "A">;
    yChannelSelector?: FunctionMaybe<"R" | "G" | "B" | "A">;
  }
  interface FeDistantLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    azimuth?: FunctionMaybe<number | string>;
    elevation?: FunctionMaybe<number | string>;
  }
  interface FeDropShadowSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "flood-color" | "flood-opacity"> {
    dx?: FunctionMaybe<number | string>;
    dy?: FunctionMaybe<number | string>;
    stdDeviation?: FunctionMaybe<number | string>;
  }
  interface FeFloodSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "flood-color" | "flood-opacity"> {}
  interface FeFuncSVGAttributes<T> extends CoreSVGAttributes<T> {
    type?: "identity" | "table" | "discrete" | "linear" | "gamma";
    tableValues?: FunctionMaybe<string>;
    slope?: FunctionMaybe<number | string>;
    intercept?: FunctionMaybe<number | string>;
    amplitude?: FunctionMaybe<number | string>;
    exponent?: FunctionMaybe<number | string>;
    offset?: FunctionMaybe<number | string>;
  }
  interface FeGaussianBlurSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    stdDeviation?: FunctionMaybe<number | string>;
  }
  interface FeImageSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    preserveAspectRatio?: FunctionMaybe<SVGPreserveAspectRatio>;
    href?: FunctionMaybe<string>;
  }
  interface FeMergeSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes {}
  interface FeMergeNodeSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      SingleInputFilterSVGAttributes {}
  interface FeMorphologySVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    operator?: FunctionMaybe<"erode" | "dilate">;
    radius?: FunctionMaybe<number | string>;
  }
  interface FeOffsetSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    dx?: FunctionMaybe<number | string>;
    dy?: FunctionMaybe<number | string>;
  }
  interface FePointLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    z?: FunctionMaybe<number | string>;
  }
  interface FeSpecularLightingSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "lighting-color"> {
    surfaceScale?: FunctionMaybe<string>;
    specularConstant?: FunctionMaybe<string>;
    specularExponent?: FunctionMaybe<string>;
    kernelUnitLength?: FunctionMaybe<number | string>;
  }
  interface FeSpotLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    z?: FunctionMaybe<number | string>;
    pointsAtX?: FunctionMaybe<number | string>;
    pointsAtY?: FunctionMaybe<number | string>;
    pointsAtZ?: FunctionMaybe<number | string>;
    specularExponent?: FunctionMaybe<number | string>;
    limitingConeAngle?: FunctionMaybe<number | string>;
  }
  interface FeTileSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {}
  interface FeTurbulanceSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes {
    baseFrequency?: FunctionMaybe<number | string>;
    numOctaves?: FunctionMaybe<number | string>;
    seed?: FunctionMaybe<number | string>;
    stitchTiles?: FunctionMaybe<"stitch" | "noStitch">;
    type?: FunctionMaybe<"fractalNoise" | "turbulence">;
  }
  interface FilterSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    filterUnits?: FunctionMaybe<SVGUnits>;
    primitiveUnits?: FunctionMaybe<SVGUnits>;
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    filterRes?: FunctionMaybe<number | string>;
  }
  interface ForeignObjectSVGAttributes<T>
    extends NewViewportSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
  }
  interface GSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {}
  interface ImageSVGAttributes<T>
    extends NewViewportSVGAttributes<T>,
      GraphicsElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "color-profile" | "image-rendering"> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    preserveAspectRatio?: FunctionMaybe<ImagePreserveAspectRatio>;
    href?: FunctionMaybe<string>;
  }
  interface LineSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    x1?: FunctionMaybe<number | string>;
    y1?: FunctionMaybe<number | string>;
    x2?: FunctionMaybe<number | string>;
    y2?: FunctionMaybe<number | string>;
  }
  interface LinearGradientSVGAttributes<T> extends GradientElementSVGAttributes<T> {
    x1?: FunctionMaybe<number | string>;
    x2?: FunctionMaybe<number | string>;
    y1?: FunctionMaybe<number | string>;
    y2?: FunctionMaybe<number | string>;
  }
  interface MarkerSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    markerUnits?: FunctionMaybe<"strokeWidth" | "userSpaceOnUse">;
    refX?: FunctionMaybe<number | string>;
    refY?: FunctionMaybe<number | string>;
    markerWidth?: FunctionMaybe<number | string>;
    markerHeight?: FunctionMaybe<number | string>;
    orient?: FunctionMaybe<string>;
  }
  interface MaskSVGAttributes<T>
    extends Omit<ContainerElementSVGAttributes<T>, "opacity" | "filter">,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    maskUnits?: FunctionMaybe<SVGUnits>;
    maskContentUnits?: FunctionMaybe<SVGUnits>;
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
  }
  interface MetadataSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface MPathSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface PathSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    d?: FunctionMaybe<string>;
    pathLength?: FunctionMaybe<number | string>;
  }
  interface PatternSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    patternUnits?: FunctionMaybe<SVGUnits>;
    patternContentUnits?: FunctionMaybe<SVGUnits>;
    patternTransform?: FunctionMaybe<string>;
    href?: string;
  }
  interface PolygonSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    points?: FunctionMaybe<string>;
  }
  interface PolylineSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    points?: FunctionMaybe<string>;
  }
  interface RadialGradientSVGAttributes<T> extends GradientElementSVGAttributes<T> {
    cx?: FunctionMaybe<number | string>;
    cy?: FunctionMaybe<number | string>;
    r?: FunctionMaybe<number | string>;
    fx?: FunctionMaybe<number | string>;
    fy?: FunctionMaybe<number | string>;
  }
  interface RectSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    rx?: FunctionMaybe<number | string>;
    ry?: FunctionMaybe<number | string>;
  }
  interface SetSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      AnimationTimingSVGAttributes {}
  interface StopSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "stop-color" | "stop-opacity"> {
    offset?: FunctionMaybe<number | string>;
  }
  interface SvgSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      NewViewportSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      ZoomAndPanSVGAttributes,
      PresentationSVGAttributes {
    version?: FunctionMaybe<string>;
    baseProfile?: FunctionMaybe<string>;
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    contentScriptType?: FunctionMaybe<string>;
    contentStyleType?: FunctionMaybe<string>;
    xmlns?: FunctionMaybe<string>;
    "xmlns:xlink"?: FunctionMaybe<string>;
  }
  interface SwitchSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {}
  interface SymbolSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      NewViewportSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes {
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    preserveAspectRatio?: FunctionMaybe<SVGPreserveAspectRatio>;
    refX?: FunctionMaybe<number | string>;
    refY?: FunctionMaybe<number | string>;
    viewBox?: FunctionMaybe<string>;
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
  }
  interface TextSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      GraphicsElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "writing-mode" | "text-rendering"> {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    dx?: FunctionMaybe<number | string>;
    dy?: FunctionMaybe<number | string>;
    rotate?: FunctionMaybe<number | string>;
    textLength?: FunctionMaybe<number | string>;
    lengthAdjust?: FunctionMaybe<"spacing" | "spacingAndGlyphs">;
  }
  interface TextPathSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      Pick<
        PresentationSVGAttributes,
        "alignment-baseline" | "baseline-shift" | "display" | "visibility"
      > {
    startOffset?: FunctionMaybe<number | string>;
    method?: FunctionMaybe<"align" | "stretch">;
    spacing?: FunctionMaybe<"auto" | "exact">;
    href?: FunctionMaybe<string>;
  }
  interface TSpanSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      Pick<
        PresentationSVGAttributes,
        "alignment-baseline" | "baseline-shift" | "display" | "visibility"
      > {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    dx?: FunctionMaybe<number | string>;
    dy?: FunctionMaybe<number | string>;
    rotate?: FunctionMaybe<number | string>;
    textLength?: FunctionMaybe<number | string>;
    lengthAdjust?: FunctionMaybe<"spacing" | "spacingAndGlyphs">;
  }
  /** @see https://developer.mozilla.org/en-US/docs/Web/SVG/Element/use */
  interface UseSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      ConditionalProcessingSVGAttributes,
      GraphicsElementSVGAttributes<T>,
      PresentationSVGAttributes,
      ExternalResourceSVGAttributes,
      TransformableSVGAttributes {
    x?: FunctionMaybe<number | string>;
    y?: FunctionMaybe<number | string>;
    width?: FunctionMaybe<number | string>;
    height?: FunctionMaybe<number | string>;
    href?: FunctionMaybe<string>;
  }
  interface ViewSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      FitToViewBoxSVGAttributes,
      ZoomAndPanSVGAttributes {
    viewTarget?: FunctionMaybe<string>;
  }
  /** @type {HTMLElementTagNameMap} */
  interface HTMLElementTags {
    a: AnchorHTMLAttributes<HTMLAnchorElement>;
    abbr: HTMLAttributes<HTMLElement>;
    address: HTMLAttributes<HTMLElement>;
    area: AreaHTMLAttributes<HTMLAreaElement>;
    article: HTMLAttributes<HTMLElement>;
    aside: HTMLAttributes<HTMLElement>;
    audio: AudioHTMLAttributes<HTMLAudioElement>;
    b: HTMLAttributes<HTMLElement>;
    base: BaseHTMLAttributes<HTMLBaseElement>;
    bdi: HTMLAttributes<HTMLElement>;
    bdo: HTMLAttributes<HTMLElement>;
    blockquote: BlockquoteHTMLAttributes<HTMLElement>;
    body: HTMLAttributes<HTMLBodyElement>;
    br: HTMLAttributes<HTMLBRElement>;
    button: ButtonHTMLAttributes<HTMLButtonElement>;
    canvas: CanvasHTMLAttributes<HTMLCanvasElement>;
    caption: HTMLAttributes<HTMLElement>;
    cite: HTMLAttributes<HTMLElement>;
    code: HTMLAttributes<HTMLElement>;
    col: ColHTMLAttributes<HTMLTableColElement>;
    colgroup: ColgroupHTMLAttributes<HTMLTableColElement>;
    data: DataHTMLAttributes<HTMLElement>;
    datalist: HTMLAttributes<HTMLDataListElement>;
    dd: HTMLAttributes<HTMLElement>;
    del: HTMLAttributes<HTMLElement>;
    details: DetailsHtmlAttributes<HTMLDetailsElement>;
    dfn: HTMLAttributes<HTMLElement>;
    dialog: DialogHtmlAttributes<HTMLDialogElement>;
    div: HTMLAttributes<HTMLDivElement>;
    dl: HTMLAttributes<HTMLDListElement>;
    dt: HTMLAttributes<HTMLElement>;
    em: HTMLAttributes<HTMLElement>;
    embed: EmbedHTMLAttributes<HTMLEmbedElement>;
    fieldset: FieldsetHTMLAttributes<HTMLFieldSetElement>;
    figcaption: HTMLAttributes<HTMLElement>;
    figure: HTMLAttributes<HTMLElement>;
    footer: HTMLAttributes<HTMLElement>;
    form: FormHTMLAttributes<HTMLFormElement>;
    h1: HTMLAttributes<HTMLHeadingElement>;
    h2: HTMLAttributes<HTMLHeadingElement>;
    h3: HTMLAttributes<HTMLHeadingElement>;
    h4: HTMLAttributes<HTMLHeadingElement>;
    h5: HTMLAttributes<HTMLHeadingElement>;
    h6: HTMLAttributes<HTMLHeadingElement>;
    head: HTMLAttributes<HTMLHeadElement>;
    header: HTMLAttributes<HTMLElement>;
    hgroup: HTMLAttributes<HTMLElement>;
    hr: HTMLAttributes<HTMLHRElement>;
    html: HTMLAttributes<HTMLHtmlElement>;
    i: HTMLAttributes<HTMLElement>;
    iframe: IframeHTMLAttributes<HTMLIFrameElement>;
    img: ImgHTMLAttributes<HTMLImageElement>;
    input: InputHTMLAttributes<HTMLInputElement>;
    ins: InsHTMLAttributes<HTMLModElement>;
    kbd: HTMLAttributes<HTMLElement>;
    label: LabelHTMLAttributes<HTMLLabelElement>;
    legend: HTMLAttributes<HTMLLegendElement>;
    li: LiHTMLAttributes<HTMLLIElement>;
    link: LinkHTMLAttributes<HTMLLinkElement>;
    main: HTMLAttributes<HTMLElement>;
    map: MapHTMLAttributes<HTMLMapElement>;
    mark: HTMLAttributes<HTMLElement>;
    menu: MenuHTMLAttributes<HTMLElement>;
    meta: MetaHTMLAttributes<HTMLMetaElement>;
    meter: MeterHTMLAttributes<HTMLElement>;
    nav: HTMLAttributes<HTMLElement>;
    noscript: HTMLAttributes<HTMLElement>;
    object: ObjectHTMLAttributes<HTMLObjectElement>;
    ol: OlHTMLAttributes<HTMLOListElement>;
    optgroup: OptgroupHTMLAttributes<HTMLOptGroupElement>;
    option: OptionHTMLAttributes<HTMLOptionElement>;
    output: OutputHTMLAttributes<HTMLElement>;
    p: HTMLAttributes<HTMLParagraphElement>;
    picture: HTMLAttributes<HTMLElement>;
    pre: HTMLAttributes<HTMLPreElement>;
    progress: ProgressHTMLAttributes<HTMLProgressElement>;
    q: QuoteHTMLAttributes<HTMLQuoteElement>;
    rp: HTMLAttributes<HTMLElement>;
    rt: HTMLAttributes<HTMLElement>;
    ruby: HTMLAttributes<HTMLElement>;
    s: HTMLAttributes<HTMLElement>;
    samp: HTMLAttributes<HTMLElement>;
    script: ScriptHTMLAttributes<HTMLScriptElement>;
    search: HTMLAttributes<HTMLElement>;
    section: HTMLAttributes<HTMLElement>;
    select: SelectHTMLAttributes<HTMLSelectElement>;
    slot: HTMLSlotElementAttributes;
    small: HTMLAttributes<HTMLElement>;
    source: SourceHTMLAttributes<HTMLSourceElement>;
    span: HTMLAttributes<HTMLSpanElement>;
    strong: HTMLAttributes<HTMLElement>;
    style: StyleHTMLAttributes<HTMLStyleElement>;
    sub: HTMLAttributes<HTMLElement>;
    summary: HTMLAttributes<HTMLElement>;
    sup: HTMLAttributes<HTMLElement>;
    table: HTMLAttributes<HTMLTableElement>;
    tbody: HTMLAttributes<HTMLTableSectionElement>;
    td: TdHTMLAttributes<HTMLTableCellElement>;
    template: TemplateHTMLAttributes<HTMLTemplateElement>;
    textarea: TextareaHTMLAttributes<HTMLTextAreaElement>;
    tfoot: HTMLAttributes<HTMLTableSectionElement>;
    th: ThHTMLAttributes<HTMLTableCellElement>;
    thead: HTMLAttributes<HTMLTableSectionElement>;
    time: TimeHTMLAttributes<HTMLElement>;
    title: HTMLAttributes<HTMLTitleElement>;
    tr: HTMLAttributes<HTMLTableRowElement>;
    track: TrackHTMLAttributes<HTMLTrackElement>;
    u: HTMLAttributes<HTMLElement>;
    ul: HTMLAttributes<HTMLUListElement>;
    var: HTMLAttributes<HTMLElement>;
    video: VideoHTMLAttributes<HTMLVideoElement>;
    wbr: HTMLAttributes<HTMLElement>;
  }
  /** @type {HTMLElementDeprecatedTagNameMap} */
  interface HTMLElementDeprecatedTags {
    big: HTMLAttributes<HTMLElement>;
    keygen: KeygenHTMLAttributes<HTMLElement>;
    menuitem: HTMLAttributes<HTMLElement>;
    noindex: HTMLAttributes<HTMLElement>;
    param: ParamHTMLAttributes<HTMLParamElement>;
  }
  /** @type {SVGElementTagNameMap} */
  interface SVGElementTags {
    animate: AnimateSVGAttributes<SVGAnimateElement>;
    animateMotion: AnimateMotionSVGAttributes<SVGAnimateMotionElement>;
    animateTransform: AnimateTransformSVGAttributes<SVGAnimateTransformElement>;
    circle: CircleSVGAttributes<SVGCircleElement>;
    clipPath: ClipPathSVGAttributes<SVGClipPathElement>;
    defs: DefsSVGAttributes<SVGDefsElement>;
    desc: DescSVGAttributes<SVGDescElement>;
    ellipse: EllipseSVGAttributes<SVGEllipseElement>;
    feBlend: FeBlendSVGAttributes<SVGFEBlendElement>;
    feColorMatrix: FeColorMatrixSVGAttributes<SVGFEColorMatrixElement>;
    feComponentTransfer: FeComponentTransferSVGAttributes<SVGFEComponentTransferElement>;
    feComposite: FeCompositeSVGAttributes<SVGFECompositeElement>;
    feConvolveMatrix: FeConvolveMatrixSVGAttributes<SVGFEConvolveMatrixElement>;
    feDiffuseLighting: FeDiffuseLightingSVGAttributes<SVGFEDiffuseLightingElement>;
    feDisplacementMap: FeDisplacementMapSVGAttributes<SVGFEDisplacementMapElement>;
    feDistantLight: FeDistantLightSVGAttributes<SVGFEDistantLightElement>;
    feDropShadow: FeDropShadowSVGAttributes<SVGFEDropShadowElement>;
    feFlood: FeFloodSVGAttributes<SVGFEFloodElement>;
    feFuncA: FeFuncSVGAttributes<SVGFEFuncAElement>;
    feFuncB: FeFuncSVGAttributes<SVGFEFuncBElement>;
    feFuncG: FeFuncSVGAttributes<SVGFEFuncGElement>;
    feFuncR: FeFuncSVGAttributes<SVGFEFuncRElement>;
    feGaussianBlur: FeGaussianBlurSVGAttributes<SVGFEGaussianBlurElement>;
    feImage: FeImageSVGAttributes<SVGFEImageElement>;
    feMerge: FeMergeSVGAttributes<SVGFEMergeElement>;
    feMergeNode: FeMergeNodeSVGAttributes<SVGFEMergeNodeElement>;
    feMorphology: FeMorphologySVGAttributes<SVGFEMorphologyElement>;
    feOffset: FeOffsetSVGAttributes<SVGFEOffsetElement>;
    fePointLight: FePointLightSVGAttributes<SVGFEPointLightElement>;
    feSpecularLighting: FeSpecularLightingSVGAttributes<SVGFESpecularLightingElement>;
    feSpotLight: FeSpotLightSVGAttributes<SVGFESpotLightElement>;
    feTile: FeTileSVGAttributes<SVGFETileElement>;
    feTurbulence: FeTurbulanceSVGAttributes<SVGFETurbulenceElement>;
    filter: FilterSVGAttributes<SVGFilterElement>;
    foreignObject: ForeignObjectSVGAttributes<SVGForeignObjectElement>;
    g: GSVGAttributes<SVGGElement>;
    image: ImageSVGAttributes<SVGImageElement>;
    line: LineSVGAttributes<SVGLineElement>;
    linearGradient: LinearGradientSVGAttributes<SVGLinearGradientElement>;
    marker: MarkerSVGAttributes<SVGMarkerElement>;
    mask: MaskSVGAttributes<SVGMaskElement>;
    metadata: MetadataSVGAttributes<SVGMetadataElement>;
    mpath: MPathSVGAttributes<SVGMPathElement>;
    path: PathSVGAttributes<SVGPathElement>;
    pattern: PatternSVGAttributes<SVGPatternElement>;
    polygon: PolygonSVGAttributes<SVGPolygonElement>;
    polyline: PolylineSVGAttributes<SVGPolylineElement>;
    radialGradient: RadialGradientSVGAttributes<SVGRadialGradientElement>;
    rect: RectSVGAttributes<SVGRectElement>;
    set: SetSVGAttributes<SVGSetElement>;
    stop: StopSVGAttributes<SVGStopElement>;
    svg: SvgSVGAttributes<SVGSVGElement>;
    switch: SwitchSVGAttributes<SVGSwitchElement>;
    symbol: SymbolSVGAttributes<SVGSymbolElement>;
    text: TextSVGAttributes<SVGTextElement>;
    textPath: TextPathSVGAttributes<SVGTextPathElement>;
    tspan: TSpanSVGAttributes<SVGTSpanElement>;
    use: UseSVGAttributes<SVGUseElement>;
    view: ViewSVGAttributes<SVGViewElement>;
  }
  interface IntrinsicElements extends HTMLElementTags, HTMLElementDeprecatedTags, SVGElementTags {}
}
`,Ke=`type MountableElement = Element | Document | ShadowRoot | DocumentFragment | Node;
interface Runtime {
  insert(parent: MountableElement, accessor: any, marker?: Node | null, init?: any): any;
  spread(node: Element, accessor: any, isSVG?: Boolean, skipChildren?: Boolean): void;
  assign(node: Element, props: any, isSVG?: Boolean, skipChildren?: Boolean): void;
  createComponent(Comp: (props: any) => any, props: any): any;
  dynamicProperty(props: any, key: string): any;
  SVGElements: Set<string>;
}
type ExpandableNode = Node & {
  [key: string]: any;
};
export type HyperScript = {
  (...args: any[]): () => ExpandableNode | ExpandableNode[];
  Fragment: (props: {
    children: (() => ExpandableNode) | (() => ExpandableNode)[];
  }) => ExpandableNode[];
};
export declare function createHyperScript(r: Runtime): HyperScript;
export {};
`,qe=`import type { HyperScript } from "./hyperscript.js";
declare const h: HyperScript;
export default h;
`,Ye=`import type { HTMLTag } from "./lit.js";
declare const html: HTMLTag;
export default html;
`,Je=`type MountableElement = Element | Document | ShadowRoot | DocumentFragment | Node;
interface Runtime {
  effect<T>(fn: (prev?: T) => T, init?: T): any;
  untrack<T>(fn: () => T): T;
  insert(parent: MountableElement, accessor: any, marker?: Node | null, init?: any): any;
  spread<T>(node: Element, accessor: (() => T) | T, isSVG?: Boolean, skipChildren?: Boolean): void;
  createComponent(Comp: (props: any) => any, props: any): any;
  addEventListener(
    node: Element,
    name: string,
    handler: EventListener | EventListenerObject | (EventListenerObject & AddEventListenerOptions),
    delegate: boolean
  ): void;
  delegateEvents(eventNames: string[]): void;
  classList(
    node: Element,
    value: {
      [k: string]: boolean;
    },
    prev?: {
      [k: string]: boolean;
    }
  ): {
    [k: string]: boolean;
  };
  style(
    node: Element,
    value: {
      [k: string]: string;
    },
    prev?: {
      [k: string]: string;
    }
  ): void;
  mergeProps(...sources: unknown[]): unknown;
  dynamicProperty(props: any, key: string): any;
  setAttribute(node: Element, name: string, value: any): void;
  setAttributeNS(node: Element, namespace: string, name: string, value: any): void;
  Aliases: Record<string, string>;
  getPropAlias(prop: string, tagName: string): string | undefined;
  Properties: Set<string>;
  ChildProperties: Set<string>;
  DelegatedEvents: Set<string>;
  SVGElements: Set<string>;
  SVGNamespace: Record<string, string>;
}
export type HTMLTag = {
  (statics: TemplateStringsArray, ...args: unknown[]): Node | Node[];
};
export declare function createHTML(
  r: Runtime,
  {
    delegateEvents,
    functionBuilder
  }?: {
    delegateEvents?: boolean;
    functionBuilder?: (...args: string[]) => Function;
  }
): HTMLTag;
export {};
`,$e=`export * from "./types/jsx";
`,Qe=`export { $RAW, createStore, unwrap } from "./store.js";
export type {
  ArrayFilterFn,
  DeepMutable,
  DeepReadonly,
  NotWrappable,
  Part,
  SetStoreFunction,
  SolidStore,
  Store,
  StoreNode,
  StorePathRange,
  StoreSetter
} from "./store.js";
export * from "./mutable.js";
export * from "./modifiers.js";
import { $NODE, isWrappable } from "./store.js";
export declare const DEV:
  | {
      readonly $NODE: typeof $NODE;
      readonly isWrappable: typeof isWrappable;
      readonly hooks: {
        onStoreNodeUpdate: import("./store.js").OnStoreNodeUpdate | null;
      };
    }
  | undefined;
`,Ze=`export type ReconcileOptions = {
  key?: string | null;
  merge?: boolean;
};
export declare function reconcile<T extends U, U>(
  value: T,
  options?: ReconcileOptions
): (state: U) => T;
export declare function produce<T>(fn: (state: T) => void): (state: T) => T;
`,en=`import { StoreNode } from "./store.js";
export declare function createMutable<T extends StoreNode>(
  state: T,
  options?: {
    name?: string;
  }
): T;
export declare function modifyMutable<T>(state: T, modifier: (state: T) => T): void;
`,nn=`import type { SetStoreFunction, Store } from "./store.js";
export type {
  ArrayFilterFn,
  DeepMutable,
  DeepReadonly,
  NotWrappable,
  Part,
  SetStoreFunction,
  SolidStore,
  Store,
  StoreNode,
  StorePathRange,
  StoreSetter
} from "./store.js";
export declare const $RAW: unique symbol;
export declare function isWrappable(obj: any): boolean;
export declare function unwrap<T>(item: T): T;
export declare function setProperty(
  state: any,
  property: PropertyKey,
  value: any,
  force?: boolean
): void;
export declare function updatePath(current: any, path: any[], traversed?: PropertyKey[]): void;
export declare function createStore<T>(state: T | Store<T>): [Store<T>, SetStoreFunction<T>];
export declare function createMutable<T>(state: T | Store<T>): T;
export declare function modifyMutable<T>(state: T, modifier: (state: T) => T): void;
type ReconcileOptions = {
  key?: string | null;
  merge?: boolean;
};
export declare function reconcile<T extends U, U extends object>(
  value: T,
  options?: ReconcileOptions
): (state: U) => T;
export declare function produce<T>(fn: (state: T) => void): (state: T) => T;
export declare const DEV: undefined;
`,tn=`export declare const $RAW: unique symbol,
  $NODE: unique symbol,
  $HAS: unique symbol,
  $SELF: unique symbol;
export declare const DevHooks: {
  onStoreNodeUpdate: OnStoreNodeUpdate | null;
};
type DataNode = {
  (): any;
  $(value?: any): void;
};
export type DataNodes = Record<PropertyKey, DataNode | undefined>;
export type OnStoreNodeUpdate = (
  state: StoreNode,
  property: PropertyKey,
  value: StoreNode | NotWrappable,
  prev: StoreNode | NotWrappable
) => void;
export interface StoreNode {
  [$NODE]?: DataNodes;
  [key: PropertyKey]: any;
}
export declare namespace SolidStore {
  interface Unwrappable {}
}
export type NotWrappable =
  | string
  | number
  | bigint
  | symbol
  | boolean
  | Function
  | null
  | undefined
  | SolidStore.Unwrappable[keyof SolidStore.Unwrappable];
export type Store<T> = T;
export declare function isWrappable<T>(obj: T | NotWrappable): obj is T;
/**
 * Returns the underlying data in the store without a proxy.
 * @param item store proxy object
 * @example
 * \`\`\`js
 * const initial = {z...};
 * const [state, setState] = createStore(initial);
 * initial === state; // => false
 * initial === unwrap(state); // => true
 * \`\`\`
 */
export declare function unwrap<T>(item: T, set?: Set<unknown>): T;
export declare function getNodes(target: StoreNode, symbol: typeof $NODE | typeof $HAS): DataNodes;
export declare function getNode(nodes: DataNodes, property: PropertyKey, value?: any): DataNode;
export declare function proxyDescriptor(
  target: StoreNode,
  property: PropertyKey
): TypedPropertyDescriptor<any> | undefined;
export declare function trackSelf(target: StoreNode): void;
export declare function ownKeys(target: StoreNode): (string | symbol)[];
export declare function setProperty(
  state: StoreNode,
  property: PropertyKey,
  value: any,
  deleting?: boolean
): void;
export declare function updatePath(
  current: StoreNode,
  path: any[],
  traversed?: PropertyKey[]
): void;
/** @deprecated */
export type DeepReadonly<T> = 0 extends 1 & T
  ? T
  : T extends NotWrappable
  ? T
  : {
      readonly [K in keyof T]: DeepReadonly<T[K]>;
    };
/** @deprecated */
export type DeepMutable<T> = 0 extends 1 & T
  ? T
  : T extends NotWrappable
  ? T
  : {
      -readonly [K in keyof T]: DeepMutable<T[K]>;
    };
export type CustomPartial<T> = T extends readonly unknown[]
  ? "0" extends keyof T
    ? {
        [K in Extract<keyof T, \`\${number}\`>]?: T[K];
      }
    : {
        [x: number]: T[number];
      }
  : Partial<T>;
export type PickMutable<T> = {
  [K in keyof T as (<U>() => U extends {
    [V in K]: T[V];
  }
    ? 1
    : 2) extends <U>() => U extends {
    -readonly [V in K]: T[V];
  }
    ? 1
    : 2
    ? K
    : never]: T[K];
};
export type StorePathRange = {
  from?: number;
  to?: number;
  by?: number;
};
export type ArrayFilterFn<T> = (item: T, index: number) => boolean;
export type StoreSetter<T, U extends PropertyKey[] = []> =
  | T
  | CustomPartial<T>
  | ((prevState: T, traversed: U) => T | CustomPartial<T>);
export type Part<T, K extends KeyOf<T> = KeyOf<T>> =
  | K
  | ([K] extends [never] ? never : readonly K[])
  | ([T] extends [readonly unknown[]] ? ArrayFilterFn<T[number]> | StorePathRange : never);
type W<T> = Exclude<T, NotWrappable>;
type KeyOf<T> = number extends keyof T
  ? 0 extends 1 & T
    ? keyof T
    : [T] extends [never]
    ? never
    : [T] extends [readonly unknown[]]
    ? number
    : keyof T
  : keyof T;
type MutableKeyOf<T> = KeyOf<T> & keyof PickMutable<T>;
type Rest<T, U extends PropertyKey[], K extends KeyOf<T> = KeyOf<T>> = [T] extends [never]
  ? never
  : K extends MutableKeyOf<T>
  ? [Part<T, K>, ...RestSetterOrContinue<T[K], [K, ...U]>]
  : K extends KeyOf<T>
  ? [Part<T, K>, ...RestContinue<T[K], [K, ...U]>]
  : never;
type RestContinue<T, U extends PropertyKey[]> = 0 extends 1 & T
  ? [...Part<any>[], StoreSetter<any, PropertyKey[]>]
  : Rest<W<T>, U>;
type RestSetterOrContinue<T, U extends PropertyKey[]> = [StoreSetter<T, U>] | RestContinue<T, U>;
export interface SetStoreFunction<T> {
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends KeyOf<W<W<W<T>[K1]>[K2]>>,
    K4 extends KeyOf<W<W<W<W<T>[K1]>[K2]>[K3]>>,
    K5 extends KeyOf<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>>,
    K6 extends KeyOf<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>>,
    K7 extends MutableKeyOf<W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    k4: Part<W<W<W<W<T>[K1]>[K2]>[K3]>, K4>,
    k5: Part<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>, K5>,
    k6: Part<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>, K6>,
    k7: Part<W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>, K7>,
    setter: StoreSetter<
      W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>[K7],
      [K7, K6, K5, K4, K3, K2, K1]
    >
  ): void;
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends KeyOf<W<W<W<T>[K1]>[K2]>>,
    K4 extends KeyOf<W<W<W<W<T>[K1]>[K2]>[K3]>>,
    K5 extends KeyOf<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>>,
    K6 extends MutableKeyOf<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    k4: Part<W<W<W<W<T>[K1]>[K2]>[K3]>, K4>,
    k5: Part<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>, K5>,
    k6: Part<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>, K6>,
    setter: StoreSetter<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6], [K6, K5, K4, K3, K2, K1]>
  ): void;
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends KeyOf<W<W<W<T>[K1]>[K2]>>,
    K4 extends KeyOf<W<W<W<W<T>[K1]>[K2]>[K3]>>,
    K5 extends MutableKeyOf<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    k4: Part<W<W<W<W<T>[K1]>[K2]>[K3]>, K4>,
    k5: Part<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>, K5>,
    setter: StoreSetter<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5], [K5, K4, K3, K2, K1]>
  ): void;
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends KeyOf<W<W<W<T>[K1]>[K2]>>,
    K4 extends MutableKeyOf<W<W<W<W<T>[K1]>[K2]>[K3]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    k4: Part<W<W<W<W<T>[K1]>[K2]>[K3]>, K4>,
    setter: StoreSetter<W<W<W<W<T>[K1]>[K2]>[K3]>[K4], [K4, K3, K2, K1]>
  ): void;
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends MutableKeyOf<W<W<W<T>[K1]>[K2]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    setter: StoreSetter<W<W<W<T>[K1]>[K2]>[K3], [K3, K2, K1]>
  ): void;
  <K1 extends KeyOf<W<T>>, K2 extends MutableKeyOf<W<W<T>[K1]>>>(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    setter: StoreSetter<W<W<T>[K1]>[K2], [K2, K1]>
  ): void;
  <K1 extends MutableKeyOf<W<T>>>(k1: Part<W<T>, K1>, setter: StoreSetter<W<T>[K1], [K1]>): void;
  (setter: StoreSetter<T, []>): void;
  <
    K1 extends KeyOf<W<T>>,
    K2 extends KeyOf<W<W<T>[K1]>>,
    K3 extends KeyOf<W<W<W<T>[K1]>[K2]>>,
    K4 extends KeyOf<W<W<W<W<T>[K1]>[K2]>[K3]>>,
    K5 extends KeyOf<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>>,
    K6 extends KeyOf<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>>,
    K7 extends KeyOf<W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>>
  >(
    k1: Part<W<T>, K1>,
    k2: Part<W<W<T>[K1]>, K2>,
    k3: Part<W<W<W<T>[K1]>[K2]>, K3>,
    k4: Part<W<W<W<W<T>[K1]>[K2]>[K3]>, K4>,
    k5: Part<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>, K5>,
    k6: Part<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>, K6>,
    k7: Part<W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>, K7>,
    ...rest: Rest<W<W<W<W<W<W<W<T>[K1]>[K2]>[K3]>[K4]>[K5]>[K6]>[K7], [K7, K6, K5, K4, K3, K2, K1]>
  ): void;
}
/**
 * Creates a reactive store that can be read through a proxy object and written with a setter function
 *
 * @description https://docs.solidjs.com/reference/store-utilities/create-store
 */
export declare function createStore<T extends object = {}>(
  ...[store, options]: {} extends T
    ? [
        store?: T | Store<T>,
        options?: {
          name?: string;
        }
      ]
    : [
        store: T | Store<T>,
        options?: {
          name?: string;
        }
      ]
): [get: Store<T>, set: SetStoreFunction<T>];
export {};
`,rn=`export {
  $DEVCOMP,
  $PROXY,
  $TRACK,
  batch,
  catchError,
  children,
  createComputed,
  createContext,
  createDeferred,
  createEffect,
  createMemo,
  createReaction,
  createRenderEffect,
  createResource,
  createRoot,
  createSelector,
  createSignal,
  enableExternalSource,
  enableScheduling,
  equalFn,
  getListener,
  getOwner,
  on,
  onCleanup,
  onError,
  onMount,
  runWithOwner,
  startTransition,
  untrack,
  useContext,
  useTransition
} from "./reactive/signal.js";
export type {
  Accessor,
  AccessorArray,
  ChildrenReturn,
  Context,
  ContextProviderComponent,
  EffectFunction,
  EffectOptions,
  InitializedResource,
  InitializedResourceOptions,
  InitializedResourceReturn,
  MemoOptions,
  NoInfer,
  OnEffectFunction,
  OnOptions,
  Owner,
  ResolvedChildren,
  ResolvedJSXElement,
  Resource,
  ResourceActions,
  ResourceFetcher,
  ResourceFetcherInfo,
  ResourceOptions,
  ResourceReturn,
  ResourceSource,
  ReturnTypes,
  Setter,
  Signal,
  SignalOptions
} from "./reactive/signal.js";
export * from "./reactive/observable.js";
export * from "./reactive/scheduler.js";
export * from "./reactive/array.js";
export * from "./render/index.js";
import type { JSX } from "./jsx.js";
type JSXElement = JSX.Element;
export type { JSXElement, JSX };
import { registerGraph, writeSignal } from "./reactive/signal.js";
export declare const DEV:
  | {
      readonly hooks: {
        afterUpdate: (() => void) | null;
        afterCreateOwner: ((owner: import("./reactive/signal.js").Owner) => void) | null;
        afterCreateSignal:
          | ((signal: import("./reactive/signal.js").SignalState<any>) => void)
          | null;
      };
      readonly writeSignal: typeof writeSignal;
      readonly registerGraph: typeof registerGraph;
    }
  | undefined;
declare global {
  var Solid$$: boolean;
}
`,on=`import * as csstype from "csstype";

/**
 * Based on JSX types for Surplus and Inferno and adapted for \`dom-expressions\`.
 *
 * https://github.com/adamhaile/surplus/blob/master/index.d.ts
 * https://github.com/infernojs/inferno/blob/master/packages/inferno/src/core/types.ts
 */
type DOMElement = Element;

export namespace JSX {
  type Element = Node | ArrayElement | (string & {}) | number | boolean | null | undefined;
  interface ArrayElement extends Array<Element> {}
  interface ElementClass {
    // empty, libs can define requirements downstream
  }
  interface ElementAttributesProperty {
    // empty, libs can define requirements downstream
  }
  interface ElementChildrenAttribute {
    children: {};
  }
  interface EventHandler<T, E extends Event> {
    (
      e: E & {
        currentTarget: T;
        target: DOMElement;
      }
    ): void;
  }

  interface BoundEventHandler<
    T,
    E extends Event,
    EHandler extends EventHandler<T, any> = EventHandler<T, E>
  > {
    0: (data: any, ...e: Parameters<EHandler>) => void;
    1: any;
  }
  type EventHandlerUnion<
    T,
    E extends Event,
    EHandler extends EventHandler<T, any> = EventHandler<T, E>
  > = EHandler | BoundEventHandler<T, E, EHandler>;

  interface EventHandlerWithOptions<T, E extends Event, EHandler = EventHandler<T, E>>
    extends AddEventListenerOptions {
    handleEvent: EHandler;
  }

  type EventHandlerWithOptionsUnion<
    T,
    E extends Event,
    EHandler extends EventHandler<T, any> = EventHandler<T, E>
  > = EHandler | EventHandlerWithOptions<T, E, EHandler>;

  interface InputEventHandler<T, E extends InputEvent> {
    (
      e: E & {
        currentTarget: T;
        target: T extends HTMLInputElement | HTMLSelectElement | HTMLTextAreaElement
          ? T
          : DOMElement;
      }
    ): void;
  }
  type InputEventHandlerUnion<T, E extends InputEvent> = EventHandlerUnion<
    T,
    E,
    InputEventHandler<T, E>
  >;

  interface ChangeEventHandler<T, E extends Event> {
    (
      e: E & {
        currentTarget: T;
        target: T extends HTMLInputElement | HTMLSelectElement | HTMLTextAreaElement
          ? T
          : DOMElement;
      }
    ): void;
  }
  type ChangeEventHandlerUnion<T, E extends Event> = EventHandlerUnion<
    T,
    E,
    ChangeEventHandler<T, E>
  >;

  interface FocusEventHandler<T, E extends FocusEvent> {
    (
      e: E & {
        currentTarget: T;
        target: T extends HTMLInputElement | HTMLSelectElement | HTMLTextAreaElement
          ? T
          : DOMElement;
      }
    ): void;
  }
  type FocusEventHandlerUnion<T, E extends FocusEvent> = EventHandlerUnion<
    T,
    E,
    FocusEventHandler<T, E>
  >;

  const SERIALIZABLE: unique symbol;
  interface SerializableAttributeValue {
    toString(): string;
    [SERIALIZABLE]: never;
  }

  interface IntrinsicAttributes {
    ref?: unknown | ((e: unknown) => void) | undefined;
  }
  interface CustomAttributes<T> {
    ref?: T | ((el: T) => void) | undefined;
    classList?:
      | {
          [k: string]: boolean | undefined;
        }
      | undefined;
    $ServerOnly?: boolean | undefined;
  }
  type Accessor<T> = () => T;
  interface Directives {}
  interface DirectiveFunctions {
    [x: string]: (el: DOMElement, accessor: Accessor<any>) => void;
  }
  interface ExplicitProperties {}
  interface ExplicitAttributes {}
  interface ExplicitBoolAttributes {}
  interface CustomEvents {}
  /** @deprecated Replaced by CustomEvents */
  interface CustomCaptureEvents {}
  type DirectiveAttributes = {
    [Key in keyof Directives as \`use:\${Key}\`]?: Directives[Key];
  };
  type DirectiveFunctionAttributes<T> = {
    [K in keyof DirectiveFunctions as string extends K
      ? never
      : \`use:\${K}\`]?: DirectiveFunctions[K] extends (
      el: infer E, // will be unknown if not provided
      ...rest: infer R // use rest so that we can check whether it's provided or not
    ) => void
      ? T extends E // everything extends unknown if E is unknown
        ? R extends [infer A] // check if has accessor provided
          ? A extends Accessor<infer V>
            ? V // it's an accessor
            : never // it isn't, type error
          : true // no accessor provided
        : never // T is the wrong element
      : never; // it isn't a function
  };
  type PropAttributes = {
    [Key in keyof ExplicitProperties as \`prop:\${Key}\`]?: ExplicitProperties[Key];
  };
  type AttrAttributes = {
    [Key in keyof ExplicitAttributes as \`attr:\${Key}\`]?: ExplicitAttributes[Key];
  };
  type BoolAttributes = {
    [Key in keyof ExplicitBoolAttributes as \`bool:\${Key}\`]?: ExplicitBoolAttributes[Key];
  };
  type OnAttributes<T> = {
    [Key in keyof CustomEvents as \`on:\${Key}\`]?: EventHandlerWithOptionsUnion<T, CustomEvents[Key]>;
  };
  type OnCaptureAttributes<T> = {
    [Key in keyof CustomCaptureEvents as \`oncapture:\${Key}\`]?: EventHandler<
      T,
      CustomCaptureEvents[Key]
    >;
  };
  interface DOMAttributes<T>
    extends CustomAttributes<T>,
      DirectiveAttributes,
      DirectiveFunctionAttributes<T>,
      PropAttributes,
      AttrAttributes,
      BoolAttributes,
      OnAttributes<T>,
      OnCaptureAttributes<T>,
      CustomEventHandlersCamelCase<T>,
      CustomEventHandlersLowerCase<T>,
      CustomEventHandlersNamespaced<T> {
    children?: Element | undefined;
    innerHTML?: string | undefined;
    innerText?: string | number | undefined;
    textContent?: string | number | undefined;
    // camel case events
    onCopy?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    onCut?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    onPaste?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    onCompositionEnd?: EventHandlerUnion<T, CompositionEvent> | undefined;
    onCompositionStart?: EventHandlerUnion<T, CompositionEvent> | undefined;
    onCompositionUpdate?: EventHandlerUnion<T, CompositionEvent> | undefined;
    onFocusOut?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onFocusIn?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onEncrypted?: EventHandlerUnion<T, Event> | undefined;
    onDragExit?: EventHandlerUnion<T, DragEvent> | undefined;
    // lower case events
    oncopy?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    oncut?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    onpaste?: EventHandlerUnion<T, ClipboardEvent> | undefined;
    oncompositionend?: EventHandlerUnion<T, CompositionEvent> | undefined;
    oncompositionstart?: EventHandlerUnion<T, CompositionEvent> | undefined;
    oncompositionupdate?: EventHandlerUnion<T, CompositionEvent> | undefined;
    onfocusout?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onfocusin?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onencrypted?: EventHandlerUnion<T, Event> | undefined;
    ondragexit?: EventHandlerUnion<T, DragEvent> | undefined;
    // lower case events
    "on:copy"?: EventHandlerWithOptionsUnion<T, ClipboardEvent> | undefined;
    "on:cut"?: EventHandlerWithOptionsUnion<T, ClipboardEvent> | undefined;
    "on:paste"?: EventHandlerWithOptionsUnion<T, ClipboardEvent> | undefined;
    "on:compositionend"?: EventHandlerWithOptionsUnion<T, CompositionEvent> | undefined;
    "on:compositionstart"?: EventHandlerWithOptionsUnion<T, CompositionEvent> | undefined;
    "on:compositionupdate"?: EventHandlerWithOptionsUnion<T, CompositionEvent> | undefined;
    "on:focusout"?:
      | EventHandlerWithOptionsUnion<T, FocusEvent, FocusEventHandler<T, FocusEvent>>
      | undefined;
    "on:focusin"?:
      | EventHandlerWithOptionsUnion<T, FocusEvent, FocusEventHandler<T, FocusEvent>>
      | undefined;
    "on:encrypted"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:dragexit"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
  }
  interface CustomEventHandlersCamelCase<T> {
    onAbort?: EventHandlerUnion<T, Event> | undefined;
    onAnimationEnd?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onAnimationIteration?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onAnimationStart?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onAuxClick?: EventHandlerUnion<T, MouseEvent> | undefined;
    onBeforeInput?: InputEventHandlerUnion<T, InputEvent> | undefined;
    onBeforeToggle?: EventHandlerUnion<T, ToggleEvent> | undefined;
    onBlur?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onCanPlay?: EventHandlerUnion<T, Event> | undefined;
    onCanPlayThrough?: EventHandlerUnion<T, Event> | undefined;
    onChange?: ChangeEventHandlerUnion<T, Event> | undefined;
    onClick?: EventHandlerUnion<T, MouseEvent> | undefined;
    onContextMenu?: EventHandlerUnion<T, MouseEvent> | undefined;
    onDblClick?: EventHandlerUnion<T, MouseEvent> | undefined;
    onDrag?: EventHandlerUnion<T, DragEvent> | undefined;
    onDragEnd?: EventHandlerUnion<T, DragEvent> | undefined;
    onDragEnter?: EventHandlerUnion<T, DragEvent> | undefined;
    onDragLeave?: EventHandlerUnion<T, DragEvent> | undefined;
    onDragOver?: EventHandlerUnion<T, DragEvent> | undefined;
    onDragStart?: EventHandlerUnion<T, DragEvent> | undefined;
    onDrop?: EventHandlerUnion<T, DragEvent> | undefined;
    onDurationChange?: EventHandlerUnion<T, Event> | undefined;
    onEmptied?: EventHandlerUnion<T, Event> | undefined;
    onEnded?: EventHandlerUnion<T, Event> | undefined;
    onError?: EventHandlerUnion<T, Event> | undefined;
    onFocus?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    onGotPointerCapture?: EventHandlerUnion<T, PointerEvent> | undefined;
    onInput?: InputEventHandlerUnion<T, InputEvent> | undefined;
    onInvalid?: EventHandlerUnion<T, Event> | undefined;
    onKeyDown?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onKeyPress?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onKeyUp?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onLoad?: EventHandlerUnion<T, Event> | undefined;
    onLoadedData?: EventHandlerUnion<T, Event> | undefined;
    onLoadedMetadata?: EventHandlerUnion<T, Event> | undefined;
    onLoadStart?: EventHandlerUnion<T, Event> | undefined;
    onLostPointerCapture?: EventHandlerUnion<T, PointerEvent> | undefined;
    onMouseDown?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseEnter?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseLeave?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseMove?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseOut?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseOver?: EventHandlerUnion<T, MouseEvent> | undefined;
    onMouseUp?: EventHandlerUnion<T, MouseEvent> | undefined;
    onPause?: EventHandlerUnion<T, Event> | undefined;
    onPlay?: EventHandlerUnion<T, Event> | undefined;
    onPlaying?: EventHandlerUnion<T, Event> | undefined;
    onPointerCancel?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerDown?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerEnter?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerLeave?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerMove?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerOut?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerOver?: EventHandlerUnion<T, PointerEvent> | undefined;
    onPointerUp?: EventHandlerUnion<T, PointerEvent> | undefined;
    onProgress?: EventHandlerUnion<T, ProgressEvent> | undefined;
    onRateChange?: EventHandlerUnion<T, Event> | undefined;
    onReset?: EventHandlerUnion<T, Event> | undefined;
    onScroll?: EventHandlerUnion<T, Event> | undefined;
    onScrollEnd?: EventHandlerUnion<T, Event> | undefined;
    onSeeked?: EventHandlerUnion<T, Event> | undefined;
    onSeeking?: EventHandlerUnion<T, Event> | undefined;
    onSelect?: EventHandlerUnion<T, Event> | undefined;
    onStalled?: EventHandlerUnion<T, Event> | undefined;
    onSubmit?: EventHandlerUnion<T, SubmitEvent> | undefined;
    onSuspend?: EventHandlerUnion<T, Event> | undefined;
    onTimeUpdate?: EventHandlerUnion<T, Event> | undefined;
    onToggle?: EventHandlerUnion<T, ToggleEvent> | undefined;
    onTouchCancel?: EventHandlerUnion<T, TouchEvent> | undefined;
    onTouchEnd?: EventHandlerUnion<T, TouchEvent> | undefined;
    onTouchMove?: EventHandlerUnion<T, TouchEvent> | undefined;
    onTouchStart?: EventHandlerUnion<T, TouchEvent> | undefined;
    onTransitionStart?: EventHandlerUnion<T, TransitionEvent> | undefined;
    onTransitionEnd?: EventHandlerUnion<T, TransitionEvent> | undefined;
    onTransitionRun?: EventHandlerUnion<T, TransitionEvent> | undefined;
    onTransitionCancel?: EventHandlerUnion<T, TransitionEvent> | undefined;
    onVolumeChange?: EventHandlerUnion<T, Event> | undefined;
    onWaiting?: EventHandlerUnion<T, Event> | undefined;
    onWheel?: EventHandlerUnion<T, WheelEvent> | undefined;
  }
  /** @type {GlobalEventHandlers} */
  interface CustomEventHandlersLowerCase<T> {
    onabort?: EventHandlerUnion<T, Event> | undefined;
    onanimationend?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onanimationiteration?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onanimationstart?: EventHandlerUnion<T, AnimationEvent> | undefined;
    onauxclick?: EventHandlerUnion<T, MouseEvent> | undefined;
    onbeforeinput?: InputEventHandlerUnion<T, InputEvent> | undefined;
    onbeforetoggle?: EventHandlerUnion<T, ToggleEvent> | undefined;
    onblur?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    oncanplay?: EventHandlerUnion<T, Event> | undefined;
    oncanplaythrough?: EventHandlerUnion<T, Event> | undefined;
    onchange?: ChangeEventHandlerUnion<T, Event> | undefined;
    onclick?: EventHandlerUnion<T, MouseEvent> | undefined;
    oncontextmenu?: EventHandlerUnion<T, MouseEvent> | undefined;
    ondblclick?: EventHandlerUnion<T, MouseEvent> | undefined;
    ondrag?: EventHandlerUnion<T, DragEvent> | undefined;
    ondragend?: EventHandlerUnion<T, DragEvent> | undefined;
    ondragenter?: EventHandlerUnion<T, DragEvent> | undefined;
    ondragleave?: EventHandlerUnion<T, DragEvent> | undefined;
    ondragover?: EventHandlerUnion<T, DragEvent> | undefined;
    ondragstart?: EventHandlerUnion<T, DragEvent> | undefined;
    ondrop?: EventHandlerUnion<T, DragEvent> | undefined;
    ondurationchange?: EventHandlerUnion<T, Event> | undefined;
    onemptied?: EventHandlerUnion<T, Event> | undefined;
    onended?: EventHandlerUnion<T, Event> | undefined;
    onerror?: EventHandlerUnion<T, Event> | undefined;
    onfocus?: FocusEventHandlerUnion<T, FocusEvent> | undefined;
    ongotpointercapture?: EventHandlerUnion<T, PointerEvent> | undefined;
    oninput?: InputEventHandlerUnion<T, InputEvent> | undefined;
    oninvalid?: EventHandlerUnion<T, Event> | undefined;
    onkeydown?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onkeypress?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onkeyup?: EventHandlerUnion<T, KeyboardEvent> | undefined;
    onload?: EventHandlerUnion<T, Event> | undefined;
    onloadeddata?: EventHandlerUnion<T, Event> | undefined;
    onloadedmetadata?: EventHandlerUnion<T, Event> | undefined;
    onloadstart?: EventHandlerUnion<T, Event> | undefined;
    onlostpointercapture?: EventHandlerUnion<T, PointerEvent> | undefined;
    onmousedown?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmouseenter?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmouseleave?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmousemove?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmouseout?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmouseover?: EventHandlerUnion<T, MouseEvent> | undefined;
    onmouseup?: EventHandlerUnion<T, MouseEvent> | undefined;
    onpause?: EventHandlerUnion<T, Event> | undefined;
    onplay?: EventHandlerUnion<T, Event> | undefined;
    onplaying?: EventHandlerUnion<T, Event> | undefined;
    onpointercancel?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerdown?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerenter?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerleave?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointermove?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerout?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerover?: EventHandlerUnion<T, PointerEvent> | undefined;
    onpointerup?: EventHandlerUnion<T, PointerEvent> | undefined;
    onprogress?: EventHandlerUnion<T, ProgressEvent> | undefined;
    onratechange?: EventHandlerUnion<T, Event> | undefined;
    onreset?: EventHandlerUnion<T, Event> | undefined;
    onscroll?: EventHandlerUnion<T, Event> | undefined;
    onscrollend?: EventHandlerUnion<T, Event> | undefined;
    onseeked?: EventHandlerUnion<T, Event> | undefined;
    onseeking?: EventHandlerUnion<T, Event> | undefined;
    onselect?: EventHandlerUnion<T, Event> | undefined;
    onstalled?: EventHandlerUnion<T, Event> | undefined;
    onsubmit?: EventHandlerUnion<T, SubmitEvent> | undefined;
    onsuspend?: EventHandlerUnion<T, Event> | undefined;
    ontimeupdate?: EventHandlerUnion<T, Event> | undefined;
    ontoggle?: EventHandlerUnion<T, ToggleEvent> | undefined;
    ontouchcancel?: EventHandlerUnion<T, TouchEvent> | undefined;
    ontouchend?: EventHandlerUnion<T, TouchEvent> | undefined;
    ontouchmove?: EventHandlerUnion<T, TouchEvent> | undefined;
    ontouchstart?: EventHandlerUnion<T, TouchEvent> | undefined;
    ontransitionstart?: EventHandlerUnion<T, TransitionEvent> | undefined;
    ontransitionend?: EventHandlerUnion<T, TransitionEvent> | undefined;
    ontransitionrun?: EventHandlerUnion<T, TransitionEvent> | undefined;
    ontransitioncancel?: EventHandlerUnion<T, TransitionEvent> | undefined;
    onvolumechange?: EventHandlerUnion<T, Event> | undefined;
    onwaiting?: EventHandlerUnion<T, Event> | undefined;
    onwheel?: EventHandlerUnion<T, WheelEvent> | undefined;
  }
  interface CustomEventHandlersNamespaced<T> {
    "on:abort"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:animationend"?: EventHandlerWithOptionsUnion<T, AnimationEvent> | undefined;
    "on:animationiteration"?: EventHandlerWithOptionsUnion<T, AnimationEvent> | undefined;
    "on:animationstart"?: EventHandlerWithOptionsUnion<T, AnimationEvent> | undefined;
    "on:auxclick"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:beforeinput"?:
      | EventHandlerWithOptionsUnion<T, InputEvent, InputEventHandler<T, InputEvent>>
      | undefined;
    "on:beforetoggle"?: EventHandlerWithOptionsUnion<T, ToggleEvent> | undefined;
    "on:blur"?:
      | EventHandlerWithOptionsUnion<T, FocusEvent, FocusEventHandler<T, FocusEvent>>
      | undefined;
    "on:canplay"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:canplaythrough"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:change"?: EventHandlerWithOptionsUnion<T, Event, ChangeEventHandler<T, Event>> | undefined;
    "on:click"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:contextmenu"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:dblclick"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:drag"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:dragend"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:dragenter"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:dragleave"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:dragover"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:dragstart"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:drop"?: EventHandlerWithOptionsUnion<T, DragEvent> | undefined;
    "on:durationchange"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:emptied"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:ended"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:error"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:focus"?:
      | EventHandlerWithOptionsUnion<T, FocusEvent, FocusEventHandler<T, FocusEvent>>
      | undefined;
    "on:gotpointercapture"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:input"?:
      | EventHandlerWithOptionsUnion<T, InputEvent, InputEventHandler<T, InputEvent>>
      | undefined;
    "on:invalid"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:keydown"?: EventHandlerWithOptionsUnion<T, KeyboardEvent> | undefined;
    "on:keypress"?: EventHandlerWithOptionsUnion<T, KeyboardEvent> | undefined;
    "on:keyup"?: EventHandlerWithOptionsUnion<T, KeyboardEvent> | undefined;
    "on:load"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:loadeddata"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:loadedmetadata"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:loadstart"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:lostpointercapture"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:mousedown"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mouseenter"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mouseleave"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mousemove"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mouseout"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mouseover"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:mouseup"?: EventHandlerWithOptionsUnion<T, MouseEvent> | undefined;
    "on:pause"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:play"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:playing"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:pointercancel"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerdown"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerenter"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerleave"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointermove"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerout"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerover"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:pointerup"?: EventHandlerWithOptionsUnion<T, PointerEvent> | undefined;
    "on:progress"?: EventHandlerWithOptionsUnion<T, ProgressEvent> | undefined;
    "on:ratechange"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:reset"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:scroll"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:scrollend"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:seeked"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:seeking"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:select"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:stalled"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:submit"?: EventHandlerWithOptionsUnion<T, SubmitEvent> | undefined;
    "on:suspend"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:timeupdate"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:toggle"?: EventHandlerWithOptionsUnion<T, ToggleEvent> | undefined;
    "on:touchcancel"?: EventHandlerWithOptionsUnion<T, TouchEvent> | undefined;
    "on:touchend"?: EventHandlerWithOptionsUnion<T, TouchEvent> | undefined;
    "on:touchmove"?: EventHandlerWithOptionsUnion<T, TouchEvent> | undefined;
    "on:touchstart"?: EventHandlerWithOptionsUnion<T, TouchEvent> | undefined;
    "on:transitionstart"?: EventHandlerWithOptionsUnion<T, TransitionEvent> | undefined;
    "on:transitionend"?: EventHandlerWithOptionsUnion<T, TransitionEvent> | undefined;
    "on:transitionrun"?: EventHandlerWithOptionsUnion<T, TransitionEvent> | undefined;
    "on:transitioncancel"?: EventHandlerWithOptionsUnion<T, TransitionEvent> | undefined;
    "on:volumechange"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:waiting"?: EventHandlerWithOptionsUnion<T, Event> | undefined;
    "on:wheel"?: EventHandlerWithOptionsUnion<T, WheelEvent> | undefined;
  }

  interface CSSProperties extends csstype.PropertiesHyphen {
    // Override
    [key: \`-\${string}\`]: string | number | undefined;
  }

  type HTMLAutocapitalize = "off" | "none" | "on" | "sentences" | "words" | "characters";
  type HTMLDir = "ltr" | "rtl" | "auto";
  type HTMLFormEncType = "application/x-www-form-urlencoded" | "multipart/form-data" | "text/plain";
  type HTMLFormMethod = "post" | "get" | "dialog";
  type HTMLCrossorigin = "anonymous" | "use-credentials" | "";
  type HTMLReferrerPolicy =
    | "no-referrer"
    | "no-referrer-when-downgrade"
    | "origin"
    | "origin-when-cross-origin"
    | "same-origin"
    | "strict-origin"
    | "strict-origin-when-cross-origin"
    | "unsafe-url";
  type HTMLIframeSandbox =
    | "allow-downloads-without-user-activation"
    | "allow-downloads"
    | "allow-forms"
    | "allow-modals"
    | "allow-orientation-lock"
    | "allow-pointer-lock"
    | "allow-popups"
    | "allow-popups-to-escape-sandbox"
    | "allow-presentation"
    | "allow-same-origin"
    | "allow-scripts"
    | "allow-storage-access-by-user-activation"
    | "allow-top-navigation"
    | "allow-top-navigation-by-user-activation"
    | "allow-top-navigation-to-custom-protocols";
  type HTMLLinkAs =
    | "audio"
    | "document"
    | "embed"
    | "fetch"
    | "font"
    | "image"
    | "object"
    | "script"
    | "style"
    | "track"
    | "video"
    | "worker";

  // All the WAI-ARIA 1.1 attributes from https://www.w3.org/TR/wai-aria-1.1/
  interface AriaAttributes {
    /**
     * Identifies the currently active element when DOM focus is on a composite widget, textbox,
     * group, or application.
     */
    "aria-activedescendant"?: string | undefined;
    /**
     * Indicates whether assistive technologies will present all, or only parts of, the changed
     * region based on the change notifications defined by the aria-relevant attribute.
     */
    "aria-atomic"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates whether inputting text could trigger display of one or more predictions of the
     * user's intended value for an input and specifies how predictions would be presented if they
     * are made.
     */
    "aria-autocomplete"?: "none" | "inline" | "list" | "both" | undefined;
    /**
     * Indicates an element is being modified and that assistive technologies MAY want to wait until
     * the modifications are complete before exposing them to the user.
     */
    "aria-busy"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates the current "checked" state of checkboxes, radio buttons, and other widgets.
     *
     * @see aria-pressed @see aria-selected.
     */
    "aria-checked"?: boolean | "false" | "mixed" | "true" | undefined;
    /**
     * Defines the total number of columns in a table, grid, or treegrid.
     *
     * @see aria-colindex.
     */
    "aria-colcount"?: number | string | undefined;
    /**
     * Defines an element's column index or position with respect to the total number of columns
     * within a table, grid, or treegrid.
     *
     * @see aria-colcount @see aria-colspan.
     */
    "aria-colindex"?: number | string | undefined;
    /**
     * Defines the number of columns spanned by a cell or gridcell within a table, grid, or
     * treegrid.
     *
     * @see aria-colindex @see aria-rowspan.
     */
    "aria-colspan"?: number | string | undefined;
    /**
     * Identifies the element (or elements) whose contents or presence are controlled by the current
     * element.
     *
     * @see aria-owns.
     */
    "aria-controls"?: string | undefined;
    /**
     * Indicates the element that represents the current item within a container or set of related
     * elements.
     */
    "aria-current"?:
      | boolean
      | "false"
      | "true"
      | "page"
      | "step"
      | "location"
      | "date"
      | "time"
      | undefined;
    /**
     * Identifies the element (or elements) that describes the object.
     *
     * @see aria-labelledby
     */
    "aria-describedby"?: string | undefined;
    /**
     * Identifies the element that provides a detailed, extended description for the object.
     *
     * @see aria-describedby.
     */
    "aria-details"?: string | undefined;
    /**
     * Indicates that the element is perceivable but disabled, so it is not editable or otherwise
     * operable.
     *
     * @see aria-hidden @see aria-readonly.
     */
    "aria-disabled"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates what functions can be performed when a dragged object is released on the drop
     * target.
     *
     * @deprecated In ARIA 1.1
     */
    "aria-dropeffect"?: "none" | "copy" | "execute" | "link" | "move" | "popup" | undefined;
    /**
     * Identifies the element that provides an error message for the object.
     *
     * @see aria-invalid @see aria-describedby.
     */
    "aria-errormessage"?: string | undefined;
    /**
     * Indicates whether the element, or another grouping element it controls, is currently expanded
     * or collapsed.
     */
    "aria-expanded"?: boolean | "false" | "true" | undefined;
    /**
     * Identifies the next element (or elements) in an alternate reading order of content which, at
     * the user's discretion, allows assistive technology to override the general default of reading
     * in document source order.
     */
    "aria-flowto"?: string | undefined;
    /**
     * Indicates an element's "grabbed" state in a drag-and-drop operation.
     *
     * @deprecated In ARIA 1.1
     */
    "aria-grabbed"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates the availability and type of interactive popup element, such as menu or dialog,
     * that can be triggered by an element.
     */
    "aria-haspopup"?:
      | boolean
      | "false"
      | "true"
      | "menu"
      | "listbox"
      | "tree"
      | "grid"
      | "dialog"
      | undefined;
    /**
     * Indicates whether the element is exposed to an accessibility API.
     *
     * @see aria-disabled.
     */
    "aria-hidden"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates the entered value does not conform to the format expected by the application.
     *
     * @see aria-errormessage.
     */
    "aria-invalid"?: boolean | "false" | "true" | "grammar" | "spelling" | undefined;
    /**
     * Indicates keyboard shortcuts that an author has implemented to activate or give focus to an
     * element.
     */
    "aria-keyshortcuts"?: string | undefined;
    /**
     * Defines a string value that labels the current element.
     *
     * @see aria-labelledby.
     */
    "aria-label"?: string | undefined;
    /**
     * Identifies the element (or elements) that labels the current element.
     *
     * @see aria-describedby.
     */
    "aria-labelledby"?: string | undefined;
    /** Defines the hierarchical level of an element within a structure. */
    "aria-level"?: number | string | undefined;
    /**
     * Indicates that an element will be updated, and describes the types of updates the user
     * agents, assistive technologies, and user can expect from the live region.
     */
    "aria-live"?: "off" | "assertive" | "polite" | undefined;
    /** Indicates whether an element is modal when displayed. */
    "aria-modal"?: boolean | "false" | "true" | undefined;
    /** Indicates whether a text box accepts multiple lines of input or only a single line. */
    "aria-multiline"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates that the user may select more than one item from the current selectable
     * descendants.
     */
    "aria-multiselectable"?: boolean | "false" | "true" | undefined;
    /** Indicates whether the element's orientation is horizontal, vertical, or unknown/ambiguous. */
    "aria-orientation"?: "horizontal" | "vertical" | undefined;
    /**
     * Identifies an element (or elements) in order to define a visual, functional, or contextual
     * parent/child relationship between DOM elements where the DOM hierarchy cannot be used to
     * represent the relationship.
     *
     * @see aria-controls.
     */
    "aria-owns"?: string | undefined;
    /**
     * Defines a short hint (a word or short phrase) intended to aid the user with data entry when
     * the control has no value. A hint could be a sample value or a brief description of the
     * expected format.
     */
    "aria-placeholder"?: string | undefined;
    /**
     * Defines an element's number or position in the current set of listitems or treeitems. Not
     * required if all elements in the set are present in the DOM.
     *
     * @see aria-setsize.
     */
    "aria-posinset"?: number | string | undefined;
    /**
     * Indicates the current "pressed" state of toggle buttons.
     *
     * @see aria-checked @see aria-selected.
     */
    "aria-pressed"?: boolean | "false" | "mixed" | "true" | undefined;
    /**
     * Indicates that the element is not editable, but is otherwise operable.
     *
     * @see aria-disabled.
     */
    "aria-readonly"?: boolean | "false" | "true" | undefined;
    /**
     * Indicates what notifications the user agent will trigger when the accessibility tree within a
     * live region is modified.
     *
     * @see aria-atomic.
     */
    "aria-relevant"?:
      | "additions"
      | "additions removals"
      | "additions text"
      | "all"
      | "removals"
      | "removals additions"
      | "removals text"
      | "text"
      | "text additions"
      | "text removals"
      | undefined;
    /** Indicates that user input is required on the element before a form may be submitted. */
    "aria-required"?: boolean | "false" | "true" | undefined;
    /** Defines a human-readable, author-localized description for the role of an element. */
    "aria-roledescription"?: string | undefined;
    /**
     * Defines the total number of rows in a table, grid, or treegrid.
     *
     * @see aria-rowindex.
     */
    "aria-rowcount"?: number | string | undefined;
    /**
     * Defines an element's row index or position with respect to the total number of rows within a
     * table, grid, or treegrid.
     *
     * @see aria-rowcount @see aria-rowspan.
     */
    "aria-rowindex"?: number | string | undefined;
    /**
     * Defines the number of rows spanned by a cell or gridcell within a table, grid, or treegrid.
     *
     * @see aria-rowindex @see aria-colspan.
     */
    "aria-rowspan"?: number | string | undefined;
    /**
     * Indicates the current "selected" state of various widgets.
     *
     * @see aria-checked @see aria-pressed.
     */
    "aria-selected"?: boolean | "false" | "true" | undefined;
    /**
     * Defines the number of items in the current set of listitems or treeitems. Not required if all
     * elements in the set are present in the DOM.
     *
     * @see aria-posinset.
     */
    "aria-setsize"?: number | string | undefined;
    /** Indicates if items in a table or grid are sorted in ascending or descending order. */
    "aria-sort"?: "none" | "ascending" | "descending" | "other" | undefined;
    /** Defines the maximum allowed value for a range widget. */
    "aria-valuemax"?: number | string | undefined;
    /** Defines the minimum allowed value for a range widget. */
    "aria-valuemin"?: number | string | undefined;
    /**
     * Defines the current value for a range widget.
     *
     * @see aria-valuetext.
     */
    "aria-valuenow"?: number | string | undefined;
    /** Defines the human readable text alternative of aria-valuenow for a range widget. */
    "aria-valuetext"?: string | undefined;
    role?:
      | "alert"
      | "alertdialog"
      | "application"
      | "article"
      | "banner"
      | "button"
      | "cell"
      | "checkbox"
      | "columnheader"
      | "combobox"
      | "complementary"
      | "contentinfo"
      | "definition"
      | "dialog"
      | "directory"
      | "document"
      | "feed"
      | "figure"
      | "form"
      | "grid"
      | "gridcell"
      | "group"
      | "heading"
      | "img"
      | "link"
      | "list"
      | "listbox"
      | "listitem"
      | "log"
      | "main"
      | "marquee"
      | "math"
      | "menu"
      | "menubar"
      | "menuitem"
      | "menuitemcheckbox"
      | "menuitemradio"
      | "meter"
      | "navigation"
      | "none"
      | "note"
      | "option"
      | "presentation"
      | "progressbar"
      | "radio"
      | "radiogroup"
      | "region"
      | "row"
      | "rowgroup"
      | "rowheader"
      | "scrollbar"
      | "search"
      | "searchbox"
      | "separator"
      | "slider"
      | "spinbutton"
      | "status"
      | "switch"
      | "tab"
      | "table"
      | "tablist"
      | "tabpanel"
      | "term"
      | "textbox"
      | "timer"
      | "toolbar"
      | "tooltip"
      | "tree"
      | "treegrid"
      | "treeitem"
      | undefined;
  }

  // TODO: Should we allow this?
  // type ClassKeys = \`class:\${string}\`;
  // type CSSKeys = Exclude<keyof csstype.PropertiesHyphen, \`-\${string}\`>;

  // type CSSAttributes = {
  //   [key in CSSKeys as \`style:\${key}\`]: csstype.PropertiesHyphen[key];
  // };

  interface HTMLAttributes<T> extends AriaAttributes, DOMAttributes<T> {
    // [key: ClassKeys]: boolean;
    accessKey?: string | undefined;
    class?: string | undefined;
    contenteditable?: boolean | "plaintext-only" | "inherit" | undefined;
    contextmenu?: string | undefined;
    dir?: HTMLDir | undefined;
    draggable?: boolean | "false" | "true" | undefined;
    hidden?: boolean | "hidden" | "until-found" | undefined;
    id?: string | undefined;
    is?: string | undefined;
    inert?: boolean | undefined;
    lang?: string | undefined;
    spellcheck?: boolean | undefined;
    style?: CSSProperties | string | undefined;
    tabindex?: number | string | undefined;
    title?: string | undefined;
    translate?: "yes" | "no" | undefined;
    about?: string | undefined;
    datatype?: string | undefined;
    inlist?: any | undefined;
    popover?: boolean | "manual" | "auto" | undefined;
    prefix?: string | undefined;
    property?: string | undefined;
    resource?: string | undefined;
    typeof?: string | undefined;
    vocab?: string | undefined;
    autocapitalize?: HTMLAutocapitalize | undefined;
    slot?: string | undefined;
    color?: string | undefined;
    itemprop?: string | undefined;
    itemscope?: boolean | undefined;
    itemtype?: string | undefined;
    itemid?: string | undefined;
    itemref?: string | undefined;
    part?: string | undefined;
    exportparts?: string | undefined;
    inputmode?:
      | "none"
      | "text"
      | "tel"
      | "url"
      | "email"
      | "numeric"
      | "decimal"
      | "search"
      | undefined;
    contentEditable?: boolean | "plaintext-only" | "inherit" | undefined;
    contextMenu?: string | undefined;
    tabIndex?: number | string | undefined;
    autoCapitalize?: HTMLAutocapitalize | undefined;
    itemProp?: string | undefined;
    itemScope?: boolean | undefined;
    itemType?: string | undefined;
    itemId?: string | undefined;
    itemRef?: string | undefined;
    exportParts?: string | undefined;
    inputMode?:
      | "none"
      | "text"
      | "tel"
      | "url"
      | "email"
      | "numeric"
      | "decimal"
      | "search"
      | undefined;
  }
  interface AnchorHTMLAttributes<T> extends HTMLAttributes<T> {
    download?: any | undefined;
    href?: string | undefined;
    hreflang?: string | undefined;
    media?: string | undefined;
    ping?: string | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    rel?: string | undefined;
    target?: string | undefined;
    type?: string | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
  }
  interface AudioHTMLAttributes<T> extends MediaHTMLAttributes<T> {}
  interface AreaHTMLAttributes<T> extends HTMLAttributes<T> {
    alt?: string | undefined;
    coords?: string | undefined;
    download?: any | undefined;
    href?: string | undefined;
    hreflang?: string | undefined;
    ping?: string | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    rel?: string | undefined;
    shape?: "rect" | "circle" | "poly" | "default" | undefined;
    target?: string | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
  }
  interface BaseHTMLAttributes<T> extends HTMLAttributes<T> {
    href?: string | undefined;
    target?: string | undefined;
  }
  interface BlockquoteHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: string | undefined;
  }
  interface ButtonHTMLAttributes<T> extends HTMLAttributes<T> {
    autofocus?: boolean | undefined;
    disabled?: boolean | undefined;
    form?: string | undefined;
    formaction?: string | SerializableAttributeValue | undefined;
    formenctype?: HTMLFormEncType | undefined;
    formmethod?: HTMLFormMethod | undefined;
    formnovalidate?: boolean | undefined;
    formtarget?: string | undefined;
    popovertarget?: string | undefined;
    popovertargetaction?: "hide" | "show" | "toggle" | undefined;
    name?: string | undefined;
    type?: "submit" | "reset" | "button" | undefined;
    value?: string | undefined;
    formAction?: string | SerializableAttributeValue | undefined;
    formEnctype?: HTMLFormEncType | undefined;
    formMethod?: HTMLFormMethod | undefined;
    formNoValidate?: boolean | undefined;
    formTarget?: string | undefined;
    popoverTarget?: string | undefined;
    popoverTargetAction?: "hide" | "show" | "toggle" | undefined;
  }
  interface CanvasHTMLAttributes<T> extends HTMLAttributes<T> {
    width?: number | string | undefined;
    height?: number | string | undefined;
  }
  interface ColHTMLAttributes<T> extends HTMLAttributes<T> {
    span?: number | string | undefined;
    width?: number | string | undefined;
  }
  interface ColgroupHTMLAttributes<T> extends HTMLAttributes<T> {
    span?: number | string | undefined;
  }
  interface DataHTMLAttributes<T> extends HTMLAttributes<T> {
    value?: string | string[] | number | undefined;
  }
  interface DetailsHtmlAttributes<T> extends HTMLAttributes<T> {
    open?: boolean | undefined;
    onToggle?: EventHandlerUnion<T, Event> | undefined;
    ontoggle?: EventHandlerUnion<T, Event> | undefined;
  }
  interface DialogHtmlAttributes<T> extends HTMLAttributes<T> {
    open?: boolean | undefined;
    onClose?: EventHandlerUnion<T, Event> | undefined;
    onCancel?: EventHandlerUnion<T, Event> | undefined;
  }
  interface EmbedHTMLAttributes<T> extends HTMLAttributes<T> {
    height?: number | string | undefined;
    src?: string | undefined;
    type?: string | undefined;
    width?: number | string | undefined;
  }
  interface FieldsetHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: boolean | undefined;
    form?: string | undefined;
    name?: string | undefined;
  }
  interface FormHTMLAttributes<T> extends HTMLAttributes<T> {
    "accept-charset"?: string | undefined;
    action?: string | SerializableAttributeValue | undefined;
    autocomplete?: string | undefined;
    encoding?: HTMLFormEncType | undefined;
    enctype?: HTMLFormEncType | undefined;
    method?: HTMLFormMethod | undefined;
    name?: string | undefined;
    novalidate?: boolean | undefined;
    target?: string | undefined;
    noValidate?: boolean | undefined;
  }
  interface IframeHTMLAttributes<T> extends HTMLAttributes<T> {
    allow?: string | undefined;
    allowfullscreen?: boolean | undefined;
    height?: number | string | undefined;
    loading?: "eager" | "lazy" | undefined;
    name?: string | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    sandbox?: HTMLIframeSandbox | string | undefined;
    src?: string | undefined;
    srcdoc?: string | undefined;
    width?: number | string | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
  }
  interface ImgHTMLAttributes<T> extends HTMLAttributes<T> {
    alt?: string | undefined;
    crossorigin?: HTMLCrossorigin | undefined;
    decoding?: "sync" | "async" | "auto" | undefined;
    height?: number | string | undefined;
    ismap?: boolean | undefined;
    isMap?: boolean | undefined;
    loading?: "eager" | "lazy" | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
    sizes?: string | undefined;
    src?: string | undefined;
    srcset?: string | undefined;
    srcSet?: string | undefined;
    usemap?: string | undefined;
    useMap?: string | undefined;
    width?: number | string | undefined;
    crossOrigin?: HTMLCrossorigin | undefined;
    elementtiming?: string | undefined;
    fetchpriority?: "high" | "low" | "auto" | undefined;
  }
  interface InputHTMLAttributes<T> extends HTMLAttributes<T> {
    accept?: string | undefined;
    alt?: string | undefined;
    autocomplete?: string | undefined;
    autocorrect?: "on" | "off" | undefined;
    autofocus?: boolean | undefined;
    capture?: boolean | string | undefined;
    checked?: boolean | undefined;
    crossorigin?: HTMLCrossorigin | undefined;
    disabled?: boolean | undefined;
    enterkeyhint?: "enter" | "done" | "go" | "next" | "previous" | "search" | "send" | undefined;
    form?: string | undefined;
    formaction?: string | SerializableAttributeValue | undefined;
    formenctype?: HTMLFormEncType | undefined;
    formmethod?: HTMLFormMethod | undefined;
    formnovalidate?: boolean | undefined;
    formtarget?: string | undefined;
    height?: number | string | undefined;
    incremental?: boolean | undefined;
    list?: string | undefined;
    max?: number | string | undefined;
    maxlength?: number | string | undefined;
    min?: number | string | undefined;
    minlength?: number | string | undefined;
    multiple?: boolean | undefined;
    name?: string | undefined;
    pattern?: string | undefined;
    placeholder?: string | undefined;
    readonly?: boolean | undefined;
    results?: number | undefined;
    required?: boolean | undefined;
    size?: number | string | undefined;
    src?: string | undefined;
    step?: number | string | undefined;
    type?: string | undefined;
    value?: string | string[] | number | undefined;
    width?: number | string | undefined;
    crossOrigin?: HTMLCrossorigin | undefined;
    formAction?: string | SerializableAttributeValue | undefined;
    formEnctype?: HTMLFormEncType | undefined;
    formMethod?: HTMLFormMethod | undefined;
    formNoValidate?: boolean | undefined;
    formTarget?: string | undefined;
    maxLength?: number | string | undefined;
    minLength?: number | string | undefined;
    readOnly?: boolean | undefined;
  }
  interface InsHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: string | undefined;
    dateTime?: string | undefined;
  }
  interface KeygenHTMLAttributes<T> extends HTMLAttributes<T> {
    autofocus?: boolean | undefined;
    challenge?: string | undefined;
    disabled?: boolean | undefined;
    form?: string | undefined;
    keytype?: string | undefined;
    keyparams?: string | undefined;
    name?: string | undefined;
  }
  interface LabelHTMLAttributes<T> extends HTMLAttributes<T> {
    for?: string | undefined;
    form?: string | undefined;
  }
  interface LiHTMLAttributes<T> extends HTMLAttributes<T> {
    value?: number | string | undefined;
  }
  interface LinkHTMLAttributes<T> extends HTMLAttributes<T> {
    as?: HTMLLinkAs | undefined;
    crossorigin?: HTMLCrossorigin | undefined;
    disabled?: boolean | undefined;
    fetchpriority?: "high" | "low" | "auto" | undefined;
    href?: string | undefined;
    hreflang?: string | undefined;
    imagesizes?: string | undefined;
    imagesrcset?: string | undefined;
    integrity?: string | undefined;
    media?: string | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    rel?: string | undefined;
    sizes?: string | undefined;
    type?: string | undefined;
    crossOrigin?: HTMLCrossorigin | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
  }
  interface MapHTMLAttributes<T> extends HTMLAttributes<T> {
    name?: string | undefined;
  }
  interface MediaHTMLAttributes<T> extends HTMLAttributes<T> {
    autoplay?: boolean | undefined;
    controls?: boolean | undefined;
    crossorigin?: HTMLCrossorigin | undefined;
    loop?: boolean | undefined;
    mediagroup?: string | undefined;
    muted?: boolean | undefined;
    preload?: "none" | "metadata" | "auto" | "" | undefined;
    src?: string | undefined;
    crossOrigin?: HTMLCrossorigin | undefined;
    mediaGroup?: string | undefined;
  }
  interface MenuHTMLAttributes<T> extends HTMLAttributes<T> {
    label?: string | undefined;
    type?: "context" | "toolbar" | undefined;
  }
  interface MetaHTMLAttributes<T> extends HTMLAttributes<T> {
    charset?: string | undefined;
    content?: string | undefined;
    "http-equiv"?: string | undefined;
    name?: string | undefined;
    media?: string | undefined;
  }
  interface MeterHTMLAttributes<T> extends HTMLAttributes<T> {
    form?: string | undefined;
    high?: number | string | undefined;
    low?: number | string | undefined;
    max?: number | string | undefined;
    min?: number | string | undefined;
    optimum?: number | string | undefined;
    value?: string | string[] | number | undefined;
  }
  interface QuoteHTMLAttributes<T> extends HTMLAttributes<T> {
    cite?: string | undefined;
  }
  interface ObjectHTMLAttributes<T> extends HTMLAttributes<T> {
    data?: string | undefined;
    form?: string | undefined;
    height?: number | string | undefined;
    name?: string | undefined;
    type?: string | undefined;
    usemap?: string | undefined;
    width?: number | string | undefined;
    useMap?: string | undefined;
  }
  interface OlHTMLAttributes<T> extends HTMLAttributes<T> {
    reversed?: boolean | undefined;
    start?: number | string | undefined;
    type?: "1" | "a" | "A" | "i" | "I" | undefined;
  }
  interface OptgroupHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: boolean | undefined;
    label?: string | undefined;
  }
  interface OptionHTMLAttributes<T> extends HTMLAttributes<T> {
    disabled?: boolean | undefined;
    label?: string | undefined;
    selected?: boolean | undefined;
    value?: string | string[] | number | undefined;
  }
  interface OutputHTMLAttributes<T> extends HTMLAttributes<T> {
    form?: string | undefined;
    for?: string | undefined;
    name?: string | undefined;
  }
  interface ParamHTMLAttributes<T> extends HTMLAttributes<T> {
    name?: string | undefined;
    value?: string | string[] | number | undefined;
  }
  interface ProgressHTMLAttributes<T> extends HTMLAttributes<T> {
    max?: number | string | undefined;
    value?: string | string[] | number | undefined;
  }
  interface ScriptHTMLAttributes<T> extends HTMLAttributes<T> {
    async?: boolean | undefined;
    charset?: string | undefined;
    crossorigin?: HTMLCrossorigin | undefined;
    defer?: boolean | undefined;
    integrity?: string | undefined;
    nomodule?: boolean | undefined;
    nonce?: string | undefined;
    referrerpolicy?: HTMLReferrerPolicy | undefined;
    src?: string | undefined;
    type?: string | undefined;
    crossOrigin?: HTMLCrossorigin | undefined;
    noModule?: boolean | undefined;
    referrerPolicy?: HTMLReferrerPolicy | undefined;
  }
  interface SelectHTMLAttributes<T> extends HTMLAttributes<T> {
    autocomplete?: string | undefined;
    autofocus?: boolean | undefined;
    disabled?: boolean | undefined;
    form?: string | undefined;
    multiple?: boolean | undefined;
    name?: string | undefined;
    required?: boolean | undefined;
    size?: number | string | undefined;
    value?: string | string[] | number | undefined;
  }
  interface HTMLSlotElementAttributes<T = HTMLSlotElement> extends HTMLAttributes<T> {
    name?: string | undefined;
  }
  interface SourceHTMLAttributes<T> extends HTMLAttributes<T> {
    media?: string | undefined;
    sizes?: string | undefined;
    src?: string | undefined;
    srcset?: string | undefined;
    type?: string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
  }
  interface StyleHTMLAttributes<T> extends HTMLAttributes<T> {
    media?: string | undefined;
    nonce?: string | undefined;
    scoped?: boolean | undefined;
    type?: string | undefined;
  }
  interface TdHTMLAttributes<T> extends HTMLAttributes<T> {
    colspan?: number | string | undefined;
    headers?: string | undefined;
    rowspan?: number | string | undefined;
    colSpan?: number | string | undefined;
    rowSpan?: number | string | undefined;
  }
  interface TemplateHTMLAttributes<T extends HTMLTemplateElement> extends HTMLAttributes<T> {
    content?: DocumentFragment | undefined;
  }
  interface TextareaHTMLAttributes<T> extends HTMLAttributes<T> {
    autocomplete?: string | undefined;
    autofocus?: boolean | undefined;
    cols?: number | string | undefined;
    dirname?: string | undefined;
    disabled?: boolean | undefined;
    enterkeyhint?: "enter" | "done" | "go" | "next" | "previous" | "search" | "send" | undefined;
    form?: string | undefined;
    maxlength?: number | string | undefined;
    minlength?: number | string | undefined;
    name?: string | undefined;
    placeholder?: string | undefined;
    readonly?: boolean | undefined;
    required?: boolean | undefined;
    rows?: number | string | undefined;
    value?: string | string[] | number | undefined;
    wrap?: "hard" | "soft" | "off" | undefined;
    maxLength?: number | string | undefined;
    minLength?: number | string | undefined;
    readOnly?: boolean | undefined;
  }
  interface ThHTMLAttributes<T> extends HTMLAttributes<T> {
    colspan?: number | string | undefined;
    headers?: string | undefined;
    rowspan?: number | string | undefined;
    colSpan?: number | string | undefined;
    rowSpan?: number | string | undefined;
    scope?: "col" | "row" | "rowgroup" | "colgroup" | undefined;
  }
  interface TimeHTMLAttributes<T> extends HTMLAttributes<T> {
    datetime?: string | undefined;
    dateTime?: string | undefined;
  }
  interface TrackHTMLAttributes<T> extends HTMLAttributes<T> {
    default?: boolean | undefined;
    kind?: "subtitles" | "captions" | "descriptions" | "chapters" | "metadata" | undefined;
    label?: string | undefined;
    src?: string | undefined;
    srclang?: string | undefined;
  }
  interface VideoHTMLAttributes<T> extends MediaHTMLAttributes<T> {
    height?: number | string | undefined;
    playsinline?: boolean | undefined;
    poster?: string | undefined;
    width?: number | string | undefined;
    disablepictureinpicture?: boolean;
  }
  type SVGPreserveAspectRatio =
    | "none"
    | "xMinYMin"
    | "xMidYMin"
    | "xMaxYMin"
    | "xMinYMid"
    | "xMidYMid"
    | "xMaxYMid"
    | "xMinYMax"
    | "xMidYMax"
    | "xMaxYMax"
    | "xMinYMin meet"
    | "xMidYMin meet"
    | "xMaxYMin meet"
    | "xMinYMid meet"
    | "xMidYMid meet"
    | "xMaxYMid meet"
    | "xMinYMax meet"
    | "xMidYMax meet"
    | "xMaxYMax meet"
    | "xMinYMin slice"
    | "xMidYMin slice"
    | "xMaxYMin slice"
    | "xMinYMid slice"
    | "xMidYMid slice"
    | "xMaxYMid slice"
    | "xMinYMax slice"
    | "xMidYMax slice"
    | "xMaxYMax slice";
  type ImagePreserveAspectRatio =
    | SVGPreserveAspectRatio
    | "defer none"
    | "defer xMinYMin"
    | "defer xMidYMin"
    | "defer xMaxYMin"
    | "defer xMinYMid"
    | "defer xMidYMid"
    | "defer xMaxYMid"
    | "defer xMinYMax"
    | "defer xMidYMax"
    | "defer xMaxYMax"
    | "defer xMinYMin meet"
    | "defer xMidYMin meet"
    | "defer xMaxYMin meet"
    | "defer xMinYMid meet"
    | "defer xMidYMid meet"
    | "defer xMaxYMid meet"
    | "defer xMinYMax meet"
    | "defer xMidYMax meet"
    | "defer xMaxYMax meet"
    | "defer xMinYMin slice"
    | "defer xMidYMin slice"
    | "defer xMaxYMin slice"
    | "defer xMinYMid slice"
    | "defer xMidYMid slice"
    | "defer xMaxYMid slice"
    | "defer xMinYMax slice"
    | "defer xMidYMax slice"
    | "defer xMaxYMax slice";
  type SVGUnits = "userSpaceOnUse" | "objectBoundingBox";
  interface CoreSVGAttributes<T> extends AriaAttributes, DOMAttributes<T> {
    id?: string | undefined;
    lang?: string | undefined;
    tabIndex?: number | string | undefined;
    tabindex?: number | string | undefined;
  }
  interface StylableSVGAttributes {
    class?: string | undefined;
    style?: CSSProperties | string | undefined;
  }
  interface TransformableSVGAttributes {
    transform?: string | undefined;
  }
  interface ConditionalProcessingSVGAttributes {
    requiredExtensions?: string | undefined;
    requiredFeatures?: string | undefined;
    systemLanguage?: string | undefined;
  }
  interface ExternalResourceSVGAttributes {
    externalResourcesRequired?: "true" | "false" | undefined;
  }
  interface AnimationTimingSVGAttributes {
    begin?: string | undefined;
    dur?: string | undefined;
    end?: string | undefined;
    min?: string | undefined;
    max?: string | undefined;
    restart?: "always" | "whenNotActive" | "never" | undefined;
    repeatCount?: number | "indefinite" | undefined;
    repeatDur?: string | undefined;
    fill?: "freeze" | "remove" | undefined;
  }
  interface AnimationValueSVGAttributes {
    calcMode?: "discrete" | "linear" | "paced" | "spline" | undefined;
    values?: string | undefined;
    keyTimes?: string | undefined;
    keySplines?: string | undefined;
    from?: number | string | undefined;
    to?: number | string | undefined;
    by?: number | string | undefined;
  }
  interface AnimationAdditionSVGAttributes {
    attributeName?: string | undefined;
    additive?: "replace" | "sum" | undefined;
    accumulate?: "none" | "sum" | undefined;
  }
  interface AnimationAttributeTargetSVGAttributes {
    attributeName?: string | undefined;
    attributeType?: "CSS" | "XML" | "auto" | undefined;
  }
  interface PresentationSVGAttributes {
    "alignment-baseline"?:
      | "auto"
      | "baseline"
      | "before-edge"
      | "text-before-edge"
      | "middle"
      | "central"
      | "after-edge"
      | "text-after-edge"
      | "ideographic"
      | "alphabetic"
      | "hanging"
      | "mathematical"
      | "inherit"
      | undefined;
    "baseline-shift"?: number | string | undefined;
    clip?: string | undefined;
    "clip-path"?: string | undefined;
    "clip-rule"?: "nonzero" | "evenodd" | "inherit" | undefined;
    color?: string | undefined;
    "color-interpolation"?: "auto" | "sRGB" | "linearRGB" | "inherit" | undefined;
    "color-interpolation-filters"?: "auto" | "sRGB" | "linearRGB" | "inherit" | undefined;
    "color-profile"?: string | undefined;
    "color-rendering"?: "auto" | "optimizeSpeed" | "optimizeQuality" | "inherit" | undefined;
    cursor?: string | undefined;
    direction?: "ltr" | "rtl" | "inherit" | undefined;
    display?: string | undefined;
    "dominant-baseline"?:
      | "auto"
      | "text-bottom"
      | "alphabetic"
      | "ideographic"
      | "middle"
      | "central"
      | "mathematical"
      | "hanging"
      | "text-top"
      | "inherit"
      | undefined;
    "enable-background"?: string | undefined;
    fill?: string | undefined;
    "fill-opacity"?: number | string | "inherit" | undefined;
    "fill-rule"?: "nonzero" | "evenodd" | "inherit" | undefined;
    filter?: string | undefined;
    "flood-color"?: string | undefined;
    "flood-opacity"?: number | string | "inherit" | undefined;
    "font-family"?: string | undefined;
    "font-size"?: string | undefined;
    "font-size-adjust"?: number | string | undefined;
    "font-stretch"?: string | undefined;
    "font-style"?: "normal" | "italic" | "oblique" | "inherit" | undefined;
    "font-variant"?: string | undefined;
    "font-weight"?: number | string | undefined;
    "glyph-orientation-horizontal"?: string | undefined;
    "glyph-orientation-vertical"?: string | undefined;
    "image-rendering"?: "auto" | "optimizeQuality" | "optimizeSpeed" | "inherit" | undefined;
    kerning?: string | undefined;
    "letter-spacing"?: number | string | undefined;
    "lighting-color"?: string | undefined;
    "marker-end"?: string | undefined;
    "marker-mid"?: string | undefined;
    "marker-start"?: string | undefined;
    mask?: string | undefined;
    opacity?: number | string | "inherit" | undefined;
    overflow?: "visible" | "hidden" | "scroll" | "auto" | "inherit" | undefined;
    pathLength?: string | number | undefined;
    "pointer-events"?:
      | "bounding-box"
      | "visiblePainted"
      | "visibleFill"
      | "visibleStroke"
      | "visible"
      | "painted"
      | "color"
      | "fill"
      | "stroke"
      | "all"
      | "none"
      | "inherit"
      | undefined;
    "shape-rendering"?:
      | "auto"
      | "optimizeSpeed"
      | "crispEdges"
      | "geometricPrecision"
      | "inherit"
      | undefined;
    "stop-color"?: string | undefined;
    "stop-opacity"?: number | string | "inherit" | undefined;
    stroke?: string | undefined;
    "stroke-dasharray"?: string | undefined;
    "stroke-dashoffset"?: number | string | undefined;
    "stroke-linecap"?: "butt" | "round" | "square" | "inherit" | undefined;
    "stroke-linejoin"?: "arcs" | "bevel" | "miter" | "miter-clip" | "round" | "inherit" | undefined;
    "stroke-miterlimit"?: number | string | "inherit" | undefined;
    "stroke-opacity"?: number | string | "inherit" | undefined;
    "stroke-width"?: number | string | undefined;
    "text-anchor"?: "start" | "middle" | "end" | "inherit" | undefined;
    "text-decoration"?:
      | "none"
      | "underline"
      | "overline"
      | "line-through"
      | "blink"
      | "inherit"
      | undefined;
    "text-rendering"?:
      | "auto"
      | "optimizeSpeed"
      | "optimizeLegibility"
      | "geometricPrecision"
      | "inherit"
      | undefined;
    "unicode-bidi"?: string | undefined;
    visibility?: "visible" | "hidden" | "collapse" | "inherit" | undefined;
    "word-spacing"?: number | string | undefined;
    "writing-mode"?: "lr-tb" | "rl-tb" | "tb-rl" | "lr" | "rl" | "tb" | "inherit" | undefined;
  }
  interface AnimationElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      ConditionalProcessingSVGAttributes {}
  interface ContainerElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "clip-path"
        | "mask"
        | "cursor"
        | "opacity"
        | "filter"
        | "enable-background"
        | "color-interpolation"
        | "color-rendering"
      > {}
  interface FilterPrimitiveElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<PresentationSVGAttributes, "color-interpolation-filters"> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    result?: string | undefined;
  }
  interface SingleInputFilterSVGAttributes {
    in?: string | undefined;
  }
  interface DoubleInputFilterSVGAttributes {
    in?: string | undefined;
    in2?: string | undefined;
  }
  interface FitToViewBoxSVGAttributes {
    viewBox?: string | undefined;
    preserveAspectRatio?: SVGPreserveAspectRatio | undefined;
  }
  interface GradientElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    gradientUnits?: SVGUnits | undefined;
    gradientTransform?: string | undefined;
    spreadMethod?: "pad" | "reflect" | "repeat" | undefined;
    href?: string | undefined;
  }
  interface GraphicsElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "clip-rule"
        | "mask"
        | "pointer-events"
        | "cursor"
        | "opacity"
        | "filter"
        | "display"
        | "visibility"
        | "color-interpolation"
        | "color-rendering"
      > {}
  interface LightSourceElementSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface NewViewportSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    viewBox?: string | undefined;
  }
  interface ShapeElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "color"
        | "fill"
        | "fill-rule"
        | "fill-opacity"
        | "stroke"
        | "stroke-width"
        | "stroke-linecap"
        | "stroke-linejoin"
        | "stroke-miterlimit"
        | "stroke-dasharray"
        | "stroke-dashoffset"
        | "stroke-opacity"
        | "shape-rendering"
        | "pathLength"
      > {}
  interface TextContentElementSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      Pick<
        PresentationSVGAttributes,
        | "font-family"
        | "font-style"
        | "font-variant"
        | "font-weight"
        | "font-stretch"
        | "font-size"
        | "font-size-adjust"
        | "kerning"
        | "letter-spacing"
        | "word-spacing"
        | "text-decoration"
        | "glyph-orientation-horizontal"
        | "glyph-orientation-vertical"
        | "direction"
        | "unicode-bidi"
        | "text-anchor"
        | "dominant-baseline"
        | "color"
        | "fill"
        | "fill-rule"
        | "fill-opacity"
        | "stroke"
        | "stroke-width"
        | "stroke-linecap"
        | "stroke-linejoin"
        | "stroke-miterlimit"
        | "stroke-dasharray"
        | "stroke-dashoffset"
        | "stroke-opacity"
      > {}
  interface ZoomAndPanSVGAttributes {
    zoomAndPan?: "disable" | "magnify" | undefined;
  }
  interface AnimateSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationAttributeTargetSVGAttributes,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes,
      Pick<PresentationSVGAttributes, "color-interpolation" | "color-rendering"> {}
  interface AnimateMotionSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes {
    path?: string | undefined;
    keyPoints?: string | undefined;
    rotate?: number | string | "auto" | "auto-reverse" | undefined;
    origin?: "default" | undefined;
  }
  interface AnimateTransformSVGAttributes<T>
    extends AnimationElementSVGAttributes<T>,
      AnimationAttributeTargetSVGAttributes,
      AnimationTimingSVGAttributes,
      AnimationValueSVGAttributes,
      AnimationAdditionSVGAttributes {
    type?: "translate" | "scale" | "rotate" | "skewX" | "skewY" | undefined;
  }
  interface CircleSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    cx?: number | string | undefined;
    cy?: number | string | undefined;
    r?: number | string | undefined;
  }
  interface ClipPathSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "clip-path"> {
    clipPathUnits?: SVGUnits | undefined;
  }
  interface DefsSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {}
  interface DescSVGAttributes<T> extends CoreSVGAttributes<T>, StylableSVGAttributes {}
  interface EllipseSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    cx?: number | string | undefined;
    cy?: number | string | undefined;
    rx?: number | string | undefined;
    ry?: number | string | undefined;
  }
  interface FeBlendSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    mode?: "normal" | "multiply" | "screen" | "darken" | "lighten" | undefined;
  }
  interface FeColorMatrixSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    type?: "matrix" | "saturate" | "hueRotate" | "luminanceToAlpha" | undefined;
    values?: string | undefined;
  }
  interface FeComponentTransferSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {}
  interface FeCompositeSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    operator?: "over" | "in" | "out" | "atop" | "xor" | "arithmetic" | undefined;
    k1?: number | string | undefined;
    k2?: number | string | undefined;
    k3?: number | string | undefined;
    k4?: number | string | undefined;
  }
  interface FeConvolveMatrixSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    order?: number | string | undefined;
    kernelMatrix?: string | undefined;
    divisor?: number | string | undefined;
    bias?: number | string | undefined;
    targetX?: number | string | undefined;
    targetY?: number | string | undefined;
    edgeMode?: "duplicate" | "wrap" | "none" | undefined;
    kernelUnitLength?: number | string | undefined;
    preserveAlpha?: "true" | "false" | undefined;
  }
  interface FeDiffuseLightingSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "lighting-color"> {
    surfaceScale?: number | string | undefined;
    diffuseConstant?: number | string | undefined;
    kernelUnitLength?: number | string | undefined;
  }
  interface FeDisplacementMapSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      DoubleInputFilterSVGAttributes,
      StylableSVGAttributes {
    scale?: number | string | undefined;
    xChannelSelector?: "R" | "G" | "B" | "A" | undefined;
    yChannelSelector?: "R" | "G" | "B" | "A" | undefined;
  }
  interface FeDistantLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    azimuth?: number | string | undefined;
    elevation?: number | string | undefined;
  }
  interface FeDropShadowSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "flood-color" | "flood-opacity"> {
    dx?: number | string | undefined;
    dy?: number | string | undefined;
    stdDeviation?: number | string | undefined;
  }
  interface FeFloodSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "flood-color" | "flood-opacity"> {}
  interface FeFuncSVGAttributes<T> extends CoreSVGAttributes<T> {
    type?: "identity" | "table" | "discrete" | "linear" | "gamma" | undefined;
    tableValues?: string | undefined;
    slope?: number | string | undefined;
    intercept?: number | string | undefined;
    amplitude?: number | string | undefined;
    exponent?: number | string | undefined;
    offset?: number | string | undefined;
  }
  interface FeGaussianBlurSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    stdDeviation?: number | string | undefined;
  }
  interface FeImageSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    preserveAspectRatio?: SVGPreserveAspectRatio | undefined;
    href?: string | undefined;
  }
  interface FeMergeSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes {}
  interface FeMergeNodeSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      SingleInputFilterSVGAttributes {}
  interface FeMorphologySVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    operator?: "erode" | "dilate" | undefined;
    radius?: number | string | undefined;
  }
  interface FeOffsetSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {
    dx?: number | string | undefined;
    dy?: number | string | undefined;
  }
  interface FePointLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    z?: number | string | undefined;
  }
  interface FeSpecularLightingSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "lighting-color"> {
    surfaceScale?: string | undefined;
    specularConstant?: string | undefined;
    specularExponent?: string | undefined;
    kernelUnitLength?: number | string | undefined;
  }
  interface FeSpotLightSVGAttributes<T> extends LightSourceElementSVGAttributes<T> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    z?: number | string | undefined;
    pointsAtX?: number | string | undefined;
    pointsAtY?: number | string | undefined;
    pointsAtZ?: number | string | undefined;
    specularExponent?: number | string | undefined;
    limitingConeAngle?: number | string | undefined;
  }
  interface FeTileSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      SingleInputFilterSVGAttributes,
      StylableSVGAttributes {}
  interface FeTurbulanceSVGAttributes<T>
    extends FilterPrimitiveElementSVGAttributes<T>,
      StylableSVGAttributes {
    baseFrequency?: number | string | undefined;
    numOctaves?: number | string | undefined;
    seed?: number | string | undefined;
    stitchTiles?: "stitch" | "noStitch" | undefined;
    type?: "fractalNoise" | "turbulence" | undefined;
  }
  interface FilterSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    filterUnits?: SVGUnits | undefined;
    primitiveUnits?: SVGUnits | undefined;
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    filterRes?: number | string | undefined;
  }
  interface ForeignObjectSVGAttributes<T>
    extends NewViewportSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
  }
  interface GSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {}
  interface ImageSVGAttributes<T>
    extends NewViewportSVGAttributes<T>,
      GraphicsElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "color-profile" | "image-rendering"> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    preserveAspectRatio?: ImagePreserveAspectRatio | undefined;
    href?: string | undefined;
  }
  interface LineSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    x1?: number | string | undefined;
    y1?: number | string | undefined;
    x2?: number | string | undefined;
    y2?: number | string | undefined;
  }
  interface LinearGradientSVGAttributes<T> extends GradientElementSVGAttributes<T> {
    x1?: number | string | undefined;
    x2?: number | string | undefined;
    y1?: number | string | undefined;
    y2?: number | string | undefined;
  }
  interface MarkerSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    markerUnits?: "strokeWidth" | "userSpaceOnUse" | undefined;
    refX?: number | string | undefined;
    refY?: number | string | undefined;
    markerWidth?: number | string | undefined;
    markerHeight?: number | string | undefined;
    orient?: string | undefined;
  }
  interface MaskSVGAttributes<T>
    extends Omit<ContainerElementSVGAttributes<T>, "opacity" | "filter">,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes {
    maskUnits?: SVGUnits | undefined;
    maskContentUnits?: SVGUnits | undefined;
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
  }
  interface MetadataSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface MPathSVGAttributes<T> extends CoreSVGAttributes<T> {}
  interface PathSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    d?: string | undefined;
    pathLength?: number | string | undefined;
  }
  interface PatternSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      Pick<PresentationSVGAttributes, "overflow" | "clip"> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    patternUnits?: SVGUnits | undefined;
    patternContentUnits?: SVGUnits | undefined;
    patternTransform?: string | undefined;
    href?: string | undefined;
  }
  interface PolygonSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    points?: string | undefined;
  }
  interface PolylineSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "marker-start" | "marker-mid" | "marker-end"> {
    points?: string | undefined;
  }
  interface RadialGradientSVGAttributes<T> extends GradientElementSVGAttributes<T> {
    cx?: number | string | undefined;
    cy?: number | string | undefined;
    r?: number | string | undefined;
    fx?: number | string | undefined;
    fy?: number | string | undefined;
  }
  interface RectSVGAttributes<T>
    extends GraphicsElementSVGAttributes<T>,
      ShapeElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    rx?: number | string | undefined;
    ry?: number | string | undefined;
  }
  interface SetSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      AnimationTimingSVGAttributes {}
  interface StopSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      Pick<PresentationSVGAttributes, "color" | "stop-color" | "stop-opacity"> {
    offset?: number | string | undefined;
  }
  interface SvgSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      NewViewportSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes,
      ZoomAndPanSVGAttributes,
      PresentationSVGAttributes {
    version?: string | undefined;
    baseProfile?: string | undefined;
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    contentScriptType?: string | undefined;
    contentStyleType?: string | undefined;
    xmlns?: string | undefined;
    "xmlns:xlink"?: string | undefined;
  }
  interface SwitchSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "display" | "visibility"> {}
  interface SymbolSVGAttributes<T>
    extends ContainerElementSVGAttributes<T>,
      NewViewportSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      FitToViewBoxSVGAttributes {
    width?: number | string | undefined;
    height?: number | string | undefined;
    preserveAspectRatio?: SVGPreserveAspectRatio | undefined;
    refX?: number | string | undefined;
    refY?: number | string | undefined;
    viewBox?: string | undefined;
    x?: number | string | undefined;
    y?: number | string | undefined;
  }
  interface TextSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      GraphicsElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      TransformableSVGAttributes,
      Pick<PresentationSVGAttributes, "writing-mode" | "text-rendering"> {
    x?: number | string | undefined;
    y?: number | string | undefined;
    dx?: number | string | undefined;
    dy?: number | string | undefined;
    rotate?: number | string | undefined;
    textLength?: number | string | undefined;
    lengthAdjust?: "spacing" | "spacingAndGlyphs" | undefined;
  }
  interface TextPathSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      Pick<
        PresentationSVGAttributes,
        "alignment-baseline" | "baseline-shift" | "display" | "visibility"
      > {
    startOffset?: number | string | undefined;
    method?: "align" | "stretch" | undefined;
    spacing?: "auto" | "exact" | undefined;
    href?: string | undefined;
  }
  interface TSpanSVGAttributes<T>
    extends TextContentElementSVGAttributes<T>,
      ConditionalProcessingSVGAttributes,
      ExternalResourceSVGAttributes,
      StylableSVGAttributes,
      Pick<
        PresentationSVGAttributes,
        "alignment-baseline" | "baseline-shift" | "display" | "visibility"
      > {
    x?: number | string | undefined;
    y?: number | string | undefined;
    dx?: number | string | undefined;
    dy?: number | string | undefined;
    rotate?: number | string | undefined;
    textLength?: number | string | undefined;
    lengthAdjust?: "spacing" | "spacingAndGlyphs" | undefined;
  }
  /** @see https://developer.mozilla.org/en-US/docs/Web/SVG/Element/use */
  interface UseSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      StylableSVGAttributes,
      ConditionalProcessingSVGAttributes,
      GraphicsElementSVGAttributes<T>,
      PresentationSVGAttributes,
      ExternalResourceSVGAttributes,
      TransformableSVGAttributes {
    x?: number | string | undefined;
    y?: number | string | undefined;
    width?: number | string | undefined;
    height?: number | string | undefined;
    href?: string | undefined;
  }
  interface ViewSVGAttributes<T>
    extends CoreSVGAttributes<T>,
      ExternalResourceSVGAttributes,
      FitToViewBoxSVGAttributes,
      ZoomAndPanSVGAttributes {
    viewTarget?: string | undefined;
  }
  /** @type {HTMLElementTagNameMap} */
  interface HTMLElementTags {
    a: AnchorHTMLAttributes<HTMLAnchorElement>;
    abbr: HTMLAttributes<HTMLElement>;
    address: HTMLAttributes<HTMLElement>;
    area: AreaHTMLAttributes<HTMLAreaElement>;
    article: HTMLAttributes<HTMLElement>;
    aside: HTMLAttributes<HTMLElement>;
    audio: AudioHTMLAttributes<HTMLAudioElement>;
    b: HTMLAttributes<HTMLElement>;
    base: BaseHTMLAttributes<HTMLBaseElement>;
    bdi: HTMLAttributes<HTMLElement>;
    bdo: HTMLAttributes<HTMLElement>;
    blockquote: BlockquoteHTMLAttributes<HTMLElement>;
    body: HTMLAttributes<HTMLBodyElement>;
    br: HTMLAttributes<HTMLBRElement>;
    button: ButtonHTMLAttributes<HTMLButtonElement>;
    canvas: CanvasHTMLAttributes<HTMLCanvasElement>;
    caption: HTMLAttributes<HTMLElement>;
    cite: HTMLAttributes<HTMLElement>;
    code: HTMLAttributes<HTMLElement>;
    col: ColHTMLAttributes<HTMLTableColElement>;
    colgroup: ColgroupHTMLAttributes<HTMLTableColElement>;
    data: DataHTMLAttributes<HTMLElement>;
    datalist: HTMLAttributes<HTMLDataListElement>;
    dd: HTMLAttributes<HTMLElement>;
    del: HTMLAttributes<HTMLElement>;
    details: DetailsHtmlAttributes<HTMLDetailsElement>;
    dfn: HTMLAttributes<HTMLElement>;
    dialog: DialogHtmlAttributes<HTMLDialogElement>;
    div: HTMLAttributes<HTMLDivElement>;
    dl: HTMLAttributes<HTMLDListElement>;
    dt: HTMLAttributes<HTMLElement>;
    em: HTMLAttributes<HTMLElement>;
    embed: EmbedHTMLAttributes<HTMLEmbedElement>;
    fieldset: FieldsetHTMLAttributes<HTMLFieldSetElement>;
    figcaption: HTMLAttributes<HTMLElement>;
    figure: HTMLAttributes<HTMLElement>;
    footer: HTMLAttributes<HTMLElement>;
    form: FormHTMLAttributes<HTMLFormElement>;
    h1: HTMLAttributes<HTMLHeadingElement>;
    h2: HTMLAttributes<HTMLHeadingElement>;
    h3: HTMLAttributes<HTMLHeadingElement>;
    h4: HTMLAttributes<HTMLHeadingElement>;
    h5: HTMLAttributes<HTMLHeadingElement>;
    h6: HTMLAttributes<HTMLHeadingElement>;
    head: HTMLAttributes<HTMLHeadElement>;
    header: HTMLAttributes<HTMLElement>;
    hgroup: HTMLAttributes<HTMLElement>;
    hr: HTMLAttributes<HTMLHRElement>;
    html: HTMLAttributes<HTMLHtmlElement>;
    i: HTMLAttributes<HTMLElement>;
    iframe: IframeHTMLAttributes<HTMLIFrameElement>;
    img: ImgHTMLAttributes<HTMLImageElement>;
    input: InputHTMLAttributes<HTMLInputElement>;
    ins: InsHTMLAttributes<HTMLModElement>;
    kbd: HTMLAttributes<HTMLElement>;
    label: LabelHTMLAttributes<HTMLLabelElement>;
    legend: HTMLAttributes<HTMLLegendElement>;
    li: LiHTMLAttributes<HTMLLIElement>;
    link: LinkHTMLAttributes<HTMLLinkElement>;
    main: HTMLAttributes<HTMLElement>;
    map: MapHTMLAttributes<HTMLMapElement>;
    mark: HTMLAttributes<HTMLElement>;
    menu: MenuHTMLAttributes<HTMLMenuElement>;
    meta: MetaHTMLAttributes<HTMLMetaElement>;
    meter: MeterHTMLAttributes<HTMLElement>;
    nav: HTMLAttributes<HTMLElement>;
    noscript: HTMLAttributes<HTMLElement>;
    object: ObjectHTMLAttributes<HTMLObjectElement>;
    ol: OlHTMLAttributes<HTMLOListElement>;
    optgroup: OptgroupHTMLAttributes<HTMLOptGroupElement>;
    option: OptionHTMLAttributes<HTMLOptionElement>;
    output: OutputHTMLAttributes<HTMLElement>;
    p: HTMLAttributes<HTMLParagraphElement>;
    picture: HTMLAttributes<HTMLElement>;
    pre: HTMLAttributes<HTMLPreElement>;
    progress: ProgressHTMLAttributes<HTMLProgressElement>;
    q: QuoteHTMLAttributes<HTMLQuoteElement>;
    rp: HTMLAttributes<HTMLElement>;
    rt: HTMLAttributes<HTMLElement>;
    ruby: HTMLAttributes<HTMLElement>;
    s: HTMLAttributes<HTMLElement>;
    samp: HTMLAttributes<HTMLElement>;
    script: ScriptHTMLAttributes<HTMLScriptElement>;
    search: HTMLAttributes<HTMLElement>;
    section: HTMLAttributes<HTMLElement>;
    select: SelectHTMLAttributes<HTMLSelectElement>;
    slot: HTMLSlotElementAttributes;
    small: HTMLAttributes<HTMLElement>;
    source: SourceHTMLAttributes<HTMLSourceElement>;
    span: HTMLAttributes<HTMLSpanElement>;
    strong: HTMLAttributes<HTMLElement>;
    style: StyleHTMLAttributes<HTMLStyleElement>;
    sub: HTMLAttributes<HTMLElement>;
    summary: HTMLAttributes<HTMLElement>;
    sup: HTMLAttributes<HTMLElement>;
    table: HTMLAttributes<HTMLTableElement>;
    tbody: HTMLAttributes<HTMLTableSectionElement>;
    td: TdHTMLAttributes<HTMLTableCellElement>;
    template: TemplateHTMLAttributes<HTMLTemplateElement>;
    textarea: TextareaHTMLAttributes<HTMLTextAreaElement>;
    tfoot: HTMLAttributes<HTMLTableSectionElement>;
    th: ThHTMLAttributes<HTMLTableCellElement>;
    thead: HTMLAttributes<HTMLTableSectionElement>;
    time: TimeHTMLAttributes<HTMLElement>;
    title: HTMLAttributes<HTMLTitleElement>;
    tr: HTMLAttributes<HTMLTableRowElement>;
    track: TrackHTMLAttributes<HTMLTrackElement>;
    u: HTMLAttributes<HTMLElement>;
    ul: HTMLAttributes<HTMLUListElement>;
    var: HTMLAttributes<HTMLElement>;
    video: VideoHTMLAttributes<HTMLVideoElement>;
    wbr: HTMLAttributes<HTMLElement>;
  }
  /** @type {HTMLElementDeprecatedTagNameMap} */
  interface HTMLElementDeprecatedTags {
    big: HTMLAttributes<HTMLElement>;
    keygen: KeygenHTMLAttributes<HTMLElement>;
    menuitem: HTMLAttributes<HTMLElement>;
    noindex: HTMLAttributes<HTMLElement>;
    param: ParamHTMLAttributes<HTMLParamElement>;
  }
  /** @type {SVGElementTagNameMap} */
  interface SVGElementTags {
    animate: AnimateSVGAttributes<SVGAnimateElement>;
    animateMotion: AnimateMotionSVGAttributes<SVGAnimateMotionElement>;
    animateTransform: AnimateTransformSVGAttributes<SVGAnimateTransformElement>;
    circle: CircleSVGAttributes<SVGCircleElement>;
    clipPath: ClipPathSVGAttributes<SVGClipPathElement>;
    defs: DefsSVGAttributes<SVGDefsElement>;
    desc: DescSVGAttributes<SVGDescElement>;
    ellipse: EllipseSVGAttributes<SVGEllipseElement>;
    feBlend: FeBlendSVGAttributes<SVGFEBlendElement>;
    feColorMatrix: FeColorMatrixSVGAttributes<SVGFEColorMatrixElement>;
    feComponentTransfer: FeComponentTransferSVGAttributes<SVGFEComponentTransferElement>;
    feComposite: FeCompositeSVGAttributes<SVGFECompositeElement>;
    feConvolveMatrix: FeConvolveMatrixSVGAttributes<SVGFEConvolveMatrixElement>;
    feDiffuseLighting: FeDiffuseLightingSVGAttributes<SVGFEDiffuseLightingElement>;
    feDisplacementMap: FeDisplacementMapSVGAttributes<SVGFEDisplacementMapElement>;
    feDistantLight: FeDistantLightSVGAttributes<SVGFEDistantLightElement>;
    feDropShadow: FeDropShadowSVGAttributes<SVGFEDropShadowElement>;
    feFlood: FeFloodSVGAttributes<SVGFEFloodElement>;
    feFuncA: FeFuncSVGAttributes<SVGFEFuncAElement>;
    feFuncB: FeFuncSVGAttributes<SVGFEFuncBElement>;
    feFuncG: FeFuncSVGAttributes<SVGFEFuncGElement>;
    feFuncR: FeFuncSVGAttributes<SVGFEFuncRElement>;
    feGaussianBlur: FeGaussianBlurSVGAttributes<SVGFEGaussianBlurElement>;
    feImage: FeImageSVGAttributes<SVGFEImageElement>;
    feMerge: FeMergeSVGAttributes<SVGFEMergeElement>;
    feMergeNode: FeMergeNodeSVGAttributes<SVGFEMergeNodeElement>;
    feMorphology: FeMorphologySVGAttributes<SVGFEMorphologyElement>;
    feOffset: FeOffsetSVGAttributes<SVGFEOffsetElement>;
    fePointLight: FePointLightSVGAttributes<SVGFEPointLightElement>;
    feSpecularLighting: FeSpecularLightingSVGAttributes<SVGFESpecularLightingElement>;
    feSpotLight: FeSpotLightSVGAttributes<SVGFESpotLightElement>;
    feTile: FeTileSVGAttributes<SVGFETileElement>;
    feTurbulence: FeTurbulanceSVGAttributes<SVGFETurbulenceElement>;
    filter: FilterSVGAttributes<SVGFilterElement>;
    foreignObject: ForeignObjectSVGAttributes<SVGForeignObjectElement>;
    g: GSVGAttributes<SVGGElement>;
    image: ImageSVGAttributes<SVGImageElement>;
    line: LineSVGAttributes<SVGLineElement>;
    linearGradient: LinearGradientSVGAttributes<SVGLinearGradientElement>;
    marker: MarkerSVGAttributes<SVGMarkerElement>;
    mask: MaskSVGAttributes<SVGMaskElement>;
    metadata: MetadataSVGAttributes<SVGMetadataElement>;
    mpath: MPathSVGAttributes<SVGMPathElement>;
    path: PathSVGAttributes<SVGPathElement>;
    pattern: PatternSVGAttributes<SVGPatternElement>;
    polygon: PolygonSVGAttributes<SVGPolygonElement>;
    polyline: PolylineSVGAttributes<SVGPolylineElement>;
    radialGradient: RadialGradientSVGAttributes<SVGRadialGradientElement>;
    rect: RectSVGAttributes<SVGRectElement>;
    set: SetSVGAttributes<SVGSetElement>;
    stop: StopSVGAttributes<SVGStopElement>;
    svg: SvgSVGAttributes<SVGSVGElement>;
    switch: SwitchSVGAttributes<SVGSwitchElement>;
    symbol: SymbolSVGAttributes<SVGSymbolElement>;
    text: TextSVGAttributes<SVGTextElement>;
    textPath: TextPathSVGAttributes<SVGTextPathElement>;
    tspan: TSpanSVGAttributes<SVGTSpanElement>;
    use: UseSVGAttributes<SVGUseElement>;
    view: ViewSVGAttributes<SVGViewElement>;
  }
  interface IntrinsicElements extends HTMLElementTags, HTMLElementDeprecatedTags, SVGElementTags {}
}
`,an=`import { Accessor } from "./signal.js";
/**
The MIT License (MIT)

Copyright (c) 2017 Adam Haile

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/
/**
 * Reactively transforms an array with a callback function - underlying helper for the \`<For>\` control flow
 *
 * similar to \`Array.prototype.map\`, but gets the index as accessor, transforms only values that changed and returns an accessor and reactively tracks changes to the list.
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/map-array
 */
export declare function mapArray<T, U>(
  list: Accessor<readonly T[] | undefined | null | false>,
  mapFn: (v: T, i: Accessor<number>) => U,
  options?: {
    fallback?: Accessor<any>;
  }
): () => U[];
/**
 * Reactively maps arrays by index instead of value - underlying helper for the \`<Index>\` control flow
 *
 * similar to \`Array.prototype.map\`, but gets the value as an accessor, transforms only changed items of the original arrays anew and returns an accessor.
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/index-array
 */
export declare function indexArray<T, U>(
  list: Accessor<readonly T[] | undefined | null | false>,
  mapFn: (v: Accessor<T>, i: number) => U,
  options?: {
    fallback?: Accessor<any>;
  }
): () => U[];
`,sn=`import { Accessor, Setter } from "./signal.js";
declare global {
  interface SymbolConstructor {
    readonly observable: symbol;
  }
}
interface Observable<T> {
  subscribe(observer: ObservableObserver<T>): {
    unsubscribe(): void;
  };
  [Symbol.observable](): Observable<T>;
}
export type ObservableObserver<T> =
  | ((v: T) => void)
  | {
      next?: (v: T) => void;
      error?: (v: any) => void;
      complete?: (v: boolean) => void;
    };
/**
 * Creates a simple observable from a signal's accessor to be used with the \`from\` operator of observable libraries like e.g. rxjs
 * \`\`\`typescript
 * import { from } from "rxjs";
 * const [s, set] = createSignal(0);
 * const obsv$ = from(observable(s));
 * obsv$.subscribe((v) => console.log(v));
 * \`\`\`
 * description https://docs.solidjs.com/reference/reactive-utilities/observable
 */
export declare function observable<T>(input: Accessor<T>): Observable<T>;
export declare function from<T>(
  producer:
    | ((setter: Setter<T | undefined>) => () => void)
    | {
        subscribe: (fn: (v: T) => void) =>
          | (() => void)
          | {
              unsubscribe: () => void;
            };
      }
): Accessor<T | undefined>;
export {};
`,ln=`export interface Task {
  id: number;
  fn: ((didTimeout: boolean) => void) | null;
  startTime: number;
  expirationTime: number;
}
export declare function requestCallback(
  fn: () => void,
  options?: {
    timeout: number;
  }
): Task;
export declare function cancelCallback(task: Task): void;
`,dn=`/**
The MIT License (MIT)

Copyright (c) 2017 Adam Haile

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/
import { requestCallback } from "./scheduler.js";
import type { JSX } from "../jsx.js";
import type { FlowComponent } from "../render/index.js";
export declare const equalFn: <T>(a: T, b: T) => boolean;
export declare const $PROXY: unique symbol;
export declare const SUPPORTS_PROXY: boolean;
export declare const $TRACK: unique symbol;
export declare const $DEVCOMP: unique symbol;
export declare var Owner: Owner | null;
export declare let Transition: TransitionState | null;
/** Object storing callbacks for debugging during development */
export declare const DevHooks: {
  afterUpdate: (() => void) | null;
  afterCreateOwner: ((owner: Owner) => void) | null;
  afterCreateSignal: ((signal: SignalState<any>) => void) | null;
};
export type ComputationState = 0 | 1 | 2;
export interface SourceMapValue {
  value: unknown;
  name?: string;
  graph?: Owner;
}
export interface SignalState<T> extends SourceMapValue {
  value: T;
  observers: Computation<any>[] | null;
  observerSlots: number[] | null;
  tValue?: T;
  comparator?: (prev: T, next: T) => boolean;
}
export interface Owner {
  owned: Computation<any>[] | null;
  cleanups: (() => void)[] | null;
  owner: Owner | null;
  context: any | null;
  sourceMap?: SourceMapValue[];
  name?: string;
}
export interface Computation<Init, Next extends Init = Init> extends Owner {
  fn: EffectFunction<Init, Next>;
  state: ComputationState;
  tState?: ComputationState;
  sources: SignalState<Next>[] | null;
  sourceSlots: number[] | null;
  value?: Init;
  updatedAt: number | null;
  pure: boolean;
  user?: boolean;
  suspense?: SuspenseContextType;
}
export interface TransitionState {
  sources: Set<SignalState<any>>;
  effects: Computation<any>[];
  promises: Set<Promise<any>>;
  disposed: Set<Computation<any>>;
  queue: Set<Computation<any>>;
  scheduler?: (fn: () => void) => unknown;
  running: boolean;
  done?: Promise<void>;
  resolve?: () => void;
}
type ExternalSourceFactory = <Prev, Next extends Prev = Prev>(
  fn: EffectFunction<Prev, Next>,
  trigger: () => void
) => ExternalSource;
export interface ExternalSource {
  track: EffectFunction<any, any>;
  dispose: () => void;
}
export type RootFunction<T> = (dispose: () => void) => T;
/**
 * Creates a new non-tracked reactive context that doesn't auto-dispose
 *
 * @param fn a function in which the reactive state is scoped
 * @param detachedOwner optional reactive context to bind the root to
 * @returns the output of \`fn\`.
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/create-root
 */
export declare function createRoot<T>(fn: RootFunction<T>, detachedOwner?: typeof Owner): T;
export type Accessor<T> = () => T;
export type Setter<in out T> = {
  <U extends T>(
    ...args: undefined extends T ? [] : [value: Exclude<U, Function> | ((prev: T) => U)]
  ): undefined extends T ? undefined : U;
  <U extends T>(value: (prev: T) => U): U;
  <U extends T>(value: Exclude<U, Function>): U;
  <U extends T>(value: Exclude<U, Function> | ((prev: T) => U)): U;
};
export type Signal<T> = [get: Accessor<T>, set: Setter<T>];
export interface SignalOptions<T> extends MemoOptions<T> {
  internal?: boolean;
}
/**
 * Creates a simple reactive state with a getter and setter
 * \`\`\`typescript
 * const [state: Accessor<T>, setState: Setter<T>] = createSignal<T>(
 *  value: T,
 *  options?: { name?: string, equals?: false | ((prev: T, next: T) => boolean) }
 * )
 * \`\`\`
 * @param value initial value of the state; if empty, the state's type will automatically extended with undefined; otherwise you need to extend the type manually if you want setting to undefined not be an error
 * @param options optional object with a name for debugging purposes and equals, a comparator function for the previous and next value to allow fine-grained control over the reactivity
 *
 * @returns \`\`\`typescript
 * [state: Accessor<T>, setState: Setter<T>]
 * \`\`\`
 * * the Accessor is merely a function that returns the current value and registers each call to the reactive root
 * * the Setter is a function that allows directly setting or mutating the value:
 * \`\`\`typescript
 * const [count, setCount] = createSignal(0);
 * setCount(count => count + 1);
 * \`\`\`
 *
 * @description https://docs.solidjs.com/reference/basic-reactivity/create-signal
 */
export declare function createSignal<T>(): Signal<T | undefined>;
export declare function createSignal<T>(value: T, options?: SignalOptions<T>): Signal<T>;
export interface BaseOptions {
  name?: string;
}
export type NoInfer<T extends any> = [T][T extends any ? 0 : never];
export interface EffectOptions extends BaseOptions {}
export type EffectFunction<Prev, Next extends Prev = Prev> = (v: Prev) => Next;
/**
 * Creates a reactive computation that runs immediately before render, mainly used to write to other reactive primitives
 * \`\`\`typescript
 * export function createComputed<Next, Init = Next>(
 *   fn: (v: Init | Next) => Next,
 *   value?: Init,
 *   options?: { name?: string }
 * ): void;
 * \`\`\`
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param value an optional initial value for the computation; if set, fn will never receive undefined as first argument
 * @param options allows to set a name in dev mode for debugging purposes
 *
 * @description https://docs.solidjs.com/reference/secondary-primitives/create-computed
 */
export declare function createComputed<Next>(
  fn: EffectFunction<undefined | NoInfer<Next>, Next>
): void;
export declare function createComputed<Next, Init = Next>(
  fn: EffectFunction<Init | Next, Next>,
  value: Init,
  options?: EffectOptions
): void;
/**
 * Creates a reactive computation that runs during the render phase as DOM elements are created and updated but not necessarily connected
 * \`\`\`typescript
 * export function createRenderEffect<T>(
 *   fn: (v: T) => T,
 *   value?: T,
 *   options?: { name?: string }
 * ): void;
 * \`\`\`
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param value an optional initial value for the computation; if set, fn will never receive undefined as first argument
 * @param options allows to set a name in dev mode for debugging purposes
 *
 * @description https://docs.solidjs.com/reference/secondary-primitives/create-render-effect
 */
export declare function createRenderEffect<Next>(
  fn: EffectFunction<undefined | NoInfer<Next>, Next>
): void;
export declare function createRenderEffect<Next, Init = Next>(
  fn: EffectFunction<Init | Next, Next>,
  value: Init,
  options?: EffectOptions
): void;
/**
 * Creates a reactive computation that runs after the render phase
 * \`\`\`typescript
 * export function createEffect<T>(
 *   fn: (v: T) => T,
 *   value?: T,
 *   options?: { name?: string }
 * ): void;
 * \`\`\`
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param value an optional initial value for the computation; if set, fn will never receive undefined as first argument
 * @param options allows to set a name in dev mode for debugging purposes
 *
 * @description https://docs.solidjs.com/reference/basic-reactivity/create-effect
 */
export declare function createEffect<Next>(
  fn: EffectFunction<undefined | NoInfer<Next>, Next>
): void;
export declare function createEffect<Next, Init = Next>(
  fn: EffectFunction<Init | Next, Next>,
  value: Init,
  options?: EffectOptions & {
    render?: boolean;
  }
): void;
/**
 * Creates a reactive computation that runs after the render phase with flexible tracking
 * \`\`\`typescript
 * export function createReaction(
 *   onInvalidate: () => void,
 *   options?: { name?: string }
 * ): (fn: () => void) => void;
 * \`\`\`
 * @param invalidated a function that is called when tracked function is invalidated.
 * @param options allows to set a name in dev mode for debugging purposes
 *
 * @description https://docs.solidjs.com/reference/secondary-primitives/create-reaction
 */
export declare function createReaction(
  onInvalidate: () => void,
  options?: EffectOptions
): (tracking: () => void) => void;
export interface Memo<Prev, Next = Prev> extends SignalState<Next>, Computation<Next> {
  value: Next;
  tOwned?: Computation<Prev | Next, Next>[];
}
export interface MemoOptions<T> extends EffectOptions {
  equals?: false | ((prev: T, next: T) => boolean);
}
/**
 * Creates a readonly derived reactive memoized signal
 * \`\`\`typescript
 * export function createMemo<T>(
 *   fn: (v: T) => T,
 *   value?: T,
 *   options?: { name?: string, equals?: false | ((prev: T, next: T) => boolean) }
 * ): () => T;
 * \`\`\`
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param value an optional initial value for the computation; if set, fn will never receive undefined as first argument
 * @param options allows to set a name in dev mode for debugging purposes and use a custom comparison function in equals
 *
 * @description https://docs.solidjs.com/reference/basic-reactivity/create-memo
 */
export declare function createMemo<Next extends Prev, Prev = Next>(
  fn: EffectFunction<undefined | NoInfer<Prev>, Next>
): Accessor<Next>;
export declare function createMemo<Next extends Prev, Init = Next, Prev = Next>(
  fn: EffectFunction<Init | Prev, Next>,
  value: Init,
  options?: MemoOptions<Next>
): Accessor<Next>;
interface Unresolved {
  state: "unresolved";
  loading: false;
  error: undefined;
  latest: undefined;
  (): undefined;
}
interface Pending {
  state: "pending";
  loading: true;
  error: undefined;
  latest: undefined;
  (): undefined;
}
interface Ready<T> {
  state: "ready";
  loading: false;
  error: undefined;
  latest: T;
  (): T;
}
interface Refreshing<T> {
  state: "refreshing";
  loading: true;
  error: undefined;
  latest: T;
  (): T;
}
interface Errored {
  state: "errored";
  loading: false;
  error: any;
  latest: never;
  (): never;
}
export type Resource<T> = Unresolved | Pending | Ready<T> | Refreshing<T> | Errored;
export type InitializedResource<T> = Ready<T> | Refreshing<T> | Errored;
export type ResourceActions<T, R = unknown> = {
  mutate: Setter<T>;
  refetch: (info?: R) => T | Promise<T> | undefined | null;
};
export type ResourceSource<S> = S | false | null | undefined | (() => S | false | null | undefined);
export type ResourceFetcher<S, T, R = unknown> = (
  k: S,
  info: ResourceFetcherInfo<T, R>
) => T | Promise<T>;
export type ResourceFetcherInfo<T, R = unknown> = {
  value: T | undefined;
  refetching: R | boolean;
};
export type ResourceOptions<T, S = unknown> = {
  initialValue?: T;
  name?: string;
  deferStream?: boolean;
  ssrLoadFrom?: "initial" | "server";
  storage?: (init: T | undefined) => [Accessor<T | undefined>, Setter<T | undefined>];
  onHydrated?: (
    k: S | undefined,
    info: {
      value: T | undefined;
    }
  ) => void;
};
export type InitializedResourceOptions<T, S = unknown> = ResourceOptions<T, S> & {
  initialValue: T;
};
export type ResourceReturn<T, R = unknown> = [Resource<T>, ResourceActions<T | undefined, R>];
export type InitializedResourceReturn<T, R = unknown> = [
  InitializedResource<T>,
  ResourceActions<T, R>
];
/**
 * Creates a resource that wraps a repeated promise in a reactive pattern:
 * \`\`\`typescript
 * // Without source
 * const [resource, { mutate, refetch }] = createResource(fetcher, options);
 * // With source
 * const [resource, { mutate, refetch }] = createResource(source, fetcher, options);
 * \`\`\`
 * @param source - reactive data function which has its non-nullish and non-false values passed to the fetcher, optional
 * @param fetcher - function that receives the source (true if source not provided), the last or initial value, and whether the resource is being refetched, and returns a value or a Promise:
 * \`\`\`typescript
 * const fetcher: ResourceFetcher<S, T, R> = (
 *   sourceOutput: S,
 *   info: { value: T | undefined, refetching: R | boolean }
 * ) => T | Promise<T>;
 * \`\`\`
 * @param options - an optional object with the initialValue and the name (for debugging purposes); see {@link ResourceOptions}
 *
 * @returns \`\`\`typescript
 * [Resource<T>, { mutate: Setter<T>, refetch: () => void }]
 * \`\`\`
 *
 * * Setting an \`initialValue\` in the options will mean that both the prev() accessor and the resource should never return undefined (if that is wanted, you need to extend the type with undefined)
 * * \`mutate\` allows to manually overwrite the resource without calling the fetcher
 * * \`refetch\` will re-run the fetcher without changing the source, and if called with a value, that value will be passed to the fetcher via the \`refetching\` property on the fetcher's second parameter
 *
 * @description https://docs.solidjs.com/reference/basic-reactivity/create-resource
 */
export declare function createResource<T, R = unknown>(
  fetcher: ResourceFetcher<true, T, R>,
  options: InitializedResourceOptions<NoInfer<T>, true>
): InitializedResourceReturn<T, R>;
export declare function createResource<T, R = unknown>(
  fetcher: ResourceFetcher<true, T, R>,
  options?: ResourceOptions<NoInfer<T>, true>
): ResourceReturn<T, R>;
export declare function createResource<T, S, R = unknown>(
  source: ResourceSource<S>,
  fetcher: ResourceFetcher<S, T, R>,
  options: InitializedResourceOptions<NoInfer<T>, S>
): InitializedResourceReturn<T, R>;
export declare function createResource<T, S, R = unknown>(
  source: ResourceSource<S>,
  fetcher: ResourceFetcher<S, T, R>,
  options?: ResourceOptions<NoInfer<T>, S>
): ResourceReturn<T, R>;
export interface DeferredOptions<T> {
  equals?: false | ((prev: T, next: T) => boolean);
  name?: string;
  timeoutMs?: number;
}
/**
 * Creates a reactive computation that only runs and notifies the reactive context when the browser is idle
 * \`\`\`typescript
 * export function createDeferred<T>(
 *   fn: (v: T) => T,
 *   options?: { timeoutMs?: number, name?: string, equals?: false | ((prev: T, next: T) => boolean) }
 * ): () => T);
 * \`\`\`
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param options allows to set the timeout in milliseconds, use a custom comparison function and set a name in dev mode for debugging purposes
 *
 * @description https://docs.solidjs.com/reference/secondary-primitives/create-deferred
 */
export declare function createDeferred<T>(
  source: Accessor<T>,
  options?: DeferredOptions<T>
): Accessor<T>;
export type EqualityCheckerFunction<T, U> = (a: U, b: T) => boolean;
/**
 * Creates a conditional signal that only notifies subscribers when entering or exiting their key matching the value
 * \`\`\`typescript
 * export function createSelector<T, U>(
 *   source: () => T
 *   fn: (a: U, b: T) => boolean,
 *   options?: { name?: string }
 * ): (k: U) => boolean;
 * \`\`\`
 * @param source
 * @param fn a function that receives its previous or the initial value, if set, and returns a new value used to react on a computation
 * @param options allows to set a name in dev mode for debugging purposes, optional
 *
 * \`\`\`typescript
 * const isSelected = createSelector(selectedId);
 * <For each={list()}>
 *   {(item) => <li classList={{ active: isSelected(item.id) }}>{item.name}</li>}
 * </For>
 * \`\`\`
 *
 * This makes the operation O(2) instead of O(n).
 *
 * @description https://docs.solidjs.com/reference/secondary-primitives/create-selector
 */
export declare function createSelector<T, U = T>(
  source: Accessor<T>,
  fn?: EqualityCheckerFunction<T, U>,
  options?: BaseOptions
): (key: U) => boolean;
/**
 * Holds changes inside the block before the reactive context is updated
 * @param fn wraps the reactive updates that should be batched
 * @returns the return value from \`fn\`
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/batch
 */
export declare function batch<T>(fn: Accessor<T>): T;
/**
 * Ignores tracking context inside its scope
 * @param fn the scope that is out of the tracking context
 * @returns the return value of \`fn\`
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/untrack
 */
export declare function untrack<T>(fn: Accessor<T>): T;
/** @deprecated */
export type ReturnTypes<T> = T extends readonly Accessor<unknown>[]
  ? {
      [K in keyof T]: T[K] extends Accessor<infer I> ? I : never;
    }
  : T extends Accessor<infer I>
  ? I
  : never;
export type AccessorArray<T> = [
  ...Extract<
    {
      [K in keyof T]: Accessor<T[K]>;
    },
    readonly unknown[]
  >
];
export type OnEffectFunction<S, Prev, Next extends Prev = Prev> = (
  input: S,
  prevInput: S | undefined,
  prev: Prev
) => Next;
export interface OnOptions {
  defer?: boolean;
}
/**
 * Makes dependencies of a computation explicit
 * \`\`\`typescript
 * export function on<S, U>(
 *   deps: Accessor<S> | AccessorArray<S>,
 *   fn: (input: S, prevInput: S | undefined, prevValue: U | undefined) => U,
 *   options?: { defer?: boolean } = {}
 * ): (prevValue: U | undefined) => U;
 * \`\`\`
 * @param deps list of reactive dependencies or a single reactive dependency
 * @param fn computation on input; the current previous content(s) of input and the previous value are given as arguments and it returns a new value
 * @param options optional, allows deferred computation until at the end of the next change
 * @returns an effect function that is passed into createEffect. For example:
 *
 * \`\`\`typescript
 * createEffect(on(a, (v) => console.log(v, b())));
 *
 * // is equivalent to:
 * createEffect(() => {
 *   const v = a();
 *   untrack(() => console.log(v, b()));
 * });
 * \`\`\`
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/on
 */
export declare function on<S, Next extends Prev, Prev = Next>(
  deps: AccessorArray<S> | Accessor<S>,
  fn: OnEffectFunction<S, undefined | NoInfer<Prev>, Next>,
  options?: OnOptions & {
    defer?: false;
  }
): EffectFunction<undefined | NoInfer<Next>, NoInfer<Next>>;
export declare function on<S, Next extends Prev, Prev = Next>(
  deps: AccessorArray<S> | Accessor<S>,
  fn: OnEffectFunction<S, undefined | NoInfer<Prev>, Next>,
  options:
    | OnOptions
    | {
        defer: true;
      }
): EffectFunction<undefined | NoInfer<Next>>;
/**
 * Runs an effect only after initial render on mount
 * @param fn an effect that should run only once on mount
 *
 * @description https://docs.solidjs.com/reference/lifecycle/on-mount
 */
export declare function onMount(fn: () => void): void;
/**
 * Runs an effect once before the reactive scope is disposed
 * @param fn an effect that should run only once on cleanup
 *
 * @returns the same {@link fn} function that was passed in
 *
 * @description https://docs.solidjs.com/reference/lifecycle/on-cleanup
 */
export declare function onCleanup<T extends () => any>(fn: T): T;
/**
 * Runs an effect whenever an error is thrown within the context of the child scopes
 * @param fn boundary for the error
 * @param handler an error handler that receives the error
 *
 * * If the error is thrown again inside the error handler, it will trigger the next available parent handler
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/catch-error
 */
export declare function catchError<T>(fn: () => T, handler: (err: Error) => void): T | undefined;
export declare function getListener(): Computation<any, any> | null;
export declare function getOwner(): Owner | null;
export declare function runWithOwner<T>(o: typeof Owner, fn: () => T): T | undefined;
export declare function enableScheduling(scheduler?: typeof requestCallback): void;
/**
 * \`\`\`typescript
 * export function startTransition(fn: () => void) => Promise<void>
 * \`\`\`
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/start-transition
 */
export declare function startTransition(fn: () => unknown): Promise<void>;
export type Transition = [Accessor<boolean>, (fn: () => void) => Promise<void>];
/**
 * \`\`\`typescript
 * export function useTransition(): [
 *   () => boolean,
 *   (fn: () => void, cb?: () => void) => void
 * ];
 * \`\`\`
 * @returns a tuple; first value is an accessor if the transition is pending and a callback to start the transition
 *
 * @description https://docs.solidjs.com/reference/reactive-utilities/use-transition
 */
export declare function useTransition(): Transition;
export declare function resumeEffects(e: Computation<any>[]): void;
export interface DevComponent<T> extends Memo<unknown> {
  props: T;
  name: string;
  component: (props: T) => unknown;
}
export declare function devComponent<P, V>(Comp: (props: P) => V, props: P): V;
export declare function registerGraph(value: SourceMapValue): void;
export type ContextProviderComponent<T> = FlowComponent<{
  value: T;
}>;
export interface Context<T> {
  id: symbol;
  Provider: ContextProviderComponent<T>;
  defaultValue: T;
}
/**
 * Creates a Context to handle a state scoped for the children of a component
 * \`\`\`typescript
 * interface Context<T> {
 *   id: symbol;
 *   Provider: FlowComponent<{ value: T }>;
 *   defaultValue: T;
 * }
 * export function createContext<T>(
 *   defaultValue?: T,
 *   options?: { name?: string }
 * ): Context<T | undefined>;
 * \`\`\`
 * @param defaultValue optional default to inject into context
 * @param options allows to set a name in dev mode for debugging purposes
 * @returns The context that contains the Provider Component and that can be used with \`useContext\`
 *
 * @description https://docs.solidjs.com/reference/component-apis/create-context
 */
export declare function createContext<T>(
  defaultValue?: undefined,
  options?: EffectOptions
): Context<T | undefined>;
export declare function createContext<T>(defaultValue: T, options?: EffectOptions): Context<T>;
/**
 * Uses a context to receive a scoped state from a parent's Context.Provider
 *
 * @param context Context object made by \`createContext\`
 * @returns the current or \`defaultValue\`, if present
 *
 * @description https://docs.solidjs.com/reference/component-apis/use-context
 */
export declare function useContext<T>(context: Context<T>): T;
export type ResolvedJSXElement = Exclude<JSX.Element, JSX.ArrayElement>;
export type ResolvedChildren = ResolvedJSXElement | ResolvedJSXElement[];
export type ChildrenReturn = Accessor<ResolvedChildren> & {
  toArray: () => ResolvedJSXElement[];
};
/**
 * Resolves child elements to help interact with children
 *
 * @param fn an accessor for the children
 * @returns a accessor of the same children, but resolved
 *
 * @description https://docs.solidjs.com/reference/component-apis/children
 */
export declare function children(fn: Accessor<JSX.Element>): ChildrenReturn;
export type SuspenseContextType = {
  increment?: () => void;
  decrement?: () => void;
  inFallback?: () => boolean;
  effects?: Computation<any>[];
  resolved?: boolean;
};
type SuspenseContext = Context<SuspenseContextType | undefined> & {
  active?(): boolean;
  increment?(): void;
  decrement?(): void;
};
declare let SuspenseContext: SuspenseContext;
export declare function getSuspenseContext(): SuspenseContext;
export declare function enableExternalSource(
  factory: ExternalSourceFactory,
  untrack?: <V>(fn: () => V) => V
): void;
export declare function readSignal(this: SignalState<any> | Memo<any>): any;
export declare function writeSignal(
  node: SignalState<any> | Memo<any>,
  value: any,
  isComp?: boolean
): any;
/**
 * @deprecated since version 1.7.0 and will be removed in next major - use catchError instead
 * onError - run an effect whenever an error is thrown within the context of the child scopes
 * @param fn an error handler that receives the error
 *
 * * If the error is thrown again inside the error handler, it will trigger the next available parent handler
 *
 * @description https://www.solidjs.com/docs/latest/api#onerror | https://docs.solidjs.com/reference/reactive-utilities/catch-error
 */
export declare function onError(fn: (err: Error) => void): void;
export {};
`,pn=`import type { JSX } from "../jsx.js";
/**
 * **[experimental]** Controls the order in which suspended content is rendered
 *
 * @description https://docs.solidjs.com/reference/components/suspense-list
 */
export declare function SuspenseList(props: {
  children: JSX.Element;
  revealOrder: "forwards" | "backwards" | "together";
  tail?: "collapsed" | "hidden";
}): JSX.Element;
/**
 * Tracks all resources inside a component and renders a fallback until they are all resolved
 * \`\`\`typescript
 * const AsyncComponent = lazy(() => import('./component'));
 *
 * <Suspense fallback={<LoadingIndicator />}>
 *   <AsyncComponent />
 * </Suspense>
 * \`\`\`
 * @description https://docs.solidjs.com/reference/components/suspense
 */
export declare function Suspense(props: {
  fallback?: JSX.Element;
  children: JSX.Element;
}): JSX.Element;
`,cn=`import type { JSX } from "../jsx.js";
export declare function enableHydration(): void;
/**
 * A general \`Component\` has no implicit \`children\` prop.  If desired, you can
 * specify one as in \`Component<{name: String, children: JSX.Element}>\`.
 */
export type Component<P extends Record<string, any> = {}> = (props: P) => JSX.Element;
/**
 * Extend props to forbid the \`children\` prop.
 * Use this to prevent accidentally passing \`children\` to components that
 * would silently throw them away.
 */
export type VoidProps<P extends Record<string, any> = {}> = P & {
  children?: never;
};
/**
 * \`VoidComponent\` forbids the \`children\` prop.
 * Use this to prevent accidentally passing \`children\` to components that
 * would silently throw them away.
 */
export type VoidComponent<P extends Record<string, any> = {}> = Component<VoidProps<P>>;
/**
 * Extend props to allow an optional \`children\` prop with the usual
 * type in JSX, \`JSX.Element\` (which allows elements, arrays, functions, etc.).
 * Use this for components that you want to accept children.
 */
export type ParentProps<P extends Record<string, any> = {}> = P & {
  children?: JSX.Element;
};
/**
 * \`ParentComponent\` allows an optional \`children\` prop with the usual
 * type in JSX, \`JSX.Element\` (which allows elements, arrays, functions, etc.).
 * Use this for components that you want to accept children.
 */
export type ParentComponent<P extends Record<string, any> = {}> = Component<ParentProps<P>>;
/**
 * Extend props to require a \`children\` prop with the specified type.
 * Use this for components where you need a specific child type,
 * typically a function that receives specific argument types.
 * Note that all JSX <Elements> are of the type \`JSX.Element\`.
 */
export type FlowProps<P extends Record<string, any> = {}, C = JSX.Element> = P & {
  children: C;
};
/**
 * \`FlowComponent\` requires a \`children\` prop with the specified type.
 * Use this for components where you need a specific child type,
 * typically a function that receives specific argument types.
 * Note that all JSX <Elements> are of the type \`JSX.Element\`.
 */
export type FlowComponent<P extends Record<string, any> = {}, C = JSX.Element> = Component<
  FlowProps<P, C>
>;
/** @deprecated: use \`ParentProps\` instead */
export type PropsWithChildren<P extends Record<string, any> = {}> = ParentProps<P>;
export type ValidComponent = keyof JSX.IntrinsicElements | Component<any> | (string & {});
/**
 * Takes the props of the passed component and returns its type
 *
 * @example
 * ComponentProps<typeof Portal> // { mount?: Node; useShadow?: boolean; children: JSX.Element }
 * ComponentProps<'div'> // JSX.HTMLAttributes<HTMLDivElement>
 */
export type ComponentProps<T extends ValidComponent> = T extends Component<infer P>
  ? P
  : T extends keyof JSX.IntrinsicElements
  ? JSX.IntrinsicElements[T]
  : Record<string, unknown>;
/**
 * Type of \`props.ref\`, for use in \`Component\` or \`props\` typing.
 *
 * @example Component<{ref: Ref<Element>}>
 */
export type Ref<T> = T | ((val: T) => void);
export declare function createComponent<T extends Record<string, any>>(
  Comp: Component<T>,
  props: T
): JSX.Element;
type DistributeOverride<T, F> = T extends undefined ? F : T;
type Override<T, U> = T extends any
  ? U extends any
    ? {
        [K in keyof T]: K extends keyof U ? DistributeOverride<U[K], T[K]> : T[K];
      } & {
        [K in keyof U]: K extends keyof T ? DistributeOverride<U[K], T[K]> : U[K];
      }
    : T & U
  : T & U;
type OverrideSpread<T, U> = T extends any
  ? {
      [K in keyof ({
        [K in keyof T]: any;
      } & {
        [K in keyof U]?: any;
      } & {
        [K in U extends any ? keyof U : keyof U]?: any;
      })]: K extends keyof T
        ? Exclude<U extends any ? U[K & keyof U] : never, undefined> | T[K]
        : U extends any
        ? U[K & keyof U]
        : never;
    }
  : T & U;
type Simplify<T> = T extends any
  ? {
      [K in keyof T]: T[K];
    }
  : T;
type _MergeProps<T extends unknown[], Curr = {}> = T extends [
  infer Next | (() => infer Next),
  ...infer Rest
]
  ? _MergeProps<Rest, Override<Curr, Next>>
  : T extends [...infer Rest, infer Next | (() => infer Next)]
  ? Override<_MergeProps<Rest, Curr>, Next>
  : T extends []
  ? Curr
  : T extends (infer I | (() => infer I))[]
  ? OverrideSpread<Curr, I>
  : Curr;
export type MergeProps<T extends unknown[]> = Simplify<_MergeProps<T>>;
export declare function mergeProps<T extends unknown[]>(...sources: T): MergeProps<T>;
export type SplitProps<T, K extends (readonly (keyof T)[])[]> = [
  ...{
    [P in keyof K]: P extends \`\${number}\`
      ? Pick<T, Extract<K[P], readonly (keyof T)[]>[number]>
      : never;
  },
  {
    [P in keyof T as Exclude<P, K[number][number]>]: T[P];
  }
];
export declare function splitProps<
  T extends Record<any, any>,
  K extends [readonly (keyof T)[], ...(readonly (keyof T)[])[]]
>(props: T, ...keys: K): SplitProps<T, K>;
export declare function lazy<T extends Component<any>>(
  fn: () => Promise<{
    default: T;
  }>
): T & {
  preload: () => Promise<{
    default: T;
  }>;
};
export declare function createUniqueId(): string;
export {};
`,un=`import { Accessor } from "../reactive/signal.js";
import type { JSX } from "../jsx.js";
/**
 * Creates a list elements from a list
 *
 * it receives a map function as its child that receives a list element and an accessor with the index and returns a JSX-Element; if the list is empty, an optional fallback is returned:
 * \`\`\`typescript
 * <For each={items} fallback={<div>No items</div>}>
 *   {(item, index) => <div data-index={index()}>{item}</div>}
 * </For>
 * \`\`\`
 * If you have a list with fixed indices and changing values, consider using \`<Index>\` instead.
 *
 * @description https://docs.solidjs.com/reference/components/for
 */
export declare function For<T extends readonly any[], U extends JSX.Element>(props: {
  each: T | undefined | null | false;
  fallback?: JSX.Element;
  children: (item: T[number], index: Accessor<number>) => U;
}): JSX.Element;
/**
 * Non-keyed iteration over a list creating elements from its items
 *
 * To be used if you have a list with fixed indices, but changing values.
 * \`\`\`typescript
 * <Index each={items} fallback={<div>No items</div>}>
 *   {(item, index) => <div data-index={index}>{item()}</div>}
 * </Index>
 * \`\`\`
 * If you have a list with changing indices, better use \`<For>\`.
 *
 * @description https://docs.solidjs.com/reference/components/index
 */
export declare function Index<T extends readonly any[], U extends JSX.Element>(props: {
  each: T | undefined | null | false;
  fallback?: JSX.Element;
  children: (item: Accessor<T[number]>, index: number) => U;
}): JSX.Element;
type RequiredParameter<T> = T extends () => unknown ? never : T;
/**
 * Conditionally render its children or an optional fallback component
 * @description https://docs.solidjs.com/reference/components/show
 */
export declare function Show<
  T,
  TRenderFunction extends (item: Accessor<NonNullable<T>>) => JSX.Element
>(props: {
  when: T | undefined | null | false;
  keyed?: false;
  fallback?: JSX.Element;
  children: JSX.Element | RequiredParameter<TRenderFunction>;
}): JSX.Element;
export declare function Show<
  T,
  TRenderFunction extends (item: NonNullable<T>) => JSX.Element
>(props: {
  when: T | undefined | null | false;
  keyed: true;
  fallback?: JSX.Element;
  children: JSX.Element | RequiredParameter<TRenderFunction>;
}): JSX.Element;
/**
 * Switches between content based on mutually exclusive conditions
 * \`\`\`typescript
 * <Switch fallback={<FourOhFour />}>
 *   <Match when={state.route === 'home'}>
 *     <Home />
 *   </Match>
 *   <Match when={state.route === 'settings'}>
 *     <Settings />
 *   </Match>
 * </Switch>
 * \`\`\`
 * @description https://docs.solidjs.com/reference/components/switch-and-match
 */
export declare function Switch(props: {
  fallback?: JSX.Element;
  children: JSX.Element;
}): JSX.Element;
export type MatchProps<T> = {
  when: T | undefined | null | false;
  keyed?: boolean;
  children: JSX.Element | ((item: NonNullable<T> | Accessor<NonNullable<T>>) => JSX.Element);
};
/**
 * Selects a content based on condition when inside a \`<Switch>\` control flow
 * \`\`\`typescript
 * <Match when={condition()}>
 *   <Content/>
 * </Match>
 * \`\`\`
 * @description https://docs.solidjs.com/reference/components/switch-and-match
 */
export declare function Match<
  T,
  TRenderFunction extends (item: Accessor<NonNullable<T>>) => JSX.Element
>(props: {
  when: T | undefined | null | false;
  keyed?: false;
  children: JSX.Element | RequiredParameter<TRenderFunction>;
}): JSX.Element;
export declare function Match<
  T,
  TRenderFunction extends (item: NonNullable<T>) => JSX.Element
>(props: {
  when: T | undefined | null | false;
  keyed: true;
  children: JSX.Element | RequiredParameter<TRenderFunction>;
}): JSX.Element;
export declare function resetErrorBoundaries(): void;
/**
 * Catches uncaught errors inside components and renders a fallback content
 *
 * Also supports a callback form that passes the error and a reset function:
 * \`\`\`typescript
 * <ErrorBoundary fallback={
 *   (err, reset) => <div onClick={reset}>Error: {err.toString()}</div>
 * }>
 *   <MyComp />
 * </ErrorBoundary>
 * \`\`\`
 * Errors thrown from the fallback can be caught by a parent ErrorBoundary
 *
 * @description https://docs.solidjs.com/reference/components/error-boundary
 */
export declare function ErrorBoundary(props: {
  fallback: JSX.Element | ((err: any, reset: () => void) => JSX.Element);
  children: JSX.Element;
}): JSX.Element;
export {};
`,mn=`import { Computation } from "../reactive/signal.js";
export type HydrationContext = {
  id: string;
  count: number;
};
type SharedConfig = {
  context?: HydrationContext;
  resources?: {
    [key: string]: any;
  };
  load?: (id: string) => Promise<any> | any;
  has?: (id: string) => boolean;
  gather?: (key: string) => void;
  registry?: Map<string, Element>;
  done?: boolean;
  count?: number;
  effects?: Computation<any, any>[];
  getContextId(): string;
  getNextContextId(): string;
};
export declare const sharedConfig: SharedConfig;
export declare function setHydrateContext(context?: HydrationContext): void;
export declare function nextHydrateContext(): HydrationContext | undefined;
export {};
`,hn=`export * from "./component.js";
export * from "./flow.js";
export * from "./Suspense.js";
export { sharedConfig } from "./hydration.js";
`,fn=`export {
  catchError,
  createRoot,
  createSignal,
  createComputed,
  createRenderEffect,
  createEffect,
  createReaction,
  createDeferred,
  createSelector,
  createMemo,
  getListener,
  onMount,
  onCleanup,
  onError,
  untrack,
  batch,
  on,
  children,
  createContext,
  useContext,
  getOwner,
  runWithOwner,
  equalFn,
  requestCallback,
  mapArray,
  indexArray,
  observable,
  from,
  $PROXY,
  $DEVCOMP,
  $TRACK,
  DEV,
  enableExternalSource
} from "./reactive.js";
export {
  mergeProps,
  splitProps,
  createComponent,
  For,
  Index,
  Show,
  Switch,
  Match,
  ErrorBoundary,
  Suspense,
  SuspenseList,
  createResource,
  resetErrorBoundaries,
  enableScheduling,
  enableHydration,
  startTransition,
  useTransition,
  createUniqueId,
  lazy,
  sharedConfig
} from "./rendering.js";
export type { Component, Resource } from "./rendering.js";
`,bn=`export declare const equalFn: <T>(a: T, b: T) => boolean;
export declare const $PROXY: unique symbol;
export declare const $TRACK: unique symbol;
export declare const $DEVCOMP: unique symbol;
export declare const DEV: undefined;
export type Accessor<T> = () => T;
export type Setter<T> = undefined extends T
  ? <U extends T>(value?: (U extends Function ? never : U) | ((prev?: T) => U)) => U
  : <U extends T>(value: (U extends Function ? never : U) | ((prev: T) => U)) => U;
export type Signal<T> = [get: Accessor<T>, set: Setter<T>];
export declare function castError(err: unknown): Error;
export declare let Owner: Owner | null;
interface Owner {
  owner: Owner | null;
  context: any | null;
  owned: Owner[] | null;
  cleanups: (() => void)[] | null;
}
export declare function createOwner(): Owner;
export declare function createRoot<T>(
  fn: (dispose: () => void) => T,
  detachedOwner?: typeof Owner
): T;
export declare function createSignal<T>(
  value: T,
  options?: {
    equals?: false | ((prev: T, next: T) => boolean);
    name?: string;
  }
): [get: () => T, set: (v: (T extends Function ? never : T) | ((prev: T) => T)) => T];
export declare function createComputed<T>(fn: (v?: T) => T, value?: T): void;
export declare const createRenderEffect: typeof createComputed;
export declare function createEffect<T>(fn: (v?: T) => T, value?: T): void;
export declare function createReaction(fn: () => void): (fn: () => void) => void;
export declare function createMemo<T>(fn: (v?: T) => T, value?: T): () => T;
export declare function createDeferred<T>(source: () => T): () => T;
export declare function createSelector<T>(
  source: () => T,
  fn?: (k: T, value: T) => boolean
): (k: T) => boolean;
export declare function batch<T>(fn: () => T): T;
export declare const untrack: typeof batch;
export declare function on<T, U>(
  deps: Array<() => T> | (() => T),
  fn: (value: Array<T> | T, prev?: Array<T> | T, prevResults?: U) => U,
  options?: {
    defer?: boolean;
  }
): (prev?: U) => U | undefined;
export declare function onMount(fn: () => void): void;
export declare function onCleanup(fn: () => void): () => void;
export declare function cleanNode(node: Owner): void;
export declare function catchError<T>(fn: () => T, handler: (err: Error) => void): T | undefined;
export declare function getListener(): null;
export interface Context<T> {
  id: symbol;
  Provider: (props: { value: T; children: any }) => any;
  defaultValue?: T;
}
export declare function createContext<T>(defaultValue?: T): Context<T>;
export declare function useContext<T>(context: Context<T>): T;
export declare function getOwner(): Owner | null;
type ChildrenReturn = Accessor<any> & {
  toArray: () => any[];
};
export declare function children(fn: () => any): ChildrenReturn;
export declare function runWithOwner<T>(o: typeof Owner, fn: () => T): T | undefined;
export interface Task {
  id: number;
  fn: ((didTimeout: boolean) => void) | null;
  startTime: number;
  expirationTime: number;
}
export declare function requestCallback(
  fn: () => void,
  options?: {
    timeout: number;
  }
): Task;
export declare function cancelCallback(task: Task): void;
export declare function mapArray<T, U>(
  list: Accessor<readonly T[] | undefined | null | false>,
  mapFn: (v: T, i: Accessor<number>) => U,
  options?: {
    fallback?: Accessor<any>;
  }
): () => U[];
export declare function indexArray<T, U>(
  list: Accessor<readonly T[] | undefined | null | false>,
  mapFn: (v: Accessor<T>, i: number) => U,
  options?: {
    fallback?: Accessor<any>;
  }
): () => U[];
export type ObservableObserver<T> =
  | ((v: T) => void)
  | {
      next: (v: T) => void;
      error?: (v: any) => void;
      complete?: (v: boolean) => void;
    };
export declare function observable<T>(input: Accessor<T>): {
  subscribe(observer: ObservableObserver<T>): {
    unsubscribe(): void;
  };
  [Symbol.observable](): any;
};
export declare function from<T>(
  producer:
    | ((setter: Setter<T>) => () => void)
    | {
        subscribe: (fn: (v: T) => void) =>
          | (() => void)
          | {
              unsubscribe: () => void;
            };
      }
): Accessor<T>;
export declare function enableExternalSource(factory: any): void;
/**
 * @deprecated since version 1.7.0 and will be removed in next major - use catchError instead
 */
export declare function onError(fn: (err: Error) => void): void;
export {};
`,gn=`import { Accessor, Setter, Signal } from "./reactive.js";
import type { JSX } from "../jsx.js";
export type Component<P = {}> = (props: P) => JSX.Element;
export type VoidProps<P = {}> = P & {
  children?: never;
};
export type VoidComponent<P = {}> = Component<VoidProps<P>>;
export type ParentProps<P = {}> = P & {
  children?: JSX.Element;
};
export type ParentComponent<P = {}> = Component<ParentProps<P>>;
export type FlowProps<P = {}, C = JSX.Element> = P & {
  children: C;
};
export type FlowComponent<P = {}, C = JSX.Element> = Component<FlowProps<P, C>>;
export type Ref<T> = T | ((val: T) => void);
export type ValidComponent = keyof JSX.IntrinsicElements | Component<any> | (string & {});
export type ComponentProps<T extends ValidComponent> = T extends Component<infer P>
  ? P
  : T extends keyof JSX.IntrinsicElements
  ? JSX.IntrinsicElements[T]
  : Record<string, unknown>;
type SharedConfig = {
  context?: HydrationContext;
  getContextId(): string;
  getNextContextId(): string;
};
export declare const sharedConfig: SharedConfig;
export declare function createUniqueId(): string;
export declare function createComponent<T>(Comp: (props: T) => JSX.Element, props: T): JSX.Element;
export declare function mergeProps<T, U>(source: T, source1: U): T & U;
export declare function mergeProps<T, U, V>(source: T, source1: U, source2: V): T & U & V;
export declare function mergeProps<T, U, V, W>(
  source: T,
  source1: U,
  source2: V,
  source3: W
): T & U & V & W;
export declare function splitProps<T extends object, K1 extends keyof T>(
  props: T,
  ...keys: [K1[]]
): [Pick<T, K1>, Omit<T, K1>];
export declare function splitProps<T extends object, K1 extends keyof T, K2 extends keyof T>(
  props: T,
  ...keys: [K1[], K2[]]
): [Pick<T, K1>, Pick<T, K2>, Omit<T, K1 | K2>];
export declare function splitProps<
  T extends object,
  K1 extends keyof T,
  K2 extends keyof T,
  K3 extends keyof T
>(
  props: T,
  ...keys: [K1[], K2[], K3[]]
): [Pick<T, K1>, Pick<T, K2>, Pick<T, K3>, Omit<T, K1 | K2 | K3>];
export declare function splitProps<
  T extends object,
  K1 extends keyof T,
  K2 extends keyof T,
  K3 extends keyof T,
  K4 extends keyof T
>(
  props: T,
  ...keys: [K1[], K2[], K3[], K4[]]
): [Pick<T, K1>, Pick<T, K2>, Pick<T, K3>, Pick<T, K4>, Omit<T, K1 | K2 | K3 | K4>];
export declare function splitProps<
  T extends object,
  K1 extends keyof T,
  K2 extends keyof T,
  K3 extends keyof T,
  K4 extends keyof T,
  K5 extends keyof T
>(
  props: T,
  ...keys: [K1[], K2[], K3[], K4[], K5[]]
): [
  Pick<T, K1>,
  Pick<T, K2>,
  Pick<T, K3>,
  Pick<T, K4>,
  Pick<T, K5>,
  Omit<T, K1 | K2 | K3 | K4 | K5>
];
export declare function For<T>(props: {
  each: T[];
  fallback?: string;
  children: (item: T, index: () => number) => string;
}): string | any[] | undefined;
export declare function Index<T>(props: {
  each: T[];
  fallback?: string;
  children: (item: () => T, index: number) => string;
}): string | any[] | undefined;
/**
 * Conditionally render its children or an optional fallback component
 * @description https://docs.solidjs.com/reference/components/show
 */
export declare function Show<T>(props: {
  when: T | undefined | null | false;
  keyed?: boolean;
  fallback?: string;
  children: string | ((item: NonNullable<T> | Accessor<NonNullable<T>>) => string);
}): string;
export declare function Switch(props: {
  fallback?: string;
  children: MatchProps<unknown> | MatchProps<unknown>[];
}): string;
type MatchProps<T> = {
  when: T | false;
  keyed?: boolean;
  children: string | ((item: NonNullable<T> | Accessor<NonNullable<T>>) => string);
};
export declare function Match<T>(props: MatchProps<T>): MatchProps<T>;
export declare function resetErrorBoundaries(): void;
export declare function ErrorBoundary(props: {
  fallback: string | ((err: any, reset: () => void) => string);
  children: string;
}):
  | string
  | ((err: any, reset: () => void) => string)
  | {
      t: string;
    };
export interface Resource<T> {
  (): T | undefined;
  state: "unresolved" | "pending" | "ready" | "refreshing" | "errored";
  loading: boolean;
  error: any;
  latest: T | undefined;
}
type SuspenseContextType = {
  resources: Map<
    string,
    {
      loading: boolean;
      error: any;
    }
  >;
  completed: () => void;
};
export type ResourceActions<T> = {
  mutate: Setter<T>;
  refetch: (info?: unknown) => void;
};
export type ResourceReturn<T> = [Resource<T>, ResourceActions<T>];
export type ResourceSource<S> = S | false | null | undefined | (() => S | false | null | undefined);
export type ResourceFetcher<S, T> = (k: S, info: ResourceFetcherInfo<T>) => T | Promise<T>;
export type ResourceFetcherInfo<T> = {
  value: T | undefined;
  refetching?: unknown;
};
export type ResourceOptions<T> = undefined extends T
  ? {
      initialValue?: T;
      name?: string;
      deferStream?: boolean;
      ssrLoadFrom?: "initial" | "server";
      storage?: () => Signal<T | undefined>;
      onHydrated?: <S, T>(k: S, info: ResourceFetcherInfo<T>) => void;
    }
  : {
      initialValue: T;
      name?: string;
      deferStream?: boolean;
      ssrLoadFrom?: "initial" | "server";
      storage?: (v?: T) => Signal<T | undefined>;
      onHydrated?: <S, T>(k: S, info: ResourceFetcherInfo<T>) => void;
    };
export declare function createResource<T, S = true>(
  fetcher: ResourceFetcher<S, T>,
  options?: ResourceOptions<undefined>
): ResourceReturn<T | undefined>;
export declare function createResource<T, S = true>(
  fetcher: ResourceFetcher<S, T>,
  options: ResourceOptions<T>
): ResourceReturn<T>;
export declare function createResource<T, S>(
  source: ResourceSource<S>,
  fetcher: ResourceFetcher<S, T>,
  options?: ResourceOptions<undefined>
): ResourceReturn<T | undefined>;
export declare function createResource<T, S>(
  source: ResourceSource<S>,
  fetcher: ResourceFetcher<S, T>,
  options: ResourceOptions<T>
): ResourceReturn<T>;
export declare function lazy<T extends Component<any>>(
  fn: () => Promise<{
    default: T;
  }>
): T & {
  preload: () => Promise<{
    default: T;
  }>;
};
export declare function enableScheduling(): void;
export declare function enableHydration(): void;
export declare function startTransition(fn: () => any): void;
export declare function useTransition(): [() => boolean, (fn: () => any) => void];
type HydrationContext = {
  id: string;
  count: number;
  serialize: (id: string, v: Promise<any> | any, deferStream?: boolean) => void;
  nextRoot: (v: any) => string;
  replace: (id: string, replacement: () => any) => void;
  block: (p: Promise<any>) => void;
  resources: Record<string, any>;
  suspense: Record<string, SuspenseContextType>;
  registerFragment: (v: string) => (v?: string, err?: any) => boolean;
  lazy: Record<string, Promise<any>>;
  async?: boolean;
  noHydrate: boolean;
};
export declare function SuspenseList(props: {
  children: string;
  revealOrder: "forwards" | "backwards" | "together";
  tail?: "collapsed" | "hidden";
}): string;
export declare function Suspense(props: { fallback?: string; children: string }):
  | string
  | number
  | boolean
  | Node
  | JSX.ArrayElement
  | {
      t: string;
    }
  | null
  | undefined;
export {};
`,yn=`import type { RendererOptions, Renderer } from "./universal.js";
export declare function createRenderer<NodeType>(
  options: RendererOptions<NodeType>
): Renderer<NodeType>;
`,xn=`export interface RendererOptions<NodeType> {
  createElement(tag: string): NodeType;
  createTextNode(value: string): NodeType;
  replaceText(textNode: NodeType, value: string): void;
  isTextNode(node: NodeType): boolean;
  setProperty<T>(node: NodeType, name: string, value: T, prev?: T): void;
  insertNode(parent: NodeType, node: NodeType, anchor?: NodeType): void;
  removeNode(parent: NodeType, node: NodeType): void;
  getParentNode(node: NodeType): NodeType | undefined;
  getFirstChild(node: NodeType): NodeType | undefined;
  getNextSibling(node: NodeType): NodeType | undefined;
}

export interface Renderer<NodeType> {
  render(code: () => NodeType, node: NodeType): () => void;
  effect<T>(fn: (prev?: T) => T, init?: T): void;
  memo<T>(fn: () => T, equal: boolean): () => T;
  createComponent<T>(Comp: (props: T) => NodeType, props: T): NodeType;
  createElement(tag: string): NodeType;
  createTextNode(value: string): NodeType;
  insertNode(parent: NodeType, node: NodeType, anchor?: NodeType): void;
  insert<T>(parent: any, accessor: (() => T) | T, marker?: any | null): NodeType;
  spread<T>(node: any, accessor: (() => T) | T, skipChildren?: Boolean): void;
  setProp<T>(node: NodeType, name: string, value: T, prev?: T): T;
  mergeProps(...sources: unknown[]): unknown;
  use<A, T>(fn: (element: NodeType, arg: A) => T, element: NodeType, arg: A): T;
}

export function createRenderer<NodeType>(options: RendererOptions<NodeType>): Renderer<NodeType>;
`,vn=`import type { RequestEvent } from "solid-js/web";
export declare function provideRequestEvent<T extends RequestEvent, U>(init: T, cb: () => U): U;
`,Tn=`import { JSX } from "./jsx.js";
export const Aliases: Record<string, string>;
export const Properties: Set<string>;
export const ChildProperties: Set<string>;
export const DelegatedEvents: Set<string>;
export const DOMElements: Set<string>;
export const SVGElements: Set<string>;
export const SVGNamespace: Record<string, string>;
export function getPropAlias(prop: string, tagName: string): string | undefined;

type MountableElement = Element | Document | ShadowRoot | DocumentFragment | Node;
export function render(code: () => JSX.Element, element: MountableElement): () => void;
export function template(html: string, isCE?: boolean, isSVG?: boolean): () => Element;
export function effect<T>(fn: (prev?: T) => T, init?: T): void;
export function memo<T>(fn: () => T, equal: boolean): () => T;
export function untrack<T>(fn: () => T): T;
export function insert<T>(
  parent: MountableElement,
  accessor: (() => T) | T,
  marker?: Node | null,
  init?: JSX.Element
): JSX.Element;
export function createComponent<T>(Comp: (props: T) => JSX.Element, props: T): JSX.Element;
export function delegateEvents(eventNames: string[], d?: Document): void;
export function clearDelegatedEvents(d?: Document): void;
export function spread<T>(
  node: Element,
  accessor: T,
  isSVG?: Boolean,
  skipChildren?: Boolean
): void;
export function assign(node: Element, props: any, isSVG?: Boolean, skipChildren?: Boolean): void;
export function setAttribute(node: Element, name: string, value: string): void;
export function setAttributeNS(node: Element, namespace: string, name: string, value: string): void;
export function setBoolAttribute(node: Element, name: string, value: any): void;
export function className(node: Element, value: string): void;
export function setProperty(node: Element, name: string, value: any): void;
export function addEventListener(
  node: Element,
  name: string,
  handler: EventListener | EventListenerObject | (EventListenerObject & AddEventListenerOptions),
  delegate: boolean
): void;
export function classList(
  node: Element,
  value: { [k: string]: boolean },
  prev?: { [k: string]: boolean }
): { [k: string]: boolean };
export function style(
  node: Element,
  value: { [k: string]: string },
  prev?: { [k: string]: string }
): void;
export function getOwner(): unknown;
export function mergeProps(...sources: unknown[]): unknown;
export function dynamicProperty(props: unknown, key: string): unknown;

export function hydrate(
  fn: () => JSX.Element,
  node: MountableElement,
  options?: { renderId?: string; owner?: unknown }
): () => void;
export function getHydrationKey(): string;
export function getNextElement(template?: HTMLTemplateElement): Element;
export function getNextMatch(start: Node, elementName: string): Element;
export function getNextMarker(start: Node): [Node, Array<Node>];
export function useAssets(fn: () => JSX.Element): void;
export function getAssets(): string;
export function HydrationScript(): JSX.Element;
export function generateHydrationScript(): string;
export function Assets(props: { children?: JSX.Element }): JSX.Element;
export function Hydration(props: { children?: JSX.Element }): JSX.Element;
export function NoHydration(props: { children?: JSX.Element }): JSX.Element;
export interface RequestEvent {
  request: Request;
}
export declare const RequestContext: unique symbol;
export function getRequestEvent(): RequestEvent | undefined;
export function runHydrationEvents(): void;
`,Sn=`export {
  getOwner,
  createComponent,
  createRoot as root,
  createRenderEffect as effect,
  createMemo as memo,
  sharedConfig,
  untrack,
  mergeProps
} from "solid-js";
`,wn=`import { hydrate as hydrateCore } from "./client.js";
import { JSX, ComponentProps, ValidComponent } from "solid-js";
export * from "./client.js";
export {
  For,
  Show,
  Suspense,
  SuspenseList,
  Switch,
  Match,
  Index,
  ErrorBoundary,
  mergeProps
} from "solid-js";
export * from "./server-mock.js";
export declare const isServer: boolean;
export declare const isDev: boolean;
export declare const hydrate: typeof hydrateCore;
/**
 * Renders components somewhere else in the DOM
 *
 * Useful for inserting modals and tooltips outside of an cropping layout. If no mount point is given, the portal is inserted in document.body; it is wrapped in a \`<div>\` unless the target is document.head or \`isSVG\` is true. setting \`useShadow\` to true places the element in a shadow root to isolate styles.
 *
 * @description https://docs.solidjs.com/reference/components/portal
 */
export declare function Portal<T extends boolean = false, S extends boolean = false>(props: {
  mount?: Node;
  useShadow?: T;
  isSVG?: S;
  ref?:
    | (S extends true ? SVGGElement : HTMLDivElement)
    | ((
        el: (T extends true
          ? {
              readonly shadowRoot: ShadowRoot;
            }
          : {}) &
          (S extends true ? SVGGElement : HTMLDivElement)
      ) => void);
  children: JSX.Element;
}): Text;
export type DynamicProps<T extends ValidComponent, P = ComponentProps<T>> = {
  [K in keyof P]: P[K];
} & {
  component: T | undefined;
};
/**
 * Renders an arbitrary custom or native component and passes the other props
 * \`\`\`typescript
 * <Dynamic component={multiline() ? 'textarea' : 'input'} value={value()} />
 * \`\`\`
 * @description https://docs.solidjs.com/reference/components/dynamic
 */
export declare function Dynamic<T extends ValidComponent>(props: DynamicProps<T>): JSX.Element;
`,_n=`export type { JSX } from "../../types/jsx.js";
`,En=`export declare function renderToString<T>(
  fn: () => T,
  options?: {
    nonce?: string;
    renderId?: string;
  }
): string;
export declare function renderToStringAsync<T>(
  fn: () => T,
  options?: {
    timeoutMs?: number;
    nonce?: string;
    renderId?: string;
  }
): Promise<string>;
export declare function renderToStream<T>(
  fn: () => T,
  options?: {
    nonce?: string;
    renderId?: string;
    onCompleteShell?: (info: { write: (v: string) => void }) => void;
    onCompleteAll?: (info: { write: (v: string) => void }) => void;
  }
): {
  pipe: (writable: { write: (v: string) => void }) => void;
  pipeTo: (writable: WritableStream) => void;
};
export declare function ssr(
  template: string[] | string,
  ...nodes: any[]
): {
  t: string;
};
export declare function ssrElement(
  name: string,
  props: any,
  children: any,
  needsId: boolean
): {
  t: string;
};
export declare function ssrClassList(value: { [k: string]: boolean }): string;
export declare function ssrStyle(value: { [k: string]: string }): string;
export declare function ssrAttribute(key: string, value: boolean): string;
export declare function ssrHydrationKey(): string;
export declare function resolveSSRNode(node: any): string;
export declare function escape(html: string): string;
/**
 * @deprecated Replaced by ssrElement
 */
export declare function ssrSpread(props: any, isSVG: boolean, skipChildren: boolean): void;
export type LegacyResults = {
  startWriting: () => void;
};
/**
 * @deprecated Replaced by renderToStream
 */
export declare function pipeToWritable<T>(
  fn: () => T,
  writable: WritableStream,
  options?: {
    nonce?: string;
    onReady?: (res: LegacyResults) => void;
    onCompleteAll?: () => void;
  }
): void;
/**
 * @deprecated Replaced by renderToStream
 */
export declare function pipeToNodeWritable<T>(
  fn: () => T,
  writable: {
    write: (v: string) => void;
  },
  options?: {
    nonce?: string;
    onReady?: (res: LegacyResults) => void;
    onCompleteAll?: () => void;
  }
): void;
`,Pn=`import { JSX } from "./jsx.js";
export const Aliases: Record<string, string>;
export const Properties: Set<string>;
export const ChildProperties: Set<string>;
export const DelegatedEvents: Set<string>;
export const DOMElements: Set<string>;
export const SVGElements: Set<string>;
export const SVGNamespace: Record<string, string>;
export function getPropAlias(prop: string, tagName: string): string | undefined;

type MountableElement = Element | Document | ShadowRoot | DocumentFragment | Node;

export function renderToString<T>(
  fn: () => T,
  options?: {
    nonce?: string;
    renderId?: string;
    onError?: (err: any) => void;
  }
): string;
export function renderToStringAsync<T>(
  fn: () => T,
  options?: {
    timeoutMs?: number;
    nonce?: string;
    renderId?: string;
    noScripts?: boolean;
    onError?: (err: any) => void;
  }
): Promise<string>;
export function renderToStream<T>(
  fn: () => T,
  options?: {
    nonce?: string;
    renderId?: string;
    onCompleteShell?: (info: { write: (v: string) => void }) => void;
    onCompleteAll?: (info: { write: (v: string) => void }) => void;
    onError?: (err: any) => void;
  }
): {
  pipe: (writable: { write: (v: string) => void }) => void;
  pipeTo: (writable: WritableStream) => Promise<void>;
};

export function HydrationScript(props: { nonce?: string; eventNames?: string[] }): JSX.Element;
export function ssr(template: string[] | string, ...nodes: any[]): { t: string };
export function ssrElement(
  name: string,
  props: any,
  children: any,
  needsId: boolean
): { t: string };
export function ssrClassList(value: { [k: string]: boolean }): string;
export function ssrStyle(value: { [k: string]: string }): string;
export function ssrAttribute(key: string, value: any, isBoolean: boolean): string;
export function ssrHydrationKey(): string;
export function resolveSSRNode(node: any): string;
export function escape(html: string): string;
export function useAssets(fn: () => JSX.Element): void;
export function getAssets(): string;
export function getHydrationKey(): string;
export function effect<T>(fn: (prev?: T) => T, init?: T): void;
export function memo<T>(fn: () => T, equal: boolean): () => T;
export function createComponent<T>(Comp: (props: T) => JSX.Element, props: T): JSX.Element;
export function mergeProps(...sources: unknown[]): unknown;
export function getOwner(): unknown;
export function generateHydrationScript(options: { nonce?: string; eventNames?: string[] }): string;
export declare const RequestContext: unique symbol;
export interface RequestEvent {
  request: Request;
  locals: Record<string | number | symbol, any>;
}
export function getRequestEvent(): RequestEvent | undefined;

export function Hydration(props: { children?: JSX.Element }): JSX.Element;
export function NoHydration(props: { children?: JSX.Element }): JSX.Element;
export function Assets(props: { children?: JSX.Element }): JSX.Element;

// deprecated
export type LegacyResults = {
  write: (text: string) => void;
  startWriting: () => void;
};
export function pipeToWritable<T>(
  fn: () => T,
  writable: WritableStream,
  options?: {
    nonce?: string;
    onReady?: (res: LegacyResults) => void;
    onCompleteAll?: () => void;
  }
): void;
export function pipeToNodeWritable<T>(
  fn: () => T,
  writable: { write: (v: string) => void },
  options?: {
    nonce?: string;
    onReady?: (res: LegacyResults) => void;
    onCompleteAll?: () => void;
  }
): void;

export function untrack<T>(fn: () => T): T;

// client-only APIs

/** @deprecated not supported on the server side */
export function classList(
  node: Element,
  value: { [k: string]: boolean },
  prev?: { [k: string]: boolean }
): { [k: string]: boolean };

/** @deprecated not supported on the server side */
export function style(
  node: Element,
  value: { [k: string]: string },
  prev?: { [k: string]: string }
): void;

/** @deprecated not supported on the server side */
export function insert<T>(
  parent: MountableElement,
  accessor: (() => T) | T,
  marker?: Node | null,
  init?: JSX.Element
): JSX.Element;

/** @deprecated not supported on the server side */
export function spread<T>(
  node: Element,
  accessor: T,
  isSVG?: Boolean,
  skipChildren?: Boolean
): void;

/** @deprecated not supported on the server side */
export function delegateEvents(eventNames: string[], d?: Document): void;
/** @deprecated not supported on the server side */
export function dynamicProperty(props: unknown, key: string): unknown;
/** @deprecated not supported on the server side */
export function setAttribute(node: Element, name: string, value: string): void;
/** @deprecated not supported on the server side */
export function setAttributeNS(node: Element, namespace: string, name: string, value: string): void;

/** @deprecated not supported on the server side */
export function addEventListener(
  node: Element,
  name: string,
  handler: () => void,
  delegate: boolean
): void;

/** @deprecated not supported on the server side */
export function render(code: () => JSX.Element, element: MountableElement): () => void;
/** @deprecated not supported on the server side */
export function template(html: string, isCE?: boolean, isSVG?: boolean): () => Element;
/** @deprecated not supported on the server side */
export function setProperty(node: Element, name: string, value: any): void;
/** @deprecated not supported on the server side */
export function className(node: Element, value: string): void;
/** @deprecated not supported on the server side */
export function assign(node: Element, props: any, isSVG?: Boolean, skipChildren?: Boolean): void;

/** @deprecated not supported on the server side */
export function hydrate(
  fn: () => JSX.Element,
  node: MountableElement,
  options?: { renderId?: string; owner?: unknown }
): () => void;

/** @deprecated not supported on the server side */
export function getNextElement(template?: HTMLTemplateElement): Element;
/** @deprecated not supported on the server side */
export function getNextMatch(start: Node, elementName: string): Element;
/** @deprecated not supported on the server side */
export function getNextMarker(start: Node): [Node, Array<Node>];
`,An=`// Generated by dts-bundle-generator v9.5.1

/**
 * Minimal \`EventEmitter\` interface that is molded against the Node.js
 * \`EventEmitter\` interface.
 */
export declare class EventEmitter<EventTypes extends EventEmitter.ValidEventTypes = string | symbol, Context extends any = any> {
	static prefixed: string | boolean;
	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 */
	eventNames(): Array<EventEmitter.EventNames<EventTypes>>;
	/**
	 * Return the listeners registered for a given event.
	 */
	listeners<T extends EventEmitter.EventNames<EventTypes>>(event: T): Array<EventEmitter.EventListener<EventTypes, T>>;
	/**
	 * Return the number of listeners listening to a given event.
	 */
	listenerCount(event: EventEmitter.EventNames<EventTypes>): number;
	/**
	 * Calls each of the listeners registered for a given event.
	 */
	emit<T extends EventEmitter.EventNames<EventTypes>>(event: T, ...args: EventEmitter.EventArgs<EventTypes, T>): boolean;
	/**
	 * Add a listener for a given event.
	 */
	on<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	addListener<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	/**
	 * Add a one-time listener for a given event.
	 */
	once<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn: EventEmitter.EventListener<EventTypes, T>, context?: Context): this;
	/**
	 * Remove the listeners of a given event.
	 */
	removeListener<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn?: EventEmitter.EventListener<EventTypes, T>, context?: Context, once?: boolean): this;
	off<T extends EventEmitter.EventNames<EventTypes>>(event: T, fn?: EventEmitter.EventListener<EventTypes, T>, context?: Context, once?: boolean): this;
	/**
	 * Remove all listeners, or those of the specified event.
	 */
	removeAllListeners(event?: EventEmitter.EventNames<EventTypes>): this;
}
export declare namespace EventEmitter {
	export interface ListenerFn<Args extends any[] = any[]> {
		(...args: Args): void;
	}
	export interface EventEmitterStatic {
		new <EventTypes extends ValidEventTypes = string | symbol, Context = any>(): EventEmitter<EventTypes, Context>;
	}
	/**
	 * \`object\` should be in either of the following forms:
	 * \`\`\`
	 * interface EventTypes {
	 *   'event-with-parameters': any[]
	 *   'event-with-example-handler': (...args: any[]) => void
	 * }
	 * \`\`\`
	 */
	export type ValidEventTypes = string | symbol | object;
	export type EventNames<T extends ValidEventTypes> = T extends string | symbol ? T : keyof T;
	export type ArgumentMap<T extends object> = {
		[K in keyof T]: T[K] extends (...args: any[]) => void ? Parameters<T[K]> : T[K] extends any[] ? T[K] : any[];
	};
	export type EventListener<T extends ValidEventTypes, K extends EventNames<T>> = T extends string | symbol ? (...args: any[]) => void : (...args: ArgumentMap<Exclude<T, string | symbol>>[Extract<K, keyof T>]) => void;
	export type EventArgs<T extends ValidEventTypes, K extends EventNames<T>> = Parameters<EventListener<T, K>>;
	export const EventEmitter: EventEmitterStatic;
}
declare type RgbColor = {
	r: number;
	g: number;
	b: number;
};
declare type HslColor = {
	h: number;
	s: number;
	l: number;
};
declare type HsvColor = {
	h: number;
	s: number;
	v: number;
};
declare type WithAlpha<O> = O & {
	a: number;
};
declare type RgbaColor = WithAlpha<RgbColor>;
declare type HslaColor = WithAlpha<HslColor>;
declare type HsvaColor = WithAlpha<HsvColor>;
/**
 * Pixi supports multiple color formats, including CSS color strings, hex, numbers, and arrays.
 *
 * When providing values for any of the color properties, you can use any of the {@link color.ColorSource} formats.
 * \`\`\`typescript
 * import { Color } from 'pixi.js';
 *
 * // All of these are valid:
 * sprite.tint = 'red';
 * sprite.tint = 0xff0000;
 * sprite.tint = '#ff0000';
 * sprite.tint = new Color('red');
 *
 * // Same for graphics fill/stroke colors and other  color values:
 * graphics.fill({ color: 'red' });
 * graphics.fill({ color: 0xff0000 });
 * graphics.stroke({ color: '#ff0000' });
 * graphics.stroke({ color: new Color('red')};
 * \`\`\`
 * @namespace color
 */
/**
 * RGBA color array.
 *
 * \`[number, number, number, number]\`
 * @memberof color
 */
export type RgbaArray = [
	number,
	number,
	number,
	number
];
/**
 * Valid formats to use when defining any color properties, also valid for the {@link color.Color} constructor.
 *
 * These types are extended from [colord](https://www.npmjs.com/package/colord) with some PixiJS-specific extensions.
 *
 * Possible value types are:
 * - [Color names](https://www.w3.org/TR/css-color-4/#named-colors):
 *   \`'red'\`, \`'green'\`, \`'blue'\`, \`'white'\`, etc.
 * - RGB hex integers (\`0xRRGGBB\`):
 *   \`0xff0000\`, \`0x00ff00\`, \`0x0000ff\`, etc.
 * - [RGB(A) hex strings](https://www.w3.org/TR/css-color-4/#hex-notation):
 *   - 6 digits (\`RRGGBB\`): \`'ff0000'\`, \`'#00ff00'\`, \`'0x0000ff'\`, etc.
 *   - 3 digits (\`RGB\`): \`'f00'\`, \`'#0f0'\`, \`'0x00f'\`, etc.
 *   - 8 digits (\`RRGGBBAA\`): \`'ff000080'\`, \`'#00ff0080'\`, \`'0x0000ff80'\`, etc.
 *   - 4 digits (\`RGBA\`): \`'f008'\`, \`'#0f08'\`, \`'0x00f8'\`, etc.
 * - RGB(A) objects:
 *   \`{ r: 255, g: 0, b: 0 }\`, \`{ r: 255, g: 0, b: 0, a: 0.5 }\`, etc.
 * - [RGB(A) strings](https://www.w3.org/TR/css-color-4/#rgb-functions):
 *   \`'rgb(255, 0, 0)'\`, \`'rgb(100% 0% 0%)'\`, \`'rgba(255, 0, 0, 0.5)'\`, \`'rgba(100% 0% 0% / 50%)'\`, etc.
 * - RGB(A) arrays:
 *   \`[1, 0, 0]\`, \`[1, 0, 0, 0.5]\`, etc.
 * - RGB(A) Float32Array:
 *   \`new Float32Array([1, 0, 0])\`, \`new Float32Array([1, 0, 0, 0.5])\`, etc.
 * - RGB(A) Uint8Array:
 *   \`new Uint8Array([255, 0, 0])\`, \`new Uint8Array([255, 0, 0, 128])\`, etc.
 * - RGB(A) Uint8ClampedArray:
 *   \`new Uint8ClampedArray([255, 0, 0])\`, \`new Uint8ClampedArray([255, 0, 0, 128])\`, etc.
 * - HSL(A) objects:
 *   \`{ h: 0, s: 100, l: 50 }\`, \`{ h: 0, s: 100, l: 50, a: 0.5 }\`, etc.
 * - [HSL(A) strings](https://www.w3.org/TR/css-color-4/#the-hsl-notation):
 *   \`'hsl(0, 100%, 50%)'\`, \`'hsl(0deg 100% 50%)'\`, \`'hsla(0, 100%, 50%, 0.5)'\`, \`'hsla(0deg 100% 50% / 50%)'\`, etc.
 * - HSV(A) objects:
 *   \`{ h: 0, s: 100, v: 100 }\`, \`{ h: 0, s: 100, v: 100, a: 0.5 }\`, etc.
 * - {@link color.Color} objects.
 * @since 7.2.0
 * @memberof color
 */
export type ColorSource = string | number | number[] | Float32Array | Uint8Array | Uint8ClampedArray | HslColor | HslaColor | HsvColor | HsvaColor | RgbColor | RgbaColor | Color | number;
/**
 * Color utility class. Can accept any {@link color.ColorSource} format in its constructor.
 * \`\`\`js
 * import { Color } from 'pixi.js';
 *
 * new Color('red').toArray(); // [1, 0, 0, 1]
 * new Color(0xff0000).toArray(); // [1, 0, 0, 1]
 * new Color('ff0000').toArray(); // [1, 0, 0, 1]
 * new Color('#f00').toArray(); // [1, 0, 0, 1]
 * new Color('0xff0000ff').toArray(); // [1, 0, 0, 1]
 * new Color('#f00f').toArray(); // [1, 0, 0, 1]
 * new Color({ r: 255, g: 0, b: 0, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('rgb(255, 0, 0, 0.5)').toArray(); // [1, 0, 0, 0.5]
 * new Color([1, 1, 1]).toArray(); // [1, 1, 1, 1]
 * new Color([1, 0, 0, 0.5]).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Float32Array([1, 0, 0, 0.5])).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Uint8Array([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color(new Uint8ClampedArray([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color({ h: 0, s: 100, l: 50, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('hsl(0, 100%, 50%, 50%)').toArray(); // [1, 0, 0, 0.5]
 * new Color({ h: 0, s: 100, v: 100, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * \`\`\`
 * @since 7.2.0
 * @memberof color
 */
export declare class Color {
	/**
	 * Default Color object for static uses
	 * @example
	 * import { Color } from 'pixi.js';
	 * Color.shared.setValue(0xffffff).toHex(); // '#ffffff'
	 */
	static readonly shared: Color;
	/**
	 * Temporary Color object for static uses internally.
	 * As to not conflict with Color.shared.
	 * @ignore
	 */
	private static readonly _temp;
	/** Pattern for hex strings */
	private static readonly HEX_PATTERN;
	/** Internal color source, from constructor or set value */
	private _value;
	/** Normalized rgba component, floats from 0-1 */
	private _components;
	/** Cache color as number */
	private _int;
	/** An array of the current Color. Only populated when \`toArray\` functions are called */
	private _arrayRgba;
	private _arrayRgb;
	/**
	 * @param {ColorSource} value - Optional value to use, if not provided, white is used.
	 */
	constructor(value?: ColorSource);
	/** Get red component (0 - 1) */
	get red(): number;
	/** Get green component (0 - 1) */
	get green(): number;
	/** Get blue component (0 - 1) */
	get blue(): number;
	/** Get alpha component (0 - 1) */
	get alpha(): number;
	/**
	 * Set the value, suitable for chaining
	 * @param value
	 * @see Color.value
	 */
	setValue(value: ColorSource): this;
	/**
	 * The current color source.
	 *
	 * When setting:
	 * - Setting to an instance of \`Color\` will copy its color source and components.
	 * - Otherwise, \`Color\` will try to normalize the color source and set the components.
	 *   If the color source is invalid, an \`Error\` will be thrown and the \`Color\` will left unchanged.
	 *
	 * Note: The \`null\` in the setter's parameter type is added to match the TypeScript rule: return type of getter
	 * must be assignable to its setter's parameter type. Setting \`value\` to \`null\` will throw an \`Error\`.
	 *
	 * When getting:
	 * - A return value of \`null\` means the previous value was overridden (e.g., {@link Color.multiply multiply},
	 *   {@link Color.premultiply premultiply} or {@link Color.round round}).
	 * - Otherwise, the color source used when setting is returned.
	 */
	set value(value: ColorSource | null);
	get value(): Exclude<ColorSource, Color> | null;
	/**
	 * Copy a color source internally.
	 * @param value - Color source
	 */
	private _cloneSource;
	/**
	 * Equality check for color sources.
	 * @param value1 - First color source
	 * @param value2 - Second color source
	 * @returns \`true\` if the color sources are equal, \`false\` otherwise.
	 */
	private _isSourceEqual;
	/**
	 * Convert to a RGBA color object.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1, a: 1 }
	 */
	toRgba(): RgbaColor;
	/**
	 * Convert to a RGB color object.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1 }
	 */
	toRgb(): RgbColor;
	/** Convert to a CSS-style rgba string: \`rgba(255,255,255,1.0)\`. */
	toRgbaString(): string;
	/**
	 * Convert to an [R, G, B] array of clamped uint8 values (0 to 255).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toUint8RgbArray(); // returns [255, 255, 255]
	 * @param {number[]|Uint8Array|Uint8ClampedArray} [out] - Output array
	 */
	toUint8RgbArray(): number[];
	toUint8RgbArray<T extends number[] | Uint8Array | Uint8ClampedArray>(out: T): T;
	/**
	 * Convert to an [R, G, B, A] array of normalized floats (numbers from 0.0 to 1.0).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toArray(); // returns [1, 1, 1, 1]
	 * @param {number[]|Float32Array} [out] - Output array
	 */
	toArray(): number[];
	toArray<T extends number[] | Float32Array>(out: T): T;
	/**
	 * Convert to an [R, G, B] array of normalized floats (numbers from 0.0 to 1.0).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toRgbArray(); // returns [1, 1, 1]
	 * @param {number[]|Float32Array} [out] - Output array
	 */
	toRgbArray(): number[];
	toRgbArray<T extends number[] | Float32Array>(out: T): T;
	/**
	 * Convert to a hexadecimal number.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toNumber(); // returns 16777215
	 */
	toNumber(): number;
	/**
	 * Convert to a BGR number
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color(0xffcc99).toBgrNumber(); // returns 0x99ccff
	 */
	toBgrNumber(): number;
	/**
	 * Convert to a hexadecimal number in little endian format (e.g., BBGGRR).
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color(0xffcc99).toLittleEndianNumber(); // returns 0x99ccff
	 * @returns {number} - The color as a number in little endian format.
	 */
	toLittleEndianNumber(): number;
	/**
	 * Multiply with another color. This action is destructive, and will
	 * override the previous \`value\` property to be \`null\`.
	 * @param {ColorSource} value - The color to multiply by.
	 */
	multiply(value: ColorSource): this;
	/**
	 * Converts color to a premultiplied alpha format. This action is destructive, and will
	 * override the previous \`value\` property to be \`null\`.
	 * @param alpha - The alpha to multiply by.
	 * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
	 * @returns {Color} - Itself.
	 */
	premultiply(alpha: number, applyToRGB?: boolean): this;
	/**
	 * Premultiplies alpha with current color.
	 * @param {number} alpha - The alpha to multiply by.
	 * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
	 * @returns {number} tint multiplied by alpha
	 */
	toPremultiplied(alpha: number, applyToRGB?: boolean): number;
	/**
	 * Convert to a hexadecimal string.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toHex(); // returns "#ffffff"
	 */
	toHex(): string;
	/**
	 * Convert to a hexadecimal string with alpha.
	 * @example
	 * import { Color } from 'pixi.js';
	 * new Color('white').toHexa(); // returns "#ffffffff"
	 */
	toHexa(): string;
	/**
	 * Set alpha, suitable for chaining.
	 * @param alpha
	 */
	setAlpha(alpha: number): this;
	/**
	 * Normalize the input value into rgba
	 * @param value - Input value
	 */
	private _normalize;
	/** Refresh the internal color rgb number */
	private _refreshInt;
	/**
	 * Clamps values to a range. Will override original values
	 * @param value - Value(s) to clamp
	 * @param min - Minimum value
	 * @param max - Maximum value
	 */
	private _clamp;
	/**
	 * Check if the value is a color-like object
	 * @param value - Value to check
	 * @returns True if the value is a color-like object
	 * @static
	 * @example
	 * import { Color } from 'pixi.js';
	 * Color.isColorLike('white'); // returns true
	 * Color.isColorLike(0xffffff); // returns true
	 * Color.isColorLike([1, 1, 1]); // returns true
	 */
	static isColorLike(value: unknown): value is ColorSource;
}
/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointData {
	/** X coord */
	x: number;
	/** Y coord */
	y: number;
}
/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointLike extends PointData {
	/**
	 * Copies x and y from the given point
	 * @param {PointData} p - The point to copy from
	 * @returns {this} Returns itself.
	 */
	copyFrom: (p: PointData) => this;
	/**
	 * Copies x and y into the given point
	 * @param {PointLike} p - The point to copy.
	 * @returns {PointLike} Given point with values updated
	 */
	copyTo: <T extends PointLike>(p: T) => T;
	/**
	 * Returns true if the given point is equal to this point
	 * @param {PointData} p - The point to check
	 * @returns {boolean} Whether the given point equal to this point
	 */
	equals: (p: PointData) => boolean;
	/**
	 * Sets the point to a new x and y position.
	 * If y is omitted, both x and y will be set to x.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=x] - position of the point on the y axis
	 */
	set: (x?: number, y?: number) => void;
}
export interface Point extends PixiMixins.Point {
}
/**
 * The Point object represents a location in a two-dimensional coordinate system, where \`x\` represents
 * the position on the horizontal axis and \`y\` represents the position on the vertical axis.
 * <br/>
 * Many Pixi functions accept the \`PointData\` type as an alternative to \`Point\`,
 * which only requires \`x\` and \`y\` properties.
 * @class
 * @implements {PointLike}
 * @memberof maths
 */
export declare class Point implements PointLike {
	/** Position of the point on the x axis */
	x: number;
	/** Position of the point on the y axis */
	y: number;
	/**
	 * Creates a new \`Point\`
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=0] - position of the point on the y axis
	 */
	constructor(x?: number, y?: number);
	/**
	 * Creates a clone of this point
	 * @returns A clone of this point
	 */
	clone(): Point;
	/**
	 * Copies \`x\` and \`y\` from the given point into this point
	 * @param p - The point to copy from
	 * @returns The point instance itself
	 */
	copyFrom(p: PointData): this;
	/**
	 * Copies this point's x and y into the given point (\`p\`).
	 * @param p - The point to copy to. Can be any of type that is or extends \`PointData\`
	 * @returns The point (\`p\`) with values updated
	 */
	copyTo<T extends PointLike>(p: T): T;
	/**
	 * Accepts another point (\`p\`) and returns \`true\` if the given point is equal to this point
	 * @param p - The point to check
	 * @returns Returns \`true\` if both \`x\` and \`y\` are equal
	 */
	equals(p: PointData): boolean;
	/**
	 * Sets the point to a new \`x\` and \`y\` position.
	 * If \`y\` is omitted, both \`x\` and \`y\` will be set to \`x\`.
	 * @param {number} [x=0] - position of the point on the \`x\` axis
	 * @param {number} [y=x] - position of the point on the \`y\` axis
	 * @returns The point instance itself
	 */
	set(x?: number, y?: number): this;
	toString(): string;
	/**
	 * A static Point object with \`x\` and \`y\` values of \`0\`. Can be used to avoid creating new objects multiple times.
	 * @readonly
	 */
	static get shared(): Point;
}
interface TransformableObject {
	position: PointData;
	scale: PointData;
	pivot: PointData;
	skew: PointData;
	rotation: number;
}
/**
 * A fast matrix for 2D transformations.
 * \`\`\`js
 * | a | c | tx|
 * | b | d | ty|
 * | 0 | 0 | 1 |
 * \`\`\`
 * @memberof maths
 */
export declare class Matrix {
	/** @default 1 */
	a: number;
	/** @default 0 */
	b: number;
	/** @default 0 */
	c: number;
	/** @default 1 */
	d: number;
	/** @default 0 */
	tx: number;
	/** @default 0 */
	ty: number;
	/** An array of the current matrix. Only populated when \`toArray\` is called */
	array: Float32Array | null;
	/**
	 * @param a - x scale
	 * @param b - y skew
	 * @param c - x skew
	 * @param d - y scale
	 * @param tx - x translation
	 * @param ty - y translation
	 */
	constructor(a?: number, b?: number, c?: number, d?: number, tx?: number, ty?: number);
	/**
	 * Creates a Matrix object based on the given array. The Element to Matrix mapping order is as follows:
	 *
	 * a = array[0]
	 * b = array[1]
	 * c = array[3]
	 * d = array[4]
	 * tx = array[2]
	 * ty = array[5]
	 * @param array - The array that the matrix will be populated from.
	 */
	fromArray(array: number[]): void;
	/**
	 * Sets the matrix properties.
	 * @param a - Matrix component
	 * @param b - Matrix component
	 * @param c - Matrix component
	 * @param d - Matrix component
	 * @param tx - Matrix component
	 * @param ty - Matrix component
	 * @returns This matrix. Good for chaining method calls.
	 */
	set(a: number, b: number, c: number, d: number, tx: number, ty: number): this;
	/**
	 * Creates an array from the current Matrix object.
	 * @param transpose - Whether we need to transpose the matrix or not
	 * @param [out=new Float32Array(9)] - If provided the array will be assigned to out
	 * @returns The newly created array which contains the matrix
	 */
	toArray(transpose?: boolean, out?: Float32Array): Float32Array;
	/**
	 * Get a new position with the current transformation applied.
	 * Can be used to go from a child's coordinate space to the world coordinate space. (e.g. rendering)
	 * @param pos - The origin
	 * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
	 * @returns {Point} The new point, transformed through this matrix
	 */
	apply<P extends PointData = Point>(pos: PointData, newPos?: P): P;
	/**
	 * Get a new position with the inverse of the current transformation applied.
	 * Can be used to go from the world coordinate space to a child's coordinate space. (e.g. input)
	 * @param pos - The origin
	 * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
	 * @returns {Point} The new point, inverse-transformed through this matrix
	 */
	applyInverse<P extends PointData = Point>(pos: PointData, newPos?: P): P;
	/**
	 * Translates the matrix on the x and y.
	 * @param x - How much to translate x by
	 * @param y - How much to translate y by
	 * @returns This matrix. Good for chaining method calls.
	 */
	translate(x: number, y: number): this;
	/**
	 * Applies a scale transformation to the matrix.
	 * @param x - The amount to scale horizontally
	 * @param y - The amount to scale vertically
	 * @returns This matrix. Good for chaining method calls.
	 */
	scale(x: number, y: number): this;
	/**
	 * Applies a rotation transformation to the matrix.
	 * @param angle - The angle in radians.
	 * @returns This matrix. Good for chaining method calls.
	 */
	rotate(angle: number): this;
	/**
	 * Appends the given Matrix to this Matrix.
	 * @param matrix - The matrix to append.
	 * @returns This matrix. Good for chaining method calls.
	 */
	append(matrix: Matrix): this;
	/**
	 * Appends two matrix's and sets the result to this matrix. AB = A * B
	 * @param a - The matrix to append.
	 * @param b - The matrix to append.
	 * @returns This matrix. Good for chaining method calls.
	 */
	appendFrom(a: Matrix, b: Matrix): this;
	/**
	 * Sets the matrix based on all the available properties
	 * @param x - Position on the x axis
	 * @param y - Position on the y axis
	 * @param pivotX - Pivot on the x axis
	 * @param pivotY - Pivot on the y axis
	 * @param scaleX - Scale on the x axis
	 * @param scaleY - Scale on the y axis
	 * @param rotation - Rotation in radians
	 * @param skewX - Skew on the x axis
	 * @param skewY - Skew on the y axis
	 * @returns This matrix. Good for chaining method calls.
	 */
	setTransform(x: number, y: number, pivotX: number, pivotY: number, scaleX: number, scaleY: number, rotation: number, skewX: number, skewY: number): this;
	/**
	 * Prepends the given Matrix to this Matrix.
	 * @param matrix - The matrix to prepend
	 * @returns This matrix. Good for chaining method calls.
	 */
	prepend(matrix: Matrix): this;
	/**
	 * Decomposes the matrix (x, y, scaleX, scaleY, and rotation) and sets the properties on to a transform.
	 * @param transform - The transform to apply the properties to.
	 * @returns The transform with the newly applied properties
	 */
	decompose(transform: TransformableObject): TransformableObject;
	/**
	 * Inverts this matrix
	 * @returns This matrix. Good for chaining method calls.
	 */
	invert(): this;
	/** Checks if this matrix is an identity matrix */
	isIdentity(): boolean;
	/**
	 * Resets this Matrix to an identity (default) matrix.
	 * @returns This matrix. Good for chaining method calls.
	 */
	identity(): this;
	/**
	 * Creates a new Matrix object with the same values as this one.
	 * @returns A copy of this matrix. Good for chaining method calls.
	 */
	clone(): Matrix;
	/**
	 * Changes the values of the given matrix to be the same as the ones in this matrix
	 * @param matrix - The matrix to copy to.
	 * @returns The matrix given in parameter with its values updated.
	 */
	copyTo(matrix: Matrix): Matrix;
	/**
	 * Changes the values of the matrix to be the same as the ones in given matrix
	 * @param matrix - The matrix to copy from.
	 * @returns this
	 */
	copyFrom(matrix: Matrix): this;
	/**
	 * check to see if two matrices are the same
	 * @param matrix - The matrix to compare to.
	 */
	equals(matrix: Matrix): boolean;
	toString(): string;
	/**
	 * A default (identity) matrix.
	 *
	 * This is a shared object, if you want to modify it consider creating a new \`Matrix\`
	 * @readonly
	 */
	static get IDENTITY(): Readonly<Matrix>;
	/**
	 * A static Matrix that can be used to avoid creating new objects.
	 * Will always ensure the matrix is reset to identity when requested.
	 * Use this object for fast but temporary calculations, as it may be mutated later on.
	 * This is a different object to the \`IDENTITY\` object and so can be modified without changing \`IDENTITY\`.
	 * @readonly
	 */
	static get shared(): Matrix;
}
export interface ObservablePoint extends PixiMixins.ObservablePoint {
}
/**
 * Observer used to listen for observable point changes.
 * @memberof maths
 */
export interface Observer<T> {
	/** Callback to call when the point has updated. */
	_onUpdate: (point?: T) => void;
}
/**
 * The ObservablePoint object represents a location in a two-dimensional coordinate system, where \`x\` represents
 * the position on the horizontal axis and \`y\` represents the position on the vertical axis.
 *
 * An \`ObservablePoint\` is a point that triggers the \`onUpdate\` method on an observer when the point's position is changed.
 * @memberof maths
 */
export declare class ObservablePoint implements PointLike {
	/** @ignore */
	_x: number;
	/** @ignore */
	_y: number;
	/** This object used to call the \`onUpdate\` callback when the point changes. */
	private readonly _observer;
	/**
	 * Creates a new \`ObservablePoint\`
	 * @param observer - Observer to pass to listen for change events.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=0] - position of the point on the y axis
	 */
	constructor(observer: Observer<ObservablePoint>, x?: number, y?: number);
	/**
	 * Creates a clone of this point.
	 * @param observer - Optional observer to pass to the new observable point.
	 * @returns a copy of this observable point
	 */
	clone(observer?: Observer<ObservablePoint>): ObservablePoint;
	/**
	 * Sets the point to a new \`x\` and \`y\` position.
	 * If \`y\` is omitted, both \`x\` and \`y\` will be set to \`x\`.
	 * @param {number} [x=0] - position of the point on the x axis
	 * @param {number} [y=x] - position of the point on the y axis
	 * @returns The observable point instance itself
	 */
	set(x?: number, y?: number): this;
	/**
	 * Copies x and y from the given point (\`p\`)
	 * @param p - The point to copy from. Can be any of type that is or extends \`PointData\`
	 * @returns The observable point instance itself
	 */
	copyFrom(p: PointData): this;
	/**
	 * Copies this point's x and y into that of the given point (\`p\`)
	 * @param p - The point to copy to. Can be any of type that is or extends \`PointData\`
	 * @returns The point (\`p\`) with values updated
	 */
	copyTo<T extends PointLike>(p: T): T;
	/**
	 * Accepts another point (\`p\`) and returns \`true\` if the given point is equal to this point
	 * @param p - The point to check
	 * @returns Returns \`true\` if both \`x\` and \`y\` are equal
	 */
	equals(p: PointData): boolean;
	toString(): string;
	/** Position of the observable point on the x axis. */
	get x(): number;
	set x(value: number);
	/** Position of the observable point on the y axis. */
	get y(): number;
	set y(value: number);
}
/**
 * Two Pi.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const PI_2: number;
/**
 * Conversion factor for converting radians to degrees.
 * @static
 * @member {number} RAD_TO_DEG
 * @memberof maths
 */
export declare const RAD_TO_DEG: number;
/**
 * Conversion factor for converting degrees to radians.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const DEG_TO_RAD: number;
/**
 * Constants that identify shapes, mainly to prevent \`instanceof\` calls.
 * @memberof maths
 */
export type SHAPE_PRIMITIVE = "polygon" | "rectangle" | "circle" | "ellipse" | "triangle" | "roundedRectangle";
/**
 * A basic object to define a Pixi shape.
 * @memberof maths
 */
export interface ShapePrimitive {
	/** The type of the object, mainly used to avoid \`instanceof\` checks */
	readonly type: SHAPE_PRIMITIVE;
	/** Checks whether the x and y coordinates passed to this function are contained within this ShapePrimitive. */
	contains(x: number, y: number): boolean;
	/** Checks whether the x and y coordinates passed to this function are contained within the stroke of this shape */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/** Creates a clone of this ShapePrimitive instance. */
	clone(): ShapePrimitive;
	/** Copies the properties from another ShapePrimitive to this ShapePrimitive. */
	copyFrom(source: ShapePrimitive): void;
	/** Copies the properties from this ShapePrimitive to another ShapePrimitive. */
	copyTo(destination: ShapePrimitive): void;
	/** Returns the framing rectangle of the ShapePrimitive as a Rectangle object. */
	getBounds(out?: Rectangle): Rectangle;
	/** The X coordinate of the shape */
	readonly x: number;
	/** The Y coordinate of the shape */
	readonly y: number;
}
export interface Rectangle extends PixiMixins.Rectangle {
}
/**
 * The \`Rectangle\` object is an area defined by its position, as indicated by its top-left corner
 * point (\`x\`, \`y\`) and by its \`width\` and its \`height\`.
 *
 * It also provides convenience methods to get and set the position and size of the rectangle such as
 * {@link maths.Rectangle#bottom|bottom}, {@link maths.Rectangle#right|right} and {@link maths.Rectangle#isEmpty|isEmpty}.
 * @memberof maths
 */
export declare class Rectangle implements ShapePrimitive {
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'rectangle'
	 */
	readonly type: SHAPE_PRIMITIVE;
	/**
	 * The X coordinate of the upper-left corner of the rectangle
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coordinate of the upper-left corner of the rectangle
	 * @default 0
	 */
	y: number;
	/**
	 * The overall width of this rectangle
	 *  @default 0
	 */
	width: number;
	/**
	 * The overall height of this rectangle
	 * @default 0
	 */
	height: number;
	/**
	 * @param x - The X coordinate of the upper-left corner of the rectangle
	 * @param y - The Y coordinate of the upper-left corner of the rectangle
	 * @param width - The overall width of the rectangle
	 * @param height - The overall height of the rectangle
	 */
	constructor(x?: string | number, y?: string | number, width?: string | number, height?: string | number);
	/** Returns the left edge of the rectangle. */
	get left(): number;
	/** Returns the right edge of the rectangle. */
	get right(): number;
	/** Returns the top edge of the rectangle. */
	get top(): number;
	/** Returns the bottom edge of the rectangle. */
	get bottom(): number;
	/** Determines whether the Rectangle is empty. */
	isEmpty(): boolean;
	/** A constant empty rectangle. This is a new object every time the property is accessed */
	static get EMPTY(): Rectangle;
	/**
	 * Creates a clone of this Rectangle
	 * @returns a copy of the rectangle
	 */
	clone(): Rectangle;
	/**
	 * Converts a Bounds object to a Rectangle object.
	 * @param bounds - The bounds to copy and convert to a rectangle.
	 * @returns Returns itself.
	 */
	copyFromBounds(bounds: Bounds): this;
	/**
	 * Copies another rectangle to this one.
	 * @param rectangle - The rectangle to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(rectangle: Rectangle): Rectangle;
	/**
	 * Copies this rectangle to another one.
	 * @param rectangle - The rectangle to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(rectangle: Rectangle): Rectangle;
	/**
	 * Checks whether the x and y coordinates given are contained within this Rectangle
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @returns Whether the x/y coordinates are within this Rectangle
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this rectangle including the stroke.
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param alignment - The alignment of the stroke, 0.5 by default
	 * @returns Whether the x/y coordinates are within this rectangle
	 */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/**
	 * Determines whether the \`other\` Rectangle transformed by \`transform\` intersects with \`this\` Rectangle object.
	 * Returns true only if the area of the intersection is >0, this means that Rectangles
	 * sharing a side are not overlapping. Another side effect is that an arealess rectangle
	 * (width or height equal to zero) can't intersect any other rectangle.
	 * @param {Rectangle} other - The Rectangle to intersect with \`this\`.
	 * @param {Matrix} transform - The transformation matrix of \`other\`.
	 * @returns {boolean} A value of \`true\` if the transformed \`other\` Rectangle intersects with \`this\`; otherwise \`false\`.
	 */
	intersects(other: Rectangle, transform?: Matrix): boolean;
	/**
	 * Pads the rectangle making it grow in all directions.
	 * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
	 * @param paddingX - The horizontal padding amount.
	 * @param paddingY - The vertical padding amount.
	 * @returns Returns itself.
	 */
	pad(paddingX?: number, paddingY?: number): this;
	/**
	 * Fits this rectangle around the passed one.
	 * @param rectangle - The rectangle to fit.
	 * @returns Returns itself.
	 */
	fit(rectangle: Rectangle): this;
	/**
	 * Enlarges rectangle that way its corners lie on grid
	 * @param resolution - resolution
	 * @param eps - precision
	 * @returns Returns itself.
	 */
	ceil(resolution?: number, eps?: number): this;
	/**
	 * Enlarges this rectangle to include the passed rectangle.
	 * @param rectangle - The rectangle to include.
	 * @returns Returns itself.
	 */
	enlarge(rectangle: Rectangle): this;
	/**
	 * Returns the framing rectangle of the rectangle as a Rectangle object
	 * @param out - optional rectangle to store the result
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	/**
	 * Checks if this rectangle fully contains another rectangle.
	 *
	 * A rectangle contains another rectangle if all four corners of the other rectangle
	 * lie within the bounds of this rectangle.
	 *
	 * \`\`\`ts
	 * const container = new Rectangle(0, 0, 100, 100);
	 * const inside = new Rectangle(25, 25, 50, 50);
	 * const partial = new Rectangle(75, 75, 50, 50);
	 *
	 * container.containsRect(inside); // Returns true
	 * container.containsRect(partial); // Returns false - partial overlap
	 * \`\`\`
	 *
	 * Note: If either rectangle has a width or height of 0, this method returns false
	 * since a zero-area rectangle cannot meaningfully contain another rectangle.
	 * @param other - The rectangle to check if it is contained within this one
	 * @returns True if the other rectangle is fully contained within this one
	 */
	containsRect(other: Rectangle): boolean;
	toString(): string;
}
/**
 * Simple bounds implementation instead of more ambiguous [number, number, number, number]
 * @memberof rendering
 */
export interface BoundsData {
	minX: number;
	minY: number;
	maxX: number;
	maxY: number;
}
/**
 * A representation of an AABB bounding box.
 * @memberof rendering
 */
export declare class Bounds {
	/** @default Infinity */
	minX: number;
	/** @default Infinity */
	minY: number;
	/** @default -Infinity */
	maxX: number;
	/** @default -Infinity */
	maxY: number;
	matrix: Matrix;
	private _rectangle;
	constructor(minX?: number, minY?: number, maxX?: number, maxY?: number);
	/**
	 * Checks if bounds are empty.
	 * @returns - True if empty.
	 */
	isEmpty(): boolean;
	/** The bounding rectangle of the bounds. */
	get rectangle(): Rectangle;
	/** Clears the bounds and resets. */
	clear(): this;
	/**
	 * Sets the bounds.
	 * @param x0 - left X of frame
	 * @param y0 - top Y of frame
	 * @param x1 - right X of frame
	 * @param y1 - bottom Y of frame
	 */
	set(x0: number, y0: number, x1: number, y1: number): void;
	/**
	 * Adds sprite frame
	 * @param x0 - left X of frame
	 * @param y0 - top Y of frame
	 * @param x1 - right X of frame
	 * @param y1 - bottom Y of frame
	 * @param matrix
	 */
	addFrame(x0: number, y0: number, x1: number, y1: number, matrix?: Matrix): void;
	/**
	 * Adds a rectangle to the bounds.
	 * @param rect - The rectangle to be added.
	 * @param matrix - The matrix to apply to the bounds.
	 */
	addRect(rect: Rectangle, matrix?: Matrix): void;
	/**
	 * Adds other {@link Bounds}.
	 * @param bounds - The Bounds to be added
	 * @param matrix
	 */
	addBounds(bounds: BoundsData, matrix?: Matrix): void;
	/**
	 * Adds other Bounds, masked with Bounds.
	 * @param mask - The Bounds to be added.
	 */
	addBoundsMask(mask: Bounds): void;
	/**
	 * Adds other Bounds, multiplied with matrix.
	 * @param matrix - The matrix to apply to the bounds.
	 */
	applyMatrix(matrix: Matrix): void;
	/**
	 * Resizes the bounds object to include the given rectangle.
	 * @param rect - The rectangle to be included.
	 */
	fit(rect: Rectangle): this;
	/**
	 * Resizes the bounds object to include the given bounds.
	 * @param left - The left value of the bounds.
	 * @param right - The right value of the bounds.
	 * @param top - The top value of the bounds.
	 * @param bottom - The bottom value of the bounds.
	 */
	fitBounds(left: number, right: number, top: number, bottom: number): this;
	/**
	 * Pads bounds object, making it grow in all directions.
	 * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
	 * @param paddingX - The horizontal padding amount.
	 * @param paddingY - The vertical padding amount.
	 */
	pad(paddingX: number, paddingY?: number): this;
	/** Ceils the bounds. */
	ceil(): this;
	/** Clones the bounds. */
	clone(): Bounds;
	/**
	 * Scales the bounds by the given values
	 * @param x - The X value to scale by.
	 * @param y - The Y value to scale by.
	 */
	scale(x: number, y?: number): this;
	/** the x value of the bounds. */
	get x(): number;
	set x(value: number);
	/** the y value of the bounds. */
	get y(): number;
	set y(value: number);
	/** the width value of the bounds. */
	get width(): number;
	set width(value: number);
	/** the height value of the bounds. */
	get height(): number;
	set height(value: number);
	/** the left value of the bounds. */
	get left(): number;
	/** the right value of the bounds. */
	get right(): number;
	/** the top value of the bounds. */
	get top(): number;
	/** the bottom value of the bounds. */
	get bottom(): number;
	/** Is the bounds positive. */
	get isPositive(): boolean;
	get isValid(): boolean;
	/**
	 * Adds screen vertices from array
	 * @param vertexData - calculated vertices
	 * @param beginOffset - begin offset
	 * @param endOffset - end offset, excluded
	 * @param matrix
	 */
	addVertexData(vertexData: Float32Array, beginOffset: number, endOffset: number, matrix?: Matrix): void;
	/**
	 * Checks if the point is contained within the bounds.
	 * @param x - x coordinate
	 * @param y - y coordinate
	 */
	containsPoint(x: number, y: number): boolean;
	toString(): string;
	/**
	 * Copies the bounds from another bounds object.
	 * @param bounds - The bounds to copy from.
	 * @returns - This bounds object.
	 */
	copyFrom(bounds: Bounds): this;
}
export interface ViewObserver {
	onViewUpdate: () => void;
}
/**
 * A view is something that is able to be rendered by the renderer.
 * @memberof scene
 */
export interface View {
	/** a unique id for this view */
	readonly uid: number;
	/** whether or not this view should be batched */
	batched: boolean;
	/**
	 * an identifier that is used to identify the type of system that will be used to render this renderable
	 * eg, 'sprite' will use the sprite system (based on the systems name
	 */
	readonly renderPipeId: string;
	/** this is an int because it is packed directly into an attribute in the shader */
	_roundPixels: 0 | 1;
	/** @private */
	_lastUsed: number;
	/**
	 *  Whether or not to round the x/y position of the object.
	 * @type {boolean}
	 */
	get roundPixels(): boolean;
	/** if true, the view will have its position rounded to the nearest whole number */
	set roundPixels(value: boolean);
	/** this is the AABB rectangle bounds of the view in local untransformed space. */
	bounds: BoundsData;
	/** Checks if the point is within the view */
	containsPoint: (point: Point) => boolean;
}
export interface Renderable extends Container, View {
}
/**
 * An instruction that can be executed by the renderer
 * @memberof rendering
 */
export interface Instruction {
	/** a the id of the render pipe that can run this instruction */
	renderPipeId: string;
	/** the name of the instruction */
	action?: string;
	/** true if this instruction can be compiled into a WebGPU bundle */
	canBundle: boolean;
}
/**
 * A set of instructions that can be executed by the renderer.
 * Basically wraps an array, but with some extra properties that help the renderer
 * to keep things nice and optimised.
 *
 * Note:
 * InstructionSet.instructions contains all the instructions, but does not resize (for performance).
 * So for the true length of the instructions you need to use InstructionSet.instructionSize
 * @memberof rendering
 */
export declare class InstructionSet {
	/** a unique id for this instruction set used through the renderer */
	readonly uid: number;
	/** the array of instructions */
	readonly instructions: Instruction[];
	/** the actual size of the array (any instructions passed this should be ignored) */
	instructionSize: number;
	/** allows for access to the render pipes of the renderer */
	renderPipes: any;
	renderables: Renderable[];
	/** used by the garbage collector to track when the instruction set was last used */
	gcTick: number;
	/** reset the instruction set so it can be reused set size back to 0 */
	reset(): void;
	/**
	 * Add an instruction to the set
	 * @param instruction - add an instruction to the set
	 */
	add(instruction: Instruction): void;
	/**
	 * Log the instructions to the console (for debugging)
	 * @internal
	 * @ignore
	 */
	log(): void;
}
/**
 * Common interface for CanvasRenderingContext2D, OffscreenCanvasRenderingContext2D, and other custom canvas 2D context.
 * @memberof environment
 */
export interface ICanvasRenderingContext2D extends CanvasState, CanvasTransform, CanvasCompositing, CanvasImageSmoothing, CanvasFillStrokeStyles, CanvasShadowStyles, CanvasFilters, CanvasRect, CanvasDrawPath, CanvasText, CanvasDrawImage, CanvasImageData, CanvasPathDrawingStyles, Omit<CanvasTextDrawingStyles, "letterSpacing">, CanvasPath {
	/** creates a pattern using the specified image and repetition. */
	createPattern(image: CanvasImageSource | ICanvas, repetition: string | null): CanvasPattern | null;
	/** provides different ways to draw an image onto the canvas */
	drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number): void;
	drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number, dw: number, dh: number): void;
	drawImage(image: CanvasImageSource | ICanvas, sx: number, sy: number, sw: number, sh: number, dx: number, dy: number, dw: number, dh: number): void;
	/** sets the horizontal spacing behavior between text characters. */
	letterSpacing?: string;
	/** sets the horizontal spacing behavior between text characters. */
	textLetterSpacing?: string;
}
export type ContextIds = "2d" | "bitmaprenderer" | "webgl" | "experimental-webgl" | "webgl2" | "experimental-webgl2" | "webgpu";
type PredefinedColorSpace$1 = "srgb" | "display-p3";
type RenderingContext$1 = ICanvasRenderingContext2D | ImageBitmapRenderingContext | WebGLRenderingContext | WebGL2RenderingContext;
export interface ICanvasRenderingContext2DSettings {
	alpha?: boolean;
	colorSpace?: PredefinedColorSpace$1;
	desynchronized?: boolean;
	willReadFrequently?: boolean;
}
export type ContextSettings = ICanvasRenderingContext2DSettings | ImageBitmapRenderingContextSettings | WebGLContextAttributes;
export interface ICanvasParentNode {
	/** Adds a node to the end of the list of children of the parent node. */
	appendChild(element: HTMLElement): void;
	/** Removes a child node from the parent node. */
	removeChild(element: HTMLElement): void;
	removeChild(element: ICanvas): void;
}
export interface ICanvasStyle {
	width?: string;
	height?: string;
	cursor?: string;
	touchAction?: string;
	msTouchAction?: string;
	msContentZooming?: string;
}
export interface ICanvasRect {
	x: number;
	y: number;
	width: number;
	height: number;
}
export interface WebGLContextEventMap {
	"webglcontextlost": WebGLContextEvent;
	"webglcontextrestore": WebGLContextEvent;
}
/**
 * Common interface for HTMLCanvasElement, OffscreenCanvas, and other custom canvas classes.
 * @extends PixiMixins.ICanvas
 * @extends Partial<EventTarget>
 * @memberof environment
 */
export interface ICanvas extends PixiMixins.ICanvas, Partial<EventTarget> {
	/** Width of the canvas. */
	width: number;
	/** Height of the canvas. */
	height: number;
	/**
	 * Get rendering context of the canvas.
	 * @param {ContextIds} contextId - The identifier of the type of context to create.
	 * @param {ContextSettings} options - The options for creating context.
	 * @returns {RenderingContext | null} The created context, or null if contextId is not supported.
	 */
	getContext(contextId: "2d", options?: ICanvasRenderingContext2DSettings): ICanvasRenderingContext2D | null;
	getContext(contextId: "bitmaprenderer", options?: ImageBitmapRenderingContextSettings): ImageBitmapRenderingContext | null;
	getContext(contextId: "webgl" | "experimental-webgl", options?: WebGLContextAttributes): WebGLRenderingContext | null;
	getContext(contextId: "webgl2" | "experimental-webgl2", options?: WebGLContextAttributes): WebGL2RenderingContext | null;
	getContext(contextId: "webgpu"): GPUCanvasContext | null;
	getContext(contextId: ContextIds, options?: ContextSettings): RenderingContext$1 | null;
	/**
	 * Get the content of the canvas as data URL.
	 * @param {string} [type] - A string indicating the image format. The default type is \`image/png\`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {string} A string containing the requested data URL.
	 */
	toDataURL?(type?: string, quality?: number): string;
	/**
	 * Creates a Blob from the content of the canvas.
	 * @param {(blob: Blob | null) => void} callback - A callback function with the resulting \`Blob\` object
	 *      as a single argument. \`null\` may be passed if the image cannot be created for any reason.
	 * @param {string} [type] - A string indicating the image format. The default type is \`image/png\`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {void}
	 */
	toBlob?(callback: (blob: Blob | null) => void, type?: string, quality?: number): void;
	/**
	 * Get the content of the canvas as Blob.
	 * @param {object} [options] - The options for creating Blob.
	 * @param {string} [options.type] - A string indicating the image format. The default type is \`image/png\`;
	 *      that type is also used if the given type isn't supported.
	 * @param {string} [options.quality] - A number between 0 and 1 indicating the image quality to be used when
	 *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
	 *      A user agent will use its default quality value if this option is not specified, or if the number
	 *      is outside the allowed range.
	 * @returns {Promise<Blob>} A \`Promise\` returning a Blob object representing the image contained in the canvas.
	 */
	convertToBlob?(options?: {
		type?: string;
		quality?: number;
	}): Promise<Blob>;
	/**
	 * Adds the listener for the specified event.
	 * @method
	 * @param {string} type - The type of event to listen for.
	 * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
	 * @param {boolean | AddEventListenerOptions} options - The options for adding event listener.
	 * @returns {void}
	 */
	addEventListener?: {
		(type: string, listener: EventListenerOrEventListenerObject, options?: boolean | AddEventListenerOptions): void;
		<K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | AddEventListenerOptions): void;
	};
	/**
	 * Removes the listener for the specified event.
	 * @method
	 * @param {string} type - The type of event to listen for.
	 * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
	 * @param {boolean | EventListenerOptions} options - The options for removing event listener.
	 * @returns {void}
	 */
	removeEventListener?: {
		(type: string, listener: EventListenerOrEventListenerObject, options?: boolean | EventListenerOptions): void;
		<K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | EventListenerOptions): void;
	};
	/**
	 * Dispatches a event.
	 * @param {Event} event - The Event object to dispatch. Its Event.target property will be set to the current EventTarget.
	 * @returns {boolean} Returns false if event is cancelable, and at least one of the event handlers which received event
	 *                    called Event.preventDefault(). Otherwise true.
	 */
	dispatchEvent(event: Event): boolean;
	/** Parent node of the canvas. */
	readonly parentNode?: ICanvasParentNode | null;
	/** Style of the canvas. */
	readonly style?: ICanvasStyle;
	/**
	 * Get the position and the size of the canvas.
	 * @returns The smallest rectangle which contains the entire canvas.
	 */
	getBoundingClientRect?(): ICanvasRect;
}
interface EarcutStatic {
	/**
	 * Triangulate an outline.
	 *
	 * @param vertices A flat array of vertice coordinates like [x0,y0, x1,y1, x2,y2, ...].
	 * @param holes An array of hole indices if any (e.g. [5, 8] for a 12-vertice input would mean one hole with vertices 5–7 and another with 8–11).
	 * @param dimensions The number of coordinates per vertice in the input array (2 by default).
	 * @return A flat array with each group of three numbers indexing a triangle in the \`vertices\` array.
	 * @example earcut([10,0, 0,50, 60,60, 70,10]); // returns [1,0,3, 3,2,1]
	 * @example with a hole: earcut([0,0, 100,0, 100,100, 0,100,  20,20, 80,20, 80,80, 20,80], [4]); // [3,0,4, 5,4,0, 3,4,7, 5,0,1, 2,3,7, 6,5,1, 2,7,6, 6,1,2]
	 * @example with 3d coords: earcut([10,0,1, 0,50,2, 60,60,3, 70,10,4], null, 3); // [1,0,3, 3,2,1]
	 */
	(vertices: ArrayLike<number>, holes?: ArrayLike<number>, dimensions?: number): number[];
	/**
	 * Transforms multi-dimensional array (e.g. GeoJSON Polygon) into the format expected by earcut.
	 * @example Transforming GeoJSON data.
	 *     const data = earcut.flatten(geojson.geometry.coordinates);
	 *     const triangles = earcut(data.vertices, data.holes, data.dimensions);
	 * @example Transforming simple triangle with hole:
	 *     const data = earcut.flatten([[[0, 0], [100, 0], [0, 100]], [[10, 10], [0, 10], [10, 0]]]);
	 *     const triangles = earcut(data.vertices, data.holes, data.dimensions);
	 * @param data Arrays of rings, with the first being the outline and the rest holes. A ring is an array points, each point being an array of numbers.
	 */
	flatten(data: ArrayLike<ArrayLike<ArrayLike<number>>>): {
		vertices: number[];
		holes: number[];
		dimensions: number;
	};
	/**
	 * Returns the relative difference between the total area of triangles and the area of the input polygon. 0 means the triangulation is fully correct.
	 * @param vertices same as earcut
	 * @param holes same as earcut
	 * @param dimensions same as earcut
	 * @param triangles see return value of earcut
	 * @example
	 *     const triangles = earcut(vertices, holes, dimensions);
	 *  const deviation = earcut.deviation(vertices, holes, dimensions, triangles);
	 */
	deviation(vertices: ArrayLike<number>, holes: ArrayLike<number> | undefined, dimensions: number, triangles: ArrayLike<number>): number;
	default: EarcutStatic;
}
declare const exports$1: EarcutStatic;
/**
 * SystemRunner is used internally by the renderers as an efficient way for systems to
 * be notified about what the renderer is up to during the rendering phase.
 *
 * \`\`\`
 * import { SystemRunner } from 'pixi.js';
 *
 * const myObject = {
 *     loaded: new SystemRunner('loaded')
 * }
 *
 * const listener = {
 *     loaded: function(){
 *         // thin
 *     }
 * }
 *
 * myObject.loaded.add(listener);
 *
 * myObject.loaded.emit();
 * \`\`\`
 *
 * Or for handling calling the same function on many items
 * \`\`\`
 * import { SystemRunner } from 'pixi.js';
 *
 * const myGame = {
 *     update: new SystemRunner('update')
 * }
 *
 * const gameObject = {
 *     update: function(time){
 *         // update my gamey state
 *     }
 * }
 *
 * myGame.update.add(gameObject);
 *
 * myGame.update.emit(time);
 * \`\`\`
 * @memberof rendering
 */
export declare class SystemRunner {
	items: any[];
	private _name;
	/**
	 * @param name - The function name that will be executed on the listeners added to this Runner.
	 */
	constructor(name: string);
	/**
	 * Dispatch/Broadcast Runner to all listeners added to the queue.
	 * @param {...any} params - (optional) parameters to pass to each listener
	 */
	emit(a0?: unknown, a1?: unknown, a2?: unknown, a3?: unknown, a4?: unknown, a5?: unknown, a6?: unknown, a7?: unknown): this;
	/**
	 * Add a listener to the Runner
	 *
	 * Runners do not need to have scope or functions passed to them.
	 * All that is required is to pass the listening object and ensure that it has contains a function that has the same name
	 * as the name provided to the Runner when it was created.
	 *
	 * Eg A listener passed to this Runner will require a 'complete' function.
	 *
	 * \`\`\`
	 * import { Runner } from 'pixi.js';
	 *
	 * const complete = new Runner('complete');
	 * \`\`\`
	 *
	 * The scope used will be the object itself.
	 * @param {any} item - The object that will be listening.
	 */
	add(item: unknown): this;
	/**
	 * Remove a single listener from the dispatch queue.
	 * @param {any} item - The listener that you would like to remove.
	 */
	remove(item: unknown): this;
	/**
	 * Check to see if the listener is already in the Runner
	 * @param {any} item - The listener that you would like to check.
	 */
	contains(item: unknown): boolean;
	/** Remove all listeners from the Runner */
	removeAll(): this;
	/** Remove all references, don't use after this. */
	destroy(): void;
	/**
	 * \`true\` if there are no this Runner contains no listeners
	 * @readonly
	 */
	get empty(): boolean;
	/**
	 * The name of the runner.
	 * @readonly
	 */
	get name(): string;
}
/**
 * Base destroy options.
 * @example
 * // Destroy the sprite and all its children.
 * sprite.destroy({ children: true });
 * @memberof scene
 */
export interface BaseDestroyOptions {
	/** Destroy children recursively. */
	children?: boolean;
}
/**
 * Options when destroying textures. Most of these use cases are internal.
 * \`\`\`js
 * // destroy the graphics context and its texture
 * graphicsContext.destroy({ texture: true });
 * \`\`\`
 * @memberof scene
 */
export interface TextureDestroyOptions {
	/** Destroy the texture as well. */
	texture?: boolean;
	/** Destroy the texture source as well. */
	textureSource?: boolean;
}
/**
 * Options when destroying a graphics context.
 * \`\`\`js
 * // destroy the graphics context and its texture
 * graphicsContext.destroy({ context: true, texture: true });
 * \`\`\`
 * @memberof scene
 */
export interface ContextDestroyOptions {
	/** Destroy the graphics context as well. */
	context?: boolean;
}
/**
 * Options when destroying a text.
 * \`\`\`js
 * // destroy the text and its style
 * text.destroy({ style: true });
 * \`\`\`
 * @memberof scene
 */
export interface TextDestroyOptions {
	/** Destroy the text style as well. */
	style?: boolean;
}
export type TypeOrBool<T> = T | boolean;
/**
 * Options for destroying a container.
 * @property {boolean} [children=false] - Destroy the children of the container as well.
 * @property {boolean} [texture=false] - Destroy the texture of the container's children.
 * @property {boolean} [textureSource=false] - Destroy the texture source of the container's children.
 * @property {boolean} [context=false] - Destroy the context of the container's children.
 * @property {boolean} [style=false] - Destroy the style of the container's children.
 * @memberof scene
 */
export type DestroyOptions = TypeOrBool<BaseDestroyOptions & ContextDestroyOptions & TextureDestroyOptions & TextDestroyOptions>;
export declare enum CLEAR {
	NONE = 0,
	COLOR = 16384,
	STENCIL = 1024,
	DEPTH = 256,
	COLOR_DEPTH = 16640,
	COLOR_STENCIL = 17408,
	DEPTH_STENCIL = 1280,
	ALL = 17664
}
/** Used for clearing render textures. true is the same as \`ALL\` false is the same as \`NONE\` */
export type CLEAR_OR_BOOL = CLEAR | boolean;
/**
 * \`extensions\` is a global object that holds all the extensions registered with PixiJS.
 * PixiJS uses a this extensions architecture a lot to make the library more modular and
 * flexible.
 *
 * For example, if you want to add load a new type of asset, you can register a new
 * {@link assets.LoaderParser} with the \`extensions\` object.
 *
 * \`\`\`js
 * import { extensions, ExtensionType } from 'pixi.js';
 *
 * // create a custom asset loader
 * const customAssetLoader = {
 *    extension: {
 *        type: ExtensionType.LoadParser,
 *        name: 'custom-asset-loader',
 *    },
 *    test(url) {
 *       // check if this new loader should be used...
 *    },
 *    load(url) {
 *        // load the asset...
 *    },
 * };
 *
 * // add the custom asset loader to pixi
 * extensions.add(customAssetLoader);
 * \`\`\`
 *
 * This would add the \`customAssetLoader\` to the list of available loaders that PixiJS can use.
 *
 * There are many different types of extensions, which are listed in {@link extensions.ExtensionType}.
 * @namespace extensions
 */
/**
 * Collection of valid extension types.
 * @memberof extensions
 */
export declare enum ExtensionType {
	/** extensions that are registered as Application plugins */
	Application = "application",
	/** extensions that are registered as WebGL render pipes */
	WebGLPipes = "webgl-pipes",
	/** extensions that are registered as WebGL render pipes adaptors */
	WebGLPipesAdaptor = "webgl-pipes-adaptor",
	/** extensions that are registered as WebGL render systems */
	WebGLSystem = "webgl-system",
	/** extensions that are registered as WebGPU render pipes */
	WebGPUPipes = "webgpu-pipes",
	/** extensions that are registered as WebGPU render pipes adaptors */
	WebGPUPipesAdaptor = "webgpu-pipes-adaptor",
	/** extensions that are registered as WebGPU render systems */
	WebGPUSystem = "webgpu-system",
	/** extensions that are registered as Canvas render pipes */
	CanvasSystem = "canvas-system",
	/** extensions that are registered as Canvas render pipes adaptors */
	CanvasPipesAdaptor = "canvas-pipes-adaptor",
	/** extensions that are registered as Canvas render systems */
	CanvasPipes = "canvas-pipes",
	/** extensions that combine the other Asset extensions */
	Asset = "asset",
	/** extensions that are used to load assets through Assets */
	LoadParser = "load-parser",
	/** extensions that are used to resolve asset urls through Assets */
	ResolveParser = "resolve-parser",
	/** extensions that are used to handle how urls are cached by Assets */
	CacheParser = "cache-parser",
	/** extensions that are used to add/remove available resources from Assets */
	DetectionParser = "detection-parser",
	/** extensions that are registered with the MaskEffectManager */
	MaskEffect = "mask-effect",
	/** A type of extension for creating a new advanced blend mode */
	BlendMode = "blend-mode",
	/** A type of extension that will be used to auto detect a resource type */
	TextureSource = "texture-source",
	/** A type of extension that will be used to auto detect an environment */
	Environment = "environment",
	/** A type of extension for building and triangulating custom shapes used in graphics. */
	ShapeBuilder = "shape-builder",
	/** A type of extension for creating custom batchers used in rendering. */
	Batcher = "batcher"
}
/**
 * The metadata for an extension.
 * @memberof extensions
 * @ignore
 */
export interface ExtensionMetadataDetails {
	/** The extension type, can be multiple types */
	type: ExtensionType | ExtensionType[];
	/** Optional. Some plugins provide an API name/property, to make them more easily accessible */
	name?: string;
	/** Optional, used for sorting the plugins in a particular order */
	priority?: number;
}
/**
 * The metadata for an extension.
 * @memberof extensions
 */
export type ExtensionMetadata = ExtensionType | ExtensionMetadataDetails;
/**
 * Format when registering an extension. Generally, the extension
 * should have these values as \`extension\` static property,
 * but you can override name or type by providing an object.
 * @memberof extensions
 */
interface ExtensionFormat {
	/** The extension type, can be multiple types */
	type: ExtensionType | ExtensionType[];
	/** Optional. Some plugins provide an API name/property, such as Renderer plugins */
	name?: string;
	/** Optional, used for sorting the plugins in a particular order */
	priority?: number;
	/** Reference to the plugin object/class */
	ref: any;
}
/**
 * Extension format that is used internally for registrations.
 * @memberof extensions
 * @ignore
 */
interface StrictExtensionFormat extends ExtensionFormat {
	/** The extension type, always expressed as multiple, even if a single */
	type: ExtensionType[];
}
export type ExtensionHandler = (extension: StrictExtensionFormat) => void;
/**
 * Get the priority for an extension.
 * @ignore
 * @param ext - Any extension
 * @param defaultPriority - Fallback priority if none is defined.
 * @returns The priority for the extension.
 * @memberof extensions
 */
export declare const normalizeExtensionPriority: (ext: ExtensionFormat | any, defaultPriority: number) => number;
/**
 * Global registration of all PixiJS extensions. One-stop-shop for extensibility.
 *
 * Import the \`extensions\` object and use it to register new functionality via the described methods below.
 * \`\`\`js
 * import { extensions } from 'pixi.js';
 *
 * // register a new extension
 * extensions.add(myExtension);
 * \`\`\`
 * @property {Function} remove - Remove extensions from PixiJS.
 * @property {Function} add - Register new extensions with PixiJS.
 * @property {Function} handle - Internal method to handle extensions by name.
 * @property {Function} handleByMap - Handle a type, but using a map by \`name\` property.
 * @property {Function} handleByNamedList - Handle a type, but using a list of extensions with a \`name\` property.
 * @property {Function} handleByList - Handle a type, but using a list of extensions.
 * @memberof extensions
 */
export declare const extensions: {
	/** @ignore */
	_addHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
	/** @ignore */
	_removeHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
	/** @ignore */
	_queue: Partial<Record<ExtensionType, StrictExtensionFormat[]>>;
	/**
	 * Remove extensions from PixiJS.
	 * @param extensions - Extensions to be removed.
	 * @returns {extensions} For chaining.
	 */
	remove(...extensions: Array<ExtensionFormat | any>): any;
	/**
	 * Register new extensions with PixiJS.
	 * @param extensions - The spread of extensions to add to PixiJS.
	 * @returns {extensions} For chaining.
	 */
	add(...extensions: Array<ExtensionFormat | any>): any;
	/**
	 * Internal method to handle extensions by name.
	 * @param type - The extension type.
	 * @param onAdd  - Function handler when extensions are added/registered {@link StrictExtensionFormat}.
	 * @param onRemove  - Function handler when extensions are removed/unregistered {@link StrictExtensionFormat}.
	 * @returns {extensions} For chaining.
	 */
	handle(type: ExtensionType, onAdd: ExtensionHandler, onRemove: ExtensionHandler): any;
	/**
	 * Handle a type, but using a map by \`name\` property.
	 * @param type - Type of extension to handle.
	 * @param map - The object map of named extensions.
	 * @returns {extensions} For chaining.
	 */
	handleByMap(type: ExtensionType, map: Record<string, any>): any;
	/**
	 * Handle a type, but using a list of extensions with a \`name\` property.
	 * @param type - Type of extension to handle.
	 * @param map - The array of named extensions.
	 * @param defaultPriority - Fallback priority if none is defined.
	 * @returns {extensions} For chaining.
	 */
	handleByNamedList(type: ExtensionType, map: {
		name: string;
		value: any;
	}[], defaultPriority?: number): any;
	/**
	 * Handle a type, but using a list of extensions.
	 * @param type - Type of extension to handle.
	 * @param list - The list of extensions.
	 * @param defaultPriority - The default priority to use if none is specified.
	 * @returns {extensions} For chaining.
	 */
	handleByList(type: ExtensionType, list: any[], defaultPriority?: number): any;
	/**
	 * Mixin the source object into the target object.
	 * @param Target - The target object to mix into.
	 * @param sources - The source(s) object to mix from
	 */
	mixin(Target: any, ...sources: Parameters<typeof Object.getOwnPropertyDescriptors>[0][]): void;
};
export interface System<INIT_OPTIONS = null, DESTROY_OPTIONS = RendererDestroyOptions> {
	init?: (options: INIT_OPTIONS) => void;
	/** Generic destroy methods to be overridden by the subclass */
	destroy?: (options?: DESTROY_OPTIONS) => void;
}
export interface SystemConstructor {
	new (renderer: Renderer): System;
}
/**
 * Options for the background system.
 * @property {ColorSource} [backgroundColor='black']
 * The background color used to clear the canvas. See {@link ColorSource} for accepted color values.
 * @property {ColorSource} [background] - Alias for backgroundColor
 * @property {number} [backgroundAlpha=1] -
 * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
 * @property {boolean} [clearBeforeRender=true] - Whether to clear the canvas before new render passes.
 * @memberof rendering
 */
export interface BackgroundSystemOptions {
	/**
	 * The background color used to clear the canvas. See {@link ColorSource} for accepted color values.
	 * @memberof rendering.SharedRendererOptions
	 * @default 'black'
	 */
	backgroundColor: ColorSource;
	/**
	 * Alias for backgroundColor
	 * @memberof rendering.SharedRendererOptions
	 */
	background?: ColorSource;
	/**
	 * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
	 * @memberof rendering.SharedRendererOptions
	 * @default 1
	 */
	backgroundAlpha: number;
	/**
	 * Whether to clear the canvas before new render passes.
	 * @memberof rendering.SharedRendererOptions
	 * @default true
	 */
	clearBeforeRender: boolean;
}
/**
 * The background system manages the background color and alpha of the main view.
 * @memberof rendering
 */
export declare class BackgroundSystem implements System<BackgroundSystemOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "background";
		readonly priority: 0;
	};
	/** default options used by the system */
	static defaultOptions: BackgroundSystemOptions;
	/**
	 * This sets if the CanvasRenderer will clear the canvas or not before the new render pass.
	 * If the scene is NOT transparent PixiJS will use a canvas sized fillRect operation every
	 * frame to set the canvas background color. If the scene is transparent PixiJS will use clearRect
	 * to clear the canvas every frame. Disable this by setting this to false. For example, if
	 * your game has a canvas filling background image you often don't need this set.
	 */
	clearBeforeRender: boolean;
	private readonly _backgroundColor;
	constructor();
	/**
	 * initiates the background system
	 * @param options - the options for the background colors
	 */
	init(options: BackgroundSystemOptions): void;
	/** The background color to fill if not transparent */
	get color(): Color;
	set color(value: ColorSource);
	/** The background color alpha. Setting this to 0 will make the canvas transparent. */
	get alpha(): number;
	set alpha(value: number);
	/** The background color as an [R, G, B, A] array. */
	get colorRgba(): RgbaArray;
	/**
	 * destroys the background system
	 * @internal
	 * @ignore
	 */
	destroy(): void;
}
/**
 * A bind group is a collection of resources that are bound together for use by a shader.
 * They are essentially a wrapper for the WebGPU BindGroup class. But with the added bonus
 * that WebGL can also work with them.
 * @see https://gpuweb.github.io/gpuweb/#dictdef-gpubindgroupdescriptor
 * @example
 * // Create a bind group with a single texture and sampler
 * const bindGroup = new BindGroup({
 *    uTexture: texture.source,
 *    uTexture: texture.style,
 * });
 *
 * Bind groups resources must implement the {@link BindResource} interface.
 * The following resources are supported:
 * - {@link TextureSource}
 * - {@link TextureStyle}
 * - {@link Buffer}
 * - {@link BufferResource}
 * - {@link UniformGroup}
 *
 * The keys in the bind group must correspond to the names of the resources in the GPU program.
 *
 * This bind group class will also watch for changes in its resources ensuring that the changes
 * are reflected in the WebGPU BindGroup.
 * @memberof rendering
 */
export declare class BindGroup {
	/** The resources that are bound together for use by a shader. */
	resources: Record<string, BindResource>;
	/**
	 * a key used internally to match it up to a WebGPU Bindgroup
	 * @internal
	 * @ignore
	 */
	_key: string;
	private _dirty;
	/**
	 * Create a new instance eof the Bind Group.
	 * @param resources - The resources that are bound together for use by a shader.
	 */
	constructor(resources?: Record<string, BindResource>);
	/**
	 * Updates the key if its flagged as dirty. This is used internally to
	 * match this bind group to a WebGPU BindGroup.
	 * @internal
	 * @ignore
	 */
	_updateKey(): void;
	/**
	 * Set a resource at a given index. this function will
	 * ensure that listeners will be removed from the current resource
	 * and added to the new resource.
	 * @param resource - The resource to set.
	 * @param index - The index to set the resource at.
	 */
	setResource(resource: BindResource, index: number): void;
	/**
	 * Returns the resource at the current specified index.
	 * @param index - The index of the resource to get.
	 * @returns - The resource at the specified index.
	 */
	getResource(index: number): BindResource;
	/**
	 * Used internally to 'touch' each resource, to ensure that the GC
	 * knows that all resources in this bind group are still being used.
	 * @param tick - The current tick.
	 * @internal
	 * @ignore
	 */
	_touch(tick: number): void;
	/** Destroys this bind group and removes all listeners. */
	destroy(): void;
	protected onResourceChange(resource: BindResource): void;
}
/**
 * an interface that allows a resource to be bound to the gpu in a bind group
 * @memberof rendering
 */
export interface BindResource {
	/**
	 * The type of resource this is
	 * @ignore
	 */
	_resourceType: string;
	/**
	 * Unique id for this resource this can change and is used to link the gpu
	 * @ignore
	 */
	_resourceId: number;
	_touched: number;
	/**
	 * a boolean that indicates if the resource has been destroyed.
	 * If true, the resource should not be used and any bind groups
	 * that will release any references to this resource.
	 * @ignore
	 */
	destroyed: boolean;
	/**
	 * event dispatch whenever the underlying resource needs to change
	 * this could be a texture or buffer that has been resized.
	 * This is important as it allows the renderer to know that it needs to rebind the resource
	 */
	on?(event: "change", listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
	/** @todo */
	off?(event: "change", listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
}
/**
 * Specifies the alpha composition mode for textures.
 *
 * - \`no-premultiply-alpha\`: Does not premultiply alpha.
 * - \`premultiply-alpha-on-upload\`: Premultiplies alpha on texture upload.
 * - \`premultiplied-alpha\`: Assumes the texture is already in premultiplied alpha format.
 * @typedef {'no-premultiply-alpha' | 'premultiply-alpha-on-upload' | 'premultiplied-alpha'} ALPHA_MODES
 */
export type ALPHA_MODES = "no-premultiply-alpha" | "premultiply-alpha-on-upload" | "premultiplied-alpha";
/**
 * Constants for multi-sampling antialiasing.
 * @see Framebuffer#multisample
 * @name MSAA_QUALITY
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */
export declare enum MSAA_QUALITY {
	NONE = 0,
	LOW = 2,
	MEDIUM = 4,
	HIGH = 8
}
export type TEXTURE_FORMATS = "r8unorm" | "r8snorm" | "r8uint" | "r8sint" | "r16uint" | "r16sint" | "r16float" | "rg8unorm" | "rg8snorm" | "rg8uint" | "rg8sint" | "r32uint" | "r32sint" | "r32float" | "rg16uint" | "rg16sint" | "rg16float" | "rgba8unorm" | "rgba8unorm-srgb" | "rgba8snorm" | "rgba8uint" | "rgba8sint" | "bgra8unorm" | "bgra8unorm-srgb" | "rgb9e5ufloat" | "rgb10a2unorm" | "rg11b10ufloat" | "rg32uint" | "rg32sint" | "rg32float" | "rgba16uint" | "rgba16sint" | "rgba16float" | "rgba32uint" | "rgba32sint" | "rgba32float" | "stencil8" | "depth16unorm" | "depth24plus" | "depth24plus-stencil8" | "depth32float" | "depth32float-stencil8" | "bc1-rgba-unorm" | "bc1-rgba-unorm-srgb" | "bc2-rgba-unorm" | "bc2-rgba-unorm-srgb" | "bc3-rgba-unorm" | "bc3-rgba-unorm-srgb" | "bc4-r-unorm" | "bc4-r-snorm" | "bc5-rg-unorm" | "bc5-rg-snorm" | "bc6h-rgb-ufloat" | "bc6h-rgb-float" | "bc7-rgba-unorm" | "bc7-rgba-unorm-srgb" | "etc2-rgb8unorm" | "etc2-rgb8unorm-srgb" | "etc2-rgb8a1unorm" | "etc2-rgb8a1unorm-srgb" | "etc2-rgba8unorm" | "etc2-rgba8unorm-srgb" | "eac-r11unorm" | "eac-r11snorm" | "eac-rg11unorm" | "eac-rg11snorm" | "astc-4x4-unorm" | "astc-4x4-unorm-srgb" | "astc-5x4-unorm" | "astc-5x4-unorm-srgb" | "astc-5x5-unorm" | "astc-5x5-unorm-srgb" | "astc-6x5-unorm" | "astc-6x5-unorm-srgb" | "astc-6x6-unorm" | "astc-6x6-unorm-srgb" | "astc-8x5-unorm" | "astc-8x5-unorm-srgb" | "astc-8x6-unorm" | "astc-8x6-unorm-srgb" | "astc-8x8-unorm" | "astc-8x8-unorm-srgb" | "astc-10x5-unorm" | "astc-10x5-unorm-srgb" | "astc-10x6-unorm" | "astc-10x6-unorm-srgb" | "astc-10x8-unorm" | "astc-10x8-unorm-srgb" | "astc-10x10-unorm" | "astc-10x10-unorm-srgb" | "astc-12x10-unorm" | "astc-12x10-unorm-srgb" | "astc-12x12-unorm" | "astc-12x12-unorm-srgb";
export type TEXTURE_VIEW_DIMENSIONS = "1d" | "2d" | "2d-array" | "cube" | "cube-array" | "3d";
export type TEXTURE_DIMENSIONS = "1d" | "2d" | "3d";
export type WRAP_MODE = 
/**
 * The texture uvs are clamped
 * @default 33071
 */
"clamp-to-edge"
/**
 * The texture uvs tile and repeat
 * @default 10497
 */
 | "repeat"
/**
 * The texture uvs tile and repeat with mirroring
 * @default 33648
 */
 | "mirror-repeat";
export declare enum DEPRECATED_WRAP_MODES {
	CLAMP = "clamp-to-edge",
	REPEAT = "repeat",
	MIRRORED_REPEAT = "mirror-repeat"
}
/** @deprecated since 8.0.0 */
export declare const WRAP_MODES: typeof DEPRECATED_WRAP_MODES;
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 * @static
 */
export type SCALE_MODE = 
/** Pixelating scaling */
"nearest"
/** Smooth scaling */
 | "linear";
export declare enum DEPRECATED_SCALE_MODES {
	NEAREST = "nearest",
	LINEAR = "linear"
}
/**
 * @deprecated since 8.0.0
 */
export declare const SCALE_MODES: typeof DEPRECATED_SCALE_MODES;
export type COMPARE_FUNCTION = "never" | "less" | "equal" | "less-equal" | "greater" | "not-equal" | "greater-equal" | "always";
export interface TextureStyleOptions extends Partial<TextureStyle> {
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	addressMode?: WRAP_MODE;
	/** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeU?: WRAP_MODE;
	/** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeV?: WRAP_MODE;
	/** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeW?: WRAP_MODE;
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	scaleMode?: SCALE_MODE;
	/** specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	magFilter?: SCALE_MODE;
	/** specifies the sampling behavior when the sample footprint is larger than one texel. */
	minFilter?: SCALE_MODE;
	/** specifies behavior for sampling between mipmap levels. */
	mipmapFilter?: SCALE_MODE;
	/** specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMinClamp?: number;
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMaxClamp?: number;
	/**
	 * When provided the sampler will be a comparison sampler with the specified
	 * {@link GPUCompareFunction}.
	 * Note: Comparison samplers may use filtering, but the sampling results will be
	 * implementation-dependent and may differ from the normal filtering rules.
	 */
	compare?: COMPARE_FUNCTION;
	/**
	 * Specifies the maximum anisotropy value clamp used by the sampler.
	 * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
	 * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
	 * be clamped to the maximum value that the platform supports.
	 *
	 * setting this to anything higher than 1 will set scale modes to 'linear'
	 */
	maxAnisotropy?: number;
}
/**
 * A texture style describes how a texture should be sampled by a shader.
 * @memberof rendering
 */
export declare class TextureStyle extends EventEmitter<{
	change: TextureStyle;
	destroy: TextureStyle;
}> implements BindResource {
	_resourceType: string;
	_touched: number;
	private _sharedResourceId;
	/** default options for the style */
	static readonly defaultOptions: TextureStyleOptions;
	/** */
	addressModeU?: WRAP_MODE;
	/** */
	addressModeV?: WRAP_MODE;
	/** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
	addressModeW?: WRAP_MODE;
	/** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	magFilter?: SCALE_MODE;
	/** Specifies the sampling behavior when the sample footprint is larger than one texel. */
	minFilter?: SCALE_MODE;
	/** Specifies behavior for sampling between mipmap levels. */
	mipmapFilter?: SCALE_MODE;
	/** */
	lodMinClamp?: number;
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	lodMaxClamp?: number;
	/**
	 * When provided the sampler will be a comparison sampler with the specified
	 * {@link GPUCompareFunction}.
	 * Note: Comparison samplers may use filtering, but the sampling results will be
	 * implementation-dependent and may differ from the normal filtering rules.
	 */
	compare?: COMPARE_FUNCTION;
	/**
	 * Specifies the maximum anisotropy value clamp used by the sampler.
	 * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
	 * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
	 * be clamped to the maximum value that the platform supports.
	 * @internal
	 * @ignore
	 */
	_maxAnisotropy?: number;
	/**
	 * Has the style been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * @param options - options for the style
	 */
	constructor(options?: TextureStyleOptions);
	set addressMode(value: WRAP_MODE);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get addressMode(): WRAP_MODE;
	set wrapMode(value: WRAP_MODE);
	get wrapMode(): WRAP_MODE;
	set scaleMode(value: SCALE_MODE);
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	get scaleMode(): SCALE_MODE;
	/** Specifies the maximum anisotropy value clamp used by the sampler. */
	set maxAnisotropy(value: number);
	get maxAnisotropy(): number;
	get _resourceId(): number;
	update(): void;
	private _generateResourceId;
	/** Destroys the style */
	destroy(): void;
}
export interface CanvasSourceOptions extends TextureSourceOptions<ICanvas> {
	/**
	 * Should the canvas be resized to preserve its screen width and height regardless
	 * of the resolution of the renderer, this is only supported for HTMLCanvasElement
	 * and will be ignored if the canvas is an OffscreenCanvas.
	 */
	autoDensity?: boolean;
	/** if true, this canvas will be set up to be transparent where possible */
	transparent?: boolean;
}
export declare class CanvasSource extends TextureSource<ICanvas> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	autoDensity: boolean;
	transparent: boolean;
	private _context2D;
	constructor(options: CanvasSourceOptions);
	resizeCanvas(): void;
	resize(width?: number, height?: number, resolution?: number): boolean;
	static test(resource: any): resource is ICanvas;
	/**
	 * Returns the 2D rendering context for the canvas.
	 * Caches the context after creating it.
	 * @returns The 2D rendering context of the canvas.
	 */
	get context2D(): CanvasRenderingContext2D;
}
export type ImageResource = ImageBitmap | HTMLCanvasElement | OffscreenCanvas | ICanvas | VideoFrame | HTMLImageElement | HTMLVideoElement;
export declare class ImageSource extends TextureSource<ImageResource> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	constructor(options: TextureSourceOptions<ImageResource>);
	static test(resource: any): resource is ImageResource;
}
export type TextureResourceOrOptions = ImageResource | TextureSourceOptions<ImageResource> | BufferSourceOptions | CanvasSourceOptions;
/**
 * @param options
 * @deprecated since v8.2.0
 * @see TextureSource.from
 */
export declare function autoDetectSource(options?: TextureResourceOrOptions): TextureSource;
export declare function resourceToTexture(options?: TextureResourceOrOptions, skipCache?: boolean): Texture;
/**
 * Helper function that creates a returns Texture based on the source you provide.
 * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
 * @param id - String or Source to create texture from
 * @param skipCache - Skip adding the texture to the cache
 * @returns The texture based on the Id provided
 */
export declare function textureFrom(id: TextureSourceLike, skipCache?: boolean): Texture;
/**
 * options for creating a new TextureSource
 * @memberof rendering
 */
export interface TextureSourceOptions<T extends Record<string, any> = any> extends TextureStyleOptions {
	/**
	 * the resource that will be uploaded to the GPU. This is where we get our pixels from
	 * eg an ImageBimt / Canvas / Video etc
	 */
	resource?: T;
	/** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
	width?: number;
	/** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
	height?: number;
	/** the resolution of the texture. */
	resolution?: number;
	/** the format that the texture data has */
	format?: TEXTURE_FORMATS;
	/**
	 * Used by internal textures
	 * @ignore
	 */
	sampleCount?: number;
	/**
	 * Only really affects RenderTextures.
	 * Should we use antialiasing for this texture. It will look better, but may impact performance as a
	 * Blit operation will be required to resolve the texture.
	 */
	antialias?: boolean;
	/** how many dimensions does this texture have? currently v8 only supports 2d */
	dimensions?: TEXTURE_DIMENSIONS;
	/** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
	mipLevelCount?: number;
	/**
	 * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
	 * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
	 * can look better when scaled down.
	 *
	 * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
	 * If you do, make sure to call \`updateMipmaps\` after you update the texture.
	 */
	autoGenerateMipmaps?: boolean;
	/** the alpha mode of the texture */
	alphaMode?: ALPHA_MODES;
	/** optional label, can be used for debugging */
	label?: string;
	/** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
	autoGarbageCollect?: boolean;
}
/**
 * A TextureSource stores the information that represents an image.
 * All textures have require TextureSource, which contains information about the source.
 * Therefore you can have many textures all using a single TextureSource (eg a sprite sheet)
 *
 * This is an class is extended depending on the source of the texture.
 * Eg if you are using an an image as your resource, then an ImageSource is used.
 * @memberof rendering
 * @typeParam T - The TextureSource's Resource type.
 */
export declare class TextureSource<T extends Record<string, any> = any> extends EventEmitter<{
	change: BindResource;
	update: TextureSource;
	unload: TextureSource;
	destroy: TextureSource;
	resize: TextureSource;
	styleChange: TextureSource;
	updateMipmaps: TextureSource;
	error: Error;
}> implements BindResource {
	protected readonly options: TextureSourceOptions<T>;
	/** The default options used when creating a new TextureSource. override these to add your own defaults */
	static defaultOptions: TextureSourceOptions;
	/** unique id for this Texture source */
	readonly uid: number;
	/** optional label, can be used for debugging */
	label: string;
	/**
	 * The resource type used by this TextureSource. This is used by the bind groups to determine
	 * how to handle this resource.
	 * @ignore
	 * @internal
	 */
	readonly _resourceType = "textureSource";
	/**
	 * i unique resource id, used by the bind group systems.
	 * This can change if the texture is resized or its resource changes
	 */
	_resourceId: number;
	/**
	 * this is how the backends know how to upload this texture to the GPU
	 * It changes depending on the resource type. Classes that extend TextureSource
	 * should override this property.
	 * @ignore
	 * @internal
	 */
	uploadMethodId: string;
	_resolution: number;
	/** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
	pixelWidth: number;
	/** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
	pixelHeight: number;
	/**
	 * the width of this texture source, accounting for resolution
	 * eg pixelWidth 200, resolution 2, then width will be 100
	 */
	width: number;
	/**
	 * the height of this texture source, accounting for resolution
	 * eg pixelHeight 200, resolution 2, then height will be 100
	 */
	height: number;
	/**
	 * the resource that will be uploaded to the GPU. This is where we get our pixels from
	 * eg an ImageBimt / Canvas / Video etc
	 */
	resource: T;
	/**
	 * The number of samples of a multisample texture. This is always 1 for non-multisample textures.
	 * To enable multisample for a texture, set antialias to true
	 * @internal
	 * @ignore
	 */
	sampleCount: number;
	/** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
	mipLevelCount: number;
	/**
	 * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
	 * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
	 * can look better when scaled down.
	 *
	 * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
	 * If you do, make sure to call \`updateMipmaps\` after you update the texture.
	 */
	autoGenerateMipmaps: boolean;
	/** the format that the texture data has */
	format: TEXTURE_FORMATS;
	/** how many dimensions does this texture have? currently v8 only supports 2d */
	dimension: TEXTURE_DIMENSIONS;
	/** the alpha mode of the texture */
	alphaMode: ALPHA_MODES;
	private _style;
	/**
	 * Only really affects RenderTextures.
	 * Should we use antialiasing for this texture. It will look better, but may impact performance as a
	 * Blit operation will be required to resolve the texture.
	 */
	antialias: boolean;
	/**
	 * Has the source been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * Used by automatic texture Garbage Collection, stores last GC tick when it was bound
	 * @protected
	 */
	_touched: number;
	/**
	 * Used by the batcher to build texture batches. faster to have the variable here!
	 * @protected
	 */
	_batchTick: number;
	/**
	 * A temporary batch location for the texture batching. Here for performance reasons only!
	 * @protected
	 */
	_textureBindLocation: number;
	isPowerOfTwo: boolean;
	/** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
	autoGarbageCollect: boolean;
	/**
	 * used internally to know where a texture came from. Usually assigned by the asset loader!
	 * @ignore
	 */
	_sourceOrigin: string;
	/**
	 * @param options - options for creating a new TextureSource
	 */
	constructor(options?: TextureSourceOptions<T>);
	/** returns itself */
	get source(): TextureSource;
	/** the style of the texture */
	get style(): TextureStyle;
	set style(value: TextureStyle);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get addressMode(): WRAP_MODE;
	set addressMode(value: WRAP_MODE);
	/** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
	get repeatMode(): WRAP_MODE;
	set repeatMode(value: WRAP_MODE);
	/** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
	get magFilter(): SCALE_MODE;
	set magFilter(value: SCALE_MODE);
	/** Specifies the sampling behavior when the sample footprint is larger than one texel. */
	get minFilter(): SCALE_MODE;
	set minFilter(value: SCALE_MODE);
	/** Specifies behavior for sampling between mipmap levels. */
	get mipmapFilter(): SCALE_MODE;
	set mipmapFilter(value: SCALE_MODE);
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	get lodMinClamp(): number;
	set lodMinClamp(value: number);
	/** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
	get lodMaxClamp(): number;
	set lodMaxClamp(value: number);
	private _onStyleChange;
	/** call this if you have modified the texture outside of the constructor */
	update(): void;
	/** Destroys this texture source */
	destroy(): void;
	/**
	 * This will unload the Texture source from the GPU. This will free up the GPU memory
	 * As soon as it is required fore rendering, it will be re-uploaded.
	 */
	unload(): void;
	/** the width of the resource. This is the REAL pure number, not accounting resolution   */
	get resourceWidth(): number;
	/** the height of the resource. This is the REAL pure number, not accounting resolution */
	get resourceHeight(): number;
	/**
	 * the resolution of the texture. Changing this number, will not change the number of pixels in the actual texture
	 * but will the size of the texture when rendered.
	 *
	 * changing the resolution of this texture to 2 for example will make it appear twice as small when rendered (as pixel
	 * density will have increased)
	 */
	get resolution(): number;
	set resolution(resolution: number);
	/**
	 * Resize the texture, this is handy if you want to use the texture as a render texture
	 * @param width - the new width of the texture
	 * @param height - the new height of the texture
	 * @param resolution - the new resolution of the texture
	 * @returns - if the texture was resized
	 */
	resize(width?: number, height?: number, resolution?: number): boolean;
	/**
	 * Lets the renderer know that this texture has been updated and its mipmaps should be re-generated.
	 * This is only important for RenderTexture instances, as standard Texture instances will have their
	 * mipmaps generated on upload. You should call this method after you make any change to the texture
	 *
	 * The reason for this is is can be quite expensive to update mipmaps for a texture. So by default,
	 * We want you, the developer to specify when this action should happen.
	 *
	 * Generally you don't want to have mipmaps generated on Render targets that are changed every frame,
	 */
	updateMipmaps(): void;
	set wrapMode(value: WRAP_MODE);
	get wrapMode(): WRAP_MODE;
	set scaleMode(value: SCALE_MODE);
	/** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
	get scaleMode(): SCALE_MODE;
	/**
	 * Refresh check for isPowerOfTwo texture based on size
	 * @private
	 */
	protected _refreshPOT(): void;
	static test(_resource: any): any;
	/**
	 * A helper function that creates a new TextureSource based on the resource you provide.
	 * @param resource - The resource to create the texture source from.
	 */
	static from: (resource: TextureResourceOrOptions) => TextureSource;
}
/**
 * Buffer usage flags. they can be combined using the bitwise OR operator
 * eg : BufferUsage.VERTEX | BufferUsage.INDEX
 * @memberof rendering
 */
export declare enum BufferUsage {
	/**
	 * The buffer can be mapped for reading. (Example: calling mapAsync() with GPUMapMode.READ)
	 * May only be combined with COPY_DST.
	 */
	MAP_READ = 1,
	/**
	 * The buffer can be mapped for writing. (Example: calling mapAsync() with GPUMapMode.WRITE)
	 * May only be combined with COPY_SRC.
	 */
	MAP_WRITE = 2,
	/**
	 * The buffer can be used as the source of a copy operation.
	 * (Examples: as the source argument of a copyBufferToBuffer() or copyBufferToTexture() call.)
	 */
	COPY_SRC = 4,
	/**
	 * The buffer can be used as the destination of a copy or write operation.
	 * (Examples: as the destination argument of a copyBufferToBuffer() or
	 * copyTextureToBuffer() call, or as the target of a writeBuffer() call.)
	 */
	COPY_DST = 8,
	/** The buffer can be used as an index buffer. (Example: passed to setIndexBuffer().) */
	INDEX = 16,
	/** The buffer can be used as a vertex buffer. (Example: passed to setVertexBuffer().) */
	VERTEX = 32,
	/**
	 * The buffer can be used as a uniform buffer.
	 * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "uniform".)
	 */
	UNIFORM = 64,
	/**
	 * The buffer can be used as a storage buffer.
	 * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "storage" or "read-only-storage".)
	 */
	STORAGE = 128,
	/**
	 * The buffer can be used as to store indirect command arguments.
	 * (Examples: as the indirectBuffer argument of a drawIndirect() or dispatchWorkgroupsIndirect() call.)
	 */
	INDIRECT = 256,
	/**
	 * The buffer can be used to capture query results.
	 * (Example: as the destination argument of a resolveQuerySet() call.)
	 */
	QUERY_RESOLVE = 512,
	/** the buffer will not be updated frequently */
	STATIC = 1024
}
/** All the various typed arrays that exist in js */
export type TypedArray = Int8Array | Uint8Array | Int16Array | Uint16Array | Int32Array | Uint32Array | Uint8ClampedArray | Float32Array | Float64Array;
/** Options for creating a buffer */
export interface BufferOptions {
	/**
	 * the data to initialize the buffer with, this can be a typed array,
	 * or a regular number array. If it is a number array, it will be converted to a Float32Array
	 */
	data?: TypedArray | number[];
	/** the size of the buffer in bytes, if not supplied, it will be inferred from the data */
	size?: number;
	/** the usage of the buffer, see {@link rendering.BufferUsage} */
	usage: number;
	/** a label for the buffer, this is useful for debugging */
	label?: string;
	/**
	 * should the GPU buffer be shrunk when the data becomes smaller?
	 * changing this will cause the buffer to be destroyed and a new one created on the GPU
	 * this can be expensive, especially if the buffer is already big enough!
	 * setting this to false will prevent the buffer from being shrunk. This will yield better performance
	 * if you are constantly setting data that is changing size often.
	 * @default true
	 */
	shrinkToFit?: boolean;
}
export interface BufferDescriptor {
	label?: string;
	size: GPUSize64;
	usage: BufferUsage;
	mappedAtCreation?: boolean;
}
/**
 * A wrapper for a WebGPU/WebGL Buffer.
 * In PixiJS, the Buffer class is used to manage the data that is sent to the GPU rendering pipeline.
 * It abstracts away the underlying GPU buffer and provides an interface for uploading typed arrays or other data to the GPU,
 * They are used in the following places:
 * <br><br>
 * .1. {@link Geometry} as attribute data or index data for geometry
 * <br>
 * .2. {@link UniformGroup} as an underlying buffer for uniform data
 * <br>
 * .3. {@link BufferResource} as an underlying part of a buffer used directly by the GPU program
 * <br>
 *
 * It is important to note that you must provide a usage type when creating a buffer. This is because
 * the underlying GPU buffer needs to know how it will be used. For example, if you are creating a buffer
 * to hold vertex data, you would use \`BufferUsage.VERTEX\`. This will tell the GPU that this buffer will be
 * used as a vertex buffer. This is important because it will affect how you can use the buffer.
 *
 * Buffers are updated by calling the {@link Buffer.update} method. This immediately updates the buffer on the GPU.
 * Be mindful of calling this more often than you need to. It is recommended to update buffers only when needed.
 *
 * In WebGPU, a GPU buffer cannot resized. This limitation is abstracted away, but know that resizing a buffer means
 * creating a brand new one and destroying the old, so it is best to limit this if possible.
 * @example
 *
 * const buffer = new Buffer({
 *     data: new Float32Array([1, 2, 3, 4]),
 *     usage: BufferUsage.VERTEX,
 * });
 * @memberof rendering
 */
declare class Buffer$1 extends EventEmitter<{
	change: BindResource;
	update: Buffer$1;
	destroy: Buffer$1;
}> implements BindResource {
	/**
	 * emits when the underlying buffer has changed shape (i.e. resized)
	 * letting the renderer know that it needs to discard the old buffer on the GPU and create a new one
	 * @event change
	 */
	/**
	 * emits when the underlying buffer data has been updated. letting the renderer know
	 * that it needs to update the buffer on the GPU
	 * @event update
	 */
	/**
	 * emits when the buffer is destroyed. letting the renderer know that it needs to destroy the buffer on the GPU
	 * @event destroy
	 */
	/** a unique id for this uniform group used through the renderer */
	readonly uid: number;
	/**
	 * a resource type, used to identify how to handle it when its in a bind group / shader resource
	 * @internal
	 * @ignore
	 */
	readonly _resourceType = "buffer";
	/**
	 * the resource id used internally by the renderer to build bind group keys
	 * @internal
	 * @ignore
	 */
	_resourceId: number;
	/**
	 * used internally to know if a uniform group was used in the last render pass
	 * @internal
	 * @ignore
	 */
	_touched: number;
	/**
	 * a description of the buffer and how it should be set up on the GPU
	 * @internal
	 * @ignore
	 */
	readonly descriptor: BufferDescriptor;
	/**
	 * @internal
	 * @ignore
	 */
	_updateID: number;
	/**
	 * @internal
	 * @ignore
	 */
	_updateSize: number;
	private _data;
	private _dataInt32;
	/**
	 * should the GPU buffer be shrunk when the data becomes smaller?
	 * changing this will cause the buffer to be destroyed and a new one created on the GPU
	 * this can be expensive, especially if the buffer is already big enough!
	 * setting this to false will prevent the buffer from being shrunk. This will yield better performance
	 * if you are constantly setting data that is changing size often.
	 * @default true
	 */
	shrinkToFit: boolean;
	/**
	 * Has the buffer been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * Creates a new Buffer with the given options
	 * @param options - the options for the buffer
	 */
	constructor(options: BufferOptions);
	/** the data in the buffer */
	get data(): TypedArray;
	set data(value: TypedArray);
	get dataInt32(): Int32Array;
	/** whether the buffer is static or not */
	get static(): boolean;
	set static(value: boolean);
	/**
	 * Sets the data in the buffer to the given value. This will immediately update the buffer on the GPU.
	 * If you only want to update a subset of the buffer, you can pass in the size of the data.
	 * @param value - the data to set
	 * @param size - the size of the data in bytes
	 * @param syncGPU - should the buffer be updated on the GPU immediately?
	 */
	setDataWithSize(value: TypedArray, size: number, syncGPU: boolean): void;
	/**
	 * updates the buffer on the GPU to reflect the data in the buffer.
	 * By default it will update the entire buffer. If you only want to update a subset of the buffer,
	 * you can pass in the size of the buffer to update.
	 * @param sizeInBytes - the new size of the buffer in bytes
	 */
	update(sizeInBytes?: number): void;
	/** Destroys the buffer */
	destroy(): void;
}
export interface BufferSourceOptions extends TextureSourceOptions<TypedArray | ArrayBuffer> {
	width: number;
	height: number;
}
export declare class BufferImageSource extends TextureSource<TypedArray | ArrayBuffer> {
	static extension: ExtensionMetadata;
	uploadMethodId: string;
	constructor(options: BufferSourceOptions);
	static test(resource: any): resource is TypedArray | ArrayBuffer;
}
/**
 * Class controls uv mapping from Texture normal space to BaseTexture normal space.
 *
 * Takes \`trim\` and \`rotate\` into account. May contain clamp settings for Meshes and TilingSprite.
 *
 * Can be used in Texture \`uvMatrix\` field, or separately, you can use different clamp settings on the same texture.
 * If you want to add support for texture region of certain feature or filter, that's what you're looking for.
 *
 * Takes track of Texture changes through \`_lastTextureID\` private field.
 * Use \`update()\` method call to track it from outside.
 * @see Texture
 * @see Mesh
 * @see TilingSprite
 * @memberof rendering
 */
export declare class TextureMatrix {
	/**
	 * Matrix operation that converts texture region coords to texture coords
	 * @readonly
	 */
	mapCoord: Matrix;
	/**
	 * Changes frame clamping
	 * Works with TilingSprite and Mesh
	 * Change to 1.5 if you texture has repeated right and bottom lines, that leads to smoother borders
	 * @default 0
	 */
	clampOffset: number;
	/**
	 * Changes frame clamping
	 * Works with TilingSprite and Mesh
	 * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
	 * @default 0.5
	 */
	clampMargin: number;
	/**
	 * Clamp region for normalized coords, left-top pixel center in xy , bottom-right in zw.
	 * Calculated based on clampOffset.
	 */
	readonly uClampFrame: Float32Array;
	/** Normalized clamp offset. Calculated based on clampOffset. */
	readonly uClampOffset: Float32Array;
	/**
	 * Tracks Texture frame changes.
	 * @ignore
	 */
	_updateID: number;
	/**
	 * Tracks Texture frame changes.
	 * @protected
	 */
	protected _textureID: number;
	protected _texture: Texture;
	/**
	 * If texture size is the same as baseTexture.
	 * @default false
	 * @readonly
	 */
	isSimple: boolean;
	/**
	 * @param texture - observed texture
	 * @param clampMargin - Changes frame clamping, 0.5 by default. Use -0.5 for extra border.
	 */
	constructor(texture: Texture, clampMargin?: number);
	/** Texture property. */
	get texture(): Texture;
	set texture(value: Texture);
	/**
	 * Multiplies uvs array to transform
	 * @param uvs - mesh uvs
	 * @param [out=uvs] - output
	 * @returns - output
	 */
	multiplyUvs(uvs: Float32Array, out?: Float32Array): Float32Array;
	/**
	 * Updates matrices if texture was changed
	 * @returns - whether or not it was updated
	 */
	update(): boolean;
}
/**
 * Stores the width of the non-scalable borders, for example when used with {@link scene.NineSlicePlane} texture.
 * @memberof rendering
 */
export interface TextureBorders {
	/** left border in pixels */
	left: number;
	/** top border in pixels */
	top: number;
	/** right border in pixels */
	right: number;
	/** bottom border in pixels */
	bottom: number;
}
/**
 * The UVs data structure for a texture.
 * @memberof rendering
 */
export type UVs = {
	x0: number;
	y0: number;
	x1: number;
	y1: number;
	x2: number;
	y2: number;
	x3: number;
	y3: number;
};
/**
 * The options that can be passed to a new Texture
 * @memberof rendering
 */
export interface TextureOptions<TextureSourceType extends TextureSource = TextureSource> {
	/** the underlying texture data that this texture will use  */
	source?: TextureSourceType;
	/** optional label, for debugging */
	label?: string;
	/** The rectangle frame of the texture to show */
	frame?: Rectangle;
	/** The area of original texture */
	orig?: Rectangle;
	/** Trimmed rectangle of original texture */
	trim?: Rectangle;
	/** Default anchor point used for sprite placement / rotation */
	defaultAnchor?: {
		x: number;
		y: number;
	};
	/** Default borders used for 9-slice scaling {@link NineSlicePlane}*/
	defaultBorders?: TextureBorders;
	/** indicates how the texture was rotated by texture packer. See {@link groupD8} */
	rotate?: number;
	/**
	 * Set to true if you plan on modifying this texture's frame, UVs, or swapping its source at runtime.
	 * This is false by default as it improves performance. Generally, it's recommended to create new
	 * textures and swap those rather than modifying an existing texture's properties unless you are
	 * working with a dynamic frames.
	 * Not setting this to true when modifying the texture can lead to visual artifacts.
	 *
	 * If this is false and you modify the texture, you can manually update the sprite's texture by calling
	 * \`sprite.onViewUpdate()\`.
	 */
	dynamic?: boolean;
}
export interface BindableTexture {
	source: TextureSource;
}
export type TextureSourceLike = TextureSource | TextureResourceOrOptions | string;
/**
 * A texture stores the information that represents an image or part of an image.
 *
 * A texture must have a loaded resource passed to it to work. It does not contain any
 * loading mechanisms.
 *
 * The Assets class can be used to load a texture from a file. This is the recommended
 * way as it will handle the loading and caching for you.
 *
 * \`\`\`js
 *
 * const texture = await Assets.load('assets/image.png');
 *
 * // once Assets has loaded the image it will be available via the from method
 * const sameTexture = Texture.from('assets/image.png');
 * // another way to access the texture once loaded
 * const sameAgainTexture = Asset.get('assets/image.png');
 *
 * const sprite1 = new Sprite(texture);
 *
 * \`\`\`
 *
 * It cannot be added to the display list directly; instead use it as the texture for a Sprite.
 * If no frame is provided for a texture, then the whole image is used.
 *
 * You can directly create a texture from an image and then reuse it multiple times like this :
 *
 * \`\`\`js
 * import { Sprite, Texture } from 'pixi.js';
 *
 * const texture = await Assets.load('assets/image.png');
 * const sprite1 = new Sprite(texture);
 * const sprite2 = new Sprite(texture);
 * \`\`\`
 *
 * If you didn't pass the texture frame to constructor, it enables \`noFrame\` mode:
 * it subscribes on baseTexture events, it automatically resizes at the same time as baseTexture.
 * @memberof rendering
 * @class
 */
export declare class Texture<TextureSourceType extends TextureSource = TextureSource> extends EventEmitter<{
	update: Texture;
	destroy: Texture;
}> implements BindableTexture {
	/**
	 * Helper function that creates a returns Texture based on the source you provide.
	 * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
	 * @param id - String or Source to create texture from
	 * @param skipCache - Skip adding the texture to the cache
	 * @returns The texture based on the Id provided
	 */
	static from: (id: TextureSourceLike, skipCache?: boolean) => Texture;
	/** label used for debugging */
	label?: string;
	/** unique id for this texture */
	readonly uid: number;
	/**
	 * Has the texture been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	_source: TextureSourceType;
	/**
	 * Indicates whether the texture is rotated inside the atlas
	 * set to 2 to compensate for texture packer rotation
	 * set to 6 to compensate for spine packer rotation
	 * can be used to rotate or mirror sprites
	 * See {@link maths.groupD8} for explanation
	 */
	readonly rotate: number;
	/** A uvs object based on the given frame and the texture source */
	readonly uvs: UVs;
	/**
	 * Anchor point that is used as default if sprite is created with this texture.
	 * Changing the \`defaultAnchor\` at a later point of time will not update Sprite's anchor point.
	 * @default {0,0}
	 */
	readonly defaultAnchor?: {
		x: number;
		y: number;
	};
	/**
	 * Default width of the non-scalable border that is used if 9-slice plane is created with this texture.
	 * @since 7.2.0
	 * @see scene.NineSliceSprite
	 */
	readonly defaultBorders?: TextureBorders;
	/**
	 * This is the area of the BaseTexture image to actually copy to the Canvas / WebGL when rendering,
	 * irrespective of the actual frame size or placement (which can be influenced by trimmed texture atlases)
	 */
	readonly frame: Rectangle;
	/** This is the area of original texture, before it was put in atlas. */
	readonly orig: Rectangle;
	/**
	 * This is the trimmed area of original texture, before it was put in atlas
	 * Please call \`updateUvs()\` after you change coordinates of \`trim\` manually.
	 */
	readonly trim: Rectangle;
	/**
	 * Does this Texture have any frame data assigned to it?
	 *
	 * This mode is enabled automatically if no frame was passed inside constructor.
	 *
	 * In this mode texture is subscribed to baseTexture events, and fires \`update\` on any change.
	 *
	 * Beware, after loading or resize of baseTexture event can fired two times!
	 * If you want more control, subscribe on baseTexture itself.
	 * @example
	 * texture.on('update', () => {});
	 */
	noFrame: boolean;
	/**
	 * Set to true if you plan on modifying the uvs of this texture.
	 * When this is the case, sprites and other objects using the texture will
	 * make sure to listen for changes to the uvs and update their vertices accordingly.
	 */
	dynamic: boolean;
	private _textureMatrix;
	/** is it a texture? yes! used for type checking */
	readonly isTexture = true;
	/**
	 * @param {rendering.TextureOptions} options - Options for the texture
	 */
	constructor({ source, label, frame, orig, trim, defaultAnchor, defaultBorders, rotate, dynamic }?: TextureOptions<TextureSourceType>);
	set source(value: TextureSourceType);
	/** the underlying source of the texture (equivalent of baseTexture in v7) */
	get source(): TextureSourceType;
	/** returns a TextureMatrix instance for this texture. By default, that object is not created because its heavy. */
	get textureMatrix(): TextureMatrix;
	/** The width of the Texture in pixels. */
	get width(): number;
	/** The height of the Texture in pixels. */
	get height(): number;
	/** Call this function when you have modified the frame of this texture. */
	updateUvs(): void;
	/**
	 * Destroys this texture
	 * @param destroySource - Destroy the source when the texture is destroyed.
	 */
	destroy(destroySource?: boolean): void;
	/**
	 * Call this if you have modified the \`texture outside\` of the constructor.
	 *
	 * If you have modified this texture's source, you must separately call \`texture.source.update()\` to see those changes.
	 */
	update(): void;
	/** @deprecated since 8.0.0 */
	get baseTexture(): TextureSource;
	/** an Empty Texture used internally by the engine */
	static EMPTY: Texture;
	/** a White texture used internally by the engine */
	static WHITE: Texture<BufferImageSource>;
}
/**
 * A render texture, extends \`Texture\`.
 * @see {@link rendering.Texture}
 * @memberof rendering
 */
export declare class RenderTexture extends Texture {
	static create(options: TextureSourceOptions): RenderTexture;
	/**
	 * Resizes the render texture.
	 * @param width - The new width of the render texture.
	 * @param height - The new height of the render texture.
	 * @param resolution - The new resolution of the render texture.
	 * @returns This texture.
	 */
	resize(width: number, height: number, resolution?: number): this;
}
export type GenerateTextureSourceOptions = Omit<TextureSourceOptions, "resource" | "width" | "height" | "resolution">;
/**
 * Options for generating a texture from a container.
 * @memberof rendering
 */
export type GenerateTextureOptions = {
	/** The container to generate the texture from */
	target: Container;
	/**
	 * The region of the container, that shall be rendered,
	 * if no region is specified, defaults to the local bounds of the container.
	 */
	frame?: Rectangle;
	/** The resolution of the texture being generated. */
	resolution?: number;
	/** The color used to clear the texture. */
	clearColor?: ColorSource;
	/** Whether to enable anti-aliasing. This may affect performance. */
	antialias?: boolean;
	/** The options passed to the texture source. */
	textureSourceOptions?: GenerateTextureSourceOptions;
};
/**
 * System that manages the generation of textures from the renderer
 *
 *
 * Do not instantiate these plugins directly. It is available from the \`renderer.textureGenerator\` property.
 * @memberof rendering
 */
export declare class GenerateTextureSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "textureGenerator";
	};
	private readonly _renderer;
	constructor(renderer: Renderer);
	/**
	 * A Useful function that returns a texture of the display object that can then be used to create sprites
	 * This can be quite useful if your container is complicated and needs to be reused multiple times.
	 * @param {GenerateTextureOptions | Container} options - Generate texture options.
	 * @param {Container} [options.container] - If not given, the renderer's resolution is used.
	 * @param {Rectangle} options.region - The region of the container, that shall be rendered,
	 * @param {number} [options.resolution] - The resolution of the texture being generated.
	 *        if no region is specified, defaults to the local bounds of the container.
	 * @param {GenerateTextureSourceOptions} [options.textureSourceOptions] - Texture options for GPU.
	 * @returns a shiny new texture of the container passed in
	 */
	generateTexture(options: GenerateTextureOptions | Container): RenderTexture;
	destroy(): void;
}
/**
 * An effect that can be applied to a container. This is used to create effects such as filters/masks etc.
 * @memberof rendering
 */
export interface Effect {
	pipe: string;
	priority: number;
	addBounds?(bounds: Bounds, skipUpdateTransform?: boolean): void;
	addLocalBounds?(bounds: Bounds, localRoot: Container): void;
	containsPoint?(point: PointData, hitTestFn: (container: Container, point: Point) => boolean): boolean;
	destroy(): void;
}
export interface EffectConstructor {
	new (options?: any): Effect;
	test?(options: any): boolean;
}
type TypedArray$1 = Float32Array | Uint32Array | Int32Array | Uint8Array;
/**
 * Flexible wrapper around \`ArrayBuffer\` that also provides typed array views on demand.
 * @memberof utils
 */
export declare class ViewableBuffer {
	/** The size of the buffer in bytes. */
	size: number;
	/** Underlying \`ArrayBuffer\` that holds all the data and is of capacity \`this.size\`. */
	rawBinaryData: ArrayBuffer;
	/** View on the raw binary data as a \`Uint32Array\`. */
	uint32View: Uint32Array;
	/** View on the raw binary data as a \`Float32Array\`. */
	float32View: Float32Array;
	uint16View: Uint16Array;
	private _int8View;
	private _uint8View;
	private _int16View;
	private _int32View;
	private _float64Array;
	private _bigUint64Array;
	/**
	 * @param length - The size of the buffer in bytes.
	 */
	constructor(length: number);
	/**
	 * @param arrayBuffer - The source array buffer.
	 */
	constructor(arrayBuffer: ArrayBuffer);
	/** View on the raw binary data as a \`Int8Array\`. */
	get int8View(): Int8Array;
	/** View on the raw binary data as a \`Uint8Array\`. */
	get uint8View(): Uint8Array;
	/**  View on the raw binary data as a \`Int16Array\`. */
	get int16View(): Int16Array;
	/** View on the raw binary data as a \`Int32Array\`. */
	get int32View(): Int32Array;
	/** View on the raw binary data as a \`Float64Array\`. */
	get float64View(): Float64Array;
	/** View on the raw binary data as a \`BigUint64Array\`. */
	get bigUint64View(): BigUint64Array;
	/**
	 * Returns the view of the given type.
	 * @param type - One of \`int8\`, \`uint8\`, \`int16\`,
	 *    \`uint16\`, \`int32\`, \`uint32\`, and \`float32\`.
	 * @returns - typed array of given type
	 */
	view(type: string): TypedArray$1;
	/** Destroys all buffer references. Do not use after calling this. */
	destroy(): void;
	/**
	 * Returns the size of the given type in bytes.
	 * @param type - One of \`int8\`, \`uint8\`, \`int16\`,
	 *   \`uint16\`, \`int32\`, \`uint32\`, and \`float32\`.
	 * @returns - size of the type in bytes
	 */
	static sizeOf(type: string): number;
}
/**
 * Various blend modes supported by Pixi
 * @memberof filters
 */
export type BLEND_MODES = "inherit" | "normal" | "add" | "multiply" | "screen" | "darken" | "lighten" | "erase" | "color-dodge" | "color-burn" | "linear-burn" | "linear-dodge" | "linear-light" | "hard-light" | "soft-light" | "pin-light" | "difference" | "exclusion" | "overlay" | "saturation" | "color" | "luminosity" | "normal-npm" | "add-npm" | "screen-npm" | "none" | "subtract" | "divide" | "vivid-light" | "hard-mix" | "negation" | "min" | "max";
/**
 * The map of blend modes supported by Pixi
 * @memberof rendering
 */
export declare const BLEND_TO_NPM: {
	normal: string;
	add: string;
	screen: string;
};
/**
 * The stencil operation to perform when using the stencil buffer
 * @memberof rendering
 */
export declare enum STENCIL_MODES {
	DISABLED = 0,
	RENDERING_MASK_ADD = 1,
	MASK_ACTIVE = 2,
	INVERSE_MASK_ACTIVE = 3,
	RENDERING_MASK_REMOVE = 4,
	NONE = 5
}
/**
 * The culling mode to use. It can be either \`none\`, \`front\` or \`back\`.
 * @memberof rendering
 */
export type CULL_MODES = "none" | "back" | "front";
/**
 * Used by the batcher to build texture batches. Holds list of textures and their respective locations.
 * @memberof rendering
 */
export declare class BatchTextureArray {
	/** Inside textures array. */
	textures: TextureSource[];
	/** Respective locations for textures. */
	ids: Record<number, number>;
	/** Number of filled elements. */
	count: number;
	constructor();
	/** Clear the textures and their locations. */
	clear(): void;
}
/**
 * The different topology types supported by the renderer used to describe how the geometry should be renderer
 * @memberof rendering
 */
export type Topology = "point-list" | "line-list" | "line-strip" | "triangle-list" | "triangle-strip";
/** @deprecated since 8.0.0 */
export declare const DRAW_MODES: {
	POINTS: string;
	LINES: string;
	LINE_STRIP: string;
	TRIANGLES: string;
	TRIANGLE_STRIP: string;
};
/**
 * The different types of vertex formats supported by the renderer
 * @memberof rendering
 */
export type VertexFormat = "uint8x2" | "uint8x4" | "sint8x2" | "sint8x4" | "unorm8x2" | "unorm8x4" | "snorm8x2" | "snorm8x4" | "uint16x2" | "uint16x4" | "sint16x2" | "sint16x4" | "unorm16x2" | "unorm16x4" | "snorm16x2" | "snorm16x4" | "float16x2" | "float16x4" | "float32" | "float32x2" | "float32x3" | "float32x4" | "uint32" | "uint32x2" | "uint32x3" | "uint32x4" | "sint32" | "sint32x2" | "sint32x3" | "sint32x4";
export type IndexBufferArray = Uint16Array | Uint32Array;
/**
 * The attribute data for a geometries attributes
 * @memberof rendering
 */
export interface Attribute {
	/** the buffer that this attributes data belongs to */
	buffer: Buffer$1;
	/** the format of the attribute */
	format?: VertexFormat;
	/** the stride of the data in the buffer - in bytes*/
	stride?: number;
	/** the offset of the attribute from the buffer, defaults to 0 - in bytes*/
	offset?: number;
	/** is this an instanced buffer? (defaults to false) */
	instance?: boolean;
	/** the number of elements to be rendered. If not specified, all vertices after the starting vertex will be drawn. */
	size?: number;
	/**
	 * the starting vertex in the geometry to start drawing from. If not specified,
	 *  drawing will start from the first vertex.
	 */
	start?: number;
	/**
	 * attribute divisor for instanced rendering. Note: this is a **WebGL-only** feature, the WebGPU renderer will
	 * issue a warning if one of the attributes has divisor set.
	 */
	divisor?: number;
}
type AttributeOption = Omit<Attribute, "buffer"> & {
	buffer: Buffer$1 | TypedArray | number[];
} | Buffer$1 | TypedArray | number[];
export type AttributeOptions = Record<string, AttributeOption>;
/**
 * the interface that describes the structure of the geometry
 * @memberof rendering
 */
export interface GeometryDescriptor {
	/** an optional label to easily identify the geometry */
	label?: string;
	/** the attributes that make up the geometry */
	attributes?: AttributeOptions;
	/** optional index buffer for this geometry */
	indexBuffer?: Buffer$1 | TypedArray | number[];
	/** the topology of the geometry, defaults to 'triangle-list' */
	topology?: Topology;
	instanceCount?: number;
}
/**
 * A Geometry is a low-level object that represents the structure of 2D shapes in terms of vertices and attributes.
 * It's a crucial component for rendering as it describes the shape and format of the data that will go through the shaders.
 * Essentially, a Geometry object holds the data you'd send to a GPU buffer.
 *
 * A geometry is basically made of two components:
 * <br>
 * <b>Attributes</b>: These are essentially arrays that define properties of the vertices like position, color,
 * texture coordinates, etc. They map directly to attributes in your vertex shaders.
 * <br>
 * <b>Indices</b>: An optional array that describes how the vertices are connected.
 * If not provided, vertices will be interpreted in the sequence they're given.
 * @example
 *
 * const geometry = new Geometry({
 *   attributes: {
 *     aPosition: [ // add some positions
 *       0, 0,
 *       0, 100,
 *       100, 100,
 *       100,   0,
 *     ],
 *     aUv: [ // add some uvs
 *       0, 0,
 *       0, 1,
 *       1, 1,
 *       1, 0,
 *     ]
 *   }
 * });
 * @memberof rendering
 * @class
 */
export declare class Geometry extends EventEmitter<{
	update: Geometry;
	destroy: Geometry;
}> {
	/** The topology of the geometry. */
	topology: Topology;
	/** The unique id of the geometry. */
	readonly uid: number;
	/** A record of the attributes of the geometry. */
	readonly attributes: Record<string, Attribute>;
	/** The buffers that the attributes use */
	readonly buffers: Buffer$1[];
	/** The index buffer of the geometry */
	indexBuffer: Buffer$1;
	/**
	 * the layout key will be generated by WebGPU all geometries that have the same structure
	 * will have the same layout key. This is used to cache the pipeline layout
	 * @internal
	 * @ignore
	 */
	_layoutKey: number;
	/** the instance count of the geometry to draw */
	instanceCount: number;
	private readonly _bounds;
	private _boundsDirty;
	/**
	 * Create a new instance of a geometry
	 * @param options - The options for the geometry.
	 */
	constructor(options?: GeometryDescriptor);
	protected onBufferUpdate(): void;
	/**
	 * Returns the requested attribute.
	 * @param id - The name of the attribute required
	 * @returns - The attribute requested.
	 */
	getAttribute(id: string): Attribute;
	/**
	 * Returns the index buffer
	 * @returns - The index buffer.
	 */
	getIndex(): Buffer$1;
	/**
	 * Returns the requested buffer.
	 * @param id - The name of the buffer required.
	 * @returns - The buffer requested.
	 */
	getBuffer(id: string): Buffer$1;
	/**
	 * Used to figure out how many vertices there are in this geometry
	 * @returns the number of vertices in the geometry
	 */
	getSize(): number;
	/**
	 * Adds an attribute to the geometry.
	 * @param name - The name of the attribute to add.
	 * @param attributeOption - The attribute option to add.
	 */
	addAttribute(name: string, attributeOption: AttributeOption): void;
	/**
	 * Adds an index buffer to the geometry.
	 * @param indexBuffer - The index buffer to add. Can be a Buffer, TypedArray, or an array of numbers.
	 */
	addIndex(indexBuffer: Buffer$1 | TypedArray | number[]): void;
	/** Returns the bounds of the geometry. */
	get bounds(): Bounds;
	/**
	 * destroys the geometry.
	 * @param destroyBuffers - destroy the buffers associated with this geometry
	 */
	destroy(destroyBuffers?: boolean): void;
}
export interface ExtractedAttributeData extends Omit<Attribute, "buffer"> {
	/** set where the shader location is for this attribute */
	location?: number;
}
/**
 * returns the attribute data from the program
 * @private
 * @param {WebGLProgram} [program] - the WebGL program
 * @param {WebGLRenderingContext} [gl] - the WebGL context
 * @returns {object} the attribute data for this program
 */
export declare function extractAttributesFromGlProgram(program: WebGLProgram, gl: WebGLRenderingContextBase, sortAttributes?: boolean): Record<string, ExtractedAttributeData>;
export interface GlAttributeData {
	type: string;
	size: number;
	location: number;
	name: string;
}
export interface GlUniformData {
	name: string;
	index: number;
	type: string;
	size: number;
	isArray: boolean;
	value: any;
}
export interface GlUniformBlockData {
	index: number;
	name: string;
	size: number;
	value?: TypedArray;
}
/**
 * The options for the gl program
 * @memberof rendering
 */
export interface GlProgramOptions {
	/** The fragment glsl shader source. */
	fragment: string;
	/** The vertex glsl shader source. */
	vertex: string;
	/** the name of the program, defaults to 'pixi-program' */
	name?: string;
	/** the preferred vertex precision for the shader, this may not be used if the device does not support it  */
	preferredVertexPrecision?: string;
	/** the preferred fragment precision for the shader, this may not be used if the device does not support it  */
	preferredFragmentPrecision?: string;
	transformFeedbackVaryings?: {
		names: string[];
		bufferMode: "separate" | "interleaved";
	};
}
/**
 * A wrapper for a WebGL Program. You can create one and then pass it to a shader.
 * This will manage the WebGL program that is compiled and uploaded to the GPU.
 *
 * To get the most out of this class, you should be familiar with glsl shaders and how they work.
 * @see https://developer.mozilla.org/en-US/docs/Web/API/WebGLProgram
 * @example
 *
 * // Create a new program
 * const program = new GlProgram({
 *   vertex: '...',
 *   fragment: '...',
 * });
 *
 *
 * There are a few key things that pixi shader will do for you automatically:
 * <br>
 * - If no precision is provided in the shader, it will be injected into the program source for you.
 * This precision will be taken form the options provided, if none is provided,
 * then the program will default to the defaultOptions.
 * <br>
 * - It will inject the program name into the shader source if none is provided.
 * <br>
 *  - It will set the program version to 300 es.
 *
 * For optimal usage and best performance, its best to reuse programs as much as possible.
 * You should use the {@link GlProgram.from} helper function to create programs.
 * @class
 * @memberof rendering
 */
export declare class GlProgram {
	/** The default options used by the program. */
	static defaultOptions: Partial<GlProgramOptions>;
	/** the fragment glsl shader source. */
	readonly fragment?: string;
	/** the vertex glsl shader source */
	readonly vertex?: string;
	/**
	 * attribute data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_attributeData: Record<string, ExtractedAttributeData>;
	/**
	 * uniform data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_uniformData: Record<string, GlUniformData>;
	/**
	 * uniform data extracted from the program once created this happens when the program is used for the first time
	 * @internal
	 * @ignore
	 */
	_uniformBlockData: Record<string, GlUniformBlockData>;
	/** details on how to use this program with transform feedback */
	transformFeedbackVaryings?: {
		names: string[];
		bufferMode: "separate" | "interleaved";
	};
	/**
	 * the key that identifies the program via its source vertex + fragment
	 * @internal
	 * @ignore
	 */
	readonly _key: number;
	/**
	 * Creates a shiny new GlProgram. Used by WebGL renderer.
	 * @param options - The options for the program.
	 */
	constructor(options: GlProgramOptions);
	/** destroys the program */
	destroy(): void;
	/**
	 * Helper function that creates a program for a given source.
	 * It will check the program cache if the program has already been created.
	 * If it has that one will be returned, if not a new one will be created and cached.
	 * @param options - The options for the program.
	 * @returns A program using the same source
	 */
	static from(options: GlProgramOptions): GlProgram;
}
export interface StructsAndGroups {
	groups: {
		group: number;
		binding: number;
		name: string;
		isUniform: boolean;
		type: string;
	}[];
	structs: {
		name: string;
		members: Record<string, string>;
	}[];
}
export declare function extractStructAndGroups(wgsl: string): StructsAndGroups;
/**
 * a WebGPU descriptions of how the program is laid out
 * @see https://gpuweb.github.io/gpuweb/#gpupipelinelayout
 * @memberof rendering
 */
export type ProgramPipelineLayoutDescription = GPUBindGroupLayoutEntry[][];
/**
 * a map the maps names of uniforms to group indexes
 * @memberof rendering
 */
export type ProgramLayout = Record<string, number>[];
/**
 * the program source
 * @memberof rendering
 */
export interface ProgramSource {
	/** The wgsl source code of the shader. */
	source: string;
	/** The main function to run in this shader */
	entryPoint?: string;
}
/**
 * The options for the gpu program
 * @memberof rendering
 */
export interface GpuProgramOptions {
	/**
	 * the name of the program, this is added to the label of the GPU Program created
	 * under the hood. Makes it much easier to debug!
	 */
	name?: string;
	/** The fragment glsl shader source. */
	fragment?: ProgramSource;
	/** The vertex glsl shader source. */
	vertex?: ProgramSource;
	/** The layout of the program. If not provided, it will be generated from the shader sources. */
	layout?: ProgramLayout;
	/** The gpu layout of the program. If not provided, it will be generated from the shader sources. */
	gpuLayout?: ProgramPipelineLayoutDescription;
}
/**
 * A wrapper for a WebGPU Program, specifically designed for the WebGPU renderer.
 * This class facilitates the creation and management of shader code that integrates with the WebGPU pipeline.
 *
 * To leverage the full capabilities of this class, familiarity with WGSL shaders is recommended.
 * @see https://gpuweb.github.io/gpuweb/#index
 * @example
 *
 * // Create a new program
 * const program = new GpuProgram({
 *   vertex: {
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 *   fragment:{
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 * });
 *
 *
 * Note: Both fragment and vertex shader sources can coexist within a single WGSL source file
 * this can make things a bit simpler.
 *
 * For optimal usage and best performance, it help to reuse programs whenever possible.
 * The {@link GpuProgram.from} helper function is designed for this purpose, utilizing an
 * internal cache to efficiently manage and retrieve program instances.
 * By leveraging this function, you can significantly reduce overhead and enhance the performance of your rendering pipeline.
 *
 * An important distinction between WebGL and WebGPU regarding program data retrieval:
 * While WebGL allows extraction of program information directly from its compiled state,
 * WebGPU does not offer such a capability. Therefore, in the context of WebGPU, we're required
 * to manually extract the program layout information from the source code itself.
 * @memberof rendering
 */
export declare class GpuProgram {
	/** The fragment glsl shader source. */
	readonly fragment?: ProgramSource;
	/** The vertex glsl shader source */
	readonly vertex?: ProgramSource;
	/**
	 * Mapping of uniform names to group indexes for organizing shader program uniforms.
	 * Automatically generated from shader sources if not provided.
	 * @example
	 * // Assuming a shader with two uniforms, \`u_time\` and \`u_resolution\`, grouped respectively:
	 * [
	 *   { "u_time": 0 },
	 *   { "u_resolution": 1 }
	 * ]
	 */
	readonly layout: ProgramLayout;
	/**
	 * Configuration for the WebGPU bind group layouts, detailing resource organization for the shader.
	 * Generated from shader sources if not explicitly provided.
	 * @example
	 * // Assuming a shader program that requires two bind groups:
	 * [
	 *   // First bind group layout entries
	 *   [{ binding: 0, visibility: GPUShaderStage.VERTEX, type: "uniform-buffer" }],
	 *   // Second bind group layout entries
	 *   [{ binding: 1, visibility: GPUShaderStage.FRAGMENT, type: "sampler" },
	 *    { binding: 2, visibility: GPUShaderStage.FRAGMENT, type: "sampled-texture" }]
	 * ]
	 */
	readonly gpuLayout: ProgramPipelineLayoutDescription;
	/**
	 * @internal
	 * @ignore
	 */
	_layoutKey: number;
	/**
	 * @internal
	 * @ignore
	 */
	_attributeLocationsKey: number;
	/** the structs and groups extracted from the shader sources */
	readonly structsAndGroups: StructsAndGroups;
	/**
	 * the name of the program, this is added to the label of the GPU Program created under the hood.
	 * Makes it much easier to debug!
	 */
	readonly name: string;
	private _attributeData;
	/** if true, the program will automatically assign global uniforms to group[0] */
	autoAssignGlobalUniforms: boolean;
	/** if true, the program will automatically assign local uniforms to group[1] */
	autoAssignLocalUniforms: boolean;
	/**
	 * Create a new GpuProgram
	 * @param options - The options for the gpu program
	 */
	constructor(options: GpuProgramOptions);
	private _generateProgramKey;
	get attributeData(): Record<string, ExtractedAttributeData>;
	/** destroys the program */
	destroy(): void;
	/**
	 * Helper function that creates a program for a given source.
	 * It will check the program cache if the program has already been created.
	 * If it has that one will be returned, if not a new one will be created and cached.
	 * @param options - The options for the program.
	 * @returns A program using the same source
	 */
	static from(options: GpuProgramOptions): GpuProgram;
}
/**
 * A record of {@link BindGroup}'s used by the shader.
 *
 * \`Record<number, BindGroup>\`
 * @memberof rendering
 */
export type ShaderGroups = Record<number, BindGroup>;
interface ShaderBase {
	/** The WebGL program used by the WebGL renderer. */
	glProgram?: GlProgram;
	/** The WebGPU program used by the WebGPU renderer. */
	gpuProgram?: GpuProgram;
	/**
	 * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
	 * 0b00 - not compatible with either
	 * 0b01 - compatible with WebGL
	 * 0b10 - compatible with WebGPU
	 * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
	 */
	compatibleRenderers?: number;
}
export interface GlShaderWith extends ShaderBase {
	/** The WebGL program used by the WebGL renderer. */
	glProgram: GlProgram;
}
export interface GpuShaderWith extends ShaderBase {
	/** The WebGPU program used by the WebGPU renderer. */
	gpuProgram: GpuProgram;
}
export interface ShaderWithGroupsDescriptor {
	/** A record of {@link BindGroup}'s used by the shader. */
	groups: ShaderGroups;
	/** an optional map of how to bind the groups. This is automatically generated by reading the WebGPU program */
	groupMap?: Record<string, Record<string, any>>;
}
interface ShaderWithResourcesDescriptor {
	/**
	 * A key value of uniform resources used by the shader.
	 * Under the hood pixi will look at the provided shaders and figure out where
	 * the resources are mapped. Its up to you to make sure the resource key
	 * matches the uniform name in the webGPU program. WebGL is a little more forgiving!
	 */
	resources?: Record<string, any>;
}
/**
 * A descriptor for a shader
 * @memberof rendering
 */
export type ShaderWith = GlShaderWith | GpuShaderWith;
/**
 * A descriptor for a shader with groups.
 * @memberof rendering
 */
export type ShaderWithGroups = ShaderWithGroupsDescriptor & ShaderWith;
export interface IShaderWithGroups extends ShaderWithGroupsDescriptor, ShaderBase {
}
/**
 * A descriptor for a shader with resources. This is an easier way to work with uniforms.
 * especially when you are not working with bind groups
 * @memberof rendering
 */
export type ShaderWithResources = ShaderWithResourcesDescriptor & ShaderWith;
export interface IShaderWithResources extends ShaderWithResourcesDescriptor, ShaderBase {
}
export type ShaderDescriptor = ShaderWithGroups & ShaderWithResources;
type GlShaderFromWith = {
	gpu?: GpuProgramOptions;
	gl: GlProgramOptions;
};
type GpuShaderFromWith = {
	gpu: GpuProgramOptions;
	gl?: GlProgramOptions;
};
export type ShaderFromGroups = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithGroups, "glProgram" | "gpuProgram">;
export type ShaderFromResources = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithResources, "glProgram" | "gpuProgram">;
/**
 * The Shader class is an integral part of the PixiJS graphics pipeline.
 * Central to rendering in PixiJS are two key elements: A [shader] and a [geometry].
 * The shader incorporates a {@link GlProgram} for WebGL or a {@link GpuProgram} for WebGPU,
 * instructing the respective technology on how to render the geometry.
 *
 * The primary goal of the Shader class is to offer a unified interface compatible with both WebGL and WebGPU.
 * When constructing a shader, you need to provide both a WebGL program and a WebGPU program due to the distinctions
 * between the two rendering engines. If only one is provided, the shader won't function with the omitted renderer.
 *
 * Both WebGL and WebGPU utilize the same resource object when passed into the shader.
 * Post-creation, the shader's interface remains consistent across both WebGL and WebGPU.
 * The sole distinction lies in whether a glProgram or a gpuProgram is employed.
 *
 * Modifying shader uniforms, which can encompass:
 *  - TextureSampler {@link TextureStyle}
 *  - TextureSource {@link TextureSource}
 *  - UniformsGroups {@link UniformGroup}
 * @example
 *
 * const shader = new Shader({
 *     glProgram: glProgram,
 *     gpuProgram: gpuProgram,
 *     resources: {
 *         uTexture: texture.source,
 *         uSampler: texture.sampler,
 *         uColor: [1, 0, 0, 1],
 *     },
 * });
 *
 * // update the uniforms
 * shader.resources.uColor[1] = 1;
 * shader.resources.uTexture = texture2.source;
 * @class
 * @memberof rendering
 */
export declare class Shader extends EventEmitter<{
	"destroy": Shader;
}> {
	/** A unique identifier for the shader */
	readonly uid: number;
	/** An instance of the GPU program used by the WebGPU renderer */
	gpuProgram: GpuProgram;
	/** An instance of the GL program used by the WebGL renderer */
	glProgram: GlProgram;
	/**
	 * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
	 * 0b00 - not compatible with either
	 * 0b01 - compatible with WebGL
	 * 0b10 - compatible with WebGPU
	 * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
	 */
	readonly compatibleRenderers: number;
	/** */
	groups: Record<number, BindGroup>;
	/** A record of the resources used by the shader. */
	resources: Record<string, any>;
	/**
	 * A record of the uniform groups and resources used by the shader.
	 * This is used by WebGL renderer to sync uniform data.
	 * @internal
	 * @ignore
	 */
	_uniformBindMap: Record<number, Record<number, string>>;
	private readonly _ownedBindGroups;
	/**
	 * Fired after rendering finishes.
	 * @event rendering.Shader#destroy
	 */
	/**
	 * There are two ways to create a shader.
	 * one is to pass in resources which is a record of uniform groups and resources.
	 * another is to pass in groups which is a record of {@link BindGroup}s.
	 * this second method is really to make use of shared {@link BindGroup}s.
	 * For most cases you will want to use resources as they are easier to work with.
	 * USe Groups if you want to share {@link BindGroup}s between shaders.
	 * you cannot mix and match - either use resources or groups.
	 * @param {ShaderWithResourcesDescriptor} options - The options for the shader using ShaderWithResourcesDescriptor.
	 */
	constructor(options: ShaderWithResources);
	constructor(options: ShaderWithGroups);
	/**
	 * Sometimes a resource group will be provided later (for example global uniforms)
	 * In such cases, this method can be used to let the shader know about the group.
	 * @param name - the name of the resource group
	 * @param groupIndex - the index of the group (should match the webGPU shader group location)
	 * @param bindIndex - the index of the bind point (should match the webGPU shader bind point)
	 */
	addResource(name: string, groupIndex: number, bindIndex: number): void;
	private _buildResourceAccessor;
	/**
	 * Use to destroy the shader when its not longer needed.
	 * It will destroy the resources and remove listeners.
	 * @param destroyPrograms - if the programs should be destroyed as well.
	 * Make sure its not being used by other shaders!
	 */
	destroy(destroyPrograms?: boolean): void;
	/**
	 * A short hand function to create a shader based of a vertex and fragment shader.
	 * @param options
	 * @returns A shiny new PixiJS shader!
	 */
	static from(options: ShaderFromGroups): Shader;
	static from(options: ShaderFromResources): Shader;
}
export type BatchAction = "startBatch" | "renderBatch";
/**
 * A batch pool is used to store batches when they are not currently in use.
 * @memberof rendering
 */
export declare class Batch implements Instruction {
	renderPipeId: string;
	action: BatchAction;
	start: number;
	size: number;
	textures: BatchTextureArray;
	blendMode: BLEND_MODES;
	topology: Topology;
	canBundle: boolean;
	/**
	 * breaking rules slightly here in the name of performance..
	 * storing references to these bindgroups here is just faster for access!
	 * keeps a reference to the GPU bind group to set when rendering this batch for WebGPU. Will be null is using WebGL.
	 */
	gpuBindGroup: GPUBindGroup;
	/**
	 * breaking rules slightly here in the name of performance..
	 * storing references to these bindgroups here is just faster for access!
	 * keeps a reference to the bind group to set when rendering this batch for WebGPU. Will be null if using WebGl.
	 */
	bindGroup: BindGroup;
	batcher: Batcher;
	destroy(): void;
}
/**
 * Represents an element that can be batched for rendering.
 * @interface
 * @memberof rendering
 */
export interface BatchableElement {
	/**
	 * The name of the batcher to use. Must be registered.
	 * @type {string}
	 */
	batcherName: string;
	/**
	 * The texture to be used for rendering.
	 * @type {Texture}
	 */
	texture: Texture;
	/**
	 * The blend mode to be applied.
	 * @type {BLEND_MODES}
	 */
	blendMode: BLEND_MODES;
	/**
	 * The size of the index data.
	 * @type {number}
	 */
	indexSize: number;
	/**
	 * The size of the attribute data.
	 * @type {number}
	 */
	attributeSize: number;
	/**
	 * The topology to be used for rendering.
	 * @type {Topology}
	 */
	topology: Topology;
	/**
	 * Whether the element should be packed as a quad for better performance.
	 * @type {boolean}
	 */
	packAsQuad: boolean;
	/**
	 * The texture ID, stored for efficient updating.
	 * @type {number}
	 * @private
	 */
	_textureId: number;
	/**
	 * The starting position in the attribute buffer.
	 * @type {number}
	 * @private
	 */
	_attributeStart: number;
	/**
	 * The starting position in the index buffer.
	 * @type {number}
	 * @private
	 */
	_indexStart: number;
	/**
	 * Reference to the batcher.
	 * @type {Batcher}
	 * @private
	 */
	_batcher: Batcher;
	/**
	 * Reference to the batch.
	 * @type {Batch}
	 * @private
	 */
	_batch: Batch;
}
/**
 * Represents a batchable quad element.
 * @extends BatchableElement
 * @memberof rendering
 */
export interface BatchableQuadElement extends BatchableElement {
	/**
	 * Indicates that this element should be packed as a quad.
	 * @type {true}
	 */
	packAsQuad: true;
	/**
	 * The size of the attribute data for this quad element.
	 * @type {4}
	 */
	attributeSize: 4;
	/**
	 * The size of the index data for this quad element.
	 * @type {6}
	 */
	indexSize: 6;
	/**
	 * The bounds data for this quad element.
	 * @type {BoundsData}
	 */
	bounds: BoundsData;
}
/**
 * Represents a batchable mesh element.
 * @extends BatchableElement
 * @memberof rendering
 */
export interface BatchableMeshElement extends BatchableElement {
	/**
	 * The UV coordinates of the mesh.
	 * @type {number[] | Float32Array}
	 */
	uvs: number[] | Float32Array;
	/**
	 * The vertex positions of the mesh.
	 * @type {number[] | Float32Array}
	 */
	positions: number[] | Float32Array;
	/**
	 * The indices of the mesh.
	 * @type {number[] | Uint16Array | Uint32Array}
	 */
	indices: number[] | Uint16Array | Uint32Array;
	/**
	 * The offset in the index buffer.
	 * @type {number}
	 */
	indexOffset: number;
	/**
	 * The offset in the attribute buffer.
	 * @type {number}
	 */
	attributeOffset: number;
	/**
	 * Indicates that this element should not be packed as a quad.
	 * @type {false}
	 */
	packAsQuad: false;
}
/**
 * The options for the batcher.
 * @memberof rendering
 */
export interface BatcherOptions {
	/** The maximum number of textures per batch. */
	maxTextures?: number;
	attributesInitialSize?: number;
	indicesInitialSize?: number;
}
/**
 * A batcher is used to batch together objects with the same texture.
 * It is an abstract class that must be extended. see DefaultBatcher for an example.
 * @memberof rendering
 */
export declare abstract class Batcher {
	static defaultOptions: Partial<BatcherOptions>;
	/** unique id for this batcher */
	readonly uid: number;
	/** The buffer containing attribute data for all elements in the batch. */
	attributeBuffer: ViewableBuffer;
	/** The buffer containing index data for all elements in the batch. */
	indexBuffer: IndexBufferArray;
	/** The current size of the attribute data in the batch. */
	attributeSize: number;
	/** The current size of the index data in the batch. */
	indexSize: number;
	/** The total number of elements currently in the batch. */
	elementSize: number;
	/** The starting index of elements in the current batch. */
	elementStart: number;
	/** Indicates whether the batch data has been modified and needs updating. */
	dirty: boolean;
	/** The current index of the batch being processed. */
	batchIndex: number;
	/** An array of all batches created during the current rendering process. */
	batches: Batch[];
	private _elements;
	private _batchIndexStart;
	private _batchIndexSize;
	/** The maximum number of textures per batch. */
	readonly maxTextures: number;
	/** The name of the batcher. Must be implemented by subclasses. */
	abstract name: string;
	/** The vertex size of the batcher. Must be implemented by subclasses. */
	protected abstract vertexSize: number;
	/** The geometry used by this batcher. Must be implemented by subclasses. */
	abstract geometry: Geometry;
	/**
	 * The shader used by this batcher. Must be implemented by subclasses.
	 * this can be shared by multiple batchers of the same type.
	 */
	abstract shader: Shader;
	/**
	 * Packs the attributes of a BatchableMeshElement into the provided views.
	 * Must be implemented by subclasses.
	 * @param element - The BatchableMeshElement to pack.
	 * @param float32View - The Float32Array view to pack into.
	 * @param uint32View - The Uint32Array view to pack into.
	 * @param index - The starting index in the views.
	 * @param textureId - The texture ID to use.
	 */
	abstract packAttributes(element: BatchableMeshElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
	/**
	 * Packs the attributes of a BatchableQuadElement into the provided views.
	 * Must be implemented by subclasses.
	 * @param element - The BatchableQuadElement to pack.
	 * @param float32View - The Float32Array view to pack into.
	 * @param uint32View - The Uint32Array view to pack into.
	 * @param index - The starting index in the views.
	 * @param textureId - The texture ID to use.
	 */
	abstract packQuadAttributes(element: BatchableQuadElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
	constructor(options?: BatcherOptions);
	begin(): void;
	add(batchableObject: BatchableElement): void;
	checkAndUpdateTexture(batchableObject: BatchableElement, texture: Texture): boolean;
	updateElement(batchableObject: BatchableElement): void;
	/**
	 * breaks the batcher. This happens when a batch gets too big,
	 * or we need to switch to a different type of rendering (a filter for example)
	 * @param instructionSet
	 */
	break(instructionSet: InstructionSet): void;
	private _finishBatch;
	finish(instructionSet: InstructionSet): void;
	/**
	 * Resizes the attribute buffer to the given size (1 = 1 float32)
	 * @param size - the size in vertices to ensure (not bytes!)
	 */
	ensureAttributeBuffer(size: number): void;
	/**
	 * Resizes the index buffer to the given size (1 = 1 float32)
	 * @param size - the size in vertices to ensure (not bytes!)
	 */
	ensureIndexBuffer(size: number): void;
	private _resizeAttributeBuffer;
	private _resizeIndexBuffer;
	packQuadIndex(indexBuffer: IndexBufferArray, index: number, indicesOffset: number): void;
	packIndex(element: BatchableMeshElement, indexBuffer: IndexBufferArray, index: number, indicesOffset: number): void;
	destroy(): void;
}
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * InstructionPipes are specifically  used to manage the state of the renderer.
 * For example, the BlendModePipe is used to set the blend mode of the renderer.
 * @memberof rendering
 */
export interface InstructionPipe<INSTRUCTION extends Instruction> {
	/**
	 * called just before we execute the draw calls , this is where the pipes have an opportunity to
	 * upload data to the GPU. This is only called if data changes.
	 * @param instructionSet - the instruction set currently being built
	 */
	upload?: (instructionSet: InstructionSet) => void;
	/**
	 * this is where the actual instruction is executed - eg make the draw call
	 * activate a filter. Any instructions that have the same renderPipeId have their
	 * execute method called
	 * @param instruction - the instruction to execute
	 */
	execute?: (instruction: INSTRUCTION) => void;
	buildReset?: (instructionSet: InstructionSet) => void;
	buildStart?: (instructionSet: InstructionSet) => void;
	buildEnd?: (instructionSet: InstructionSet) => void;
	/** Called just after the render ends giving the RenderPipes a chance to do any cleanup */
	renderEnd?: () => void;
	/** Called just before the render starts giving the RenderPipes a chance to do any setup */
	renderStart?: () => void;
	/**
	 * Used by the effect pipes push and pop effects to the renderer. A push effect allows
	 * the renderer to change its state to support the effect. A pop effect allows the renderer
	 * to return to its previous state. An example of this would be the filter effect.
	 * @param effect - the effect to push
	 * @param targetContainer - the container that the effect is being applied to
	 * @param instructionSet - the instruction set currently being built
	 */
	push?: (effect: Effect, targetContainer: Container, instructionSet: InstructionSet) => void;
	/**
	 * Used by effect pipes to pop effects from the renderer.
	 * @param effect - the effect to pop
	 * @param targetContainer - the container that the effect is being applied to
	 * @param instructionSet - the instruction set currently being built
	 */
	pop?: (effect: Effect, targetContainer: Container, instructionSet: InstructionSet) => void;
}
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * RenderPipes are specifically used to render Renderables like a Mesh.
 * @memberof rendering
 */
export interface RenderPipe<RENDERABLE = Renderable> {
	/**
	 * This is where the renderable is added to the instruction set. This is called once per renderable.
	 * For instance, a MeshRenderPipe could be used to enqueue a 'draw mesh' command
	 * to the rendering instruction set, catering to the rendering of mesh geometry.
	 * In more complex scenarios, such as the SpritePipe, this seamlessly coordinates
	 * with a batchPipe to efficiently batch and add batch instructions to the instructions set
	 *
	 * Add is called when the instructions set is being built.
	 * @param renderable - the renderable that needs to be rendered
	 * @param instructionSet - the instruction set currently being built
	 */
	addRenderable: (renderable: RENDERABLE, instructionSet: InstructionSet) => void;
	/**
	 * Called whenever a renderable has been been updated, eg its position has changed.
	 * This is only called in the render loop if the instructions set is being reused
	 * from the last frame. Otherwise addRenderable is called.
	 * @param renderable - the renderable that needs to be rendered
	 */
	updateRenderable: (renderable: RENDERABLE) => void;
	/**
	 * Called whenever a renderable is destroyed, often the pipes keep a webGL / webGPU specific representation
	 * of the renderable that needs to be tidied up when the renderable is destroyed.
	 * @param renderable - the renderable that needs to be rendered
	 */
	destroyRenderable: (renderable: RENDERABLE) => void;
	/**
	 * This function is called when the renderer is determining if it can use the same instruction set again to
	 * improve performance. If this function returns true, the renderer will rebuild the whole instruction set
	 * for the scene. This is only called if the scene has not its changed its structure .
	 * @param renderable
	 * @returns {boolean}
	 */
	validateRenderable: (renderable: RENDERABLE) => boolean;
}
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * BatchPipes are specifically used to build and render Batches.
 */
export interface BatchPipe {
	/**
	 * Add a add a batchable object to the batch.
	 * @param renderable - a batchable object that can be added to the batch
	 * @param instructionSet - the instruction set currently being built
	 */
	addToBatch: (renderable: BatchableElement, instructionSet: InstructionSet) => void;
	/**
	 * Forces the batch to break. This can happen if for example you need to render everything and then
	 * change the render target.
	 * @param instructionSet - the instruction set currently being built
	 */
	break: (instructionSet: InstructionSet) => void;
}
/** A helpful type that can be used to create a new RenderPipe, BatchPipe or InstructionPipe */
export interface PipeConstructor {
	new (renderer: Renderer, adaptor?: any): RenderPipe | BatchPipe | InstructionPipe<any>;
}
/**
 * Options for creating a render target.
 * @memberof rendering
 */
export interface RenderTargetOptions {
	/** the width of the RenderTarget */
	width?: number;
	/** the height of the RenderTarget */
	height?: number;
	/** the resolution of the RenderTarget */
	resolution?: number;
	/** an array of textures, or a number indicating how many color textures there should be */
	colorTextures?: BindableTexture[] | number;
	/** should this render target have a stencil buffer? */
	stencil?: boolean;
	/** should this render target have a depth buffer? */
	depth?: boolean;
	/** a depth stencil texture that the depth and stencil outputs will be written to */
	depthStencilTexture?: BindableTexture | boolean;
	/** should this render target be antialiased? */
	antialias?: boolean;
	/** is this a root element, true if this is gl context owners render target */
	isRoot?: boolean;
}
/**
 * A class that describes what the renderers are rendering to.
 * This can be as simple as a Texture, or as complex as a multi-texture, multi-sampled render target.
 * Support for stencil and depth buffers is also included.
 *
 * If you need something more complex than a Texture to render to, you should use this class.
 * Under the hood, all textures you render to have a RenderTarget created on their behalf.
 * @memberof rendering
 */
export declare class RenderTarget {
	/** The default options for a render target */
	static defaultOptions: RenderTargetOptions;
	/** unique id for this render target */
	readonly uid: number;
	/**
	 * An array of textures that can be written to by the GPU - mostly this has one texture in Pixi, but you could
	 * write to multiple if required! (eg deferred lighting)
	 */
	colorTextures: TextureSource[];
	/** the stencil and depth buffer will right to this texture in WebGPU */
	depthStencilTexture: TextureSource;
	/** if true, will ensure a stencil buffer is added. For WebGPU, this will automatically create a depthStencilTexture */
	stencil: boolean;
	/** if true, will ensure a depth buffer is added. For WebGPU, this will automatically create a depthStencilTexture */
	depth: boolean;
	dirtyId: number;
	isRoot: boolean;
	private readonly _size;
	/** if true, then when the render target is destroyed, it will destroy all the textures that were created for it. */
	private readonly _managedColorTextures;
	/**
	 * @param [descriptor] - Options for creating a render target.
	 */
	constructor(descriptor?: RenderTargetOptions);
	get size(): [
		number,
		number
	];
	get width(): number;
	get height(): number;
	get pixelWidth(): number;
	get pixelHeight(): number;
	get resolution(): number;
	get colorTexture(): TextureSource;
	protected onSourceResize(source: TextureSource): void;
	/**
	 * This will ensure a depthStencil texture is created for this render target.
	 * Most likely called by the mask system to make sure we have stencil buffer added.
	 * @internal
	 * @ignore
	 */
	ensureDepthStencilTexture(): void;
	resize(width: number, height: number, resolution?: number, skipColorTexture?: boolean): void;
	destroy(): void;
}
/**
 * Represents a render target.
 * @memberof rendering
 * @ignore
 */
export declare class GlRenderTarget {
	width: number;
	height: number;
	msaa: boolean;
	framebuffer: WebGLFramebuffer;
	resolveTargetFramebuffer: WebGLFramebuffer;
	msaaRenderBuffer: WebGLRenderbuffer[];
	depthStencilRenderBuffer: WebGLRenderbuffer;
}
/**
 * A class which holds the canvas contexts and textures for a render target.
 * @memberof rendering
 * @ignore
 */
export declare class GpuRenderTarget {
	contexts: GPUCanvasContext[];
	msaaTextures: TextureSource[];
	msaa: boolean;
	msaaSamples: number;
	width: number;
	height: number;
	descriptor: GPURenderPassDescriptor;
}
/**
 * A render surface is a texture, canvas, or render target
 * @memberof rendering
 * @see environment.ICanvas
 * @see rendering.Texture
 * @see rendering.RenderTarget
 */
export type RenderSurface = ICanvas | BindableTexture | RenderTarget;
/**
 * An adaptor interface for RenderTargetSystem to support WebGL and WebGPU.
 * This is used internally by the renderer, and is not intended to be used directly.
 * @ignore
 */
export interface RenderTargetAdaptor<RENDER_TARGET extends GlRenderTarget | GpuRenderTarget> {
	init(
	/** the renderer */
	renderer: Renderer, 
	/** the render target system */
	renderTargetSystem: RenderTargetSystem<RENDER_TARGET>): void;
	/** A function copies the contents of a render surface to a texture */
	copyToTexture(
	/** the render surface to copy from  */
	sourceRenderSurfaceTexture: RenderTarget, 
	/** the texture to copy to */
	destinationTexture: Texture, 
	/** the origin of the copy */
	originSrc: {
		x: number;
		y: number;
	}, 
	/** the size of the copy */
	size: {
		width: number;
		height: number;
	}, 
	/** the destination origin (top left to paste from!) */
	originDest?: {
		x: number;
		y: number;
	}): Texture;
	/** starts a render pass on the render target */
	startRenderPass(
	/** the render target to start the render pass on */
	renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, 
	/** the color to clear to */
	clearColor?: RgbaArray, 
	/** the viewport to use */
	viewport?: Rectangle): void;
	/** clears the current render target to the specified color */
	clear(
	/** the render target to clear */
	renderTarget: RenderTarget, 
	/** the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111 */
	clear: CLEAR_OR_BOOL, 
	/** the color to clear to   */
	clearColor?: RgbaArray, 
	/** the viewport to use */
	viewport?: Rectangle): void;
	/** finishes the current render pass */
	finishRenderPass(renderTarget: RenderTarget): void;
	/** called after the render pass is finished */
	postrender?(renderTarget: RenderTarget): void;
	/** called before the render main pass is started */
	prerender?(renderTarget: RenderTarget): void;
	/**
	 * initializes a gpu render target. Both renderers use this function to initialize a gpu render target
	 * Its different type of object depending on the renderer.
	 */
	initGpuRenderTarget(
	/** the render target to initialize */
	renderTarget: RenderTarget): RENDER_TARGET;
	/** called when a render target is resized */
	resizeGpuRenderTarget(
	/** the render target to resize */
	renderTarget: RenderTarget): void;
	/** destroys the gpu render target */
	destroyGpuRenderTarget(
	/** the render target to destroy */
	gpuRenderTarget: RENDER_TARGET): void;
}
/**
 * A system that manages render targets. A render target is essentially a place where the shaders can color in the pixels.
 * The render target system is responsible for binding the render target to the renderer, and managing the viewport.
 * Render targets can be pushed and popped.
 *
 * To make it easier, you can also bind textures and canvases too. This will automatically create a render target for you.
 * The render target itself is a lot more powerful than just a texture or canvas,
 * as it can have multiple textures attached to it.
 * It will also give ou fine grain control over the stencil buffer / depth texture.
 * @example
 *
 * \`\`\`js
 *
 * // create a render target
 * const renderTarget = new RenderTarget({
 *   colorTextures: [new TextureSource({ width: 100, height: 100 })],
 * });
 *
 * // bind the render target
 * renderer.renderTarget.bind(renderTarget);
 *
 * // draw something!
 * \`\`\`
 * @memberof rendering
 */
export declare class RenderTargetSystem<RENDER_TARGET extends GlRenderTarget | GpuRenderTarget> implements System {
	/** When rendering of a scene begins, this is where the root render surface is stored */
	rootRenderTarget: RenderTarget;
	/** This is the root viewport for the render pass*/
	rootViewPort: Rectangle;
	/** A boolean that lets the dev know if the current render pass is rendering to the screen. Used by some plugins */
	renderingToScreen: boolean;
	/** the current active render target */
	renderTarget: RenderTarget;
	/** the current active render surface that the render target is created from */
	renderSurface: RenderSurface;
	/** the current viewport that the gpu is using */
	readonly viewport: Rectangle;
	/**
	 * a runner that lets systems know if the active render target has changed.
	 * Eg the Stencil System needs to know so it can manage the stencil buffer
	 */
	readonly onRenderTargetChange: SystemRunner;
	/** the projection matrix that is used by the shaders based on the active render target and the viewport */
	readonly projectionMatrix: Matrix;
	/** the default clear color for render targets */
	readonly defaultClearColor: RgbaArray;
	/** a reference to the adaptor that interfaces with WebGL / WebGP */
	readonly adaptor: RenderTargetAdaptor<RENDER_TARGET>;
	/**
	 * a hash that stores the render target for a given render surface. When you pass in a texture source,
	 * a render target is created for it. This map stores and makes it easy to retrieve the render target
	 */
	private readonly _renderSurfaceToRenderTargetHash;
	/** A hash that stores a gpu render target for a given render target. */
	private _gpuRenderTargetHash;
	/**
	 * A stack that stores the render target and frame that is currently being rendered to.
	 * When push is called, the current render target is stored in this stack.
	 * When pop is called, the previous render target is restored.
	 */
	private readonly _renderTargetStack;
	/** A reference to the renderer */
	private readonly _renderer;
	constructor(renderer: Renderer);
	/** called when dev wants to finish a render pass */
	finishRenderPass(): void;
	/**
	 * called when the renderer starts to render a scene.
	 * @param options
	 * @param options.target - the render target to render to
	 * @param options.clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
	 * @param options.clearColor - the color to clear to
	 * @param options.frame - the frame to render to
	 */
	renderStart({ target, clear, clearColor, frame }: {
		target: RenderSurface;
		clear: CLEAR_OR_BOOL;
		clearColor: RgbaArray;
		frame?: Rectangle;
	}): void;
	postrender(): void;
	/**
	 * Binding a render surface! This is the main function of the render target system.
	 * It will take the RenderSurface (which can be a texture, canvas, or render target) and bind it to the renderer.
	 * Once bound all draw calls will be rendered to the render surface.
	 *
	 * If a frame is not provide and the render surface is a texture, the frame of the texture will be used.
	 * @param renderSurface - the render surface to bind
	 * @param clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
	 * @param clearColor - the color to clear to
	 * @param frame - the frame to render to
	 * @returns the render target that was bound
	 */
	bind(renderSurface: RenderSurface, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, frame?: Rectangle): RenderTarget;
	clear(target?: RenderSurface, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray): void;
	protected contextChange(): void;
	/**
	 * Push a render surface to the renderer. This will bind the render surface to the renderer,
	 * @param renderSurface - the render surface to push
	 * @param clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
	 * @param clearColor - the color to clear to
	 * @param frame - the frame to use when rendering to the render surface
	 */
	push(renderSurface: RenderSurface, clear?: CLEAR | boolean, clearColor?: RgbaArray, frame?: Rectangle): RenderTarget;
	/** Pops the current render target from the renderer and restores the previous render target. */
	pop(): void;
	/**
	 * Gets the render target from the provide render surface. Eg if its a texture,
	 * it will return the render target for the texture.
	 * If its a render target, it will return the same render target.
	 * @param renderSurface - the render surface to get the render target for
	 * @returns the render target for the render surface
	 */
	getRenderTarget(renderSurface: RenderSurface): RenderTarget;
	/**
	 * Copies a render surface to another texture.
	 *
	 * NOTE:
	 * for sourceRenderSurfaceTexture, The render target must be something that is written too by the renderer
	 *
	 * The following is not valid:
	 * @example
	 * const canvas = document.createElement('canvas')
	 * canvas.width = 200;
	 * canvas.height = 200;
	 *
	 * const ctx = canvas2.getContext('2d')!
	 * ctx.fillStyle = 'red'
	 * ctx.fillRect(0, 0, 200, 200);
	 *
	 * const texture = RenderTexture.create({
	 *   width: 200,
	 *   height: 200,
	 * })
	 * const renderTarget = renderer.renderTarget.getRenderTarget(canvas2);
	 *
	 * renderer.renderTarget.copyToTexture(renderTarget,texture, {x:0,y:0},{width:200,height:200},{x:0,y:0});
	 *
	 * The best way to copy a canvas is to create a texture from it. Then render with that.
	 *
	 * Parsing in a RenderTarget canvas context (with a 2d context)
	 * @param sourceRenderSurfaceTexture - the render surface to copy from
	 * @param destinationTexture - the texture to copy to
	 * @param originSrc - the origin of the copy
	 * @param originSrc.x - the x origin of the copy
	 * @param originSrc.y - the y origin of the copy
	 * @param size - the size of the copy
	 * @param size.width - the width of the copy
	 * @param size.height - the height of the copy
	 * @param originDest - the destination origin (top left to paste from!)
	 * @param originDest.x - the x origin of the paste
	 * @param originDest.y - the y origin of the paste
	 */
	copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
		x: number;
		y: number;
	}, size: {
		width: number;
		height: number;
	}, originDest: {
		x: number;
		y: number;
	}): Texture<TextureSource<any>>;
	/**
	 * ensures that we have a depth stencil buffer available to render to
	 * This is used by the mask system to make sure we have a stencil buffer.
	 */
	ensureDepthStencil(): void;
	/** nukes the render target system */
	destroy(): void;
	private _initRenderTarget;
	getGpuRenderTarget(renderTarget: RenderTarget): RENDER_TARGET;
	resetState(): void;
}
/**
 * Options passed to the ViewSystem
 * @memberof rendering
 * @property {number} [width=800] - The width of the screen.
 * @property {number} [height=600] - The height of the screen.
 * @property {ICanvas} [canvas] - The canvas to use as a view, optional.
 * @property {boolean} [autoDensity=false] - Resizes renderer view in CSS pixels to allow for resolutions other than 1.
 *  This is only supported for HTMLCanvasElement and will be ignored if the canvas is an OffscreenCanvas.
 * @property {number} [resolution] - The resolution / device pixel ratio of the renderer.
 * @property {boolean} [antialias=false] - Whether to enable anti-aliasing. This may affect performance.
 * @property {boolean} [depth] -
 * Whether to ensure the main view has can make use of the depth buffer. Always true for WebGL renderer.
 * @property {boolean} [multiView] - TODO: multiView
 * @property {number} [backgroundAlpha] - The alpha of the background.
 */
export interface ViewSystemOptions {
	/**
	 * The width of the screen.
	 * @default 800
	 * @memberof rendering.SharedRendererOptions
	 */
	width?: number;
	/**
	 * The height of the screen.
	 * @default 600
	 * @memberof rendering.SharedRendererOptions
	 */
	height?: number;
	/**
	 * The canvas to use as a view, optional.
	 * @memberof rendering.SharedRendererOptions
	 */
	canvas?: ICanvas;
	/** @deprecated */
	view?: ICanvas;
	/**
	 * Resizes renderer view in CSS pixels to allow for resolutions other than 1.
	 *
	 * This is only supported for HTMLCanvasElement
	 * and will be ignored if the canvas is an OffscreenCanvas.
	 * @memberof rendering.SharedRendererOptions
	 */
	autoDensity?: boolean;
	/**
	 * The resolution / device pixel ratio of the renderer.
	 * @memberof rendering.SharedRendererOptions
	 */
	resolution?: number;
	/**
	 * Whether to enable anti-aliasing. This may affect performance.
	 * @memberof rendering.SharedRendererOptions
	 */
	antialias?: boolean;
	/**
	 * Whether to ensure the main view has can make use of the depth buffer. Always true for WebGL renderer.
	 * @memberof rendering.SharedRendererOptions
	 */
	depth?: boolean;
	/**
	 * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
	 * @default 1
	 */
	backgroundAlpha?: number;
}
export interface ViewSystemDestroyOptions {
	/** Whether to remove the view element from the DOM. Defaults to \`false\`. */
	removeView?: boolean;
}
/**
 * The view system manages the main canvas that is attached to the DOM.
 * This main role is to deal with how the holding the view reference and dealing with how it is resized.
 * @memberof rendering
 */
export declare class ViewSystem implements System<ViewSystemOptions, TypeOrBool<ViewSystemDestroyOptions>> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "view";
		readonly priority: 0;
	};
	/** The default options for the view system. */
	static defaultOptions: ViewSystemOptions;
	/** The canvas element that everything is drawn to. */
	canvas: ICanvas;
	/** The texture that is used to draw the canvas to the screen. */
	texture: Texture<CanvasSource>;
	/**
	 * Whether CSS dimensions of canvas view should be resized to screen dimensions automatically.
	 * This is only supported for HTMLCanvasElement and will be ignored if the canvas is an OffscreenCanvas.
	 * @member {boolean}
	 */
	get autoDensity(): boolean;
	set autoDensity(value: boolean);
	/** Whether to enable anti-aliasing. This may affect performance. */
	antialias: boolean;
	/**
	 * Measurements of the screen. (0, 0, screenWidth, screenHeight).
	 *
	 * Its safe to use as filterArea or hitArea for the whole stage.
	 */
	screen: Rectangle;
	/** The render target that the view is drawn to. */
	renderTarget: RenderTarget;
	/** The resolution / device pixel ratio of the renderer. */
	get resolution(): number;
	set resolution(value: number);
	/**
	 * initiates the view system
	 * @param options - the options for the view
	 */
	init(options: ViewSystemOptions): void;
	/**
	 * Resizes the screen and canvas to the specified dimensions.
	 * @param desiredScreenWidth - The new width of the screen.
	 * @param desiredScreenHeight - The new height of the screen.
	 * @param resolution
	 */
	resize(desiredScreenWidth: number, desiredScreenHeight: number, resolution: number): void;
	/**
	 * Destroys this System and optionally removes the canvas from the dom.
	 * @param {options | false} options - The options for destroying the view, or "false".
	 * @param options.removeView - Whether to remove the view element from the DOM. Defaults to \`false\`.
	 */
	destroy(options?: TypeOrBool<ViewSystemDestroyOptions>): void;
}
export interface ViewContainerOptions extends ContainerOptions, PixiMixins.ViewContainerOptions {
}
export interface ViewContainer extends PixiMixins.ViewContainer, Container {
}
/**
 * A ViewContainer is a type of container that represents a view.
 * This view can be a Sprite, a Graphics object, or any other object that can be rendered.
 * This class is abstract and should not be used directly.
 * @memberof scene
 */
export declare abstract class ViewContainer extends Container implements View {
	/** @private */
	readonly renderPipeId: string;
	/** @private */
	readonly canBundle = true;
	/** @private */
	allowChildren: boolean;
	/** @private */
	_roundPixels: 0 | 1;
	/** @private */
	_lastUsed: number;
	protected _bounds: Bounds;
	protected _boundsDirty: boolean;
	/**
	 * The local bounds of the view.
	 * @type {rendering.Bounds}
	 */
	get bounds(): Bounds;
	/** @private */
	protected abstract updateBounds(): void;
	/**
	 * Whether or not to round the x/y position of the sprite.
	 * @type {boolean}
	 */
	get roundPixels(): boolean;
	set roundPixels(value: boolean);
	constructor(options: ViewContainerOptions);
	/**
	 * Checks if the object contains the given point.
	 * @param point - The point to check
	 */
	containsPoint(point: PointData): boolean;
	/** @private */
	abstract batched: boolean;
	/** @private */
	protected onViewUpdate(): void;
	destroy(options?: DestroyOptions): void;
	collectRenderablesSimple(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
}
type RenderFunction = (renderer: Renderer) => void;
/**
 * Options for the {@link scene.RenderContainer} constructor.
 * @memberof scene
 */
export interface RenderContainerOptions extends ContainerOptions {
	/** the optional custom render function if you want to inject the function via the constructor */
	render?: RenderFunction;
	/** how to know if the custom render logic contains a point or not, used for interaction */
	containsPoint?: (point: Point) => boolean;
	/** how to add the bounds of this object when measuring */
	addBounds?: (bounds: BoundsData) => void;
}
/**
 * A container that allows for custom rendering logic. Its essentially calls the render function each frame
 * and allows for custom rendering logic - the render could be a WebGL renderer or WebGPU render or even a canvas render.
 * Its up to you to define the logic.
 *
 * This can be used in two ways, either by extending the class and overriding the render method,
 * or by passing a custom render function
 * @example
 * \`\`\`js
 * import { RenderContainer } from 'pixi.js';
 *
 * // extend the class
 * class MyRenderContainer extends RenderContainer
 * {
 *    render(renderer)
 *    {
 *      renderer.clear({
 *         clearColor: 'green', // clear the screen to green when rendering this item
 *      });
 *   }
 * }
 *
 * // override the render method
 * const renderContainer = new RenderContainer(
 * (renderer) =>  {
 *     renderer.clear({
 *       clearColor: 'green', // clear the screen to green when rendering this item
 *     });
 * })
 * \`\`\`
 * @memberof scene
 * @extends scene.Container
 */
export declare class RenderContainer extends ViewContainer implements Instruction {
	readonly renderPipeId: string;
	batched: boolean;
	/**
	 * Adds the bounds of this text to the bounds object.
	 * @param bounds - The output bounds object.
	 */
	addBounds: (bounds: Bounds) => void;
	/**
	 * @param options - The options for the container.
	 */
	constructor(options: RenderContainerOptions | RenderFunction);
	/** @private */
	protected updateBounds(): void;
	/**
	 * An overridable function that can be used to render the object using the current renderer.
	 * @param _renderer - The current renderer
	 */
	render(_renderer: Renderer): void;
}
/**
 * The CustomRenderPipe is a render pipe that allows for custom rendering logic for your renderable objects.
 * @example
 * import { RenderContainer } from 'pixi.js';
 *
 * const renderContainer = new RenderContainer(
 * (renderer) =>  {
 *     renderer.clear({
 *       clearColor: 'green', // clear the screen to green when rendering this item
 *     });
 * })
 * @memberof rendering
 */
export declare class CustomRenderPipe implements InstructionPipe<RenderContainer>, RenderPipe<RenderContainer> {
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "customRender";
	};
	private _renderer;
	constructor(renderer: Renderer);
	updateRenderable(): void;
	destroyRenderable(): void;
	validateRenderable(): boolean;
	addRenderable(container: RenderContainer, instructionSet: InstructionSet): void;
	execute(container: RenderContainer): void;
	destroy(): void;
}
export declare class BatchGeometry extends Geometry {
	constructor();
}
/**
 * Represents the common elements for default batch rendering.
 * This interface defines the properties that are used by the DefaultBatcher
 * to render elements efficiently in a batch.
 * @memberof rendering
 */
export interface DefaultBatchElements {
	/**
	 * The color of the element that will be multiplied with the texture color.
	 * This is typically represented as a 32-bit integer in RGBA format.
	 */
	color: number;
	/**
	 * Determines whether the element should be rounded to the nearest pixel.
	 * - 0: No rounding (default)
	 * - 1: Round to nearest pixel
	 * This can help with visual consistency, especially for pixel art styles.
	 */
	roundPixels: 0 | 1;
	/**
	 * The transform matrix of the element.
	 * This matrix represents the position, scale, rotation, and skew of the element.
	 */
	transform: Matrix;
}
/**
 * Represents a batchable quad element with default batch properties.
 * @memberof rendering
 */
export interface DefaultBatchableQuadElement extends BatchableQuadElement, DefaultBatchElements {
}
/**
 * Represents a batchable mesh element with default batch properties.
 * @memberof rendering
 */
export interface DefaultBatchableMeshElement extends BatchableMeshElement, DefaultBatchElements {
}
/**
 * The default batcher is used to batch quads and meshes. This batcher will batch the following elements:
 * - tints
 * - roundPixels
 * - texture
 * - transform
 * @memberof rendering
 */
export declare class DefaultBatcher extends Batcher {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.Batcher
		];
		readonly name: "default";
	};
	geometry: BatchGeometry;
	shader: Shader;
	name: "default";
	/** The size of one attribute. 1 = 32 bit. x, y, u, v, color, textureIdAndRound -> total = 6 */
	vertexSize: number;
	/**
	 * Packs the attributes of a DefaultBatchableMeshElement into the provided views.
	 * @param element - The DefaultBatchableMeshElement to pack.
	 * @param float32View - The Float32Array view to pack into.
	 * @param uint32View - The Uint32Array view to pack into.
	 * @param index - The starting index in the views.
	 * @param textureId - The texture ID to use.
	 */
	packAttributes(element: DefaultBatchableMeshElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
	/**
	 * Packs the attributes of a DefaultBatchableQuadElement into the provided views.
	 * @param element - The DefaultBatchableQuadElement to pack.
	 * @param float32View - The Float32Array view to pack into.
	 * @param uint32View - The Uint32Array view to pack into.
	 * @param index - The starting index in the views.
	 * @param textureId - The texture ID to use.
	 */
	packQuadAttributes(element: DefaultBatchableQuadElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
}
/**
 * A batchable sprite object.
 * @ignore
 */
export declare class BatchableSprite implements DefaultBatchableQuadElement {
	batcherName: string;
	topology: Topology;
	readonly attributeSize = 4;
	readonly indexSize = 6;
	readonly packAsQuad = true;
	transform: Matrix;
	renderable: Container;
	texture: Texture;
	bounds: BoundsData;
	roundPixels: 0 | 1;
	_indexStart: number;
	_textureId: number;
	_attributeStart: number;
	_batcher: Batcher;
	_batch: Batch;
	get blendMode(): BLEND_MODES;
	get color(): number;
	reset(): void;
}
/**
 * Options for caching a container as a texture.
 * @memberof rendering
 * @see {@link RenderGroup#textureOptions}
 */
export interface CacheAsTextureOptions {
	/**
	 * If true, the texture will be antialiased. This smooths out the edges of the texture.
	 * @default false
	 */
	antialias?: boolean;
	/**
	 * The resolution of the texture. A higher resolution means a sharper texture but uses more memory.
	 * By default the resolution is 1 which is the same as the rendererers resolution.
	 */
	resolution?: number;
}
/**
 * A RenderGroup is a class that is responsible for I generating a set of instructions that are used to render the
 * root container and its children. It also watches for any changes in that container or its children,
 * these changes are analysed and either the instruction set is rebuild or the instructions data is updated.
 * @memberof rendering
 */
export declare class RenderGroup implements Instruction {
	renderPipeId: string;
	root: Container;
	canBundle: boolean;
	renderGroupParent: RenderGroup;
	renderGroupChildren: RenderGroup[];
	worldTransform: Matrix;
	worldColorAlpha: number;
	worldColor: number;
	worldAlpha: number;
	readonly childrenToUpdate: Record<number, {
		list: Container[];
		index: number;
	}>;
	updateTick: number;
	gcTick: number;
	readonly childrenRenderablesToUpdate: {
		list: Container[];
		index: number;
	};
	structureDidChange: boolean;
	instructionSet: InstructionSet;
	private readonly _onRenderContainers;
	/**
	 * Indicates if the cached texture needs to be updated.
	 * @default true
	 */
	textureNeedsUpdate: boolean;
	/**
	 * Indicates if the container should be cached as a texture.
	 * @default false
	 */
	isCachedAsTexture: boolean;
	/**
	 * The texture used for caching the container. this is only set if isCachedAsTexture is true.
	 * It can only be accessed after a render pass.
	 * @type {Texture | undefined}
	 */
	texture?: Texture;
	/**
	 * The bounds of the cached texture.
	 * @type {Bounds | undefined}
	 * @ignore
	 */
	_textureBounds?: Bounds;
	/**
	 * The options for caching the container as a texture.
	 * @type {CacheAsTextureOptions}
	 */
	textureOptions: CacheAsTextureOptions;
	/**
	 *  holds a reference to the batchable render sprite
	 *  @ignore
	 */
	_batchableRenderGroup: BatchableSprite;
	/**
	 * Holds a reference to the closest parent RenderGroup that has isCachedAsTexture enabled.
	 * This is used to properly transform coordinates when rendering into cached textures.
	 * @type {RenderGroup | null}
	 * @ignore
	 */
	_parentCacheAsTextureRenderGroup: RenderGroup;
	private _inverseWorldTransform;
	private _textureOffsetInverseTransform;
	private _inverseParentTextureTransform;
	private _matrixDirty;
	init(root: Container): void;
	enableCacheAsTexture(options?: CacheAsTextureOptions): void;
	disableCacheAsTexture(): void;
	updateCacheTexture(): void;
	reset(): void;
	get localTransform(): Matrix;
	addRenderGroupChild(renderGroupChild: RenderGroup): void;
	private _removeRenderGroupChild;
	addChild(child: Container): void;
	removeChild(child: Container): void;
	removeChildren(children: Container[]): void;
	onChildUpdate(child: Container): void;
	updateRenderable(renderable: ViewContainer): void;
	onChildViewUpdate(child: Container): void;
	get isRenderable(): boolean;
	/**
	 * adding a container to the onRender list will make sure the user function
	 * passed in to the user defined 'onRender\` callBack
	 * @param container - the container to add to the onRender list
	 */
	addOnRender(container: Container): void;
	removeOnRender(container: Container): void;
	runOnRender(renderer: Renderer): void;
	destroy(): void;
	getChildren(out?: Container[]): Container[];
	private _getChildren;
	invalidateMatrices(): void;
	/**
	 * Returns the inverse of the world transform matrix.
	 * @returns {Matrix} The inverse of the world transform matrix.
	 */
	get inverseWorldTransform(): Matrix;
	/**
	 * Returns the inverse of the texture offset transform matrix.
	 * @returns {Matrix} The inverse of the texture offset transform matrix.
	 */
	get textureOffsetInverseTransform(): Matrix;
	/**
	 * Returns the inverse of the parent texture transform matrix.
	 * This is used to properly transform coordinates when rendering into cached textures.
	 * @returns {Matrix} The inverse of the parent texture transform matrix.
	 */
	get inverseParentTextureTransform(): Matrix;
	/**
	 * Returns a matrix that transforms coordinates to the correct coordinate space of the texture being rendered to.
	 * This is the texture offset inverse transform of the closest parent RenderGroup that is cached as a texture.
	 * @returns {Matrix | null} The transform matrix for the cached texture coordinate space,
	 * or null if no parent is cached as texture.
	 */
	get cacheToLocalTransform(): Matrix;
}
export declare class RenderGroupPipe implements InstructionPipe<RenderGroup> {
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "renderGroup";
	};
	private _renderer;
	constructor(renderer: Renderer);
	addRenderGroup(renderGroup: RenderGroup, instructionSet: InstructionSet): void;
	execute(renderGroup: RenderGroup): void;
	destroy(): void;
	private _addRenderableDirect;
	private _addRenderableCacheAsTexture;
	private _executeCacheAsTexture;
	private _executeDirect;
}
/**
 * The view system manages the main canvas that is attached to the DOM.
 * This main role is to deal with how the holding the view reference and dealing with how it is resized.
 * @memberof rendering
 */
export declare class RenderGroupSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "renderGroup";
	};
	private readonly _renderer;
	constructor(renderer: Renderer);
	protected render({ container, transform }: {
		container: Container;
		transform: Matrix;
	}): void;
	destroy(): void;
	private _updateCachedRenderGroups;
	private _updateRenderGroups;
	private _updateRenderables;
	/**
	 * @param renderGroup
	 * @param renderPipes
	 * @deprecated since 8.3.0
	 */
	private _buildInstructions;
}
/**
 * Defines a size with a width and a height.
 * @memberof maths
 */
export interface Size {
	/** The width. */
	width: number;
	/** The height. */
	height: number;
}
export type Optional<T, K extends keyof T> = Omit<T, K> & Partial<Pick<T, K>>;
export interface MeasureMixinConstructor {
	width?: number;
	height?: number;
}
export interface MeasureMixin extends Required<MeasureMixinConstructor> {
	getSize(out?: Size): Size;
	setSize(width: number, height?: number): void;
	setSize(value: Optional<Size, "height">): void;
	getLocalBounds(bounds?: Bounds): Bounds;
	getBounds(skipUpdate?: boolean, bounds?: Bounds): Bounds;
	_localBoundsCacheData: LocalBoundsCacheData;
	_localBoundsCacheId: number;
	_setWidth(width: number, localWidth: number): void;
	_setHeight(height: number, localHeight: number): void;
}
interface LocalBoundsCacheData {
	data: number[];
	index: number;
	didChange: boolean;
	localBounds: Bounds;
}
export declare const measureMixin: Partial<Container>;
/**
 * Options for the {@link scene.Sprite} constructor.
 * @memberof scene
 */
export interface SpriteOptions extends PixiMixins.SpriteOptions, ViewContainerOptions {
	/** The texture to use for the sprite. */
	texture?: Texture;
	/** The anchor point of the sprite. */
	anchor?: PointData | number;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
}
export interface Sprite extends PixiMixins.Sprite, ViewContainer {
}
/**
 * The Sprite object is one of the most important objects in PixiJS. It is a
 * drawing item that can be added to a scene and rendered to the screen.
 *
 * A sprite can be created directly from an image like this:
 *
 * \`\`\`js
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('assets/image.png');
 * \`\`\`
 *
 * The more efficient way to create sprites is using a {@link assets.Spritesheet},
 * as swapping base textures when rendering to the screen is inefficient.
 *
 * \`\`\`js
 * import { Assets, Sprite } from 'pixi.js';
 *
 * const sheet = await Assets.load('assets/spritesheet.json');
 * const sprite = new Sprite(sheet.textures['image.png']);
 * \`\`\`
 * @memberof scene
 * @extends scene.Container
 */
export declare class Sprite extends ViewContainer {
	/**
	 * Helper function that creates a new sprite based on the source you provide.
	 * The source can be - frame id, image, video, canvas element, video element, texture
	 * @param source - Source to create texture from
	 * @param [skipCache] - Whether to skip the cache or not
	 * @returns The newly created sprite
	 */
	static from(source: Texture | TextureSourceLike, skipCache?: boolean): Sprite;
	readonly renderPipeId: string;
	batched: boolean;
	readonly _anchor: ObservablePoint;
	_texture: Texture;
	private readonly _visualBounds;
	private _width;
	private _height;
	/**
	 * @param options - The options for creating the sprite.
	 */
	constructor(options?: SpriteOptions | Texture);
	set texture(value: Texture);
	/** The texture that the sprite is using. */
	get texture(): Texture;
	/**
	 * The bounds of the sprite, taking the texture's trim into account.
	 * @type {rendering.Bounds}
	 */
	get visualBounds(): BoundsData;
	/**
	 * @deprecated
	 */
	get sourceBounds(): BoundsData;
	/** @private */
	protected updateBounds(): void;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
	/**
	 * The anchor sets the origin point of the sprite. The default value is taken from the {@link Texture}
	 * and passed to the constructor.
	 *
	 * The default is \`(0,0)\`, this means the sprite's origin is the top left.
	 *
	 * Setting the anchor to \`(0.5,0.5)\` means the sprite's origin is centered.
	 *
	 * Setting the anchor to \`(1,1)\` would mean the sprite's origin point will be the bottom right corner.
	 *
	 * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
	 * @example
	 * import { Sprite } from 'pixi.js';
	 *
	 * const sprite = new Sprite({texture: Texture.WHITE});
	 * sprite.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
	 */
	get anchor(): ObservablePoint;
	set anchor(value: PointData | number);
	/** The width of the sprite, setting this will actually modify the scale to achieve the value set. */
	get width(): number;
	set width(value: number);
	/** The height of the sprite, setting this will actually modify the scale to achieve the value set. */
	get height(): number;
	set height(value: number);
	/**
	 * Retrieves the size of the Sprite as a [Size]{@link Size} object.
	 * This is faster than get the width and height separately.
	 * @param out - Optional object to store the size in.
	 * @returns - The size of the Sprite.
	 */
	getSize(out?: Size): Size;
	/**
	 * Sets the size of the Sprite to the specified width and height.
	 * This is faster than setting the width and height separately.
	 * @param value - This can be either a number or a [Size]{@link Size} object.
	 * @param height - The height to set. Defaults to the value of \`width\` if not provided.
	 */
	setSize(value: number | Optional<Size, "height">, height?: number): void;
}
export declare class SpritePipe implements RenderPipe<Sprite> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "sprite";
	};
	private _renderer;
	private _gpuSpriteHash;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	addRenderable(sprite: Sprite, instructionSet: InstructionSet): void;
	updateRenderable(sprite: Sprite): void;
	validateRenderable(sprite: Sprite): boolean;
	destroyRenderable(sprite: Sprite): void;
	private _updateBatchableSprite;
	private _getGpuSprite;
	private _initGPUSprite;
	destroy(): void;
}
/** The GPU object. */
interface GPU$1 {
	/** The GPU adapter */
	adapter: GPUAdapter;
	/** The GPU device */
	device: GPUDevice;
}
/**
 * Options for the WebGPU context.
 * @property {GpuPowerPreference} [powerPreference=default] - An optional hint indicating what configuration of GPU
 * is suitable for the WebGPU context, can be \`'high-performance'\` or \`'low-power'\`.
 * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
 * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
 * @property {boolean} [forceFallbackAdapter=false] - Force the use of the fallback adapter
 * @memberof rendering
 */
export interface GpuContextOptions {
	/**
	 * An optional hint indicating what configuration of GPU is suitable for the WebGPU context,
	 * can be \`'high-performance'\` or \`'low-power'\`.
	 * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
	 * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
	 * @default undefined
	 * @memberof rendering.WebGPUOptions
	 */
	powerPreference?: GpuPowerPreference;
	/**
	 * Force the use of the fallback adapter
	 * @default false
	 * @memberof rendering.WebGPUOptions
	 */
	forceFallbackAdapter: boolean;
}
/**
 * System plugin to the renderer to manage the context.
 * @class
 * @memberof rendering
 */
export declare class GpuDeviceSystem implements System<GpuContextOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "device";
	};
	/** The default options for the GpuDeviceSystem. */
	static defaultOptions: GpuContextOptions;
	/** The GPU device */
	gpu: GPU$1;
	private _renderer;
	private _initPromise;
	/**
	 * @param {WebGPURenderer} renderer - The renderer this System works for.
	 */
	constructor(renderer: WebGPURenderer);
	init(options: GpuContextOptions): Promise<void>;
	/**
	 * Handle the context change event
	 * @param gpu
	 */
	protected contextChange(gpu: GPU$1): void;
	/**
	 * Helper class to create a WebGL Context
	 * @param {object} options - An options object that gets passed in to the canvas element containing the
	 *    context attributes
	 * @see https://developer.mozilla.org/en/docs/Web/API/HTMLCanvasElement/getContext
	 * @returns {WebGLRenderingContext} the WebGL context
	 */
	private _createDeviceAndAdaptor;
	destroy(): void;
}
/**
 * This manages the WebGPU bind groups. this is how data is bound to a shader when rendering
 * @memberof rendering
 */
export declare class BindGroupSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "bindGroup";
	};
	private readonly _renderer;
	private _hash;
	private _gpu;
	constructor(renderer: WebGPURenderer);
	protected contextChange(gpu: GPU$1): void;
	getBindGroup(bindGroup: BindGroup, program: GpuProgram, groupIndex: number): GPUBindGroup;
	private _createBindGroup;
	destroy(): void;
}
/**
 * System plugin to the renderer to manage buffers.
 * @memberof rendering
 */
export declare class GpuBufferSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "buffer";
	};
	protected CONTEXT_UID: number;
	private _gpuBuffers;
	private readonly _managedBuffers;
	private _gpu;
	constructor(renderer: WebGPURenderer);
	protected contextChange(gpu: GPU$1): void;
	getGPUBuffer(buffer: Buffer$1): GPUBuffer;
	updateBuffer(buffer: Buffer$1): GPUBuffer;
	/** dispose all WebGL resources of all managed buffers */
	destroyAll(): void;
	createGPUBuffer(buffer: Buffer$1): GPUBuffer;
	protected onBufferChange(buffer: Buffer$1): void;
	/**
	 * Disposes buffer
	 * @param buffer - buffer with data
	 */
	protected onBufferDestroy(buffer: Buffer$1): void;
	destroy(): void;
	private _destroyBuffer;
}
/**
 * The system that handles color masking for the GPU.
 * @memberof rendering
 */
export declare class GpuColorMaskSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "colorMask";
	};
	private readonly _renderer;
	private _colorMaskCache;
	constructor(renderer: WebGPURenderer);
	setMask(colorMask: number): void;
	destroy(): void;
}
/**
 * This is a WebGL state, and is is passed to {@link StateSystem}.
 *
 * Each mesh rendered may require WebGL to be in a different state.
 * For example you may want different blend mode or to enable polygon offsets
 * @memberof rendering
 */
export declare class State {
	/**
	 * The data is a unique number based on the states settings.
	 * This lets us quickly compare states with a single number rather than looking
	 * at all the individual settings.
	 */
	data: number;
	_blendModeId: number;
	private _blendMode;
	private _polygonOffset;
	constructor();
	/**
	 * Activates blending of the computed fragment color values.
	 * @default true
	 */
	get blend(): boolean;
	set blend(value: boolean);
	/**
	 * Activates adding an offset to depth values of polygon's fragments
	 * @default false
	 */
	get offsets(): boolean;
	set offsets(value: boolean);
	/** The culling settings for this state none - No culling back - Back face culling front - Front face culling */
	set cullMode(value: CULL_MODES);
	get cullMode(): CULL_MODES;
	/**
	 * Activates culling of polygons.
	 * @default false
	 */
	get culling(): boolean;
	set culling(value: boolean);
	/**
	 * Activates depth comparisons and updates to the depth buffer.
	 * @default false
	 */
	get depthTest(): boolean;
	set depthTest(value: boolean);
	/**
	 * Enables or disables writing to the depth buffer.
	 * @default true
	 */
	get depthMask(): boolean;
	set depthMask(value: boolean);
	/**
	 * Specifies whether or not front or back-facing polygons can be culled.
	 * @default false
	 */
	get clockwiseFrontFace(): boolean;
	set clockwiseFrontFace(value: boolean);
	/**
	 * The blend mode to be applied when this state is set. Apply a value of \`normal\` to reset the blend mode.
	 * Setting this mode to anything other than NO_BLEND will automatically switch blending on.
	 * @default 'normal'
	 */
	get blendMode(): BLEND_MODES;
	set blendMode(value: BLEND_MODES);
	/**
	 * The polygon offset. Setting this property to anything other than 0 will automatically enable polygon offset fill.
	 * @default 0
	 */
	get polygonOffset(): number;
	set polygonOffset(value: number);
	toString(): string;
	/**
	 * A quickly getting an instance of a State that is configured for 2d rendering.
	 * @returns a new State with values set for 2d rendering
	 */
	static for2d(): State;
	static default2d: State;
}
/**
 * The system that handles encoding commands for the GPU.
 * @memberof rendering
 */
export declare class GpuEncoderSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "encoder";
		readonly priority: 1;
	};
	commandEncoder: GPUCommandEncoder;
	renderPassEncoder: GPURenderPassEncoder;
	commandFinished: Promise<void>;
	private _resolveCommandFinished;
	private _gpu;
	private _boundBindGroup;
	private _boundVertexBuffer;
	private _boundIndexBuffer;
	private _boundPipeline;
	private readonly _renderer;
	constructor(renderer: WebGPURenderer);
	renderStart(): void;
	beginRenderPass(gpuRenderTarget: GpuRenderTarget): void;
	endRenderPass(): void;
	setViewport(viewport: Rectangle): void;
	setPipelineFromGeometryProgramAndState(geometry: Geometry, program: GpuProgram, state: any, topology?: Topology): void;
	setPipeline(pipeline: GPURenderPipeline): void;
	private _setVertexBuffer;
	private _setIndexBuffer;
	resetBindGroup(index: number): void;
	setBindGroup(index: number, bindGroup: BindGroup, program: GpuProgram): void;
	setGeometry(geometry: Geometry, program: GpuProgram): void;
	private _setShaderBindGroups;
	private _syncBindGroup;
	draw(options: {
		geometry: Geometry;
		shader: Shader;
		state?: State;
		topology?: Topology;
		size?: number;
		start?: number;
		instanceCount?: number;
		skipSync?: boolean;
	}): void;
	finishRenderPass(): void;
	postrender(): void;
	restoreRenderPass(): void;
	private _clearCache;
	destroy(): void;
	protected contextChange(gpu: GPU$1): void;
}
/**
 * This manages the stencil buffer. Used primarily for masking
 * @memberof rendering
 */
export declare class GpuStencilSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "stencil";
	};
	private readonly _renderer;
	private _renderTargetStencilState;
	private _activeRenderTarget;
	constructor(renderer: WebGPURenderer);
	protected onRenderTargetChange(renderTarget: RenderTarget): void;
	setStencilMode(stencilMode: STENCIL_MODES, stencilReference: number): void;
	destroy(): void;
}
export declare const UNIFORM_TYPES_VALUES: readonly [
	"f32",
	"i32",
	"vec2<f32>",
	"vec3<f32>",
	"vec4<f32>",
	"mat2x2<f32>",
	"mat3x3<f32>",
	"mat4x4<f32>",
	"mat3x2<f32>",
	"mat4x2<f32>",
	"mat2x3<f32>",
	"mat4x3<f32>",
	"mat2x4<f32>",
	"mat3x4<f32>",
	"vec2<i32>",
	"vec3<i32>",
	"vec4<i32>"
];
/** useful for checking if a type is supported - a map of supported types with a true value. */
export declare const UNIFORM_TYPES_MAP: Record<UNIFORM_TYPES, boolean>;
export type UNIFORM_TYPES_SINGLE = typeof UNIFORM_TYPES_VALUES[number];
type OPTIONAL_SPACE = " " | "";
export type UNIFORM_TYPES_ARRAY = \`array<\${UNIFORM_TYPES_SINGLE},\${OPTIONAL_SPACE}\${number}>\`;
export type UNIFORM_TYPES = UNIFORM_TYPES_SINGLE | UNIFORM_TYPES_ARRAY;
export interface UniformData {
	/** the value of the uniform, this could be any object - a parser will figure out how to write it to the buffer */
	value: unknown;
	type: UNIFORM_TYPES;
	/** the size of the variable (eg 2 for vec2, 3 for vec3, 4 for vec4) */
	size?: number;
	name?: string;
}
export interface UboElement {
	data: UniformData;
	offset: number;
	size: number;
}
export interface UboLayout {
	uboElements: UboElement[];
	/** float32 size // TODO change to bytes */
	size: number;
}
export type UniformsSyncCallback = (...args: any[]) => void;
type FLOPS<T = UniformData> = T extends {
	value: infer V;
} ? V : never;
type ExtractUniformObject<T = Record<string, UniformData>> = {
	[K in keyof T]: FLOPS<T[K]>;
};
/**
 * Uniform group options
 * @memberof rendering
 */
export type UniformGroupOptions = {
	/**
	 * if true the UniformGroup is handled as an Uniform buffer object.
	 * This is the only way WebGPU can work with uniforms. WebGL2 can also use this.
	 * So don't set to true if you want to use WebGPU :D
	 */
	ubo?: boolean;
	/** if true, then you are responsible for when the data is uploaded to the GPU by calling \`update()\` */
	isStatic?: boolean;
};
/**
 * Uniform group holds uniform map and some ID's for work
 *
 * \`UniformGroup\` has two modes:
 *
 * 1: Normal mode
 * Normal mode will upload the uniforms with individual function calls as required. This is the default mode
 * for WebGL rendering.
 *
 * 2: Uniform buffer mode
 * This mode will treat the uniforms as a uniform buffer. You can pass in either a buffer that you manually handle, or
 * or a generic object that PixiJS will automatically map to a buffer for you.
 * For maximum benefits, make Ubo UniformGroups static, and only update them each frame.
 * This is the only way uniforms can be used with WebGPU.
 *
 * Rules of UBOs:
 * - UBOs only work with WebGL2, so make sure you have a fallback!
 * - Only floats are supported (including vec[2,3,4], mat[2,3,4])
 * - Samplers cannot be used in ubo's (a GPU limitation)
 * - You must ensure that the object you pass in exactly matches in the shader ubo structure.
 * Otherwise, weirdness will ensue!
 * - The name of the ubo object added to the group must match exactly the name of the ubo in the shader.
 *
 * When declaring your uniform options, you ust parse in the value and the type of the uniform.
 * The types correspond to the WebGPU types {@link UNIFORM_TYPES}
 *
 Uniforms can be modified via the classes 'uniforms' property. It will contain all the uniforms declared in the constructor.
 *
 * \`\`\`glsl
 * // UBO in shader:
 * uniform myCoolData { // Declaring a UBO...
 *     mat4 uCoolMatrix;
 *     float uFloatyMcFloatFace;
 * };
 * \`\`\`
 *
 * \`\`\`js
 * // A new Uniform Buffer Object...
 * const myCoolData = new UniformGroup({
 *     uCoolMatrix: {value:new Matrix(), type: 'mat4<f32>'},
 *     uFloatyMcFloatFace: {value:23, type: 'f32'},
 * }}
 *
 * // modify the data
 * myCoolData.uniforms.uFloatyMcFloatFace = 42;
 * // Build a shader...
 * const shader = Shader.from(srcVert, srcFrag, {
 *     myCoolData // Name matches the UBO name in the shader. Will be processed accordingly.
 * })
 *
 *
 *  \`\`\`
 * @memberof rendering
 */
export declare class UniformGroup<UNIFORMS extends {
	[key: string]: UniformData;
} = any> implements BindResource {
	/** The default options used by the uniform group. */
	static defaultOptions: UniformGroupOptions;
	/** used internally to know if a uniform group was used in the last render pass */
	_touched: number;
	/** a unique id for this uniform group used through the renderer */
	readonly uid: number;
	/** a resource type, used to identify how to handle it when its in a bind group / shader resource */
	_resourceType: string;
	/** the resource id used internally by the renderer to build bind group keys */
	_resourceId: number;
	/** the structures of the uniform group */
	uniformStructures: UNIFORMS;
	/** the uniforms as an easily accessible map of properties */
	uniforms: ExtractUniformObject<UNIFORMS>;
	/** true if it should be used as a uniform buffer object */
	ubo: boolean;
	/** an underlying buffer that will be uploaded to the GPU when using this UniformGroup */
	buffer?: Buffer$1;
	/**
	 * if true, then you are responsible for when the data is uploaded to the GPU.
	 * otherwise, the data is reuploaded each frame.
	 */
	isStatic: boolean;
	/** used ito identify if this is a uniform group */
	readonly isUniformGroup = true;
	/**
	 * used to flag if this Uniform groups data is different from what it has stored in its buffer / on the GPU
	 * @internal
	 * @ignore
	 */
	_dirtyId: number;
	/**
	 * a signature string generated for internal use
	 * @internal
	 * @ignore
	 */
	readonly _signature: number;
	readonly destroyed = false;
	/**
	 * Create a new Uniform group
	 * @param uniformStructures - The structures of the uniform group
	 * @param options - The optional parameters of this uniform group
	 */
	constructor(uniformStructures: UNIFORMS, options?: UniformGroupOptions);
	/** Call this if you want the uniform groups data to be uploaded to the GPU only useful if \`isStatic\` is true. */
	update(): void;
}
export interface UboAdaptor {
	createUboElements: (uniformData: UniformData[]) => UboLayout;
	generateUboSync: (uboElements: UboElement[]) => UniformsSyncCallback;
}
/**
 * System plugin to the renderer to manage uniform buffers.
 * @memberof rendering
 */
export declare class UboSystem implements System {
	/** Cache of uniform buffer layouts and sync functions, so we don't have to re-create them */
	private _syncFunctionHash;
	private readonly _adaptor;
	constructor(adaptor: UboAdaptor);
	/**
	 * Overridable function by \`pixi.js/unsafe-eval\` to silence
	 * throwing an error if platform doesn't support unsafe-evals.
	 * @private
	 */
	private _systemCheck;
	ensureUniformGroup(uniformGroup: UniformGroup): void;
	getUniformGroupData(uniformGroup: UniformGroup): {
		layout: UboLayout;
		syncFunction: (uniforms: Record<string, any>, data: Float32Array, dataInt32: Int32Array, offset: number) => void;
	};
	private _initUniformGroup;
	private _generateUboSync;
	syncUniformGroup(uniformGroup: UniformGroup, data?: Float32Array, offset?: number): boolean;
	updateUniformGroup(uniformGroup: UniformGroup): boolean;
	destroy(): void;
}
/**
 * System plugin to the renderer to manage uniform buffers. With a WGSL twist!
 * @memberof rendering
 */
export declare class GpuUboSystem extends UboSystem {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "ubo";
	};
	constructor();
}
/**
 * A resource that can be bound to a bind group and used in a shader.
 * Whilst a buffer can be used as a resource, this class allows you to specify an offset and size of the buffer to use.
 * This is useful if you have a large buffer and only part of it is used in a shader.
 *
 * This resource, will listen for changes on the underlying buffer and emit a itself if the buffer changes shape.
 * @example
 *
 * const buffer = new Buffer({
 *     data: new Float32Array(1000),
 *    usage: BufferUsage.UNIFORM,
 * });
 * // Create a buffer resource that uses the first 100 bytes of a buffer
 * const bufferResource = new BufferResource({
 *    buffer,
 *    offset: 0,
 *    size: 100,
 * });
 * @memberof rendering
 */
export declare class BufferResource extends EventEmitter<{
	change: BindResource;
}> implements BindResource {
	/**
	 * emits when the underlying buffer has changed shape (i.e. resized)
	 * letting the renderer know that it needs to discard the old buffer on the GPU and create a new one
	 * @event change
	 */
	/** a unique id for this uniform group used through the renderer */
	readonly uid: number;
	/**
	 * a resource type, used to identify how to handle it when its in a bind group / shader resource
	 * @internal
	 * @ignore
	 */
	readonly _resourceType = "bufferResource";
	/**
	 * used internally to know if a uniform group was used in the last render pass
	 * @internal
	 * @ignore
	 */
	_touched: number;
	/**
	 * the resource id used internally by the renderer to build bind group keys
	 * @internal
	 * @ignore
	 */
	_resourceId: number;
	/** the underlying buffer that this resource is using */
	buffer: Buffer$1;
	/** the offset of the buffer this resource is using. If not provided, then it will use the offset of the buffer. */
	readonly offset: number;
	/** the size of the buffer this resource is using. If not provided, then it will use the size of the buffer. */
	readonly size: number;
	/**
	 * A cheeky hint to the GL renderer to let it know this is a BufferResource
	 * @internal
	 * @ignore
	 */
	readonly _bufferResource = true;
	/**
	 * Has the Buffer resource been destroyed?
	 * @readonly
	 */
	destroyed: boolean;
	/**
	 * Create a new Buffer Resource.
	 * @param options - The options for the buffer resource
	 * @param options.buffer - The underlying buffer that this resource is using
	 * @param options.offset - The offset of the buffer this resource is using.
	 * If not provided, then it will use the offset of the buffer.
	 * @param options.size - The size of the buffer this resource is using.
	 * If not provided, then it will use the size of the buffer.
	 */
	constructor({ buffer, offset, size }: {
		buffer: Buffer$1;
		offset?: number;
		size?: number;
	});
	protected onBufferChange(): void;
	/**
	 * Destroys this resource. Make sure the underlying buffer is not used anywhere else
	 * if you want to destroy it as well, or code will explode
	 * @param destroyBuffer - Should the underlying buffer be destroyed as well?
	 */
	destroy(destroyBuffer?: boolean): void;
}
export declare class GpuUniformBatchPipe {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUPipes
		];
		readonly name: "uniformBatch";
	};
	private _renderer;
	private _bindGroupHash;
	private readonly _batchBuffer;
	private _buffers;
	private _bindGroups;
	private _bufferResources;
	constructor(renderer: WebGPURenderer);
	renderEnd(): void;
	private _resetBindGroups;
	getUniformBindGroup(group: UniformGroup<any>, duplicate: boolean): BindGroup;
	getUboResource(group: UniformGroup<any>): BufferResource;
	getArrayBindGroup(data: Float32Array): BindGroup;
	getArrayBufferResource(data: Float32Array): BufferResource;
	private _getBufferResource;
	private _getBindGroup;
	private _uploadBindGroups;
	destroy(): void;
}
/**
 * A system that creates and manages the GPU pipelines.
 *
 * Caching Mechanism: At its core, the system employs a two-tiered caching strategy to minimize
 * the redundant creation of GPU pipelines (or "pipes"). This strategy is based on generating unique
 * keys that represent the state of the graphics settings and the specific requirements of the
 * item being rendered. By caching these pipelines, subsequent draw calls with identical configurations
 * can reuse existing pipelines instead of generating new ones.
 *
 * State Management: The system differentiates between "global" state properties (like color masks
 * and stencil masks, which do not change frequently) and properties that may vary between draw calls
 * (such as geometry, shaders, and blend modes). Unique keys are generated for both these categories
 * using getStateKey for global state and getGraphicsStateKey for draw-specific settings. These keys are
 * then then used to caching the pipe. The next time we need a pipe we can check
 * the cache by first looking at the state cache and then the pipe cache.
 * @memberof rendering
 */
export declare class PipelineSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "pipeline";
	};
	private readonly _renderer;
	protected CONTEXT_UID: number;
	private _moduleCache;
	private _bufferLayoutsCache;
	private readonly _bindingNamesCache;
	private _pipeCache;
	private readonly _pipeStateCaches;
	private _gpu;
	private _stencilState;
	private _stencilMode;
	private _colorMask;
	private _multisampleCount;
	private _depthStencilAttachment;
	constructor(renderer: WebGPURenderer);
	protected contextChange(gpu: GPU$1): void;
	setMultisampleCount(multisampleCount: number): void;
	setRenderTarget(renderTarget: GpuRenderTarget): void;
	setColorMask(colorMask: number): void;
	setStencilMode(stencilMode: STENCIL_MODES): void;
	setPipeline(geometry: Geometry, program: GpuProgram, state: State, passEncoder: GPURenderPassEncoder): void;
	getPipeline(geometry: Geometry, program: GpuProgram, state: State, topology?: Topology): GPURenderPipeline;
	private _createPipeline;
	private _getModule;
	private _createModule;
	private _generateBufferKey;
	private _generateAttributeLocationsKey;
	/**
	 * Returns a hash of buffer names mapped to bind locations.
	 * This is used to bind the correct buffer to the correct location in the shader.
	 * @param geometry - The geometry where to get the buffer names
	 * @param program - The program where to get the buffer names
	 * @returns An object of buffer names mapped to the bind location.
	 */
	getBufferNamesToBind(geometry: Geometry, program: GpuProgram): Record<string, string>;
	private _createVertexBufferLayouts;
	private _updatePipeHash;
	destroy(): void;
}
/**
 * The WebGPU adaptor for the render target system. Allows the Render Target System to
 * be used with the WebGPU renderer
 * @memberof rendering
 * @ignore
 */
export declare class GpuRenderTargetAdaptor implements RenderTargetAdaptor<GpuRenderTarget> {
	private _renderTargetSystem;
	private _renderer;
	init(renderer: WebGPURenderer, renderTargetSystem: RenderTargetSystem<GpuRenderTarget>): void;
	copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
		x: number;
		y: number;
	}, size: {
		width: number;
		height: number;
	}, originDest: {
		x: number;
		y: number;
	}): Texture<TextureSource<any>>;
	startRenderPass(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
	finishRenderPass(): void;
	/**
	 * returns the gpu texture for the first color texture in the render target
	 * mainly used by the filter manager to get copy the texture for blending
	 * @param renderTarget
	 * @returns a gpu texture
	 */
	private _getGpuColorTexture;
	getDescriptor(renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, clearValue: RgbaArray): GPURenderPassDescriptor;
	clear(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
	initGpuRenderTarget(renderTarget: RenderTarget): GpuRenderTarget;
	destroyGpuRenderTarget(gpuRenderTarget: GpuRenderTarget): void;
	ensureDepthStencilTexture(renderTarget: RenderTarget): void;
	resizeGpuRenderTarget(renderTarget: RenderTarget): void;
}
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGl renderer
 * @memberof rendering
 */
export declare class GpuRenderTargetSystem extends RenderTargetSystem<GpuRenderTarget> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "renderTarget";
	};
	adaptor: GpuRenderTargetAdaptor;
	constructor(renderer: WebGPURenderer);
}
/**
 * System plugin to the renderer to manage the shaders.
 * @memberof rendering
 */
export interface ShaderSystem extends System {
	/** the maximum number of textures that can be bound to a shader */
	readonly maxTextures: number;
}
export interface GPUProgramData {
	bindGroups: GPUBindGroupLayout[];
	pipeline: GPUPipelineLayout;
}
/**
 * A system that manages the rendering of GpuPrograms.
 * @memberof rendering
 */
export declare class GpuShaderSystem implements ShaderSystem {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "shader";
	};
	maxTextures: number;
	private _gpu;
	private readonly _gpuProgramData;
	protected contextChange(gpu: GPU$1): void;
	getProgramData(program: GpuProgram): GPUProgramData;
	private _createGPUProgramData;
	destroy(): void;
}
/**
 * System plugin to the renderer to manage WebGL state machines.
 * @memberof rendering
 */
export declare class GpuStateSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "state";
	};
	/**
	 * State ID
	 * @readonly
	 */
	stateId: number;
	/**
	 * Polygon offset
	 * @readonly
	 */
	polygonOffset: number;
	/**
	 * Blend mode
	 * @default 'none'
	 * @readonly
	 */
	blendMode: BLEND_MODES;
	/** Whether current blend equation is different */
	protected _blendEq: boolean;
	/**
	 * GL context
	 * @member {WebGLRenderingContext}
	 * @readonly
	 */
	protected gpu: GPU$1;
	/**
	 * Default WebGL State
	 * @readonly
	 */
	protected defaultState: State;
	constructor();
	protected contextChange(gpu: GPU$1): void;
	/**
	 * Gets the blend mode data for the current state
	 * @param state - The state to get the blend mode from
	 */
	getColorTargets(state: State): GPUColorTargetState[];
	destroy(): void;
}
export type GetPixelsOutput = {
	pixels: Uint8ClampedArray;
	width: number;
	height: number;
};
export interface CanvasGenerator {
	generateCanvas(texture: Texture): ICanvas;
	getPixels(texture: Texture): GetPixelsOutput;
}
/**
 * The system that handles textures for the GPU.
 * @memberof rendering
 */
export declare class GpuTextureSystem implements System, CanvasGenerator {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUSystem
		];
		readonly name: "texture";
	};
	readonly managedTextures: TextureSource[];
	protected CONTEXT_UID: number;
	private _gpuSources;
	private _gpuSamplers;
	private _bindGroupHash;
	private _textureViewHash;
	private readonly _uploads;
	private _gpu;
	private _mipmapGenerator?;
	private readonly _renderer;
	constructor(renderer: WebGPURenderer);
	protected contextChange(gpu: GPU$1): void;
	initSource(source: TextureSource): GPUTexture;
	protected onSourceUpdate(source: TextureSource): void;
	protected onSourceUnload(source: TextureSource): void;
	protected onUpdateMipmaps(source: TextureSource): void;
	protected onSourceDestroy(source: TextureSource): void;
	protected onSourceResize(source: TextureSource): void;
	private _initSampler;
	getGpuSampler(sampler: TextureStyle): GPUSampler;
	getGpuSource(source: TextureSource): GPUTexture;
	/**
	 * this returns s bind group for a specific texture, the bind group contains
	 * - the texture source
	 * - the texture style
	 * - the texture matrix
	 * This is cached so the bind group should only be created once per texture
	 * @param texture - the texture you want the bindgroup for
	 * @returns the bind group for the texture
	 */
	getTextureBindGroup(texture: Texture): BindGroup;
	private _createTextureBindGroup;
	getTextureView(texture: BindableTexture): GPUTextureView;
	private _createTextureView;
	generateCanvas(texture: Texture): ICanvas;
	getPixels(texture: Texture): GetPixelsOutput;
	destroy(): void;
}
interface System$1 {
	extension: {
		name: string;
	};
	defaultOptions?: any;
	new (...args: any): any;
}
type SystemsWithExtensionList = System$1[];
type InstanceType$1<T extends new (...args: any) => any> = T extends new (...args: any) => infer R ? R : any;
type NameType<T extends SystemsWithExtensionList> = T[number]["extension"]["name"];
export type ExtractSystemTypes<T extends SystemsWithExtensionList> = {
	[K in NameType<T>]: InstanceType$1<Extract<T[number], {
		extension: {
			name: K;
		};
	}>>;
};
type NotUnknown<T> = T extends unknown ? keyof T extends never ? never : T : T;
type KnownProperties<T> = {
	[K in keyof T as NotUnknown<T[K]> extends never ? never : K]: T[K];
};
type FlattenOptions<T> = T extends {
	[K: string]: infer U;
} ? U : never;
type OptionsUnion<T extends SystemsWithExtensionList> = FlattenOptions<SeparateOptions<T>>;
type DefaultOptionsTypes<T extends SystemsWithExtensionList> = {
	[K in NameType<T>]: Extract<T[number], {
		extension: {
			name: K;
		};
	}>["defaultOptions"];
};
type SeparateOptions<T extends SystemsWithExtensionList> = KnownProperties<DefaultOptionsTypes<T>>;
type UnionToIntersection<U> = (U extends any ? (k: U) => void : never) extends ((k: infer I) => void) ? I : never;
export type ExtractRendererOptions<T extends SystemsWithExtensionList> = UnionToIntersection<OptionsUnion<T>>;
export interface BatcherAdaptor {
	start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
	init?(batchPipe: BatcherPipe): void;
	execute(batchPipe: BatcherPipe, batch: Batch): void;
	contextChange?(): void;
}
/**
 * A pipe that batches elements into batches and sends them to the renderer.
 *
 * You can install new Batchers using ExtensionType.Batcher. Each render group will
 * have a default batcher and any required ones will be created on demand.
 * @memberof rendering
 */
export declare class BatcherPipe implements InstructionPipe<Batch>, BatchPipe {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "batch";
	};
	state: State;
	renderer: Renderer;
	private readonly _batchersByInstructionSet;
	private _adaptor;
	/** A record of all active batchers, keyed by their names */
	private _activeBatches;
	/** The currently active batcher being used to batch elements */
	private _activeBatch;
	static _availableBatchers: Record<string, new () => Batcher>;
	static getBatcher(name: string): Batcher;
	constructor(renderer: Renderer, adaptor: BatcherAdaptor);
	buildStart(instructionSet: InstructionSet): void;
	addToBatch(batchableObject: BatchableElement, instructionSet: InstructionSet): void;
	break(instructionSet: InstructionSet): void;
	buildEnd(instructionSet: InstructionSet): void;
	upload(instructionSet: InstructionSet): void;
	execute(batch: Batch): void;
	destroy(): void;
}
/**
 * A BatcherAdaptor that uses WebGL to render batches.
 * @memberof rendering
 * @ignore
 */
export declare class GlBatchAdaptor implements BatcherAdaptor {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipesAdaptor
		];
		readonly name: "batch";
	};
	private readonly _tempState;
	/**
	 * We only want to sync the a batched shaders uniforms once on first use
	 * this is a hash of shader uids to a boolean value.  When the shader is first bound
	 * we set the value to true.  When the shader is bound again we check the value and
	 * if it is true we know that the uniforms have already been synced and we skip it.
	 */
	private _didUploadHash;
	init(batcherPipe: BatcherPipe): void;
	contextChange(): void;
	start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
	execute(batchPipe: BatcherPipe, batch: Batch): void;
}
export type GlRenderingContext = WebGL2RenderingContext;
export declare function checkMaxIfStatementsInShader(maxIfs: number, gl: GlRenderingContext): number;
/**
 * Returns the maximum number of textures that can be batched. This uses WebGL1's \`MAX_TEXTURE_IMAGE_UNITS\`.
 * The response for this is that to get this info via WebGPU, we would need to make a context, which
 * would make this function async, and we want to avoid that.
 * @private
 * @returns {number} The maximum number of textures that can be batched
 */
export declare function getMaxTexturesPerBatch(): number;
export declare function generateGPULayout(maxTextures: number): GPUBindGroupLayoutEntry[];
export declare function generateLayout(maxTextures: number): Record<string, number>;
export declare function getTextureBatchBindGroup(textures: TextureSource[], size: number): BindGroup;
/**
 * A BatcherAdaptor that uses the GPU to render batches.
 * @memberof rendering
 * @ignore
 */
export declare class GpuBatchAdaptor implements BatcherAdaptor {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUPipesAdaptor
		];
		readonly name: "batch";
	};
	private _shader;
	private _geometry;
	start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
	execute(batchPipe: BatcherPipe, batch: Batch): void;
}
/**
 * DefaultShader is a specialized shader class designed for batch rendering.
 * It extends the base Shader class and provides functionality for handling
 * color, texture batching, and pixel rounding in both WebGL and WebGPU contexts.
 *
 * It is used by the default batcher
 * @extends Shader
 * @memberof rendering
 */
export declare class DefaultShader extends Shader {
	constructor(maxTextures: number);
}
/** the vertex source code, an obj */
export type Vertex = {
	/** stick uniforms and functions in here all headers will be compiled at the top of the shader */
	header?: string;
	/** code will be added at the start of the shader */
	start?: string;
	/** code will be run here before lighting happens */
	main?: string;
	/** code here will to modify anything before it is passed to the fragment shader */
	end?: string;
};
export type Fragment = {
	/** stick uniforms and functions in here all headers will be compiled at the top of the shader */
	header?: string;
	/** code will be added at the start of the shader */
	start?: string;
	/** code will be run here before lighting happens */
	main?: string;
	/** code here will to modify anything before it is passed to the fragment shader */
	end?: string;
};
/**
 * HighShaderBit is a part of a shader.
 * it is used to compile HighShaders.
 *
 * Internally shaders are made up of many of these.
 * You can even write your own and compile them in.
 */
export interface HighShaderBit {
	/** used to make the shader easier to understand! */
	name?: string;
	/** the snippets of vertex code */
	vertex?: Vertex;
	/** the snippets of fragment code */
	fragment?: Fragment;
}
/** source code to compile a shader. this can be directly used by pixi and should be good to go! */
export interface HighShaderSource {
	fragment: string;
	vertex: string;
}
export declare function compileHighShaderGpuProgram({ bits, name }: {
	bits: HighShaderBit[];
	name: string;
}): GpuProgram;
export declare function compileHighShaderGlProgram({ bits, name }: {
	bits: HighShaderBit[];
	name: string;
}): GlProgram;
/** A high template consists of vertex and fragment source */
export interface HighShaderTemplate {
	name?: string;
	fragment: string;
	vertex: string;
}
export interface CompileHighShaderOptions {
	template: HighShaderTemplate;
	bits: HighShaderBit[];
}
/**
 * This function will take a HighShader template, some High fragments and then merge them in to a shader source.
 * @param options
 * @param options.template
 * @param options.bits
 */
export declare function compileHighShader({ template, bits }: CompileHighShaderOptions): HighShaderSource;
export declare function compileHighShaderGl({ template, bits }: CompileHighShaderOptions): HighShaderSource;
/**
 * takes the HighFragment source parts and adds them to the hook hash
 * @param srcParts - the hash of hook arrays
 * @param parts - the code to inject into the hooks
 * @param name - optional the name of the part to add
 */
export declare function addBits(srcParts: Record<string, string>, parts: Record<string, string[]>, name?: string): void;
export declare const findHooksRx: RegExp;
/**
 * takes a program string and returns an hash mapping the hooks to empty arrays
 * @param programSrc - the program containing hooks
 */
export declare function compileHooks(programSrc: string): Record<string, string[]>;
export declare function compileInputs(fragments: any[], template: string, sort?: boolean): string;
export declare function compileOutputs(fragments: any[], template: string): string;
/**
 * formats a shader so its more pleasant to read!
 * @param shader - a glsl shader program source
 */
export declare function formatShader(shader: string): string;
/**
 * takes a shader src and replaces any hooks with the HighFragment code.
 * @param templateSrc - the program src template
 * @param fragmentParts - the fragments to inject
 */
export declare function injectBits(templateSrc: string, fragmentParts: Record<string, string[]>): string;
export declare const vertexGPUTemplate = "\\n    @in aPosition: vec2<f32>;\\n    @in aUV: vec2<f32>;\\n\\n    @out @builtin(position) vPosition: vec4<f32>;\\n    @out vUV : vec2<f32>;\\n    @out vColor : vec4<f32>;\\n\\n    {{header}}\\n\\n    struct VSOutput {\\n        {{struct}}\\n    };\\n\\n    @vertex\\n    fn main( {{in}} ) -> VSOutput {\\n\\n        var worldTransformMatrix = globalUniforms.uWorldTransformMatrix;\\n        var modelMatrix = mat3x3<f32>(\\n            1.0, 0.0, 0.0,\\n            0.0, 1.0, 0.0,\\n            0.0, 0.0, 1.0\\n          );\\n        var position = aPosition;\\n        var uv = aUV;\\n\\n        {{start}}\\n        \\n        vColor = vec4<f32>(1., 1., 1., 1.);\\n\\n        {{main}}\\n\\n        vUV = uv;\\n\\n        var modelViewProjectionMatrix = globalUniforms.uProjectionMatrix * worldTransformMatrix * modelMatrix;\\n\\n        vPosition =  vec4<f32>((modelViewProjectionMatrix *  vec3<f32>(position, 1.0)).xy, 0.0, 1.0);\\n       \\n        vColor *= globalUniforms.uWorldColorAlpha;\\n\\n        {{end}}\\n\\n        {{return}}\\n    };\\n";
export declare const fragmentGPUTemplate = "\\n    @in vUV : vec2<f32>;\\n    @in vColor : vec4<f32>;\\n   \\n    {{header}}\\n\\n    @fragment\\n    fn main(\\n        {{in}}\\n      ) -> @location(0) vec4<f32> {\\n        \\n        {{start}}\\n\\n        var outColor:vec4<f32>;\\n      \\n        {{main}}\\n        \\n        var finalColor:vec4<f32> = outColor * vColor;\\n\\n        {{end}}\\n\\n        return finalColor;\\n      };\\n";
export declare const vertexGlTemplate = "\\n    in vec2 aPosition;\\n    in vec2 aUV;\\n\\n    out vec4 vColor;\\n    out vec2 vUV;\\n\\n    {{header}}\\n\\n    void main(void){\\n\\n        mat3 worldTransformMatrix = uWorldTransformMatrix;\\n        mat3 modelMatrix = mat3(\\n            1.0, 0.0, 0.0,\\n            0.0, 1.0, 0.0,\\n            0.0, 0.0, 1.0\\n          );\\n        vec2 position = aPosition;\\n        vec2 uv = aUV;\\n        \\n        {{start}}\\n        \\n        vColor = vec4(1.);\\n        \\n        {{main}}\\n        \\n        vUV = uv;\\n        \\n        mat3 modelViewProjectionMatrix = uProjectionMatrix * worldTransformMatrix * modelMatrix;\\n\\n        gl_Position = vec4((modelViewProjectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\\n\\n        vColor *= uWorldColorAlpha;\\n\\n        {{end}}\\n    }\\n";
export declare const fragmentGlTemplate = "\\n   \\n    in vec4 vColor;\\n    in vec2 vUV;\\n\\n    out vec4 finalColor;\\n\\n    {{header}}\\n\\n    void main(void) {\\n        \\n        {{start}}\\n\\n        vec4 outColor;\\n      \\n        {{main}}\\n        \\n        finalColor = outColor * vColor;\\n        \\n        {{end}}\\n    }\\n";
export declare const colorBit: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
};
export declare const colorBitGl: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
};
export declare function generateTextureBatchBit(maxTextures: number): HighShaderBit;
export declare function generateTextureBatchBitGl(maxTextures: number): HighShaderBit;
export declare const globalUniformsBit: {
	name: string;
	vertex: {
		header: string;
	};
};
export declare const globalUniformsUBOBitGl: {
	name: string;
	vertex: {
		header: string;
	};
};
export declare const globalUniformsBitGl: {
	name: string;
	vertex: {
		header: string;
	};
};
export declare const localUniformBit: {
	name: string;
	vertex: {
		header: string;
		main: string;
		end: string;
	};
};
export declare const localUniformBitGroup2: {
	vertex: {
		header: string;
		main: string;
		end: string;
	};
	name: string;
};
export declare const localUniformBitGl: {
	name: string;
	vertex: {
		header: string;
		main: string;
		end: string;
	};
};
export declare const roundPixelsBit: {
	name: string;
	vertex: {
		header: string;
	};
};
export declare const roundPixelsBitGl: {
	name: string;
	vertex: {
		header: string;
	};
};
export declare const textureBit: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
export declare const textureBitGl: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
/**
 * A generic class for managing a pool of items.
 * @template T The type of items in the pool. Must implement {@link utils.PoolItem}.
 * @memberof utils
 */
export declare class Pool<T extends PoolItem> {
	readonly _classType: PoolItemConstructor<T>;
	private readonly _pool;
	private _count;
	private _index;
	/**
	 * Constructs a new Pool.
	 * @param ClassType - The constructor of the items in the pool.
	 * @param {number} [initialSize] - The initial size of the pool.
	 */
	constructor(ClassType: PoolItemConstructor<T>, initialSize?: number);
	/**
	 * Prepopulates the pool with a given number of items.
	 * @param total - The number of items to add to the pool.
	 */
	prepopulate(total: number): void;
	/**
	 * Gets an item from the pool. Calls the item's \`init\` method if it exists.
	 * If there are no items left in the pool, a new one will be created.
	 * @param {unknown} [data] - Optional data to pass to the item's constructor.
	 * @returns {T} The item from the pool.
	 */
	get(data?: unknown): T;
	/**
	 * Returns an item to the pool. Calls the item's \`reset\` method if it exists.
	 * @param {T} item - The item to return to the pool.
	 */
	return(item: T): void;
	/**
	 * Gets the number of items in the pool.
	 * @readonly
	 * @member {number}
	 */
	get totalSize(): number;
	/**
	 * Gets the number of items in the pool that are free to use without needing to create more.
	 * @readonly
	 * @member {number}
	 */
	get totalFree(): number;
	/**
	 * Gets the number of items in the pool that are currently in use.
	 * @readonly
	 * @member {number}
	 */
	get totalUsed(): number;
	/** clears the pool - mainly used for debugging! */
	clear(): void;
}
/**
 * An object that can be stored in a {@link utils.Pool}.
 * @memberof utils
 */
export type PoolItem = {
	init?: (data?: any) => void;
	reset?: () => void;
	[key: string]: any;
};
/**
 * The constructor of an object that can be stored in a {@link utils.Pool}.
 * @typeParam K - The type of the object that can be stored in a {@link utils.Pool}.
 * @memberof utils
 */
export type PoolItemConstructor<K extends PoolItem> = new () => K;
export declare class AlphaMask implements Effect, PoolItem {
	static extension: ExtensionMetadata;
	priority: number;
	mask: Container;
	inverse: boolean;
	pipe: string;
	renderMaskToTexture: boolean;
	constructor(options?: {
		mask: Container;
	});
	init(mask: Container): void;
	reset(): void;
	addBounds(bounds: Bounds, skipUpdateTransform?: boolean): void;
	addLocalBounds(bounds: Bounds, localRoot: Container): void;
	containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
	destroy(): void;
	static test(mask: any): boolean;
}
type FilterAction = "pushFilter" | "popFilter";
/**
 * The filter pipeline is responsible for applying filters scene items!
 *
 * KNOWN BUGS:
 * 1. Global bounds calculation is incorrect if it is used when flip flopping filters. The maths can be found below
 * eg: filters [noiseFilter, blurFilter] noiseFilter will calculate the global bounds incorrectly.
 *
 * 2. RenderGroups do not work with filters. This is because the renderGroup matrix is not currently taken into account.
 *
 * Implementation notes:
 * 1. Gotcha - nesting filters that require blending will not work correctly. This creates a chicken and egg problem
 * the complexity and performance required to do this is not worth it i feel.. but lets see if others agree!
 *
 * 2. Filters are designed to be changed on the fly, this is means that changing filter information each frame will
 * not trigger an instruction rebuild. If you are constantly turning a filter on and off.. its therefore better to set
 * enabled to true or false on the filter. Or setting an empty array.
 *
 * 3. Need to look at perhaps aliasing when flip flopping filters. Really we should only need to antialias the FIRST
 * Texture we render too. The rest can be non aliased. This might help performance.
 * Currently we flip flop with an antialiased texture if antialiasing is enabled on the filter.
 */
export interface FilterInstruction extends Instruction {
	renderPipeId: "filter";
	action: FilterAction;
	container?: Container;
	renderables?: Renderable[];
	filterEffect: FilterEffect;
}
export interface FilterData {
	skip: boolean;
	enabledLength?: number;
	inputTexture: Texture;
	bounds: Bounds;
	blendRequired: boolean;
	container: Container;
	filterEffect: FilterEffect;
	previousRenderSurface: RenderSurface;
	backTexture?: Texture;
}
/**
 * System that manages the filter pipeline
 * @memberof rendering
 */
export declare class FilterSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "filter";
	};
	readonly renderer: Renderer;
	private _filterStackIndex;
	private _filterStack;
	private readonly _filterGlobalUniforms;
	private readonly _globalFilterBindGroup;
	private _activeFilterData;
	constructor(renderer: Renderer);
	/**
	 * The back texture of the currently active filter. Requires the filter to have \`blendRequired\` set to true.
	 * @readonly
	 */
	get activeBackTexture(): Texture | undefined;
	push(instruction: FilterInstruction): void;
	pop(): void;
	getBackTexture(lastRenderSurface: RenderTarget, bounds: Bounds, previousBounds?: Bounds): Texture<TextureSource<any>>;
	applyFilter(filter: Filter, input: Texture, output: RenderSurface, clear: boolean): void;
	private _getFilterData;
	/**
	 * Multiply _input normalized coordinates_ to this matrix to get _sprite texture normalized coordinates_.
	 *
	 * Use \`outputMatrix * vTextureCoord\` in the shader.
	 * @param outputMatrix - The matrix to output to.
	 * @param {Sprite} sprite - The sprite to map to.
	 * @returns The mapped matrix.
	 */
	calculateSpriteMatrix(outputMatrix: Matrix, sprite: Sprite): Matrix;
	destroy?: () => void;
}
/**
 * Filters provide additional shading and post-processing effects to any display object and its children
 * they are attached to.
 *
 * You attached filters to a display object using its \`filters\` array property.
 *
 * \`\`\`js
 * import { Sprite, BlurFilter, HardMixBlend } from 'pixi.js';
 *
 * const sprite = Sprite.from('myTexture.png');
 *
 * // single filter
 * sprite.filters = new BlurFilter({ strength: 8 });
 *
 * // or multiple filters
 * sprite.filters = [new BlurFilter({ strength: 8 }), new HardMixBlend()];
 * \`\`\`
 *
 * Pixi has a number of built-in filters which can be used in your game or application:
 *
 * - {@link filters.AlphaFilter} - Applies alpha to the display object and any of its children.
 * - {@link filters.BlurFilter} - Applies a Gaussian blur to the display object.
 * - {@link filters.BlurFilterPass} - Applies a blur pass to an object.
 * - {@link filters.ColorBurnBlend} - Blend mode to add color burn to display objects.
 * - {@link filters.ColorDodgeBlend} - Blend mode to add color dodge to display objects.
 * - {@link filters.ColorMatrixFilter} - Transform the color channels by matrix multiplication.
 * - {@link filters.DarkenBlend} - Blend mode to darken display objects.
 * - {@link filters.DisplacementFilter} - Applies a displacement map to distort an object.
 * - {@link filters.DivideBlend} - Blend mode to divide display objects.
 * - {@link filters.HardMixBlend} - Blend mode to hard mix display objects.
 * - {@link filters.LinearBurnBlend} - Blend mode to add linear burn to display objects.
 * - {@link filters.LinearDodgeBlend} - Blend mode to add linear dodge to display objects.
 * - {@link filters.LinearLightBlend} - Blend mode to add linear light to display objects.
 * - {@link filters.NoiseFilter} - Applies random noise to an object.
 * - {@link filters.PinLightBlend} - Blend mode to add pin light to display objects.
 * - {@link filters.SubtractBlend} - Blend mode to subtract display objects.
 *
 * <br/>
 * For more available filters, check out the
 *  {@link https://pixijs.io/filters/docs/ pixi-filters} repository.
 *
 * You can also check out the awesome {@link https://pixijs.io/filters/examples/ Filter demo} to see
 * filters in action and combine them!
 * @namespace filters
 */
/**
 * The options to use when creating a new filter.
 * @memberof filters
 */
export interface FilterOptions {
	/** optional blend mode used by the filter when rendering (defaults to 'normal') */
	blendMode?: BLEND_MODES;
	/**
	 * the resolution the filter should be rendered at. The lower the resolution, the more performant
	 * the filter will be, but the lower the quality of the output. (default 1)
	 * If 'inherit', the resolution of the render target is used.
	 * Consider lowering this for things like blurs filters
	 */
	resolution?: number | "inherit";
	/**
	 * the amount of pixels to pad the container with when applying the filter. For example a blur extends the
	 * container out as it blurs, so padding is applied to ensure that extra detail is rendered as well
	 * without clipping occurring. (default 0)
	 */
	padding?: number;
	/**
	 * If true the filter will make use of antialiasing. Although it looks better this can have a performance impact.
	 * If set to 'inherit', the filter will detect the antialiasing of the render target and change this automatically.
	 * Definitely don't set this to true if the render target has antialiasing set to false. As it will antialias,
	 * but you won't see the difference. (default 'off')
	 *
	 * This can be a boolean or [FilterAntialias]{@link filters.FilterAntialias} string.
	 */
	antialias?: FilterAntialias | boolean;
	/**
	 * If this is set to true, the filter system will grab a snap shot of the area being rendered
	 * to and pass this into the shader. This is useful for blend modes that need to be aware of the pixels
	 * they are rendering to. Only use if you need that data, otherwise its an extra gpu copy you don't need!
	 * (default false)
	 */
	blendRequired?: boolean;
	/**
	 * If this is set to true, the filter system will clip filter texture into viewport
	 * This is useful for filters that applied to whole texture.
	 * (default true)
	 */
	clipToViewport?: boolean;
}
/** Filter options mixed with shader resources. A filter needs a shader and some resources to work. */
export type FilterWithShader = FilterOptions & IShaderWithResources;
/**
 * The antialiasing mode of the filter. This can be either:
 * - \`on\` - the filter is always antialiased regardless of the render target settings
 * - \`off\` - (default) the filter is never antialiased regardless of the render target settings
 * - \`inherit\` - the filter uses the antialias settings of the render target
 * @memberof filters
 */
export type FilterAntialias = "on" | "off" | "inherit";
/**
 * The Filter class is the base for all filter effects used in Pixi.js
 * As it extends a shader, it requires that a glProgram is parsed in to work with WebGL and a gpuProgram for WebGPU.
 * If you don't proved one, then the filter is skipped and just rendered as if it wasn't there for that renderer.
 *
 * A filter can be applied to anything that extends Container in Pixi.js which also includes Sprites, Graphics etc.
 *
 * Its worth noting Performance-wise filters can be pretty expensive if used too much in a single scene.
 * The following happens under the hood when a filter is applied:
 *
 * .1. Break the current batch
 * <br>
 * .2. The target is measured using getGlobalBounds
 * (recursively go through all children and figure out how big the object is)
 * <br>
 * .3. Get the closest Po2 Textures from the texture pool
 * <br>
 * .4. Render the target to that texture
 * <br>
 * .5. Render that texture back to the main frame buffer as a quad using the filters program.
 * <br>
 * <br>
 * Some filters (such as blur) require multiple passes too which can result in an even bigger performance hit. So be careful!
 * Its not generally the complexity of the shader that is the bottle neck,
 * but all the framebuffer / shader switching that has to take place.
 * One filter applied to a container with many objects is MUCH faster than many filter applied to many objects.
 * @class
 * @memberof filters
 */
export declare class Filter extends Shader {
	/**
	 * The default filter settings
	 * @static
	 */
	static readonly defaultOptions: FilterOptions;
	/**
	 * The padding of the filter. Some filters require extra space to breath such as a blur.
	 * Increasing this will add extra width and height to the bounds of the object that the
	 * filter is applied to.
	 * @default 0
	 */
	padding: number;
	/**
	 * should the filter use antialiasing?
	 * @default inherit
	 */
	antialias: FilterAntialias;
	/** If enabled is true the filter is applied, if false it will not. */
	enabled: boolean;
	/**
	 * The gpu state the filter requires to render.
	 * @internal
	 * @ignore
	 */
	_state: State;
	/**
	 * The resolution of the filter. Setting this to be lower will lower the quality but
	 * increase the performance of the filter.
	 * @default 1
	 */
	resolution: number | "inherit";
	/**
	 * Whether or not this filter requires the previous render texture for blending.
	 * @default false
	 */
	blendRequired: boolean;
	/**
	 * Clip texture into viewport or not
	 * @default true
	 */
	clipToViewport: boolean;
	/**
	 * @param options - The optional parameters of this filter.
	 */
	constructor(options: FilterWithShader);
	/**
	 * Applies the filter
	 * @param filterManager - The renderer to retrieve the filter from
	 * @param input - The input render target.
	 * @param output - The target to output to.
	 * @param clearMode - Should the output be cleared before rendering to it
	 */
	apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
	/**
	 * Get the blend mode of the filter.
	 * @default "normal"
	 */
	get blendMode(): BLEND_MODES;
	/** Sets the blend mode of the filter. */
	set blendMode(value: BLEND_MODES);
	/**
	 * A short hand function to create a filter based of a vertex and fragment shader src.
	 * @param options
	 * @returns A shiny new PixiJS filter!
	 */
	static from(options: FilterOptions & ShaderFromResources): Filter;
}
/**
 * A filter effect is an effect that can be applied to a container that involves applying special pixel effects
 * to that container as it is rendered. Used internally when the filters property is modified on a container
 */
export declare class FilterEffect implements Effect {
	/** read only filters array - to modify, set it again! */
	filters: readonly Filter[];
	/**
	 * If specified, rather than calculating the bounds of the container that the filter
	 * will apply to, we use this rect instead. This is a local rect - so will have the containers transform
	 * applied to it
	 */
	filterArea?: Rectangle;
	/** the pipe that knows how to handle this effect */
	pipe: string;
	/** the priority of this effect */
	priority: number;
	destroy(): void;
}
type MaskMode = "pushMaskBegin" | "pushMaskEnd" | "popMaskBegin" | "popMaskEnd";
declare class AlphaMaskEffect extends FilterEffect implements PoolItem {
	constructor();
	get sprite(): Sprite;
	set sprite(value: Sprite);
	get inverse(): boolean;
	set inverse(value: boolean);
	init: () => void;
}
export interface AlphaMaskInstruction extends Instruction {
	renderPipeId: "alphaMask";
	action: MaskMode;
	mask: AlphaMask;
	inverse: boolean;
	maskedContainer: Container;
	renderMask: boolean;
}
export interface AlphaMaskData {
	filterEffect: AlphaMaskEffect;
	maskedContainer: Container;
	previousRenderTarget?: RenderTarget;
	filterTexture?: Texture;
}
export declare class AlphaMaskPipe implements InstructionPipe<AlphaMaskInstruction> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "alphaMask";
	};
	private _renderer;
	private _activeMaskStage;
	constructor(renderer: Renderer);
	push(mask: Effect, maskedContainer: Container, instructionSet: InstructionSet): void;
	pop(mask: Effect, _maskedContainer: Container, instructionSet: InstructionSet): void;
	execute(instruction: AlphaMaskInstruction): void;
	destroy(): void;
}
export declare class ColorMask implements Effect, PoolItem {
	static extension: ExtensionMetadata;
	priority: number;
	mask: number;
	pipe: string;
	constructor(options: {
		mask: number;
	});
	init(mask: number): void;
	destroy(): void;
	static test(mask: any): boolean;
}
export interface ColorMaskInstruction extends Instruction {
	renderPipeId: "colorMask";
	colorMask: number;
}
export declare class ColorMaskPipe implements InstructionPipe<ColorMaskInstruction> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "colorMask";
	};
	private readonly _renderer;
	private _colorStack;
	private _colorStackIndex;
	private _currentColor;
	constructor(renderer: Renderer);
	buildStart(): void;
	push(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
	pop(_mask: Effect, _container: Container, instructionSet: InstructionSet): void;
	execute(instruction: ColorMaskInstruction): void;
	destroy(): void;
}
interface MaskConversionTest {
	test: (item: any) => boolean;
	maskClass: new (item: any) => Effect & PoolItem;
}
export type MaskEffect = {
	mask: unknown;
} & Effect;
/**
 * A class that manages the conversion of masks to mask effects.
 * @memberof rendering
 * @ignore
 */
export declare class MaskEffectManagerClass {
	/**
	 * @private
	 */
	readonly _effectClasses: EffectConstructor[];
	private readonly _tests;
	private _initialized;
	init(): void;
	add(test: MaskConversionTest): void;
	getMaskEffect(item: any): MaskEffect;
	returnMaskEffect(effect: Effect & PoolItem): void;
}
export declare const MaskEffectManager: MaskEffectManagerClass;
export declare class ScissorMask implements Effect {
	priority: number;
	mask: Container;
	pipe: string;
	constructor(mask: Container);
	addBounds(bounds: Bounds, skipUpdateTransform?: boolean): void;
	addLocalBounds(bounds: Bounds, localRoot: Container): void;
	containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
	reset(): void;
	destroy(): void;
}
export declare class StencilMask implements Effect, PoolItem {
	static extension: ExtensionMetadata;
	priority: number;
	mask: Container;
	pipe: string;
	constructor(options: {
		mask: Container;
	});
	init(mask: Container): void;
	reset(): void;
	addBounds(bounds: Bounds, skipUpdateTransform: boolean): void;
	addLocalBounds(bounds: Bounds, localRoot: Container): void;
	containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
	destroy(): void;
	static test(mask: any): boolean;
}
type MaskMode$1 = "pushMaskBegin" | "pushMaskEnd" | "popMaskBegin" | "popMaskEnd";
export interface StencilMaskInstruction extends Instruction {
	renderPipeId: "stencilMask";
	action: MaskMode$1;
	inverse: boolean;
	mask: StencilMask;
}
export declare class StencilMaskPipe implements InstructionPipe<StencilMaskInstruction> {
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "stencilMask";
	};
	private _renderer;
	private _maskStackHash;
	private _maskHash;
	constructor(renderer: Renderer);
	push(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
	pop(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
	execute(instruction: StencilMaskInstruction): void;
	destroy(): void;
}
export declare function addMaskBounds(mask: Container, bounds: Bounds, skipUpdateTransform: boolean): void;
export declare function addMaskLocalBounds(mask: Container, bounds: Bounds, localRoot: Container): void;
export declare function getMatrixRelativeToParent(target: Container, root: Container, matrix: Matrix): Matrix;
/**
 * Constants for various buffer types in Pixi
 * @see BUFFER_TYPE
 * @name BUFFER_TYPE
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */
export declare enum BUFFER_TYPE {
	ELEMENT_ARRAY_BUFFER = 34963,
	ARRAY_BUFFER = 34962,
	UNIFORM_BUFFER = 35345
}
export declare class GlBuffer {
	buffer: WebGLBuffer;
	updateID: number;
	byteLength: number;
	type: number;
	_lastBindBaseLocation: number;
	_lastBindCallId: number;
	constructor(buffer: WebGLBuffer, type: BUFFER_TYPE);
}
/**
 * System plugin to the renderer to manage buffers.
 *
 * WebGL uses Buffers as a way to store objects to the GPU.
 * This system makes working with them a lot easier.
 *
 * Buffers are used in three main places in WebGL
 * - geometry information
 * - Uniform information (via uniform buffer objects - a WebGL 2 only feature)
 * - Transform feedback information. (WebGL 2 only feature)
 *
 * This system will handle the binding of buffers to the GPU as well as uploading
 * them. With this system, you never need to work directly with GPU buffers, but instead work with
 * the Buffer class.
 * @class
 * @memberof rendering
 */
export declare class GlBufferSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "buffer";
	};
	private _gl;
	private _gpuBuffers;
	/** Cache keeping track of the base bound buffer bases */
	private _boundBufferBases;
	private _renderer;
	private _minBaseLocation;
	private _maxBindings;
	private _nextBindBaseIndex;
	private _bindCallId;
	/**
	 * @param {Renderer} renderer - The renderer this System works for.
	 */
	constructor(renderer: WebGLRenderer);
	/**
	 * @ignore
	 */
	destroy(): void;
	/** Sets up the renderer context and necessary buffers. */
	protected contextChange(): void;
	getGlBuffer(buffer: Buffer$1): GlBuffer;
	/**
	 * This binds specified buffer. On first run, it will create the webGL buffers for the context too
	 * @param buffer - the buffer to bind to the renderer
	 */
	bind(buffer: Buffer$1): void;
	/**
	 * Binds an uniform buffer to at the given index.
	 *
	 * A cache is used so a buffer will not be bound again if already bound.
	 * @param glBuffer - the buffer to bind
	 * @param index - the base index to bind it to.
	 */
	bindBufferBase(glBuffer: GlBuffer, index: number): void;
	nextBindBase(hasTransformFeedback: boolean): void;
	freeLocationForBufferBase(glBuffer: GlBuffer): number;
	getLastBindBaseLocation(glBuffer: GlBuffer): number;
	/**
	 * Binds a buffer whilst also binding its range.
	 * This will make the buffer start from the offset supplied rather than 0 when it is read.
	 * @param glBuffer - the buffer to bind
	 * @param index - the base index to bind at, defaults to 0
	 * @param offset - the offset to bind at (this is blocks of 256). 0 = 0, 1 = 256, 2 = 512 etc
	 * @param size - the size to bind at (this is blocks of 256).
	 */
	bindBufferRange(glBuffer: GlBuffer, index?: number, offset?: number, size?: number): void;
	/**
	 * Will ensure the data in the buffer is uploaded to the GPU.
	 * @param {Buffer} buffer - the buffer to update
	 */
	updateBuffer(buffer: Buffer$1): GlBuffer;
	/** dispose all WebGL resources of all managed buffers */
	destroyAll(): void;
	/**
	 * Disposes buffer
	 * @param {Buffer} buffer - buffer with data
	 * @param {boolean} [contextLost=false] - If context was lost, we suppress deleteVertexArray
	 */
	protected onBufferDestroy(buffer: Buffer$1, contextLost?: boolean): void;
	/**
	 * creates and attaches a GLBuffer object tied to the current context.
	 * @param buffer
	 * @protected
	 */
	protected createGLBuffer(buffer: Buffer$1): GlBuffer;
	resetState(): void;
}
interface WEBGL_compressed_texture_pvrtc$1 {
	COMPRESSED_RGB_PVRTC_4BPPV1_IMG: number;
	COMPRESSED_RGBA_PVRTC_4BPPV1_IMG: number;
	COMPRESSED_RGB_PVRTC_2BPPV1_IMG: number;
	COMPRESSED_RGBA_PVRTC_2BPPV1_IMG: number;
}
interface WEBGL_compressed_texture_etc$1 {
	COMPRESSED_R11_EAC: number;
	COMPRESSED_SIGNED_R11_EAC: number;
	COMPRESSED_RG11_EAC: number;
	COMPRESSED_SIGNED_RG11_EAC: number;
	COMPRESSED_RGB8_ETC2: number;
	COMPRESSED_RGBA8_ETC2_EAC: number;
	COMPRESSED_SRGB8_ETC2: number;
	COMPRESSED_SRGB8_ALPHA8_ETC2_EAC: number;
	COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2: number;
	COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2: number;
}
interface WEBGL_compressed_texture_etc1$1 {
	COMPRESSED_RGB_ETC1_WEBGL: number;
}
export interface WEBGL_compressed_texture_atc {
	COMPRESSED_RGB_ATC_WEBGL: number;
	COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL: number;
	COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL: number;
}
interface EXT_texture_compression_bptc$1 {
	COMPRESSED_RGBA_BPTC_UNORM_EXT: number;
	COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT: number;
	COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT: number;
	COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT: number;
}
interface EXT_texture_compression_rgtc$1 {
	COMPRESSED_RED_RGTC1_EXT: number;
	COMPRESSED_SIGNED_RED_RGTC1_EXT: number;
	COMPRESSED_RED_GREEN_RGTC2_EXT: number;
	COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT: number;
}
export interface WebGLExtensions {
	drawBuffers?: WEBGL_draw_buffers;
	depthTexture?: OES_texture_float;
	loseContext?: WEBGL_lose_context;
	vertexArrayObject?: OES_vertex_array_object;
	anisotropicFiltering?: EXT_texture_filter_anisotropic;
	uint32ElementIndex?: OES_element_index_uint;
	floatTexture?: OES_texture_float;
	floatTextureLinear?: OES_texture_float_linear;
	textureHalfFloat?: OES_texture_half_float;
	textureHalfFloatLinear?: OES_texture_half_float_linear;
	colorBufferFloat?: EXT_color_buffer_float;
	vertexAttribDivisorANGLE?: ANGLE_instanced_arrays;
	s3tc?: WEBGL_compressed_texture_s3tc;
	s3tc_sRGB?: WEBGL_compressed_texture_s3tc_srgb;
	etc?: WEBGL_compressed_texture_etc$1;
	etc1?: WEBGL_compressed_texture_etc1$1;
	pvrtc?: WEBGL_compressed_texture_pvrtc$1;
	atc?: WEBGL_compressed_texture_atc;
	astc?: WEBGL_compressed_texture_astc;
	bptc?: EXT_texture_compression_bptc$1;
	rgtc?: EXT_texture_compression_rgtc$1;
	srgb?: EXT_sRGB;
}
/**
 * Options for the context system.
 * @memberof rendering
 * @property {WebGL2RenderingContext | null} [context=null] - User-provided WebGL rendering context object.
 * @property {GpuPowerPreference} [powerPreference='default'] - An optional hint indicating what configuration
 * of GPU is suitable for the WebGL context, can be \`'high-performance'\` or \`'low-power'\`. Setting to \`'high-performance'\`
 * will prioritize rendering performance over power consumption, while setting to \`'low-power'\` will prioritize power saving
 * over rendering performance.
 * @property {boolean} [premultipliedAlpha=true] - Whether the compositor will assume the drawing buffer contains
 * colors with premultiplied alpha.
 * @property {boolean} [preserveDrawingBuffer=false] - Whether to enable drawing buffer preservation.
 * If enabled, the drawing buffer will preserve
 * its value until cleared or overwritten. Enable this if you need to call \`toDataUrl\` on the WebGL context.
 * @property {boolean} [antialias] - Whether to enable antialiasing.
 * @property {1 | 2} [preferWebGLVersion=2] - The preferred WebGL version to use.
 */
export interface ContextSystemOptions {
	/**
	 * User-provided WebGL rendering context object.
	 * @default null
	 * @memberof rendering.SharedRendererOptions
	 */
	context: WebGL2RenderingContext | null;
	/**
	 * An optional hint indicating what configuration of GPU is suitable for the WebGL context,
	 * can be \`'high-performance'\` or \`'low-power'\`.
	 * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
	 * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
	 * @memberof rendering.SharedRendererOptions
	 * @default undefined
	 */
	powerPreference?: GpuPowerPreference;
	/**
	 * Whether the compositor will assume the drawing buffer contains colors with premultiplied alpha.
	 * @default true
	 * @memberof rendering.SharedRendererOptions
	 */
	premultipliedAlpha: boolean;
	/**
	 * Whether to enable drawing buffer preservation. If enabled, the drawing buffer will preserve
	 * its value until cleared or overwritten. Enable this if you need to call \`toDataUrl\` on the WebGL context.
	 * @default false
	 * @memberof rendering.SharedRendererOptions
	 */
	preserveDrawingBuffer: boolean;
	antialias?: boolean;
	/**
	 * The preferred WebGL version to use.
	 * @default 2
	 * @memberof rendering.SharedRendererOptions
	 */
	preferWebGLVersion?: 1 | 2;
	/**
	 * Whether to enable multi-view rendering. Set to true when rendering to multiple
	 * canvases on the dom.
	 * @default false
	 * @memberof rendering.SharedRendererOptions
	 */
	multiView: boolean;
}
/**
 * System plugin to the renderer to manage the context
 * @memberof rendering
 */
export declare class GlContextSystem implements System<ContextSystemOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "context";
	};
	/** The default options for the system. */
	static defaultOptions: ContextSystemOptions;
	protected CONTEXT_UID: number;
	protected gl: WebGL2RenderingContext;
	/**
	 * Features supported by current renderer.
	 * @type {object}
	 * @readonly
	 */
	supports: {
		/** Support for 32-bit indices buffer. */
		uint32Indices: boolean;
		/** Support for UniformBufferObjects */
		uniformBufferObject: boolean;
		/** Support for VertexArrayObjects */
		vertexArrayObject: boolean;
		/** Support for SRGB texture format */
		srgbTextures: boolean;
		/** Support for wrapping modes if a texture is non-power of two */
		nonPowOf2wrapping: boolean;
		/** Support for MSAA (antialiasing of dynamic textures) */
		msaa: boolean;
		/** Support for mipmaps if a texture is non-power of two */
		nonPowOf2mipmaps: boolean;
	};
	/**
	 * Extensions available.
	 * @type {object}
	 * @readonly
	 * @property {WEBGL_draw_buffers} drawBuffers - WebGL v1 extension
	 * @property {WEBGL_depth_texture} depthTexture - WebGL v1 extension
	 * @property {OES_texture_float} floatTexture - WebGL v1 extension
	 * @property {WEBGL_lose_context} loseContext - WebGL v1 extension
	 * @property {OES_vertex_array_object} vertexArrayObject - WebGL v1 extension
	 * @property {EXT_texture_filter_anisotropic} anisotropicFiltering - WebGL v1 and v2 extension
	 */
	extensions: WebGLExtensions;
	webGLVersion: 1 | 2;
	/**
	 * Whether to enable multi-view rendering. Set to true when rendering to multiple
	 * canvases on the dom.
	 * @default false
	 */
	multiView: boolean;
	/**
	 * The canvas that the WebGL Context is rendering to.
	 * This will be the view canvas. But if multiView is enabled, this canvas will not be attached to the DOM.
	 * It will be rendered to and then copied to the target canvas.
	 * @readonly
	 */
	canvas: ICanvas;
	private _renderer;
	private _contextLossForced;
	/** @param renderer - The renderer this System works for. */
	constructor(renderer: WebGLRenderer);
	/**
	 * \`true\` if the context is lost
	 * @readonly
	 */
	get isLost(): boolean;
	/**
	 * Handles the context change event.
	 * @param {WebGLRenderingContext} gl - New WebGL context.
	 */
	protected contextChange(gl: WebGL2RenderingContext): void;
	init(options: ContextSystemOptions): void;
	ensureCanvasSize(targetCanvas: ICanvas): void;
	/**
	 * Initializes the context.
	 * @protected
	 * @param {WebGLRenderingContext} gl - WebGL context
	 */
	protected initFromContext(gl: WebGL2RenderingContext): void;
	/**
	 * Initialize from context options
	 * @protected
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext
	 * @param preferWebGLVersion
	 * @param {object} options - context attributes
	 */
	protected createContext(preferWebGLVersion: 1 | 2, options: WebGLContextAttributes): void;
	/** Auto-populate the {@link GlContextSystem.extensions extensions}. */
	protected getExtensions(): void;
	/**
	 * Handles a lost webgl context
	 * @param {WebGLContextEvent} event - The context lost event.
	 */
	protected handleContextLost(event: WebGLContextEvent): void;
	/** Handles a restored webgl context. */
	protected handleContextRestored(): void;
	destroy(): void;
	/**
	 * this function can be called to force a webGL context loss
	 * this will release all resources on the GPU.
	 * Useful if you need to put Pixi to sleep, and save some GPU memory
	 *
	 * As soon as render is called - all resources will be created again.
	 */
	forceContextLoss(): void;
	/**
	 * Validate context.
	 * @param {WebGLRenderingContext} gl - Render context.
	 */
	protected validateContext(gl: WebGL2RenderingContext): void;
}
/**
 * System plugin to the renderer to manage geometry.
 * @memberof rendering
 */
export declare class GlGeometrySystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "geometry";
	};
	/**
	 * \`true\` if we has \`*_vertex_array_object\` extension.
	 * @readonly
	 */
	hasVao: boolean;
	/**
	 * \`true\` if has \`ANGLE_instanced_arrays\` extension.
	 * @readonly
	 */
	hasInstance: boolean;
	protected gl: GlRenderingContext;
	protected _activeGeometry: Geometry;
	protected _activeVao: WebGLVertexArrayObject;
	protected _geometryVaoHash: Record<number, Record<string, WebGLVertexArrayObject>>;
	/** Renderer that owns this {@link GeometrySystem}. */
	private _renderer;
	/** @param renderer - The renderer this System works for. */
	constructor(renderer: WebGLRenderer);
	/** Sets up the renderer context and necessary buffers. */
	protected contextChange(): void;
	/**
	 * Binds geometry so that is can be drawn. Creating a Vao if required
	 * @param geometry - Instance of geometry to bind.
	 * @param program - Instance of program to use vao for.
	 */
	bind(geometry?: Geometry, program?: GlProgram): void;
	/** Reset and unbind any active VAO and geometry. */
	resetState(): void;
	/** Update buffers of the currently bound geometry. */
	updateBuffers(): void;
	/**
	 * Check compatibility between a geometry and a program
	 * @param geometry - Geometry instance.
	 * @param program - Program instance.
	 */
	protected checkCompatibility(geometry: Geometry, program: GlProgram): void;
	/**
	 * Takes a geometry and program and generates a unique signature for them.
	 * @param geometry - To get signature from.
	 * @param program - To test geometry against.
	 * @returns - Unique signature of the geometry and program
	 */
	protected getSignature(geometry: Geometry, program: GlProgram): string;
	protected getVao(geometry: Geometry, program: GlProgram): WebGLVertexArrayObject;
	/**
	 * Creates or gets Vao with the same structure as the geometry and stores it on the geometry.
	 * If vao is created, it is bound automatically. We use a shader to infer what and how to set up the
	 * attribute locations.
	 * @param geometry - Instance of geometry to to generate Vao for.
	 * @param program
	 * @param _incRefCount - Increment refCount of all geometry buffers.
	 */
	protected initGeometryVao(geometry: Geometry, program: GlProgram, _incRefCount?: boolean): WebGLVertexArrayObject;
	/**
	 * Disposes geometry.
	 * @param geometry - Geometry with buffers. Only VAO will be disposed
	 * @param [contextLost=false] - If context was lost, we suppress deleteVertexArray
	 */
	protected onGeometryDestroy(geometry: Geometry, contextLost?: boolean): void;
	/**
	 * Dispose all WebGL resources of all managed geometries.
	 * @param [contextLost=false] - If context was lost, we suppress \`gl.delete\` calls
	 */
	destroyAll(contextLost?: boolean): void;
	/**
	 * Activate vertex array object.
	 * @param geometry - Geometry instance.
	 * @param program - Shader program instance.
	 */
	protected activateVao(geometry: Geometry, program: GlProgram): void;
	/**
	 * Draws the currently bound geometry.
	 * @param topology - The type primitive to render.
	 * @param size - The number of elements to be rendered. If not specified, all vertices after the
	 *  starting vertex will be drawn.
	 * @param start - The starting vertex in the geometry to start drawing from. If not specified,
	 *  drawing will start from the first vertex.
	 * @param instanceCount - The number of instances of the set of elements to execute. If not specified,
	 *  all instances will be drawn.
	 */
	draw(topology?: Topology, size?: number, start?: number, instanceCount?: number): this;
	/** Unbind/reset everything. */
	protected unbind(): void;
	destroy(): void;
}
export declare function getGlTypeFromFormat(format: VertexFormat): number;
/**
 * The options for the back buffer system.
 * @memberof rendering
 * @property {boolean} [useBackBuffer=false] - if true will use the back buffer where required
 * @property {boolean} [antialias=false] - if true will ensure the texture is antialiased
 */
export interface GlBackBufferOptions {
	/**
	 * if true will use the back buffer where required
	 * @default false
	 * @memberof rendering.WebGLOptions
	 */
	useBackBuffer?: boolean;
	/** if true will ensure the texture is antialiased */
	antialias?: boolean;
}
/**
 * For blend modes you need to know what pixels you are actually drawing to. For this to be possible in WebGL
 * we need to render to a texture and then present that texture to the screen. This system manages that process.
 *
 * As the main scene is rendered to a texture, it means we can sample it and copy its pixels,
 * something not possible on the main canvas.
 *
 * If antialiasing is set to to true and useBackBuffer is set to true, then the back buffer will be antialiased.
 * and the main gl context will not.
 *
 * You only need to activate this back buffer if you are using a blend mode that requires it.
 *
 * to activate is simple, you pass \`useBackBuffer:true\` to your render options
 * @memberof rendering
 */
export declare class GlBackBufferSystem implements System<GlBackBufferOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "backBuffer";
		readonly priority: 1;
	};
	/** default options for the back buffer system */
	static defaultOptions: GlBackBufferOptions;
	/** if true, the back buffer is used */
	useBackBuffer: boolean;
	private _backBufferTexture;
	private readonly _renderer;
	private _targetTexture;
	private _useBackBufferThisRender;
	private _antialias;
	private _state;
	private _bigTriangleShader;
	constructor(renderer: WebGLRenderer);
	init(options?: GlBackBufferOptions): void;
	/**
	 * This is called before the RenderTargetSystem is started. This is where
	 * we replace the target with the back buffer if required.
	 * @param options - The options for this render.
	 */
	protected renderStart(options: RenderOptions): void;
	protected renderEnd(): void;
	private _presentBackBuffer;
	private _getBackBufferTexture;
	/** destroys the back buffer */
	destroy(): void;
}
/**
 * The system that handles color masking for the WebGL.
 * @memberof rendering
 */
export declare class GlColorMaskSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "colorMask";
	};
	private readonly _renderer;
	private _colorMaskCache;
	constructor(renderer: WebGLRenderer);
	setMask(colorMask: number): void;
	destroy?: () => void;
}
/**
 * The system that handles encoding commands for the WebGL.
 * @memberof rendering
 */
export declare class GlEncoderSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "encoder";
	};
	readonly commandFinished: Promise<void>;
	private readonly _renderer;
	constructor(renderer: WebGLRenderer);
	setGeometry(geometry: Geometry, shader?: Shader): void;
	finishRenderPass(): void;
	draw(options: {
		geometry: Geometry;
		shader: Shader;
		state?: State;
		topology?: Topology;
		size?: number;
		start?: number;
		instanceCount?: number;
		skipSync?: boolean;
	}): void;
	destroy(): void;
}
/**
 * This manages the stencil buffer. Used primarily for masking
 * @memberof rendering
 */
export declare class GlStencilSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "stencil";
	};
	private _gl;
	private readonly _stencilCache;
	private _renderTargetStencilState;
	private _stencilOpsMapping;
	private _comparisonFuncMapping;
	private _activeRenderTarget;
	constructor(renderer: WebGLRenderer);
	protected contextChange(gl: WebGLRenderingContext): void;
	protected onRenderTargetChange(renderTarget: RenderTarget): void;
	resetState(): void;
	setStencilMode(stencilMode: STENCIL_MODES, stencilReference: number): void;
	destroy?: () => void;
}
/**
 * System plugin to the renderer to manage uniform buffers. But with an WGSL adaptor.
 * @memberof rendering
 */
export declare class GlUboSystem extends UboSystem {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "ubo";
	};
	constructor();
}
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGL renderer
 * @memberof rendering
 * @ignore
 */
export declare class GlRenderTargetAdaptor implements RenderTargetAdaptor<GlRenderTarget> {
	private _renderTargetSystem;
	private _renderer;
	private _clearColorCache;
	private _viewPortCache;
	init(renderer: WebGLRenderer, renderTargetSystem: RenderTargetSystem<GlRenderTarget>): void;
	contextChange(): void;
	copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
		x: number;
		y: number;
	}, size: {
		width: number;
		height: number;
	}, originDest: {
		x: number;
		y: number;
	}): Texture<TextureSource<any>>;
	startRenderPass(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
	finishRenderPass(renderTarget?: RenderTarget): void;
	initGpuRenderTarget(renderTarget: RenderTarget): GlRenderTarget;
	destroyGpuRenderTarget(gpuRenderTarget: GlRenderTarget): void;
	clear(_renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, clearColor?: RgbaArray): void;
	resizeGpuRenderTarget(renderTarget: RenderTarget): void;
	private _initColor;
	private _resizeColor;
	private _initStencil;
	private _resizeStencil;
	prerender(renderTarget: RenderTarget): void;
	postrender(renderTarget: RenderTarget): void;
}
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGl renderer
 * @memberof rendering
 */
export declare class GlRenderTargetSystem extends RenderTargetSystem<GlRenderTarget> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "renderTarget";
	};
	adaptor: GlRenderTargetAdaptor;
	constructor(renderer: WebGLRenderer);
}
export type PRECISION = \`highp\` | \`mediump\` | \`lowp\`;
/**
 * @private
 */
export declare class IGLUniformData {
	location: WebGLUniformLocation;
	value: number | boolean | Float32Array | Int32Array | Uint32Array | boolean[];
}
/**
 * Helper class to create a WebGL Program
 * @private
 */
export declare class GlProgramData {
	/** The shader program. */
	program: WebGLProgram;
	/**
	 * Holds the uniform data which contains uniform locations
	 * and current uniform values used for caching and preventing unneeded GPU commands.
	 */
	uniformData: Record<string, any>;
	/**
	 * UniformGroups holds the various upload functions for the shader. Each uniform group
	 * and program have a unique upload function generated.
	 */
	uniformGroups: Record<string, any>;
	/** A hash that stores where UBOs are bound to on the program. */
	uniformBlockBindings: Record<string, any>;
	/** A hash for lazily-generated uniform uploading functions. */
	uniformSync: Record<string, any>;
	/**
	 * A place where dirty ticks are stored for groups
	 * If a tick here does not match with the Higher level Programs tick, it means
	 * we should re upload the data.
	 */
	uniformDirtyGroups: Record<string, any>;
	/**
	 * Makes a new Pixi program.
	 * @param program - webgl program
	 * @param uniformData - uniforms
	 */
	constructor(program: WebGLProgram, uniformData: {
		[key: string]: IGLUniformData;
	});
	/** Destroys this program. */
	destroy(): void;
}
export interface ShaderSyncData {
	textureCount: number;
	blockIndex: number;
}
export type ShaderSyncFunction = (renderer: WebGLRenderer, shader: Shader, syncData: ShaderSyncData) => void;
/**
 * System plugin to the renderer to manage the shaders for WebGL.
 * @memberof rendering
 */
export declare class GlShaderSystem implements ShaderSystem {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "shader";
	};
	maxTextures: number;
	/**
	 * @internal
	 * @private
	 */
	_activeProgram: GlProgram;
	private _programDataHash;
	private readonly _renderer;
	_gl: WebGL2RenderingContext;
	private _shaderSyncFunctions;
	constructor(renderer: WebGLRenderer);
	protected contextChange(gl: GlRenderingContext): void;
	/**
	 * Changes the current shader to the one given in parameter.
	 * @param shader - the new shader
	 * @param skipSync - false if the shader should automatically sync its uniforms.
	 * @returns the glProgram that belongs to the shader.
	 */
	bind(shader: Shader, skipSync?: boolean): void;
	/**
	 * Updates the uniform group.
	 * @param uniformGroup - the uniform group to update
	 */
	updateUniformGroup(uniformGroup: UniformGroup): void;
	/**
	 * Binds a uniform block to the shader.
	 * @param uniformGroup - the uniform group to bind
	 * @param name - the name of the uniform block
	 * @param index - the index of the uniform block
	 */
	bindUniformBlock(uniformGroup: UniformGroup | BufferResource, name: string, index?: number): void;
	private _setProgram;
	/**
	 * @param program - the program to get the data for
	 * @internal
	 * @private
	 */
	_getProgramData(program: GlProgram): GlProgramData;
	private _createProgramData;
	destroy(): void;
	/**
	 * Creates a function that can be executed that will sync the shader as efficiently as possible.
	 * Overridden by the unsafe eval package if you don't want eval used in your project.
	 * @param shader - the shader to generate the sync function for
	 * @param shaderSystem - the shader system to use
	 * @returns - the generated sync function
	 * @ignore
	 */
	_generateShaderSync(shader: Shader, shaderSystem: GlShaderSystem): ShaderSyncFunction;
	resetState(): void;
}
/**
 * Generates the a function that will efficiently sync shader resources with the GPU.
 * @param shader - The shader to generate the code for
 * @param shaderSystem - An instance of the shader system
 */
export declare function generateShaderSyncCode(shader: Shader, shaderSystem: GlShaderSystem): ShaderSyncFunction;
/**
 * Automatically generates a uniform group that holds the texture samplers for a shader.
 * This is used mainly by the shaders that batch textures!
 * @param maxTextures - the number of textures that this uniform group will contain.
 * @returns a uniform group that holds the texture samplers.
 */
export declare function getBatchSamplersUniformGroup(maxTextures: number): UniformGroup<any>;
/**
 * System plugin to the renderer to manage shaders.
 * @memberof rendering
 */
export declare class GlUniformGroupSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "uniformGroup";
	};
	/**
	 * The current WebGL rendering context.
	 * @member {WebGLRenderingContext}
	 */
	protected gl: GlRenderingContext;
	/** Cache to holds the generated functions. Stored against UniformObjects unique signature. */
	private _cache;
	private _renderer;
	private _uniformGroupSyncHash;
	/** @param renderer - The renderer this System works for. */
	constructor(renderer: WebGLRenderer);
	protected contextChange(gl: GlRenderingContext): void;
	/**
	 * Uploads the uniforms values to the currently bound shader.
	 * @param group - the uniforms values that be applied to the current shader
	 * @param program
	 * @param syncData
	 * @param syncData.textureCount
	 */
	updateUniformGroup(group: UniformGroup, program: GlProgram, syncData: {
		textureCount: number;
	}): void;
	/**
	 * Overridable by the pixi.js/unsafe-eval package to use static syncUniforms instead.
	 * @param group
	 * @param program
	 */
	private _getUniformSyncFunction;
	private _createUniformSyncFunction;
	private _generateUniformsSync;
	/**
	 * Takes a uniform group and data and generates a unique signature for them.
	 * @param group - The uniform group to get signature of
	 * @param group.uniforms
	 * @param uniformData - Uniform information generated by the shader
	 * @param preFix
	 * @returns Unique signature of the uniform group
	 */
	private _getSignature;
	/** Destroys this System and removes all its textures. */
	destroy(): void;
}
export declare function migrateFragmentFromV7toV8(fragmentShader: string): string;
/**
 * @private
 * @param {WebGLRenderingContext} gl - The current WebGL context {WebGLProgram}
 * @param {number} type - the type, can be either VERTEX_SHADER or FRAGMENT_SHADER
 * @param {string} src - The vertex shader source as an array of strings.
 * @returns {WebGLShader} the shader
 */
export declare function compileShader(gl: WebGLRenderingContextBase, type: number, src: string): WebGLShader;
/**
 * @method defaultValue
 * @param {string} type - Type of value
 * @param {number} size
 * @private
 */
export declare function defaultValue(type: string, size: number): number | Float32Array | Int32Array | Uint32Array | boolean | boolean[];
/**
 * This function looks at the attribute information provided to the geometry and attempts
 * to fill in an gaps. WE do this by looking at the extracted data from the shader and
 * making best guesses.
 *
 * Most of th etime users don't need to provide all the attribute info beyond the data itself, so we
 * can fill in the gaps for them. If you are using attributes in a more advanced way, you can
 * don't forget to add all the info at creation!
 * @param geometry - the geometry to ensure attributes for
 * @param extractedData - the extracted data from the shader
 */
export declare function ensureAttributes(geometry: Geometry, extractedData: Record<string, ExtractedAttributeData>): void;
/**
 * generates a WebGL Program object from a high level Pixi Program.
 * @param gl - a rendering context on which to generate the program
 * @param program - the high level Pixi Program.
 * @private
 */
export declare function generateProgram(gl: GlRenderingContext, program: GlProgram): GlProgramData;
export declare function getMaxFragmentPrecision(): PRECISION;
/**
 * returns a little WebGL context to use for program inspection.
 * @static
 * @private
 * @returns {WebGLRenderingContext} a gl context to test with
 */
export declare function getTestContext(): GlRenderingContext;
/**
 * returns the uniform block data from the program
 * @private
 * @param program - the webgl program
 * @param gl - the WebGL context
 * @returns {object} the uniform data for this program
 */
export declare function getUboData(program: WebGLProgram, gl: WebGL2RenderingContext): Record<string, GlUniformBlockData>;
/**
 * returns the uniform data from the program
 * @private
 * @param program - the webgl program
 * @param gl - the WebGL context
 * @returns {object} the uniform data for this program
 */
export declare function getUniformData(program: WebGLProgram, gl: WebGLRenderingContextBase): {
	[key: string]: GlUniformData;
};
/**
 *
 * logs out any program errors
 * @param gl - The current WebGL context
 * @param program - the WebGL program to display errors for
 * @param vertexShader  - the fragment WebGL shader program
 * @param fragmentShader - the vertex WebGL shader program
 * @private
 */
export declare function logProgramError(gl: WebGLRenderingContext, program: WebGLProgram, vertexShader: WebGLShader, fragmentShader: WebGLShader): void;
/**
 * @private
 * @method mapSize
 * @param {string} type
 */
export declare function mapSize(type: string): number;
export declare function mapType(gl: any, type: number): string;
export declare function mapGlToVertexFormat(gl: any, type: number): VertexFormat;
export declare function addProgramDefines(src: string, isES300: boolean, isFragment?: boolean): string;
interface EnsurePrecisionOptions {
	requestedVertexPrecision: PRECISION;
	requestedFragmentPrecision: PRECISION;
	maxSupportedVertexPrecision: PRECISION;
	maxSupportedFragmentPrecision: PRECISION;
}
/**
 * Sets the float precision on the shader, ensuring the device supports the request precision.
 * If the precision is already present, it just ensures that the device is able to handle it.
 * @param src
 * @param options
 * @param options.requestedVertexPrecision
 * @param options.requestedFragmentPrecision
 * @param options.maxSupportedVertexPrecision
 * @param options.maxSupportedFragmentPrecision
 * @param isFragment
 * @private
 */
export declare function ensurePrecision(src: string, options: EnsurePrecisionOptions, isFragment: boolean): string;
export declare function insertVersion(src: string, isES300: boolean): string;
export declare function setProgramName(src: string, { name }: {
	name: string;
}, isFragment?: boolean): string;
export declare function stripVersion(src: string, isES300: boolean): string;
export declare const WGSL_TO_STD40_SIZE: Record<string, number>;
export declare function createUboElementsSTD40(uniformData: UniformData[]): UboLayout;
export declare function createUboSyncFunctionSTD40(uboElements: UboElement[]): UniformsSyncCallback;
/**
 * This generates a function that will sync an array to the uniform buffer
 * following the std140 layout
 * @param uboElement - the element to generate the array sync for
 * @param offsetToAdd - the offset to append at the start of the code
 * @returns - the generated code
 */
export declare function generateArraySyncSTD40(uboElement: UboElement, offsetToAdd: number): string;
export declare function generateUniformsSync(group: UniformGroup, uniformData: Record<string, any>): UniformsSyncCallback;
export type ArraySetterFunction = (v: any, location: WebGLUniformLocation, gl: any) => void;
export declare const UNIFORM_TO_SINGLE_SETTERS: Record<UNIFORM_TYPES | string, string>;
export declare const UNIFORM_TO_ARRAY_SETTERS: Record<UNIFORM_TYPES | string, string>;
/**
 * System plugin to the renderer to manage WebGL state machines
 * @memberof rendering
 */
export declare class GlStateSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "state";
	};
	/**
	 * State ID
	 * @readonly
	 */
	stateId: number;
	/**
	 * Polygon offset
	 * @readonly
	 */
	polygonOffset: number;
	/**
	 * Blend mode
	 * @default 'none'
	 * @readonly
	 */
	blendMode: BLEND_MODES;
	/** Whether current blend equation is different */
	protected _blendEq: boolean;
	/**
	 * GL context
	 * @member {WebGLRenderingContext}
	 * @readonly
	 */
	protected gl: GlRenderingContext;
	protected blendModesMap: Record<BLEND_MODES, number[]>;
	/**
	 * Collection of calls
	 * @member {Function[]}
	 */
	protected readonly map: ((value: boolean) => void)[];
	/**
	 * Collection of check calls
	 * @member {Function[]}
	 */
	protected readonly checks: ((system: this, state: State) => void)[];
	/**
	 * Default WebGL State
	 * @readonly
	 */
	protected defaultState: State;
	/**
	 * Whether to invert the front face when rendering
	 * This is used for render textures where the Y-coordinate is flipped
	 * @default false
	 */
	private _invertFrontFace;
	private _glFrontFace;
	private _cullFace;
	private _frontFaceDirty;
	private _frontFace;
	constructor(renderer: WebGLRenderer);
	protected onRenderTargetChange(renderTarget: RenderTarget): void;
	protected contextChange(gl: GlRenderingContext): void;
	/**
	 * Sets the current state
	 * @param {*} state - The state to set.
	 */
	set(state: State): void;
	/**
	 * Sets the state, when previous state is unknown.
	 * @param {*} state - The state to set
	 */
	forceState(state: State): void;
	/**
	 * Sets whether to enable or disable blending.
	 * @param value - Turn on or off WebGl blending.
	 */
	setBlend(value: boolean): void;
	/**
	 * Sets whether to enable or disable polygon offset fill.
	 * @param value - Turn on or off webgl polygon offset testing.
	 */
	setOffset(value: boolean): void;
	/**
	 * Sets whether to enable or disable depth test.
	 * @param value - Turn on or off webgl depth testing.
	 */
	setDepthTest(value: boolean): void;
	/**
	 * Sets whether to enable or disable depth mask.
	 * @param value - Turn on or off webgl depth mask.
	 */
	setDepthMask(value: boolean): void;
	/**
	 * Sets whether to enable or disable cull face.
	 * @param {boolean} value - Turn on or off webgl cull face.
	 */
	setCullFace(value: boolean): void;
	/**
	 * Sets the gl front face.
	 * @param {boolean} value - true is clockwise and false is counter-clockwise
	 */
	setFrontFace(value: boolean): void;
	/**
	 * Sets the blend mode.
	 * @param {number} value - The blend mode to set to.
	 */
	setBlendMode(value: BLEND_MODES): void;
	/**
	 * Sets the polygon offset.
	 * @param {number} value - the polygon offset
	 * @param {number} scale - the polygon offset scale
	 */
	setPolygonOffset(value: number, scale: number): void;
	/** Resets all the logic and disables the VAOs. */
	resetState(): void;
	/**
	 * Checks to see which updates should be checked based on which settings have been activated.
	 *
	 * For example, if blend is enabled then we should check the blend modes each time the state is changed
	 * or if polygon fill is activated then we need to check if the polygon offset changes.
	 * The idea is that we only check what we have too.
	 * @param func - the checking function to add or remove
	 * @param value - should the check function be added or removed.
	 */
	private _updateCheck;
	/**
	 * A private little wrapper function that we call to check the blend mode.
	 * @param system - the System to perform the state check on
	 * @param state - the state that the blendMode will pulled from
	 */
	private static _checkBlendMode;
	/**
	 * A private little wrapper function that we call to check the polygon offset.
	 * @param system - the System to perform the state check on
	 * @param state - the state that the blendMode will pulled from
	 */
	private static _checkPolygonOffset;
	/**
	 * @ignore
	 */
	destroy(): void;
}
/**
 * Maps gl blend combinations to WebGL.
 * @param gl
 * @returns {object} Map of gl blend combinations to WebGL.
 */
export declare function mapWebGLBlendModesToPixi(gl: GlRenderingContext): Record<BLEND_MODES, number[]>;
/**
 * Various GL texture/resources formats.
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} [RGBA=6408] -
 * @property {number} [RGB=6407] -
 * @property {number} [RG=33319] -
 * @property {number} [RED=6403] -
 * @property {number} [RGBA_INTEGER=36249] -
 * @property {number} [RGB_INTEGER=36248] -
 * @property {number} [RG_INTEGER=33320] -
 * @property {number} [RED_INTEGER=36244] -
 * @property {number} [ALPHA=6406] -
 * @property {number} [LUMINANCE=6409] -
 * @property {number} [LUMINANCE_ALPHA=6410] -
 * @property {number} [DEPTH_COMPONENT=6402] -
 * @property {number} [DEPTH_STENCIL=34041] -
 */
export declare enum GL_FORMATS {
	RGBA = 6408,
	RGB = 6407,
	RG = 33319,
	RED = 6403,
	RGBA_INTEGER = 36249,
	RGB_INTEGER = 36248,
	RG_INTEGER = 33320,
	RED_INTEGER = 36244,
	ALPHA = 6406,
	LUMINANCE = 6409,
	LUMINANCE_ALPHA = 6410,
	DEPTH_COMPONENT = 6402,
	DEPTH_STENCIL = 34041
}
/**
 * Various GL target types.
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} [TEXTURE_2D=3553] -
 * @property {number} [TEXTURE_CUBE_MAP=34067] -
 * @property {number} [TEXTURE_2D_ARRAY=35866] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_X=34069] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_X=34070] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_Y=34071] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_Y=34072] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_Z=34073] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_Z=34074] -
 */
export declare enum GL_TARGETS {
	TEXTURE_2D = 3553,
	TEXTURE_CUBE_MAP = 34067,
	TEXTURE_2D_ARRAY = 35866,
	TEXTURE_CUBE_MAP_POSITIVE_X = 34069,
	TEXTURE_CUBE_MAP_NEGATIVE_X = 34070,
	TEXTURE_CUBE_MAP_POSITIVE_Y = 34071,
	TEXTURE_CUBE_MAP_NEGATIVE_Y = 34072,
	TEXTURE_CUBE_MAP_POSITIVE_Z = 34073,
	TEXTURE_CUBE_MAP_NEGATIVE_Z = 34074
}
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 * @name WRAP_MODES
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */
export declare enum GL_WRAP_MODES {
	CLAMP = 33071,
	REPEAT = 10497,
	MIRRORED_REPEAT = 33648
}
export declare enum GL_TYPES {
	/**
	 * 8 bits per channel for gl.RGBA
	 * @default 5121
	 */
	UNSIGNED_BYTE = 5121,
	/**
	 * @default 5123
	 */
	UNSIGNED_SHORT = 5123,
	/**
	 * 5 red bits, 6 green bits, 5 blue bits.
	 * @default 33635
	 */
	UNSIGNED_SHORT_5_6_5 = 33635,
	/**
	 * 4 red bits, 4 green bits, 4 blue bits, 4 alpha bits.
	 * @default 32819
	 */
	UNSIGNED_SHORT_4_4_4_4 = 32819,
	/**
	 * 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit.
	 * @default 32820
	 */
	UNSIGNED_SHORT_5_5_5_1 = 32820,
	/**
	 * @default 5125
	 */
	UNSIGNED_INT = 5125,
	/**
	 * @default 35899
	 */
	UNSIGNED_INT_10F_11F_11F_REV = 35899,
	/**
	 * @default 33640
	 */
	UNSIGNED_INT_2_10_10_10_REV = 33640,
	/**
	 * @default 34042
	 */
	UNSIGNED_INT_24_8 = 34042,
	/**
	 * @default 35902
	 */
	UNSIGNED_INT_5_9_9_9_REV = 35902,
	/**
	 * @default 5120
	 */
	BYTE = 5120,
	/**
	 * @default 5122
	 */
	SHORT = 5122,
	/**
	 * @default 5124
	 */
	INT = 5124,
	/**
	 * @default 5126
	 */
	FLOAT = 5126,
	/**
	 * @default 36269
	 */
	FLOAT_32_UNSIGNED_INT_24_8_REV = 36269,
	/**
	 * @default 36193
	 */
	HALF_FLOAT = 36193
}
/**
 * Internal texture for WebGL context
 * @memberof rendering
 * @ignore
 */
export declare class GlTexture {
	target: GL_TARGETS;
	/** The WebGL texture. */
	texture: WebGLTexture;
	/** Width of texture that was used in texImage2D. */
	width: number;
	/** Height of texture that was used in texImage2D. */
	height: number;
	/** Whether mip levels has to be generated. */
	mipmap: boolean;
	/** Type copied from texture source. */
	type: number;
	/** Type copied from texture source. */
	internalFormat: number;
	/** Type of sampler corresponding to this texture. See {@link SAMPLER_TYPES} */
	samplerType: number;
	format: GL_FORMATS;
	constructor(texture: WebGLTexture);
}
/**
 * The system for managing textures in WebGL.
 * @memberof rendering
 */
export declare class GlTextureSystem implements System, CanvasGenerator {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem
		];
		readonly name: "texture";
	};
	readonly managedTextures: TextureSource[];
	private readonly _renderer;
	private _glTextures;
	private _glSamplers;
	private _boundTextures;
	private _activeTextureLocation;
	private _boundSamplers;
	private readonly _uploads;
	private _gl;
	private _mapFormatToInternalFormat;
	private _mapFormatToType;
	private _mapFormatToFormat;
	private _premultiplyAlpha;
	private readonly _useSeparateSamplers;
	constructor(renderer: WebGLRenderer);
	protected contextChange(gl: GlRenderingContext): void;
	initSource(source: TextureSource): void;
	bind(texture: BindableTexture, location?: number): void;
	bindSource(source: TextureSource, location?: number): void;
	private _bindSampler;
	unbind(texture: BindableTexture): void;
	private _activateLocation;
	private _initSource;
	protected onStyleChange(source: TextureSource): void;
	protected updateStyle(source: TextureSource, firstCreation: boolean): void;
	protected onSourceUnload(source: TextureSource): void;
	protected onSourceUpdate(source: TextureSource): void;
	protected onUpdateMipmaps(source: TextureSource, bind?: boolean): void;
	protected onSourceDestroy(source: TextureSource): void;
	private _initSampler;
	private _getGlSampler;
	getGlSource(source: TextureSource): GlTexture;
	generateCanvas(texture: Texture): ICanvas;
	getPixels(texture: Texture): GetPixelsOutput;
	destroy(): void;
	resetState(): void;
}
export interface GLTextureUploader {
	id: string;
	upload(source: TextureSource, glTexture: GlTexture, gl: GlRenderingContext, webGLVersion: number): void;
}
export declare const glUploadBufferImageResource: GLTextureUploader;
export declare const glUploadCompressedTextureResource: GLTextureUploader;
export declare const glUploadImageResource: GLTextureUploader;
export declare const glUploadVideoResource: GLTextureUploader;
export declare function applyStyleParams(style: TextureStyle, gl: WebGL2RenderingContext, mipmaps: boolean, anisotropicExt: EXT_texture_filter_anisotropic, glFunctionName: "samplerParameteri" | "texParameteri", firstParam: 3553 | WebGLSampler, forceClamp: boolean, 
/** if true we can skip setting certain values if the values is the same as the default gl values */
firstCreation: boolean): void;
export declare function getSupportedGlCompressedTextureFormats(): TEXTURE_FORMATS[];
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @returns Lookup table.
 */
export declare function mapFormatToGlFormat(gl: GlRenderingContext): Record<string, number>;
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param gl - The rendering context.
 * @param extensions - The WebGL extensions.
 * @returns Lookup table.
 */
export declare function mapFormatToGlInternalFormat(gl: GlRenderingContext, extensions: WebGLExtensions): Record<string, number>;
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @returns Lookup table.
 */
export declare function mapFormatToGlType(gl: GlRenderingContext): Record<string, number>;
export declare const scaleModeToGlFilter: {
	linear: number;
	nearest: number;
};
export declare const mipmapScaleModeToGlFilter: {
	linear: {
		linear: number;
		nearest: number;
	};
	nearest: {
		linear: number;
		nearest: number;
	};
};
export declare const wrapModeToGlAddress: {
	"clamp-to-edge": number;
	repeat: number;
	"mirror-repeat": number;
};
export declare const compareModeToGlCompare: {
	never: number;
	less: number;
	equal: number;
	"less-equal": number;
	greater: number;
	"not-equal": number;
	"greater-equal": number;
	always: number;
};
export declare function unpremultiplyAlpha(pixels: Uint8Array | Uint8ClampedArray): void;
export declare function GpuReadBuffer(buffer: Buffer$1, renderer: WebGPURenderer): void;
export declare class UboBatch {
	data: Float32Array;
	private readonly _minUniformOffsetAlignment;
	byteIndex: number;
	constructor({ minUniformOffsetAlignment }: {
		minUniformOffsetAlignment: number;
	});
	clear(): void;
	addEmptyGroup(size: number): number;
	addGroup(array: Float32Array): number;
	destroy(): void;
}
export declare function calculateProjection(pm: Matrix, x: number, y: number, width: number, height: number, flipY: boolean): Matrix;
export declare const WGSL_ALIGN_SIZE_DATA: Record<UNIFORM_TYPES | string, {
	align: number;
	size: number;
}>;
export declare function createUboElementsWGSL(uniformData: UniformData[]): UboLayout;
export declare function createUboSyncFunctionWGSL(uboElements: UboElement[]): UniformsSyncCallback;
export declare function extractAttributesFromGpuProgram({ source, entryPoint }: ProgramSource): Record<string, ExtractedAttributeData>;
/**
 * This generates a function that will sync an array to the uniform buffer
 * following the wgsl layout
 * @param uboElement - the element to generate the array sync for
 * @param offsetToAdd - the offset to append at the start of the code
 * @returns - the generated code
 */
export declare function generateArraySyncWGSL(uboElement: UboElement, offsetToAdd: number): string;
export declare function generateGpuLayoutGroups({ groups }: StructsAndGroups): ProgramPipelineLayoutDescription;
export declare function generateLayoutHash({ groups }: StructsAndGroups): ProgramLayout;
export declare function removeStructAndGroupDuplicates(vertexStructsAndGroups: StructsAndGroups, fragmentStructsAndGroups: StructsAndGroups): {
	structs: {
		name: string;
		members: Record<string, string>;
	}[];
	groups: {
		group: number;
		binding: number;
		name: string;
		isUniform: boolean;
		type: string;
	}[];
};
export declare const GpuBlendModesToPixi: Partial<Record<BLEND_MODES, GPUBlendState>>;
export interface StencilState {
	stencilWriteMask?: number;
	stencilReadMask?: number;
	stencilFront?: {
		compare: "always" | "equal" | "not-equal";
		passOp: "increment-clamp" | "decrement-clamp" | "keep" | "replace";
	};
	stencilBack?: {
		compare: "always" | "equal" | "not-equal";
		passOp: "increment-clamp" | "decrement-clamp" | "keep" | "replace";
	};
}
export declare const GpuStencilModesToPixi: StencilState[];
export interface GpuTextureUploader<T extends TextureSource = TextureSource> {
	type: string;
	upload(source: T, gpuTexture: GPUTexture, gpu: GPU$1): void;
}
export declare const gpuUploadBufferImageResource: GpuTextureUploader<BufferImageSource>;
export declare class CompressedSource extends TextureSource<Uint8Array[]> {
	readonly uploadMethodId = "compressed";
	constructor(options: TextureSourceOptions);
}
export declare const blockDataMap: Record<string, {
	blockBytes: number;
	blockWidth: number;
	blockHeight: number;
}>;
export declare const gpuUploadCompressedTextureResource: GpuTextureUploader<CompressedSource>;
export declare const gpuUploadImageResource: GpuTextureUploader<TextureSource<any>>;
export type ArrayFixed<T, L extends number> = [
	T,
	...Array<T>
] & {
	length: L;
};
export type Dict<T> = {
	[key: string]: T;
};
type VideoResource = HTMLVideoElement;
/**
 * Options for video sources.
 * @memberof rendering
 */
export interface VideoSourceOptions extends TextureSourceOptions<VideoResource> {
	/** If true, the video will start loading immediately. */
	autoLoad?: boolean;
	/** If true, the video will start playing as soon as it is loaded. */
	autoPlay?: boolean;
	/** The number of times a second to update the texture from the video. Leave at 0 to update at every render. */
	updateFPS?: number;
	/** If true, the video will be loaded with the \`crossorigin\` attribute. */
	crossorigin?: boolean | string;
	/** If true, the video will loop when it ends. */
	loop?: boolean;
	/** If true, the video will be muted. */
	muted?: boolean;
	/** If true, the video will play inline. */
	playsinline?: boolean;
	/** If true, the video will be preloaded. */
	preload?: boolean;
	/** The time in milliseconds to wait for the video to preload before timing out. */
	preloadTimeoutMs?: number;
	/** The alpha mode of the video. */
	alphaMode?: ALPHA_MODES;
}
export interface VideoResourceOptionsElement {
	src: string;
	mime: string;
}
/**
 * A source for video-based textures.
 * @memberof rendering
 */
export declare class VideoSource extends TextureSource<VideoResource> {
	static extension: ExtensionMetadata;
	/** The default options for video sources. */
	static defaultOptions: VideoSourceOptions;
	/** Whether or not the video is ready to play. */
	isReady: boolean;
	/** The upload method for this texture. */
	uploadMethodId: string;
	/**
	 * When set to true will automatically play videos used by this texture once
	 * they are loaded. If false, it will not modify the playing state.
	 * @default true
	 */
	protected autoPlay: boolean;
	/**
	 * \`true\` to use Ticker.shared to auto update the base texture.
	 * @default true
	 */
	private _autoUpdate;
	/**
	 * \`true\` if the instance is currently connected to Ticker.shared to auto update the base texture.
	 * @default false
	 */
	private _isConnectedToTicker;
	/**
	 * Promise when loading.
	 * @default null
	 */
	private _load;
	private _msToNextUpdate;
	private _preloadTimeout;
	/** Callback when completed with load. */
	private _resolve;
	private _reject;
	private _updateFPS;
	private _videoFrameRequestCallbackHandle;
	constructor(options: VideoSourceOptions);
	/** Update the video frame if the source is not destroyed and meets certain conditions. */
	protected updateFrame(): void;
	/** Callback to update the video frame and potentially request the next frame update. */
	private _videoFrameRequestCallback;
	/**
	 * Checks if the resource has valid dimensions.
	 * @returns {boolean} True if width and height are set, otherwise false.
	 */
	get isValid(): boolean;
	/**
	 * Start preloading the video resource.
	 * @returns {Promise<this>} Handle the validate event
	 */
	load(): Promise<this>;
	/**
	 * Handle video error events.
	 * @param event - The error event
	 */
	private _onError;
	/**
	 * Checks if the underlying source is playing.
	 * @returns True if playing.
	 */
	private _isSourcePlaying;
	/**
	 * Checks if the underlying source is ready for playing.
	 * @returns True if ready.
	 */
	private _isSourceReady;
	/** Runs the update loop when the video is ready to play. */
	private _onPlayStart;
	/** Stops the update loop when a pause event is triggered. */
	private _onPlayStop;
	/** Handles behavior when the video completes seeking to the current playback position. */
	private _onSeeked;
	private _onCanPlay;
	private _onCanPlayThrough;
	/** Fired when the video is loaded and ready to play. */
	private _mediaReady;
	/** Cleans up resources and event listeners associated with this texture. */
	destroy(): void;
	/** Should the base texture automatically update itself, set to true by default. */
	get autoUpdate(): boolean;
	set autoUpdate(value: boolean);
	/**
	 * How many times a second to update the texture from the video.
	 * Leave at 0 to update at every render.
	 * A lower fps can help performance, as updating the texture at 60fps on a 30ps video may not be efficient.
	 */
	get updateFPS(): number;
	set updateFPS(value: number);
	/**
	 * Configures the updating mechanism based on the current state and settings.
	 *
	 * This method decides between using the browser's native video frame callback or a custom ticker
	 * for updating the video frame. It ensures optimal performance and responsiveness
	 * based on the video's state, playback status, and the desired frames-per-second setting.
	 *
	 * - If \`_autoUpdate\` is enabled and the video source is playing:
	 *   - It will prefer the native video frame callback if available and no specific FPS is set.
	 *   - Otherwise, it will use a custom ticker for manual updates.
	 * - If \`_autoUpdate\` is disabled or the video isn't playing, any active update mechanisms are halted.
	 */
	private _configureAutoUpdate;
	/**
	 * Map of video MIME types that can't be directly derived from file extensions.
	 * @readonly
	 */
	static MIME_TYPES: Dict<string>;
	static test(resource: any): resource is VideoResource;
}
export declare const gpuUploadVideoResource: GpuTextureUploader<VideoSource>;
export declare function getSupportedGPUCompressedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
/**
 * A class which generates mipmaps for a GPUTexture.
 * Thanks to @toji for the original implementation
 * https://github.com/toji/web-texture-tool/blob/main/src/webgpu-mipmap-generator.js
 * @memberof rendering
 * @ignore
 */
export declare class GpuMipmapGenerator {
	device: GPUDevice;
	sampler: GPUSampler;
	pipelines: Record<string, GPURenderPipeline>;
	mipmapShaderModule: any;
	constructor(device: GPUDevice);
	private _getMipmapPipeline;
	/**
	 * Generates mipmaps for the given GPUTexture from the data in level 0.
	 * @param {module:External.GPUTexture} texture - Texture to generate mipmaps for.
	 * @returns {module:External.GPUTexture} - The originally passed texture
	 */
	generateMipmap(texture: GPUTexture): GPUTexture;
}
interface AdvancedBlendInstruction extends Instruction {
	renderPipeId: "blendMode";
	blendMode: BLEND_MODES;
	activeBlend: Renderable[];
}
/**
 * This Pipe handles the blend mode switching of the renderer.
 * It will insert instructions into the {@link renderers.InstructionSet} to switch the blend mode according to the
 * blend modes of the scene graph.
 *
 * This pipe is were wwe handle Advanced blend modes. Advanced blend modes essentially wrap the renderables
 * in a filter that applies the blend mode.
 *
 * You only need to use this class if you are building your own render instruction set rather than letting PixiJS build
 * the instruction set for you by traversing the scene graph
 * @memberof rendering
 */
export declare class BlendModePipe implements InstructionPipe<AdvancedBlendInstruction> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "blendMode";
	};
	private _renderer;
	private _renderableList;
	private _activeBlendMode;
	private _isAdvanced;
	private _filterHash;
	constructor(renderer: Renderer);
	prerender(): void;
	/**
	 * This ensures that a blendMode switch is added to the instruction set if the blend mode has changed.
	 * @param renderable - The renderable we are adding to the instruction set
	 * @param blendMode - The blend mode of the renderable
	 * @param instructionSet - The instruction set we are adding to
	 */
	setBlendMode(renderable: Renderable, blendMode: BLEND_MODES, instructionSet: InstructionSet): void;
	private _beginAdvancedBlendMode;
	private _endAdvancedBlendMode;
	/**
	 * called when the instruction build process is starting this will reset internally to the default blend mode
	 * @internal
	 * @ignore
	 */
	buildStart(): void;
	/**
	 * called when the instruction build process is finished, ensuring that if there is an advanced blend mode
	 * active, we add the final render instructions added to the instruction set
	 * @param instructionSet - The instruction set we are adding to
	 * @internal
	 * @ignore
	 */
	buildEnd(instructionSet: InstructionSet): void;
	/**
	 * @internal
	 * @ignore
	 */
	destroy(): void;
}
/**
 * Copies from one buffer to another.
 * This is an optimised function that will use \`Float64Array\` window.
 * This means it can copy twice as fast!
 * @param sourceBuffer - the array buffer to copy from
 * @param destinationBuffer - the array buffer to copy to
 * @private
 */
export declare function fastCopy(sourceBuffer: ArrayBuffer, destinationBuffer: ArrayBuffer): void;
declare const imageTypes: {
	png: string;
	jpg: string;
	webp: string;
};
type Formats = keyof typeof imageTypes;
/**
 * Options for creating an image from a renderer.
 * @memberof rendering
 */
export interface ImageOptions {
	/** The format of the image. */
	format?: Formats;
	/** The quality of the image. */
	quality?: number;
}
/**
 * Options for extracting content from a renderer.
 * @memberof rendering
 */
export interface BaseExtractOptions {
	/** The target to extract. */
	target: Container | Texture;
	/** The region of the target to extract. */
	frame?: Rectangle;
	/** The resolution of the extracted content. */
	resolution?: number;
	/** The color used to clear the extracted content. */
	clearColor?: ColorSource;
	/** Whether to enable anti-aliasing. This may affect performance. */
	antialias?: boolean;
}
/**
 * Options for extracting an HTMLImage from the renderer.
 * @memberof rendering
 */
export type ExtractImageOptions = BaseExtractOptions & ImageOptions;
/**
 * Options for extracting and downloading content from a renderer.
 * @memberof rendering
 */
export type ExtractDownloadOptions = BaseExtractOptions & {
	/** The filename to use when downloading the content. */
	filename: string;
};
/**
 * Options for extracting content from a renderer.
 * @memberof rendering
 */
export type ExtractOptions = BaseExtractOptions | ExtractImageOptions | ExtractDownloadOptions;
/**
 * This class provides renderer-specific plugins for exporting content from a renderer.
 * For instance, these plugins can be used for saving an Image, Canvas element or for exporting the raw image data (pixels).
 *
 * Do not instantiate these plugins directly. It is available from the \`renderer.extract\` property.
 * @example
 * import { Application, Graphics } from 'pixi.js';
 *
 * // Create a new application (extract will be auto-added to renderer)
 * const app = new Application();
 * await app.init();
 *
 * // Draw a red circle
 * const graphics = new Graphics()
 *     .circle(0, 0, 50);
 *     .fill(0xFF0000)
 *
 * // Render the graphics as an HTMLImageElement
 * const image = await app.renderer.extract.image(graphics);
 * document.body.appendChild(image);
 * @memberof rendering
 */
export declare class ExtractSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "extract";
	};
	/** Default options for creating an image. */
	static defaultImageOptions: ImageOptions;
	private _renderer;
	/** @param renderer - The renderer this System works for. */
	constructor(renderer: Renderer);
	private _normalizeOptions;
	/**
	 * Will return a HTML Image of the target
	 * @param options - The options for creating the image, or the target to extract
	 * @returns - HTML Image of the target
	 */
	image(options: ExtractImageOptions | Container | Texture): Promise<HTMLImageElement>;
	/**
	 * Will return a base64 encoded string of this target. It works by calling
	 * \`Extract.canvas\` and then running toDataURL on that.
	 * @param options - The options for creating the image, or the target to extract
	 */
	base64(options: ExtractImageOptions | Container | Texture): Promise<string>;
	/**
	 * Creates a Canvas element, renders this target to it and then returns it.
	 * @param options - The options for creating the canvas, or the target to extract
	 * @returns - A Canvas element with the texture rendered on.
	 */
	canvas(options: ExtractOptions | Container | Texture): ICanvas;
	/**
	 * Will return a one-dimensional array containing the pixel data of the entire texture in RGBA
	 * order, with integer values between 0 and 255 (included).
	 * @param options - The options for extracting the image, or the target to extract
	 * @returns - One-dimensional array containing the pixel data of the entire texture
	 */
	pixels(options: ExtractOptions | Container | Texture): GetPixelsOutput;
	/**
	 * Will return a texture of the target
	 * @param options - The options for creating the texture, or the target to extract
	 * @returns - A texture of the target
	 */
	texture(options: ExtractOptions | Container | Texture): Texture;
	/**
	 * Will extract a HTMLImage of the target and download it
	 * @param options - The options for downloading and extracting the image, or the target to extract
	 */
	download(options: ExtractDownloadOptions | Container | Texture): void;
	/**
	 * Logs the target to the console as an image. This is a useful way to debug what's happening in the renderer.
	 * @param options - The options for logging the image, or the target to log
	 */
	log(options: (ExtractOptions & {
		width?: number;
	}) | Container | Texture): void;
	destroy(): void;
}
/**
 * Takes a vertices array and a matrix and transforms the vertices based on the matrix.
 * this out put is written to the uvs array
 * @param vertices - the vertices to calculate uvs from
 * @param verticesStride - the stride of the vertice
 * @param verticesOffset - the offset of the vertices
 * @param uvs - the uvs to fill
 * @param uvsOffset - the offset of the uvs
 * @param uvsStride - the stride of the uvs
 * @param size - the size of the vertices
 * @param matrix - the matrix to apply to the uvs
 * @memberof rendering
 */
export declare function buildUvs(vertices: number[], verticesStride: number, verticesOffset: number, uvs: number[], uvsOffset: number, uvsStride: number, size: number, matrix?: Matrix): void;
export declare function buildSimpleUvs(uvs: number[], uvsOffset: number, uvsStride: number, size: number): void;
/**
 * Converts something into a buffer. If it is already a buffer it will pass it through
 * if it is a number array it will convert it to a float32 array before being passed into a buffer
 * the buffer will be created with the correct usage flags for geometry attributes
 * @param buffer - number array
 * @param index - is this an index buffer?
 * @returns a buffer
 * @memberof rendering
 */
export declare function ensureIsBuffer(buffer: Buffer$1 | TypedArray | number[], index: boolean): Buffer$1;
export declare function getAttributeInfoFromFormat(format: VertexFormat): {
	size: number;
	stride: number;
	normalised: boolean;
};
/**
 * Gets the 2D bounds of a geometry, based on a specific attribute.
 * @param geometry - Geometry to to measure
 * @param attributeId - AttributeId that contains the x,y data
 * @param bounds - Bounds to store the result in
 * @returns the bounds
 */
export declare function getGeometryBounds(geometry: Geometry, attributeId: string, bounds: Bounds): Bounds;
/**
 * Transforms the vertices in an array with the given matrix.
 * @param vertices - the vertices to transform
 * @param m - the matrix to apply to the vertices
 * @param offset - the offset of the vertices (defaults to 0)
 * @param stride - the stride of the vertices (defaults to 2)
 * @param size - the size of the vertices (defaults to vertices.length / stride - offset)
 * @memberof rendering
 */
export declare function transformVertices(vertices: number[], m: Matrix, offset?: number, stride?: number, size?: number): void;
export type GlobalUniformGroup = UniformGroup<{
	uProjectionMatrix: {
		value: Matrix;
		type: "mat3x3<f32>";
	};
	uWorldTransformMatrix: {
		value: Matrix;
		type: "mat3x3<f32>";
	};
	uWorldColorAlpha: {
		value: Float32Array;
		type: "vec4<f32>";
	};
	uResolution: {
		value: number[];
		type: "vec2<f32>";
	};
}>;
export interface GlobalUniformOptions {
	size?: number[];
	projectionMatrix?: Matrix;
	worldTransformMatrix?: Matrix;
	worldColor?: number;
	offset?: PointData;
}
export interface GlobalUniformData {
	projectionMatrix: Matrix;
	worldTransformMatrix: Matrix;
	worldColor: number;
	resolution: number[];
	offset: PointData;
	bindGroup: BindGroup;
}
export interface GlobalUniformRenderer {
	renderTarget: GlRenderTargetSystem | GpuRenderTargetSystem;
	renderPipes: Renderer["renderPipes"];
	ubo: UboSystem;
	type: RendererType;
}
/**
 * System plugin to the renderer to manage global uniforms for the renderer.
 * @memberof rendering
 */
export declare class GlobalUniformSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "globalUniforms";
	};
	private readonly _renderer;
	private _stackIndex;
	private _globalUniformDataStack;
	private readonly _uniformsPool;
	private readonly _activeUniforms;
	private readonly _bindGroupPool;
	private readonly _activeBindGroups;
	private _currentGlobalUniformData;
	constructor(renderer: GlobalUniformRenderer);
	reset(): void;
	start(options: GlobalUniformOptions): void;
	bind({ size, projectionMatrix, worldTransformMatrix, worldColor, offset, }: GlobalUniformOptions): void;
	push(options: GlobalUniformOptions): void;
	pop(): void;
	get bindGroup(): BindGroup;
	get globalUniformData(): GlobalUniformData;
	get uniformGroup(): UniformGroup<any>;
	private _createUniforms;
	destroy(): void;
}
/**
 * Checks if the render target is viewable on the screen
 * Basically, is it a canvas element and is that canvas element in the DOM
 * @param renderTarget - the render target to check
 * @returns true if the render target is viewable on the screen
 */
export declare function isRenderingToScreen(renderTarget: RenderTarget): boolean;
/**
 * Takes a Texture source and a normalised frame
 * and returns a viewport for that frame.
 * @param viewport - The viewport rectangle to set.
 * @param source - The source to get the pixel width and height from.
 * @param frame - The frame to get the viewport from.
 * @returns the passed in viewport.
 */
export declare function viewportFromFrame(viewport: Rectangle, source: TextureSource, frame?: Rectangle): Rectangle;
/**
 * The SchedulerSystem manages scheduled tasks with specific intervals.
 * @memberof rendering
 */
export declare class SchedulerSystem implements System<null> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "scheduler";
		readonly priority: 0;
	};
	private readonly _tasks;
	/** a small off set to apply to the repeat schedules. This is just to make sure they run at slightly different times */
	private _offset;
	/** Initializes the scheduler system and starts the ticker. */
	init(): void;
	/**
	 * Schedules a repeating task.
	 * @param func - The function to execute.
	 * @param duration - The interval duration in milliseconds.
	 * @param useOffset - this will spread out tasks so that they do not all run at the same time
	 * @returns The unique identifier for the scheduled task.
	 */
	repeat(func: (elapsed: number) => void, duration: number, useOffset?: boolean): number;
	/**
	 * Cancels a scheduled task.
	 * @param id - The unique identifier of the task to cancel.
	 */
	cancel(id: number): void;
	/**
	 * Updates and executes the scheduled tasks.
	 * @private
	 */
	private _update;
	/**
	 * Destroys the scheduler system and removes all tasks.
	 * @internal
	 * @ignore
	 */
	destroy(): void;
}
export declare enum ShaderStage {
	VERTEX = 1,
	FRAGMENT = 2,
	COMPUTE = 4
}
export declare function createUboSyncFunction(uboElements: UboElement[], parserCode: "uboWgsl" | "uboStd40", arrayGenerationFunction: (uboElement: UboElement, offsetToAdd: number) => string, singleSettersMap: Record<UNIFORM_TYPES_SINGLE, string>): UniformsSyncCallback;
/**
 * @method defaultValue
 * @param {string} type - Type of value
 * @param {number} size
 * @private
 */
export declare function getDefaultUniformValue(type: string, size: number): number | Float32Array | Int32Array | Uint32Array | boolean | boolean[];
export declare const uboSyncFunctionsSTD40: Record<UNIFORM_TYPES_SINGLE, string>;
export declare const uboSyncFunctionsWGSL: Record<UNIFORM_TYPES_SINGLE, string>;
export interface UniformParserDefinition {
	type: UNIFORM_TYPES;
	test(data: UniformData): boolean;
	ubo?: string;
	uboWgsl?: string;
	uboStd40?: string;
	uniform?: string;
}
export declare const uniformParsers: UniformParserDefinition[];
/**
 * Options for the startup system.
 * @property {boolean} [hello=false] - Whether to log the version and type information of renderer to console.
 * @memberof rendering
 */
export interface HelloSystemOptions {
	/**
	 * Whether to log the version and type information of renderer to console.
	 * @memberof rendering.SharedRendererOptions
	 * @default false
	 */
	hello: boolean;
}
/**
 * A simple system responsible for initiating the renderer.
 * @memberof rendering
 */
export declare class HelloSystem implements System<HelloSystemOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "hello";
		readonly priority: -2;
	};
	/** The default options for the system. */
	static defaultOptions: HelloSystemOptions;
	private readonly _renderer;
	constructor(renderer: Renderer);
	/**
	 * It all starts here! This initiates every system, passing in the options for any system by name.
	 * @param options - the config for the renderer and all its systems
	 */
	init(options: HelloSystemOptions): void;
}
/**
 * Adjusts a blend mode for the current alpha mode. Returns the blend mode that works with that format.
 * eg 'normal' blend mode will return 'normal-npm' when rendering with premultiplied alpha.
 * and 'normal' if the texture is already premultiplied (the default)
 * @param blendMode - The blend mode to get the adjusted blend mode for.
 * @param textureSource - The texture to test the format of.
 * @returns - the blend mode that should be used to render this texture correctly based on its alphaMode
 */
export declare function getAdjustedBlendModeBlend(blendMode: BLEND_MODES, textureSource: TextureSource): BLEND_MODES;
export interface CanvasAndContext {
	canvas: ICanvas;
	context: ICanvasRenderingContext2D;
}
/**
 * Texture pool, used by FilterSystem and plugins.
 *
 * Stores collection of temporary pow2 or screen-sized renderTextures
 *
 * If you use custom RenderTexturePool for your filters, you can use methods
 * \`getFilterTexture\` and \`returnFilterTexture\` same as in
 * @name CanvasPool
 * @memberof rendering
 */
export declare class CanvasPoolClass {
	canvasOptions: ICanvasRenderingContext2DSettings;
	/**
	 * Allow renderTextures of the same size as screen, not just pow2
	 *
	 * Automatically sets to true after \`setScreenSize\`
	 * @default false
	 */
	enableFullScreen: boolean;
	private _canvasPool;
	constructor(canvasOptions?: ICanvasRenderingContext2DSettings);
	/**
	 * Creates texture with params that were specified in pool constructor.
	 * @param pixelWidth - Width of texture in pixels.
	 * @param pixelHeight - Height of texture in pixels.
	 */
	private _createCanvasAndContext;
	/**
	 * Gets a Power-of-Two render texture or fullScreen texture
	 * @param minWidth - The minimum width of the render texture.
	 * @param minHeight - The minimum height of the render texture.
	 * @param resolution - The resolution of the render texture.
	 * @returns The new render texture.
	 */
	getOptimalCanvasAndContext(minWidth: number, minHeight: number, resolution?: number): CanvasAndContext;
	/**
	 * Place a render texture back into the pool.
	 * @param canvasAndContext
	 */
	returnCanvasAndContext(canvasAndContext: CanvasAndContext): void;
	clear(): void;
}
export declare const CanvasPool: CanvasPoolClass;
/**
 * Options for the {@link RenderableGCSystem}.
 * @memberof rendering
 * @property {boolean} [renderableGCActive=true] - If set to true, this will enable the garbage collector on the renderables.
 * @property {number} [renderableGCAMaxIdle=60000] -
 * The maximum idle frames before a texture is destroyed by garbage collection.
 * @property {number} [renderableGCCheckCountMax=60000] - time between two garbage collections.
 */
export interface RenderableGCSystemOptions {
	/**
	 * If set to true, this will enable the garbage collector on the GPU.
	 * @default true
	 * @memberof rendering.SharedRendererOptions
	 */
	renderableGCActive: boolean;
	/**
	 * The maximum idle frames before a texture is destroyed by garbage collection.
	 * @default 60 * 60
	 * @memberof rendering.SharedRendererOptions
	 */
	renderableGCMaxUnusedTime: number;
	/**
	 * Frames between two garbage collections.
	 * @default 600
	 * @memberof rendering.SharedRendererOptions
	 */
	renderableGCFrequency: number;
}
/**
 * The RenderableGCSystem is responsible for cleaning up GPU resources that are no longer being used.
 *
 * When rendering objects like sprites, text, etc - GPU resources are created and managed by the renderer.
 * If these objects are no longer needed but not properly destroyed (via sprite.destroy()), their GPU resources
 * would normally leak. This system prevents that by automatically cleaning up unused GPU resources.
 *
 * Key features:
 * - Runs every 30 seconds by default to check for unused resources
 * - Cleans up resources not rendered for over 1 minute
 * - Works independently of rendering - will clean up even when not actively rendering
 * - When cleaned up resources are needed again, new GPU objects are quickly assigned from a pool
 * - Can be disabled with renderableGCActive:false for manual control
 *
 * Best practices:
 * - Always call destroy() explicitly when done with renderables (e.g. sprite.destroy())
 * - This system is a safety net, not a replacement for proper cleanup
 * - Adjust frequency and timeouts via options if needed
 *
 * Example:
 * \`\`\`js
 * // Sprite created but reference lost without destroy
 * let sprite = new Sprite(texture);
 *
 * // internally the renderer will assign a resource to the sprite
 * renderer.render(sprite);
 *
 * sprite = null; // Reference lost but GPU resources still exist
 *
 * // After 1 minute of not being rendered:
 * // - RenderableGC will clean up the sprite's GPU resources
 * // - JS garbage collector can then clean up the sprite itself
 * \`\`\`
 * @implements {System<RenderableGCSystemOptions>}
 */
export declare class RenderableGCSystem implements System<RenderableGCSystemOptions> {
	/**
	 * Extension metadata for registering this system with the renderer.
	 * @ignore
	 */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "renderableGC";
		readonly priority: 0;
	};
	/**
	 * Default configuration options for the garbage collection system.
	 * These can be overridden when initializing the renderer.
	 */
	static defaultOptions: RenderableGCSystemOptions;
	/** Maximum time in ms a resource can be unused before being garbage collected */
	maxUnusedTime: number;
	/** Reference to the renderer this system belongs to */
	private _renderer;
	/** Array of renderables being tracked for garbage collection */
	private readonly _managedRenderables;
	/** ID of the main GC scheduler handler */
	private _handler;
	/** How frequently GC runs in ms */
	private _frequency;
	/** Current timestamp used for age calculations */
	private _now;
	/** Array of hash objects being tracked for cleanup */
	private readonly _managedHashes;
	/** ID of the hash cleanup scheduler handler */
	private _hashHandler;
	/** Array of arrays being tracked for cleanup */
	private readonly _managedArrays;
	/** ID of the array cleanup scheduler handler */
	private _arrayHandler;
	/**
	 * Creates a new RenderableGCSystem instance.
	 * @param renderer - The renderer this garbage collection system works for
	 */
	constructor(renderer: Renderer);
	/**
	 * Initializes the garbage collection system with the provided options.
	 * @param options - Configuration options for the renderer
	 */
	init(options: RenderableGCSystemOptions): void;
	/**
	 * Gets whether the garbage collection system is currently enabled.
	 * @returns True if GC is enabled, false otherwise
	 */
	get enabled(): boolean;
	/**
	 * Enables or disables the garbage collection system.
	 * When enabled, schedules periodic cleanup of resources.
	 * When disabled, cancels all scheduled cleanups.
	 */
	set enabled(value: boolean);
	/**
	 * Adds a hash table to be managed by the garbage collector.
	 * @param context - The object containing the hash table
	 * @param hash - The property name of the hash table
	 */
	addManagedHash<T>(context: T, hash: string): void;
	/**
	 * Adds an array to be managed by the garbage collector.
	 * @param context - The object containing the array
	 * @param hash - The property name of the array
	 */
	addManagedArray<T>(context: T, hash: string): void;
	/**
	 * Updates the GC timestamp and tracking before rendering.
	 * @param options - The render options
	 * @param options.container - The container to render
	 */
	prerender({ container }: RenderOptions): void;
	/**
	 * Starts tracking a renderable for garbage collection.
	 * @param renderable - The renderable to track
	 */
	addRenderable(renderable: Renderable): void;
	/**
	 * Performs garbage collection by cleaning up unused renderables.
	 * Removes renderables that haven't been used for longer than maxUnusedTime.
	 */
	run(): void;
	/** Cleans up the garbage collection system. Disables GC and removes all tracked resources. */
	destroy(): void;
	/**
	 * Removes a renderable from being tracked when it's destroyed.
	 * @param renderable - The renderable to stop tracking
	 */
	private _removeRenderable;
	/**
	 * Updates the GC tick counter for a render group and its children.
	 * @param renderGroup - The render group to update
	 * @param gcTick - The new tick value
	 */
	private _updateInstructionGCTick;
}
/**
 * Options for the {@link TextureGCSystem}.
 * @memberof rendering
 * @property {boolean} [textureGCActive=true] - If set to true, this will enable the garbage collector on the GPU.
 * @property {number} [textureGCAMaxIdle=60 * 60] -
 * The maximum idle frames before a texture is destroyed by garbage collection.
 * @property {number} [textureGCCheckCountMax=600] - Frames between two garbage collections.
 */
export interface TextureGCSystemOptions {
	/**
	 * If set to true, this will enable the garbage collector on the GPU.
	 * @default true
	 * @memberof rendering.SharedRendererOptions
	 */
	textureGCActive: boolean;
	/**
	 * @deprecated since 8.3.0
	 * @see {@link TextureGCSystem.textureGCMaxIdle}
	 * @memberof rendering.SharedRendererOptions
	 */
	textureGCAMaxIdle: number;
	/**
	 * The maximum idle frames before a texture is destroyed by garbage collection.
	 * @default 60 * 60
	 * @memberof rendering.SharedRendererOptions
	 */
	textureGCMaxIdle: number;
	/**
	 * Frames between two garbage collections.
	 * @default 600
	 * @memberof rendering.SharedRendererOptions
	 */
	textureGCCheckCountMax: number;
}
/**
 * System plugin to the renderer to manage texture garbage collection on the GPU,
 * ensuring that it does not get clogged up with textures that are no longer being used.
 * @memberof rendering
 */
export declare class TextureGCSystem implements System<TextureGCSystemOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "textureGC";
	};
	/** default options for the TextureGCSystem */
	static defaultOptions: TextureGCSystemOptions;
	/**
	 * Frame count since started.
	 * @readonly
	 */
	count: number;
	/**
	 * Frame count since last garbage collection.
	 * @readonly
	 */
	checkCount: number;
	/**
	 * Maximum idle frames before a texture is destroyed by garbage collection.
	 * @see TextureGCSystem.defaultMaxIdle
	 */
	maxIdle: number;
	/**
	 * Frames between two garbage collections.
	 * @see TextureGCSystem.defaultCheckCountMax
	 */
	checkCountMax: number;
	/**
	 * Current garbage collection mode.
	 * @see TextureGCSystem.defaultMode
	 */
	active: boolean;
	private _renderer;
	/** @param renderer - The renderer this System works for. */
	constructor(renderer: Renderer);
	init(options: TextureGCSystemOptions): void;
	/**
	 * Checks to see when the last time a texture was used.
	 * If the texture has not been used for a specified amount of time, it will be removed from the GPU.
	 */
	protected postrender(): void;
	/**
	 * Checks to see when the last time a texture was used.
	 * If the texture has not been used for a specified amount of time, it will be removed from the GPU.
	 */
	run(): void;
	destroy(): void;
}
/**
 * Texture pool, used by FilterSystem and plugins.
 *
 * Stores collection of temporary pow2 or screen-sized renderTextures
 *
 * If you use custom RenderTexturePool for your filters, you can use methods
 * \`getFilterTexture\` and \`returnFilterTexture\` same as in default pool
 * @memberof rendering
 * @name TexturePool
 */
export declare class TexturePoolClass {
	/** The default options for texture pool */
	textureOptions: TextureSourceOptions;
	/**
	 * Allow renderTextures of the same size as screen, not just pow2
	 *
	 * Automatically sets to true after \`setScreenSize\`
	 * @default false
	 */
	enableFullScreen: boolean;
	private _texturePool;
	private _poolKeyHash;
	/**
	 * @param textureOptions - options that will be passed to BaseRenderTexture constructor
	 * @param {SCALE_MODE} [textureOptions.scaleMode] - See {@link SCALE_MODE} for possible values.
	 */
	constructor(textureOptions?: TextureSourceOptions);
	/**
	 * Creates texture with params that were specified in pool constructor.
	 * @param pixelWidth - Width of texture in pixels.
	 * @param pixelHeight - Height of texture in pixels.
	 * @param antialias
	 */
	createTexture(pixelWidth: number, pixelHeight: number, antialias: boolean): Texture;
	/**
	 * Gets a Power-of-Two render texture or fullScreen texture
	 * @param frameWidth - The minimum width of the render texture.
	 * @param frameHeight - The minimum height of the render texture.
	 * @param resolution - The resolution of the render texture.
	 * @param antialias
	 * @returns The new render texture.
	 */
	getOptimalTexture(frameWidth: number, frameHeight: number, resolution: number, antialias: boolean): Texture;
	/**
	 * Gets extra texture of the same size as input renderTexture
	 * @param texture - The texture to check what size it is.
	 * @param antialias - Whether to use antialias.
	 * @returns A texture that is a power of two
	 */
	getSameSizeTexture(texture: Texture, antialias?: boolean): Texture<TextureSource<any>>;
	/**
	 * Place a render texture back into the pool.
	 * @param renderTexture - The renderTexture to free
	 */
	returnTexture(renderTexture: Texture): void;
	/**
	 * Clears the pool.
	 * @param destroyTextures - Destroy all stored textures.
	 */
	clear(destroyTextures?: boolean): void;
}
export declare const TexturePool: TexturePoolClass;
/**
 * Stores a texture's frame in UV coordinates, in
 * which everything lies in the rectangle \`[(0,0), (1,0),
 * (1,1), (0,1)]\`.
 *
 * | Corner       | Coordinates |
 * |--------------|-------------|
 * | Top-Left     | \`(x0,y0)\`   |
 * | Top-Right    | \`(x1,y1)\`   |
 * | Bottom-Right | \`(x2,y2)\`   |
 * | Bottom-Left  | \`(x3,y3)\`   |
 * @protected
 * @memberof rendering
 */
export declare class TextureUvs {
	/** X-component of top-left corner \`(x0,y0)\`. */
	x0: number;
	/** Y-component of top-left corner \`(x0,y0)\`. */
	y0: number;
	/** X-component of top-right corner \`(x1,y1)\`. */
	x1: number;
	/** Y-component of top-right corner \`(x1,y1)\`. */
	y1: number;
	/** X-component of bottom-right corner \`(x2,y2)\`. */
	x2: number;
	/** Y-component of bottom-right corner \`(x2,y2)\`. */
	y2: number;
	/** X-component of bottom-left corner \`(x3,y3)\`. */
	x3: number;
	/** Y-component of bottom-right corner \`(x3,y3)\`. */
	y3: number;
	uvsFloat32: Float32Array;
	constructor();
	/**
	 * Sets the texture Uvs based on the given frame information.
	 * @protected
	 * @param frame - The frame of the texture
	 * @param baseFrame - The base frame of the texture
	 * @param rotate - Rotation of frame, see {@link groupD8}
	 */
	set(frame: Rectangle, baseFrame: Size, rotate: number): void;
	toString(): string;
}
export declare function generateUID(): number;
export declare function getCanvasTexture(canvas: ICanvas, options?: CanvasSourceOptions): Texture<CanvasSource>;
export declare function hasCachedCanvasTexture(canvas: ICanvas): boolean;
export declare function getSupportedCompressedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
export declare const nonCompressedFormats: TEXTURE_FORMATS[];
export declare function getSupportedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
export declare function createIdFromString(value: string, groupId: string): number;
export declare function parseFunctionBody(fn: (...args: any[]) => any): string;
declare const DefaultWebGPUSystems: (typeof BackgroundSystem | typeof GlobalUniformSystem | typeof HelloSystem | typeof ViewSystem | typeof RenderGroupSystem | typeof TextureGCSystem | typeof GenerateTextureSystem | typeof ExtractSystem | typeof RendererInitHook | typeof RenderableGCSystem | typeof SchedulerSystem | typeof GpuUboSystem | typeof GpuEncoderSystem | typeof GpuDeviceSystem | typeof GpuBufferSystem | typeof GpuTextureSystem | typeof GpuRenderTargetSystem | typeof GpuShaderSystem | typeof GpuStateSystem | typeof PipelineSystem | typeof GpuColorMaskSystem | typeof GpuStencilSystem | typeof BindGroupSystem)[];
declare const DefaultWebGPUPipes: (typeof BlendModePipe | typeof BatcherPipe | typeof SpritePipe | typeof RenderGroupPipe | typeof AlphaMaskPipe | typeof StencilMaskPipe | typeof ColorMaskPipe | typeof CustomRenderPipe | typeof GpuUniformBatchPipe)[];
type WebGPUSystems = ExtractSystemTypes<typeof DefaultWebGPUSystems> & PixiMixins.RendererSystems & PixiMixins.WebGPUSystems;
export type WebGPUPipes = ExtractSystemTypes<typeof DefaultWebGPUPipes> & PixiMixins.RendererPipes & PixiMixins.WebGPUPipes;
/**
 * Options for WebGPURenderer.
 * @memberof rendering
 */
export interface WebGPUOptions extends SharedRendererOptions, ExtractRendererOptions<typeof DefaultWebGPUSystems>, PixiMixins.WebGPUOptions {
}
export interface WebGPURenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGPUPipes, WebGPUOptions, T>, WebGPUSystems {
}
/**
 * The WebGPU PixiJS Renderer. This renderer allows you to use the next-generation graphics API, WebGPU.
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = new WebGPURenderer();
 * await renderer.init();
 *
 * // Add the renderer to the stage
 * document.body.appendChild(renderer.canvas);
 *
 * // Create a new stage
 * const stage = new Container();
 *
 * // Render the stage
 * renderer.render(stage);
 * \`\`\`
 *
 * You can use {@link rendering.autoDetectRenderer} to create a renderer that will automatically detect the best
 * renderer for the environment.
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = await rendering.autoDetectRenderer();
 * \`\`\`
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a WebGPU renderer:
 *
 * | WebGPU Core Systems                      | Systems that are specific to the WebGL renderer                               |
 * | ---------------------------------------- | ----------------------------------------------------------------------------- |
 * | {@link rendering.GpuUboSystem}           | This manages WebGPU uniform buffer objects feature for shaders                |
 * | {@link rendering.GpuEncoderSystem}       | This manages the WebGPU command encoder                                       |
 * | {@link rendering.GpuDeviceSystem}        | This manages the WebGPU Device and its extensions                             |
 * | {@link rendering.GpuBufferSystem}        | This manages buffers and their GPU resources, keeps everything in sync        |
 * | {@link rendering.GpuTextureSystem}       | This manages textures and their GPU resources, keeps everything in sync       |
 * | {@link rendering.GpuRenderTargetSystem}  | This manages what we render too. For example the screen, or another texture   |
 * | {@link rendering.GpuShaderSystem}        | This manages shaders, programs that run on the GPU to output lovely pixels    |
 * | {@link rendering.GpuStateSystem}         | This manages the state of the WebGPU Pipelines. eg the various flags that can be set blend modes / depthTesting etc |
 * | {@link rendering.PipelineSystem}         | This manages the WebGPU pipelines, used for rendering                         |
 * | {@link rendering.GpuColorMaskSystem}     | This manages the color mask. Used for color masking                           |
 * | {@link rendering.GpuStencilSystem}       | This manages the stencil buffer. Used primarily for masking                   |
 * | {@link rendering.BindGroupSystem}        | This manages the WebGPU bind groups. this is how data is bound to a shader when rendering |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @memberof rendering
 * @property {rendering.GpuUboSystem} ubo - UboSystem instance.
 * @property {rendering.GpuEncoderSystem} encoder - EncoderSystem instance.
 * @property {rendering.GpuDeviceSystem} device - DeviceSystem instance.
 * @property {rendering.GpuBufferSystem} buffer - BufferSystem instance.
 * @property {rendering.GpuTextureSystem} texture - TextureSystem instance.
 * @property {rendering.GpuRenderTargetSystem} renderTarget - RenderTargetSystem instance.
 * @property {rendering.GpuShaderSystem} shader - ShaderSystem instance.
 * @property {rendering.GpuStateSystem} state - StateSystem instance.
 * @property {rendering.PipelineSystem} pipeline - PipelineSystem instance.
 * @property {rendering.GpuColorMaskSystem} colorMask - ColorMaskSystem instance.
 * @property {rendering.GpuStencilSystem} stencil - StencilSystem instance.
 * @property {rendering.BindGroupSystem} bindGroup - BindGroupSystem instance.
 * @extends rendering.AbstractRenderer
 */
export declare class WebGPURenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGPUPipes, WebGPUOptions, T> implements WebGPUSystems {
	/** The WebGPU Device. */
	gpu: GPU$1;
	constructor();
}
/**
 * Options for {@link rendering.autoDetectRenderer}.
 * @memberof rendering
 */
export interface AutoDetectOptions extends RendererOptions {
	/** The preferred renderer type. WebGPU is recommended as its generally faster than WebGL. */
	preference?: "webgl" | "webgpu";
	/** Optional WebGPUOptions to pass only to WebGPU renderer. */
	webgpu?: Partial<WebGPUOptions>;
	/** Optional WebGLOptions to pass only to the WebGL renderer */
	webgl?: Partial<WebGLOptions>;
}
/**
 * Automatically determines the most appropriate renderer for the current environment.
 *
 * The function will prioritize the WebGL renderer as it is the most tested safe API to use.
 * In the near future as WebGPU becomes more stable and ubiquitous, it will be prioritized over WebGL.
 *
 * The selected renderer's code is then dynamically imported to optimize
 * performance and minimize the initial bundle size.
 *
 * To maximize the benefits of dynamic imports, it's recommended to use a modern bundler
 * that supports code splitting. This will place the renderer code in a separate chunk,
 * which is loaded only when needed.
 * @example
 *
 * // create a renderer
 * const renderer = await autoDetectRenderer({
 *   width: 800,
 *   height: 600,
 *   antialias: true,
 * });
 *
 * // custom for each renderer
 * const renderer = await autoDetectRenderer({
 *   width: 800,
 *   height: 600,
 *   webgpu:{
 *     antialias: true,
 *     backgroundColor: 'red'
 *   },
 *   webgl:{
 *     antialias: true,
 *     backgroundColor: 'green'
 *   }
 *  });
 * @param options - A partial configuration object based on the \`AutoDetectOptions\` type.
 * @returns A Promise that resolves to an instance of the selected renderer.
 * @memberof rendering
 */
export declare function autoDetectRenderer(options: Partial<AutoDetectOptions>): Promise<Renderer>;
/**
 * The app module provides a set of classes to use as a starting point when building applications.
 *
 * <aside>This module has a mixin for <code>TickerPlugin</code> and <code>ResizePlugin</code>.
 * These will need to be imported if you are managing your own renderer.</aside>
 *
 * \`\`\`js
 * import { Application } from 'pixi.js';
 *
 * const app = new Application();
 *
 * await app.init();
 *
 * // don't forget to add the canvas to the DOM
 * document.body.appendChild(app.canvas);
 * \`\`\`
 * @namespace app
 */
/**
 * Any plugin that's usable for Application should contain these methods.
 * @example
 * import { ApplicationPlugin } from 'pixi.js';
 *
 * const plugin: ApplicationPlugin = {
 *    init: (options: Partial<ApplicationOptions>) =>
 *    {
 *       // handle init here, use app options if needed
 *    },
 *    destroy: () =>
 *    {
 *       // handle destruction code here
 *    }
 * }
 * @memberof app
 * @see {@link app.ApplicationOptions}
 * @ignore
 */
export interface ApplicationPlugin {
	/**
	 * Called when Application is constructed, scoped to Application instance.
	 * Passes in \`options\` as the only argument, which are Application \`init()\` options.
	 * @param {object} options - Application options.
	 */
	init(options: Partial<ApplicationOptions>): void;
	/** Called when destroying Application, scoped to Application instance. */
	destroy(): void;
}
/**
 * Application options supplied to the {@link app.Application#init} method.
 * @memberof app
 * @example
 * import { Application } from 'pixi.js';
 *
 * const app = new Application();
 *
 * await app.init({
 *    autoStart: false,
 *    resizeTo: window,
 *    sharedTicker: true,
 * });
 */
export interface ApplicationOptions extends AutoDetectOptions, PixiMixins.ApplicationOptions {
}
export interface Application extends PixiMixins.Application {
}
/**
 * Convenience class to create a new PixiJS application.
 *
 * This class automatically creates the renderer, ticker and root container.
 * @example
 * import { Application, Sprite } from 'pixi.js';
 *
 * // Create the application
 * const app = new Application();
 *
 * await app.init({ width: 800, height: 600 });
 *
 * // Add the view to the DOM
 * document.body.appendChild(app.canvas);
 *
 * // ex, add display objects
 * app.stage.addChild(Sprite.from('something.png'));
 * @memberof app
 */
export declare class Application<R extends Renderer = Renderer> {
	/**
	 * Collection of installed plugins.
	 * @alias _plugins
	 */
	static _plugins: ApplicationPlugin[];
	/** The root display container that's rendered. */
	stage: Container;
	/**
	 * WebGL renderer if available, otherwise CanvasRenderer.
	 * @member {rendering.Renderer}
	 */
	renderer: R;
	/** Create new Application instance */
	constructor();
	/** @deprecated since 8.0.0 */
	constructor(options?: Partial<ApplicationOptions>);
	/**
	 * @param options - The optional application and renderer parameters.
	 */
	init(options?: Partial<ApplicationOptions>): Promise<void>;
	/** Render the current stage. */
	render(): void;
	/**
	 * Reference to the renderer's canvas element.
	 * @readonly
	 * @member {HTMLCanvasElement}
	 */
	get canvas(): R["canvas"];
	/**
	 * Reference to the renderer's canvas element.
	 * @member {HTMLCanvasElement}
	 * @deprecated since 8.0.0
	 */
	get view(): R["canvas"];
	/**
	 * Reference to the renderer's screen rectangle. Its safe to use as \`filterArea\` or \`hitArea\` for the whole screen.
	 * @readonly
	 */
	get screen(): Rectangle;
	/**
	 * Destroys the application and all of its resources.
	 * @param {object|boolean}[rendererDestroyOptions=false] - The options for destroying the renderer.
	 * @param {boolean}[rendererDestroyOptions.removeView=false] - Removes the Canvas element from the DOM.
	 * @param {object|boolean} [options=false] - The options for destroying the stage.
	 * @param {boolean} [options.children=false] - If set to true, all the children will have their destroy method
	 * called as well. \`options\` will be passed on to those calls.
	 * @param {boolean} [options.texture=false] - Only used for children with textures e.g. Sprites.
	 * If options.children is set to true,
	 * it should destroy the texture of the child sprite.
	 * @param {boolean} [options.textureSource=false] - Only used for children with textures e.g. Sprites.
	 *  If options.children is set to true,
	 * it should destroy the texture source of the child sprite.
	 * @param {boolean} [options.context=false] - Only used for children with graphicsContexts e.g. Graphics.
	 * If options.children is set to true,
	 * it should destroy the context of the child graphics.
	 */
	destroy(rendererDestroyOptions?: RendererDestroyOptions, options?: DestroyOptions): void;
}
declare global {
	var __PIXI_APP_INIT__: undefined | ((arg: Application | Renderer, version: string) => void);
	var __PIXI_RENDERER_INIT__: undefined | ((arg: Application | Renderer, version: string) => void);
}
/**
 * Calls global __PIXI_APP_INIT__ hook with the application instance, after the application is initialized.
 * @memberof app
 */
export declare class ApplicationInitHook {
	/** @ignore */
	static extension: ExtensionMetadata;
	static init(): void;
	static destroy(): void;
}
/**
 * Calls global __PIXI_RENDERER_INIT__ hook with the renderer instance, after the renderer is initialized.
 * @memberof rendering
 */
export declare class RendererInitHook implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "initHook";
		readonly priority: -10;
	};
	private _renderer;
	constructor(renderer: Renderer);
	init(): void;
	destroy(): void;
}
export declare const SharedSystems: (typeof BackgroundSystem | typeof GlobalUniformSystem | typeof HelloSystem | typeof ViewSystem | typeof RenderGroupSystem | typeof TextureGCSystem | typeof GenerateTextureSystem | typeof ExtractSystem | typeof RendererInitHook | typeof RenderableGCSystem | typeof SchedulerSystem)[];
export declare const SharedRenderPipes: (typeof BlendModePipe | typeof BatcherPipe | typeof SpritePipe | typeof RenderGroupPipe | typeof AlphaMaskPipe | typeof StencilMaskPipe | typeof ColorMaskPipe | typeof CustomRenderPipe)[];
/**
 * Options for the shared systems of a renderer.
 * @memberof rendering
 */
export interface SharedRendererOptions extends ExtractRendererOptions<typeof SharedSystems>, PixiMixins.RendererOptions {
	/**
	 * Whether to stop PixiJS from dynamically importing default extensions for the renderer.
	 * It is false by default, and means PixiJS will load all the default extensions, based
	 * on the environment e.g browser/webworker.
	 * If you set this to true, then you will need to manually import the systems and extensions you need.
	 *
	 * e.g.
	 * \`\`\`js
	 * import 'accessibility';
	 * import 'app';
	 * import 'events';
	 * import 'spritesheet';
	 * import 'graphics';
	 * import 'mesh';
	 * import 'text';
	 * import 'text-bitmap';
	 * import 'text-html';
	 * import { autoDetectRenderer } from 'pixi.js';
	 *
	 * const renderer = await autoDetectRenderer({
	 *   width: 800,
	 *   height: 600,
	 *   skipExtensionImports: true,
	 * });
	 * \`\`\`
	 * @default false
	 */
	skipExtensionImports?: boolean;
	/**
	 * @default true
	 * @deprecated since 8.1.6
	 * @see \`skipExtensionImports\`
	 */
	manageImports?: boolean;
}
export interface RendererConfig {
	type: number;
	name: string;
	runners?: string[];
	systems: {
		name: string;
		value: SystemConstructor;
	}[];
	renderPipes: {
		name: string;
		value: PipeConstructor;
	}[];
	renderPipeAdaptors: {
		name: string;
		value: any;
	}[];
}
/**
 * The options for rendering a view.
 * @memberof rendering
 */
export interface RenderOptions extends ClearOptions {
	/** The container to render. */
	container: Container;
	/** the transform to apply to the container. */
	transform?: Matrix;
}
/**
 * The options for clearing the render target.
 * @memberof rendering
 */
export interface ClearOptions {
	/**
	 * The render target to render. if this target is a canvas and  you are using the WebGL renderer,
	 * please ensure you have set \`multiView\` to \`true\` on renderer.
	 */
	target?: RenderSurface;
	/** The color to clear with. */
	clearColor?: ColorSource;
	/** The clear mode to use. */
	clear?: CLEAR_OR_BOOL;
}
export type RendererDestroyOptions = TypeOrBool<ViewSystemDestroyOptions>;
declare const defaultRunners: readonly [
	"init",
	"destroy",
	"contextChange",
	"resolutionChange",
	"resetState",
	"renderEnd",
	"renderStart",
	"render",
	"update",
	"postrender",
	"prerender"
];
type DefaultRunners = typeof defaultRunners[number];
type Runners = {
	[key in DefaultRunners]: SystemRunner;
} & {
	[K: ({} & string) | ({} & symbol)]: SystemRunner;
};
/**
 * The base class for a PixiJS Renderer. It contains the shared logic for all renderers.
 *
 * You should not use this class directly, but instead use {@linkrendering.WebGLRenderer}
 * or {@link rendering.WebGPURenderer}.
 * Alternatively, you can also use {@link rendering.autoDetectRenderer} if you want us to
 * determine the best renderer for you.
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a renderer:
 *
 *
 * | Generic Systems                      | Systems that manage functionality that all renderer types share               |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.ViewSystem}              | This manages the main view of the renderer usually a Canvas              |
 * | {@link rendering.BackgroundSystem}        | This manages the main views background color and alpha                   |
 * | {@link events.EventSystem}           | This manages UI events.                                                       |
 * | {@link accessibility.AccessibilitySystem} | This manages accessibility features. Requires \`import 'pixi.js/accessibility'\`|
 *
 * | Core Systems                   | Provide an optimised, easy to use API to work with WebGL/WebGPU               |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.RenderGroupSystem} | This manages the what what we are rendering to (eg - canvas or texture)   |
 * | {@link rendering.GlobalUniformSystem} | This manages shaders, programs that run on the GPU to calculate 'em pixels.   |
 * | {@link rendering.TextureGCSystem}     | This will automatically remove textures from the GPU if they are not used.    |
 *
 * | PixiJS High-Level Systems            | Set of specific systems designed to work with PixiJS objects                  |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.HelloSystem}               | Says hello, buy printing out the pixi version into the console log (along with the renderer type)       |
 * | {@link rendering.GenerateTextureSystem} | This adds the ability to generate textures from any Container       |
 * | {@link rendering.FilterSystem}          | This manages the filtering pipeline for post-processing effects.             |
 * | {@link rendering.PrepareSystem}               | This manages uploading assets to the GPU. Requires \`import 'pixi.js/prepare'\`|
 * | {@link rendering.ExtractSystem}               | This extracts image data from display objects.                               |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @abstract
 * @memberof rendering
 * @property {rendering.HelloSystem} hello - HelloSystem instance.
 * @property {rendering.RenderGroupSystem} renderGroup - RenderGroupSystem instance.
 * @property {rendering.TextureGCSystem} textureGC - TextureGCSystem instance.
 * @property {rendering.FilterSystem} filter - FilterSystem instance.
 * @property {rendering.GlobalUniformSystem} globalUniforms - GlobalUniformSystem instance.
 * @property {rendering.TextureSystem} texture - TextureSystem instance.
 * @property {rendering.EventSystem} events - EventSystem instance.
 * @property {rendering.ExtractSystem} extract - ExtractSystem instance. Requires \`import 'pixi.js/extract'\`.
 * @property {rendering.PrepareSystem} prepare - PrepareSystem instance. Requires \`import 'pixi.js/prepare'\`.
 * @property {rendering.AccessibilitySystem} accessibility - AccessibilitySystem instance. Requires \`import 'pixi.js/accessibility'\`.
 */
export declare class AbstractRenderer<PIPES, OPTIONS extends SharedRendererOptions, CANVAS extends ICanvas = HTMLCanvasElement> extends EventEmitter<{
	resize: [
		screenWidth: number,
		screenHeight: number,
		resolution: number
	];
}> {
	/** The default options for the renderer. */
	static defaultOptions: {
		/**
		 * Default resolution / device pixel ratio of the renderer.
		 * @default 1
		 */
		resolution: number;
		/**
		 * Should the \`failIfMajorPerformanceCaveat\` flag be enabled as a context option used in the \`isWebGLSupported\`
		 * function. If set to true, a WebGL renderer can fail to be created if the browser thinks there could be
		 * performance issues when using WebGL.
		 *
		 * In PixiJS v6 this has changed from true to false by default, to allow WebGL to work in as many
		 * scenarios as possible. However, some users may have a poor experience, for example, if a user has a gpu or
		 * driver version blacklisted by the
		 * browser.
		 *
		 * If your application requires high performance rendering, you may wish to set this to false.
		 * We recommend one of two options if you decide to set this flag to false:
		 *
		 * 1: Use the Canvas renderer as a fallback in case high performance WebGL is
		 *    not supported.
		 *
		 * 2: Call \`isWebGLSupported\` (which if found in the utils package) in your code before attempting to create a
		 *    PixiJS renderer, and show an error message to the user if the function returns false, explaining that their
		 *    device & browser combination does not support high performance WebGL.
		 *    This is a much better strategy than trying to create a PixiJS renderer and finding it then fails.
		 * @default false
		 */
		failIfMajorPerformanceCaveat: boolean;
		/**
		 * Should round pixels be forced when rendering?
		 * @default false
		 */
		roundPixels: boolean;
	};
	readonly type: number;
	/** The name of the renderer. */
	readonly name: string;
	_roundPixels: 0 | 1;
	readonly runners: Runners;
	readonly renderPipes: PIPES;
	/** The view system manages the main canvas that is attached to the DOM */
	view: ViewSystem;
	/** The background system manages the background color and alpha of the main view. */
	background: BackgroundSystem;
	/** System that manages the generation of textures from the renderer */
	textureGenerator: GenerateTextureSystem;
	protected _initOptions: OPTIONS;
	protected config: RendererConfig;
	private _systemsHash;
	private _lastObjectRendered;
	/**
	 * Set up a system with a collection of SystemClasses and runners.
	 * Systems are attached dynamically to this class when added.
	 * @param config - the config for the system manager
	 */
	constructor(config: RendererConfig);
	/**
	 * Initialize the renderer.
	 * @param options - The options to use to create the renderer.
	 */
	init(options?: Partial<OPTIONS>): Promise<void>;
	/**
	 * Renders the object to its view.
	 * @param options - The options to render with.
	 * @param options.container - The container to render.
	 * @param [options.target] - The target to render to.
	 */
	render(options: RenderOptions | Container): void;
	/** @deprecated since 8.0.0 */
	render(container: Container, options: {
		renderTexture: any;
	}): void;
	/**
	 * Resizes the WebGL view to the specified width and height.
	 * @param desiredScreenWidth - The desired width of the screen.
	 * @param desiredScreenHeight - The desired height of the screen.
	 * @param resolution - The resolution / device pixel ratio of the renderer.
	 */
	resize(desiredScreenWidth: number, desiredScreenHeight: number, resolution?: number): void;
	clear(options?: ClearOptions): void;
	/** The resolution / device pixel ratio of the renderer. */
	get resolution(): number;
	set resolution(value: number);
	/**
	 * Same as view.width, actual number of pixels in the canvas by horizontal.
	 * @member {number}
	 * @readonly
	 * @default 800
	 */
	get width(): number;
	/**
	 * Same as view.height, actual number of pixels in the canvas by vertical.
	 * @default 600
	 */
	get height(): number;
	/**
	 * The canvas element that everything is drawn to.
	 * @type {environment.ICanvas}
	 */
	get canvas(): CANVAS;
	/**
	 * the last object rendered by the renderer. Useful for other plugins like interaction managers
	 * @readonly
	 */
	get lastObjectRendered(): Container;
	/**
	 * Flag if we are rendering to the screen vs renderTexture
	 * @readonly
	 * @default true
	 */
	get renderingToScreen(): boolean;
	/**
	 * Measurements of the screen. (0, 0, screenWidth, screenHeight).
	 *
	 * Its safe to use as filterArea or hitArea for the whole stage.
	 */
	get screen(): Rectangle;
	/**
	 * Create a bunch of runners based of a collection of ids
	 * @param runnerIds - the runner ids to add
	 */
	private _addRunners;
	private _addSystems;
	/**
	 * Add a new system to the renderer.
	 * @param ClassRef - Class reference
	 * @param name - Property name for system, if not specified
	 *        will use a static \`name\` property on the class itself. This
	 *        name will be assigned as s property on the Renderer so make
	 *        sure it doesn't collide with properties on Renderer.
	 * @returns Return instance of renderer
	 */
	private _addSystem;
	private _addPipes;
	destroy(options?: RendererDestroyOptions): void;
	/**
	 * Generate a texture from a container.
	 * @param options - options or container target to use when generating the texture
	 * @returns a texture
	 */
	generateTexture(options: GenerateTextureOptions | Container): Texture;
	/**
	 * Whether the renderer will round coordinates to whole pixels when rendering.
	 * Can be overridden on a per scene item basis.
	 */
	get roundPixels(): boolean;
	/**
	 * Overridable function by \`pixi.js/unsafe-eval\` to silence
	 * throwing an error if platform doesn't support unsafe-evals.
	 * @private
	 * @ignore
	 */
	_unsafeEvalCheck(): void;
	/**
	 * Resets the rendering state of the renderer.
	 * This is useful when you want to use the WebGL context directly and need to ensure PixiJS's internal state
	 * stays synchronized. When modifying the WebGL context state externally, calling this method before the next Pixi
	 * render will reset all internal caches and ensure it executes correctly.
	 *
	 * This is particularly useful when combining PixiJS with other rendering engines like Three.js:
	 * \`\`\`js
	 * // Reset Three.js state
	 * threeRenderer.resetState();
	 *
	 * // Render a Three.js scene
	 * threeRenderer.render(threeScene, threeCamera);
	 *
	 * // Reset PixiJS state since Three.js modified the WebGL context
	 * pixiRenderer.resetState();
	 *
	 * // Now render Pixi content
	 * pixiRenderer.render(pixiScene);
	 * \`\`\`
	 */
	resetState(): void;
}
declare const DefaultWebGLSystems: (typeof BackgroundSystem | typeof GlobalUniformSystem | typeof HelloSystem | typeof ViewSystem | typeof RenderGroupSystem | typeof TextureGCSystem | typeof GenerateTextureSystem | typeof ExtractSystem | typeof RendererInitHook | typeof RenderableGCSystem | typeof SchedulerSystem | typeof GlUboSystem | typeof GlBackBufferSystem | typeof GlContextSystem | typeof GlBufferSystem | typeof GlTextureSystem | typeof GlRenderTargetSystem | typeof GlGeometrySystem | typeof GlUniformGroupSystem | typeof GlShaderSystem | typeof GlEncoderSystem | typeof GlStateSystem | typeof GlStencilSystem | typeof GlColorMaskSystem)[];
declare const DefaultWebGLPipes: (typeof BlendModePipe | typeof BatcherPipe | typeof SpritePipe | typeof RenderGroupPipe | typeof AlphaMaskPipe | typeof StencilMaskPipe | typeof ColorMaskPipe | typeof CustomRenderPipe)[];
type WebGLSystems = ExtractSystemTypes<typeof DefaultWebGLSystems> & PixiMixins.RendererSystems & PixiMixins.WebGLSystems;
/** The default WebGL renderer, uses WebGL2 contexts. */
export type WebGLPipes = ExtractSystemTypes<typeof DefaultWebGLPipes> & PixiMixins.RendererPipes & PixiMixins.WebGLPipes;
/**
 * Options for WebGLRenderer.
 * @memberof rendering
 */
export interface WebGLOptions extends SharedRendererOptions, ExtractRendererOptions<typeof DefaultWebGLSystems>, PixiMixins.WebGLOptions {
}
/**
 * The default WebGL renderer, uses WebGL2 contexts.
 * @memberof rendering
 */
export interface WebGLRenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGLPipes, WebGLOptions, T>, WebGLSystems {
}
/**
 * The WebGL PixiJS Renderer. This renderer allows you to use the most common graphics API, WebGL (and WebGL2).
 *
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = new WebGLRenderer();
 * await renderer.init();
 *
 * // Add the renderer to the stage
 * document.body.appendChild(renderer.canvas);
 *
 * // Create a new stage
 * const stage = new Container();
 *
 * // Render the stage
 * renderer.render(stage);
 * \`\`\`
 *
 * You can use {@link rendering.autoDetectRenderer} to create a renderer that will automatically detect the best
 * renderer for the environment.
 *
 *
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = await rendering.autoDetectRenderer({
 *    preference:'webgl',
 * });
 * \`\`\`
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a WebGL renderer:
 *
 * | WebGL Core Systems                          | Systems that are specific to the WebGL renderer                               |
 * | ------------------------------------------- | ----------------------------------------------------------------------------- |
 * | {@link rendering.GlUboSystem}               | This manages WebGL2 uniform buffer objects feature for shaders                |
 * | {@link rendering.GlBackBufferSystem}        | manages the back buffer, used so that we can pixi can pixels from the screen  |
 * | {@link rendering.GlContextSystem}           | This manages the WebGL context and its extensions                             |
 * | {@link rendering.GlBufferSystem}            | This manages buffers and their GPU resources, keeps everything in sync        |
 * | {@link rendering.GlTextureSystem}           | This manages textures and their GPU resources, keeps everything in sync       |
 * | {@link rendering.GlRenderTargetSystem}      | This manages what we render too. For example the screen, or another texture   |
 * | {@link rendering.GlGeometrySystem}          | This manages geometry, used for drawing meshes via the GPU                    |
 * | {@link rendering.GlUniformGroupSystem}      | This manages uniform groups. Syncing shader properties with the GPU           |
 * | {@link rendering.GlShaderSystem}            | This manages shaders, programs that run on the GPU to output lovely pixels    |
 * | {@link rendering.GlEncoderSystem}           | This manages encoders, a WebGPU Paradigm, use it to draw a mesh + shader      |
 * | {@link rendering.GlStateSystem}             | This manages the state of the WebGL context. eg the various flags that can be set blend modes / depthTesting etc |
 * | {@link rendering.GlStencilSystem}           | This manages the stencil buffer. Used primarily for masking                   |
 * | {@link rendering.GlColorMaskSystem}         | This manages the color mask. Used for color masking                           |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @memberof rendering
 * @property {rendering.GlUboSystem} ubo - UboSystem instance.
 * @property {rendering.GlBackBufferSystem} backBuffer - BackBufferSystem instance.
 * @property {rendering.GlContextSystem} context - ContextSystem instance.
 * @property {rendering.GlBufferSystem} buffer - BufferSystem instance.
 * @property {rendering.GlTextureSystem} texture - TextureSystem instance.
 * @property {rendering.GlRenderTargetSystem} renderTarget - RenderTargetSystem instance.
 * @property {rendering.GlGeometrySystem} geometry - GeometrySystem instance.
 * @property {rendering.GlUniformGroupSystem} uniformGroup - UniformGroupSystem instance.
 * @property {rendering.GlShaderSystem} shader - ShaderSystem instance.
 * @property {rendering.GlEncoderSystem} encoder - EncoderSystem instance.
 * @property {rendering.GlStateSystem} state - StateSystem instance.
 * @property {rendering.GlStencilSystem} stencil - StencilSystem instance.
 * @property {rendering.GlColorMaskSystem} colorMask - ColorMaskSystem instance.
 * @extends rendering.AbstractRenderer
 */
export declare class WebGLRenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGLPipes, WebGLOptions, T> implements WebGLSystems {
	gl: GlRenderingContext;
	constructor();
}
/** A generic renderer. */
/**
 * @memberof rendering
 * @extends rendering.WebGLRenderer
 * @extends rendering.WebGPURenderer
 */
export type Renderer<T extends ICanvas = HTMLCanvasElement> = WebGLRenderer<T> | WebGPURenderer<T>;
export type RenderPipes = WebGLPipes | WebGPUPipes;
/**
 * @extends rendering.WebGLOptions
 * @extends rendering.WebGPUOptions
 */
export interface RendererOptions extends WebGLOptions, WebGPUOptions {
}
/**
 * Ids for the different render types.
 * The idea is that you can use bitwise operations to filter whether or not you want to do something
 * in a certain render type.
 * Filters for example can be compatible for both webGL or WebGPU but not compatible with canvas.
 * So internally if it works with both we set filter.compatibleRenderers = RendererType.WEBGL | RendererType.WEBGPU
 * if it only works with webgl we set filter.compatibleRenderers = RendererType.WEBGL
 *
 */
export declare enum RendererType {
	WEBGL = 1,
	WEBGPU = 2,
	BOTH = 3
}
export type GpuPowerPreference = "low-power" | "high-performance";
/**
 * Options for configuring a RenderLayer.
 * @memberof scene
 */
export interface RenderLayerOptions {
	/**
	 * If true, the layer's children will be sorted by zIndex before rendering
	 * If false, you can manually sort the children using sortRenderLayerChildren when ever you need!
	 * @default false
	 */
	sortableChildren?: boolean;
	/**
	 * Custom sort function to sort layer children. Default sorts by zIndex.
	 * @param a - First container to compare
	 * @param b - Second container to compare
	 * @returns Negative if a should render before b, positive if b should render before a
	 */
	sortFunction?: (a: Container, b: Container) => number;
}
type ContainerKeys = keyof Container;
type PartialContainerKeys = Exclude<ContainerKeys, "parent" | "didChange" | "_updateFlags" | keyof EventEmitter | "parentRenderLayer" | "destroyed" | "layerParentId" | "sortableChildren" | "getFastGlobalBounds">;
export type IRenderLayer = Omit<RenderLayerClass, PartialContainerKeys>;
/**
 * The RenderLayer API provides a way to control the rendering order of objects independently
 * of their logical parent-child relationships in the scene graph.
 * This allows developers to decouple how objects are transformed
 * (via their logical parent) from how they are rendered on the screen.
 *
 * ### Key Concepts
 *
 * #### RenderLayers Control Rendering Order:
 * - RenderLayers define where in the render stack objects are drawn,
 * but they do not affect an object's transformations (e.g., position, scale, rotation) or logical hierarchy.
 * - RenderLayers can be added anywhere in the scene graph.
 *
 * #### Logical Parenting Remains Unchanged:
 * - Objects still have a logical parent for transformations via addChild.
 * - Assigning an object to a layer does not reparent it.
 *
 * #### Explicit Control:
 * - Developers assign objects to layers using renderLayer.add and remove them using renderLayer.remove.
 * ---
 * ### API Details
 *
 * #### 1. Creating a RenderLayer
 * A RenderLayer is a lightweight object responsible for controlling render order.
 * It has no children or transformations of its own
 * but can be inserted anywhere in the scene graph to define its render position.
 * \`\`\`js
 * const layer = new RenderLayer();
 * app.stage.addChild(layer); // Insert the layer into the scene graph
 * \`\`\`
 *
 * #### 2. Adding Objects to a Layer
 * Use renderLayer.add to assign an object to a layer.
 * This overrides the object's default render order defined by its logical parent.
 * \`\`\`js
 * const rect = new PIXI.Graphics();
 * container.addChild(rect);    // Add to logical parent
 * layer.attach(rect);      // Control render order via the layer
 * \`\`\`
 *
 * #### 3. Removing Objects from a Layer
 * To stop an object from being rendered in the layer, use remove.
 * \`\`\`js
 * layer.remove(rect); // Stop rendering rect via the layer
 * \`\`\`
 * When an object is removed from its logical parent (removeChild), it is automatically removed from the layer.
 *
 * #### 4. Re-Adding Objects to Layers
 * If an object is re-added to a logical parent, it does not automatically reassign itself to the layer.
 * Developers must explicitly reassign it.
 * \`\`\`js
 * container.addChild(rect);    // Logical parent
 * layer.attach(rect);      // Explicitly reassign to the layer
 * \`\`\`
 *
 * #### 5. Layer Position in Scene Graph
 * A layer's position in the scene graph determines its render priority relative to other layers and objects.
 * Layers can be inserted anywhere in the scene graph.
 * \`\`\`js
 * const backgroundLayer = new RenderLayer();
 * const uiLayer = new RenderLayer();
 *
 * app.stage.addChild(backgroundLayer);
 * app.stage.addChild(world);
 * app.stage.addChild(uiLayer);
 * \`\`\`
 * This is a new API and therefore considered experimental at this stage.
 * While the core is pretty robust, there are still a few tricky issues we need to tackle.
 * However, even with the known issues below, we believe this API is incredibly useful!
 *
 * Known issues:
 *  - Interaction may not work as expected since hit testing does not account for the visual render order created by layers.
 *    For example, if an object is visually moved to the front via a layer, hit testing will still use its original position.
 *  - RenderLayers and their children must all belong to the same renderGroup to work correctly
 * @memberof scene
 * @class RenderLayer
 * @extends null
 */
export declare class RenderLayerClass extends Container {
	/**
	 * Default options for RenderLayer instances
	 * @property {boolean} sortableChildren - If true, layer children will be automatically sorted each render.
	 * Default false.
	 * @property {Function} sortFunction - Function used to sort layer children. Default sorts by zIndex.
	 */
	static defaultOptions: RenderLayerOptions;
	/** Function used to sort layer children if sortableChildren is true */
	sortFunction: (a: Container, b: Container) => number;
	/** List of objects to be rendered by this layer */
	renderLayerChildren: Container[];
	/**
	 * Creates a new RenderLayer instance
	 * @param options - Configuration options for the RenderLayer
	 * @param {boolean} [options.sortableChildren=false] - If true, layer children will be automatically sorted each render
	 * @param {Function} [options.sortFunction] - Custom function to sort layer children. Default sorts by zIndex
	 */
	constructor(options?: RenderLayerOptions);
	/**
	 * Add an Container to this render layer. The Container will be rendered as part of this layer
	 * while maintaining its original parent in the scene graph.
	 * If the Container already belongs to a layer, it will be removed from the old layer before being added to this one.
	 * @param children - The Container(s) to add to this layer
	 */
	attach<U extends Container[]>(...children: U): U[0];
	/**
	 * Remove an Container from this render layer. The Container will no longer be rendered
	 * as part of this layer but maintains its original parent.
	 * @param children - The Container(s) to remove from this layer
	 */
	detach<U extends Container[]>(...children: U): U[0];
	/** Remove all objects from this render layer. */
	detachAll(): void;
	collectRenderables(instructionSet: InstructionSet, renderer: Renderer, _currentLayer: RenderLayerClass): void;
	/**
	 * Sort the layer's children using the defined sort function.
	 * Will be called each render if sortableChildren is true.
	 * Otherwise can call this manually.
	 */
	sortRenderLayerChildren(): void;
	_getGlobalBoundsRecursive(factorRenderLayers: boolean, bounds: Bounds, _currentLayer: RenderLayerClass): void;
}
export declare const RenderLayer: new (options?: RenderLayerOptions) => IRenderLayer;
export type ContainerChild = Container;
export interface ContainerEvents<C extends ContainerChild> extends PixiMixins.ContainerEvents {
	added: [
		container: Container
	];
	childAdded: [
		child: C,
		container: Container,
		index: number
	];
	removed: [
		container: Container
	];
	childRemoved: [
		child: C,
		container: Container,
		index: number
	];
	destroyed: [
		container: Container
	];
}
type AnyEvent = {
	[K: ({} & string) | ({} & symbol)]: any;
};
export declare const UPDATE_COLOR = 1;
export declare const UPDATE_BLEND = 2;
export declare const UPDATE_VISIBLE = 4;
export declare const UPDATE_TRANSFORM = 8;
export interface UpdateTransformOptions {
	x: number;
	y: number;
	scaleX: number;
	scaleY: number;
	rotation: number;
	skewX: number;
	skewY: number;
	pivotX: number;
	pivotY: number;
}
/**
 * Constructor options used for \`Container\` instances.
 * \`\`\`js
 * const container = new Container({
 *    position: new Point(100, 200),
 *    scale: new Point(2, 2),
 *    rotation: Math.PI / 2,
 * });
 * \`\`\`
 * @memberof scene
 * @see scene.Container
 */
export interface ContainerOptions<C extends ContainerChild = ContainerChild> extends PixiMixins.ContainerOptions {
	/** @see scene.Container#isRenderGroup */
	isRenderGroup?: boolean;
	/** @see scene.Container#blendMode */
	blendMode?: BLEND_MODES;
	/** @see scene.Container#tint */
	tint?: ColorSource;
	/** @see scene.Container#alpha */
	alpha?: number;
	/** @see scene.Container#angle */
	angle?: number;
	/** @see scene.Container#children */
	children?: C[];
	/** @see scene.Container#parent */
	parent?: Container;
	/** @see scene.Container#renderable */
	renderable?: boolean;
	/** @see scene.Container#rotation */
	rotation?: number;
	/** @see scene.Container#scale */
	scale?: PointData | number;
	/** @see scene.Container#pivot */
	pivot?: PointData | number;
	/** @see scene.Container#position */
	position?: PointData;
	/** @see scene.Container#skew */
	skew?: PointData;
	/** @see scene.Container#visible */
	visible?: boolean;
	/** @see scene.Container#x */
	x?: number;
	/** @see scene.Container#y */
	y?: number;
	/** @see scene.Container#boundArea */
	boundsArea?: Rectangle;
}
export interface Container<C extends ContainerChild> extends PixiMixins.Container<C>, EventEmitter<ContainerEvents<C> & AnyEvent> {
}
/**
 * Container is a general-purpose display object that holds children. It also adds built-in support for advanced
 * rendering features like masking and filtering.
 *
 * It is the base class of all display objects that act as a container for other objects, including Graphics
 * and Sprite.
 *
 * <details id="transforms">
 *
 * <summary>Transforms</summary>
 *
 * The [transform]{@link scene.Container#transform} of a display object describes the projection from its
 * local coordinate space to its parent's local coordinate space. The following properties are derived
 * from the transform:
 *
 * <table>
 *   <thead>
 *     <tr>
 *       <th>Property</th>
 *       <th>Description</th>
 *     </tr>
 *   </thead>
 *   <tbody>
 *     <tr>
 *       <td>[pivot]{@link scene.Container#pivot}</td>
 *       <td>
 *         Invariant under rotation, scaling, and skewing. The projection of into the parent's space of the pivot
 *         is equal to position, regardless of the other three transformations. In other words, It is the center of
 *         rotation, scaling, and skewing.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[position]{@link scene.Container#position}</td>
 *       <td>
 *         Translation. This is the position of the [pivot]{@link scene.Container#pivot} in the parent's local
 *         space. The default value of the pivot is the origin (0,0). If the top-left corner of your display object
 *         is (0,0) in its local space, then the position will be its top-left corner in the parent's local space.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[scale]{@link scene.Container#scale}</td>
 *       <td>
 *         Scaling. This will stretch (or compress) the display object's projection. The scale factors are along the
 *         local coordinate axes. In other words, the display object is scaled before rotated or skewed. The center
 *         of scaling is the [pivot]{@link scene.Container#pivot}.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[rotation]{@link scene.Container#rotation}</td>
 *       <td>
 *          Rotation. This will rotate the display object's projection by this angle (in radians).
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[skew]{@link scene.Container#skew}</td>
 *       <td>
 *         <p>Skewing. This can be used to deform a rectangular display object into a parallelogram.</p>
 *         <p>
 *         In PixiJS, skew has a slightly different behaviour than the conventional meaning. It can be
 *         thought of the net rotation applied to the coordinate axes (separately). For example, if "skew.x" is
 *         ⍺ and "skew.y" is β, then the line x = 0 will be rotated by ⍺ (y = -x*cot⍺) and the line y = 0 will be
 *         rotated by β (y = x*tanβ). A line y = x*tanϴ (i.e. a line at angle ϴ to the x-axis in local-space) will
 *         be rotated by an angle between ⍺ and β.
 *         </p>
 *         <p>
 *         It can be observed that if skew is applied equally to both axes, then it will be equivalent to applying
 *         a rotation. Indeed, if "skew.x" = -ϴ and "skew.y" = ϴ, it will produce an equivalent of "rotation" = ϴ.
 *         </p>
 *         <p>
 *         Another quite interesting observation is that "skew.x", "skew.y", rotation are commutative operations. Indeed,
 *         because rotation is essentially a careful combination of the two.
 *         </p>
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[angle]{@link scene.Container#angle}</td>
 *       <td>Rotation. This is an alias for [rotation]{@link scene.Container#rotation}, but in degrees.</td>
 *     </tr>
 *     <tr>
 *       <td>[x]{@link scene.Container#x}</td>
 *       <td>Translation. This is an alias for position.x!</td>
 *     </tr>
 *     <tr>
 *       <td>[y]{@link scene.Container#y}</td>
 *       <td>Translation. This is an alias for position.y!</td>
 *     </tr>
 *     <tr>
 *       <td>[width]{@link scene.Container#width}</td>
 *       <td>
 *         Implemented in [Container]{@link scene.Container}. Scaling. The width property calculates scale.x by dividing
 *         the "requested" width by the local bounding box width. It is indirectly an abstraction over scale.x, and there
 *         is no concept of user-defined width.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[height]{@link scene.Container#height}</td>
 *       <td>
 *         Implemented in [Container]{@link scene.Container}. Scaling. The height property calculates scale.y by dividing
 *         the "requested" height by the local bounding box height. It is indirectly an abstraction over scale.y, and there
 *         is no concept of user-defined height.
 *       </td>
 *     </tr>
 *   </tbody>
 * </table>
 * </details>
 *
 * <details id="alpha">
 * <summary>Alpha</summary>
 *
 * This alpha sets a display object's **relative opacity** w.r.t its parent. For example, if the alpha of a display
 * object is 0.5 and its parent's alpha is 0.5, then it will be rendered with 25% opacity (assuming alpha is not
 * applied on any ancestor further up the chain).
 * </details>
 *
 * <details id="visible">
 * <summary>Renderable vs Visible</summary>
 *
 * The \`renderable\` and \`visible\` properties can be used to prevent a display object from being rendered to the
 * screen. However, there is a subtle difference between the two. When using \`renderable\`, the transforms  of the display
 * object (and its children subtree) will continue to be calculated. When using \`visible\`, the transforms will not
 * be calculated.
 * \`\`\`ts
 * import { BlurFilter, Container, Graphics, Sprite } from 'pixi.js';
 *
 * const container = new Container();
 * const sprite = Sprite.from('https://s3-us-west-2.amazonaws.com/s.cdpn.io/693612/IaUrttj.png');
 *
 * sprite.width = 512;
 * sprite.height = 512;
 *
 * // Adds a sprite as a child to this container. As a result, the sprite will be rendered whenever the container
 * // is rendered.
 * container.addChild(sprite);
 *
 * // Blurs whatever is rendered by the container
 * container.filters = [new BlurFilter()];
 *
 * // Only the contents within a circle at the center should be rendered onto the screen.
 * container.mask = new Graphics()
 *     .beginFill(0xffffff)
 *     .drawCircle(sprite.width / 2, sprite.height / 2, Math.min(sprite.width, sprite.height) / 2)
 *     .endFill();
 * \`\`\`
 *
 * </details>
 *
 * <details id="renderGroup">
 * <summary>RenderGroup</summary>
 *
 * In PixiJS v8, containers can be set to operate in 'render group mode',
 * transforming them into entities akin to a stage in traditional rendering paradigms.
 * A render group is a root renderable entity, similar to a container,
 * but it's rendered in a separate pass with its own unique set of rendering instructions.
 * This approach enhances rendering efficiency and organization, particularly in complex scenes.
 *
 * You can enable render group mode on any container using container.enableRenderGroup()
 * or by initializing a new container with the render group property set to true (new Container({isRenderGroup: true})).
 *  The method you choose depends on your specific use case and setup requirements.
 *
 * An important aspect of PixiJS’s rendering process is the automatic treatment of rendered scenes as render groups.
 * This conversion streamlines the rendering process, but understanding when and how this happens is crucial
 * to fully leverage its benefits.
 *
 * One of the key advantages of using render groups is the performance efficiency in moving them. Since transformations
 *  are applied at the GPU level, moving a render group, even one with complex and numerous children,
 * doesn't require recalculating the rendering instructions or performing transformations on each child.
 * This makes operations like panning a large game world incredibly efficient.
 *
 * However, it's crucial to note that render groups do not batch together.
 * This means that turning every container into a render group could actually slow things down,
 * as each render group is processed separately. It's best to use render groups judiciously, at a broader level,
 * rather than on a per-child basis.
 * This approach ensures you get the performance benefits without overburdening the rendering process.
 *
 * RenderGroups maintain their own set of rendering instructions,
 * ensuring that changes or updates within a render group don't affect the rendering
 * instructions of its parent or other render groups.
 *  This isolation ensures more stable and predictable rendering behavior.
 *
 * Additionally, renderGroups can be nested, allowing for powerful options in organizing different aspects of your scene.
 * This feature is particularly beneficial for separating complex game graphics from UI elements,
 * enabling intricate and efficient scene management in complex applications.
 *
 * This means that Containers have 3 levels of matrix to be mindful of:
 *
 * 1. localTransform, this is the transform of the container based on its own properties
 * 2. groupTransform, this it the transform of the container relative to the renderGroup it belongs too
 * 3. worldTransform, this is the transform of the container relative to the Scene being rendered
 * </details>
 * @memberof scene
 */
export declare class Container<C extends ContainerChild = ContainerChild> extends EventEmitter<ContainerEvents<C> & AnyEvent> {
	/**
	 * Mixes all enumerable properties and methods from a source object to Container.
	 * @param source - The source of properties and methods to mix in.
	 * @deprecated since 8.8.0
	 */
	static mixin(source: Dict<any>): void;
	/** unique id for this container */
	readonly uid: number;
	/** @private */
	_updateFlags: number;
	/** @private */
	renderGroup: RenderGroup;
	/** @private */
	parentRenderGroup: RenderGroup;
	/** @private */
	parentRenderGroupIndex: number;
	/** @private */
	didChange: boolean;
	/** @private */
	didViewUpdate: boolean;
	/** @private */
	relativeRenderGroupDepth: number;
	/**
	 * The array of children of this container.
	 * @readonly
	 */
	children: C[];
	/** The display object container that contains this display object. */
	parent: Container;
	/** @private */
	includeInBuild: boolean;
	/** @private */
	measurable: boolean;
	/** @private */
	isSimple: boolean;
	/**
	 * The RenderLayer this container belongs to, if any.
	 * If it belongs to a RenderLayer, it will be rendered from the RenderLayer's position in the scene.
	 * @readonly
	 */
	parentRenderLayer: IRenderLayer;
	/**
	 * @internal
	 * @ignore
	 */
	updateTick: number;
	/**
	 * Current transform of the object based on local factors: position, scale, other stuff.
	 * @readonly
	 */
	localTransform: Matrix;
	/**
	 * The relative group transform is a transform relative to the render group it belongs too. It will include all parent
	 * transforms and up to the render group (think of it as kind of like a stage - but the stage can be nested).
	 * If this container is is self a render group matrix will be relative to its parent render group
	 * @readonly
	 */
	relativeGroupTransform: Matrix;
	/**
	 * The group transform is a transform relative to the render group it belongs too.
	 * If this container is render group then this will be an identity matrix. other wise it
	 * will be the same as the relativeGroupTransform.
	 * Use this value when actually rendering things to the screen
	 * @readonly
	 */
	groupTransform: Matrix;
	private _worldTransform;
	/** If the object has been destroyed via destroy(). If true, it should not be used. */
	destroyed: boolean;
	/**
	 * The coordinate of the object relative to the local coordinates of the parent.
	 * @internal
	 * @ignore
	 */
	_position: ObservablePoint;
	/**
	 * The scale factor of the object.
	 * @internal
	 * @ignore
	 */
	_scale: ObservablePoint;
	/**
	 * The pivot point of the container that it rotates around.
	 * @internal
	 * @ignore
	 */
	_pivot: ObservablePoint;
	/**
	 * The skew amount, on the x and y axis.
	 * @internal
	 * @ignore
	 */
	_skew: ObservablePoint;
	/**
	 * The X-coordinate value of the normalized local X axis,
	 * the first column of the local transformation matrix without a scale.
	 * @internal
	 * @ignore
	 */
	_cx: number;
	/**
	 * The Y-coordinate value of the normalized local X axis,
	 * the first column of the local transformation matrix without a scale.
	 * @internal
	 * @ignore
	 */
	_sx: number;
	/**
	 * The X-coordinate value of the normalized local Y axis,
	 * the second column of the local transformation matrix without a scale.
	 * @internal
	 * @ignore
	 */
	_cy: number;
	/**
	 * The Y-coordinate value of the normalized local Y axis,
	 * the second column of the local transformation matrix without a scale.
	 * @internal
	 * @ignore
	 */
	_sy: number;
	/**
	 * The rotation amount.
	 * @internal
	 * @ignore
	 */
	private _rotation;
	localColor: number;
	localAlpha: number;
	groupAlpha: number;
	groupColor: number;
	groupColorAlpha: number;
	/**
	 * @internal
	 * @ignore
	 */
	localBlendMode: BLEND_MODES;
	/**
	 * @internal
	 * @ignore
	 */
	groupBlendMode: BLEND_MODES;
	/**
	 * This property holds three bits: culled, visible, renderable
	 * the third bit represents culling (0 = culled, 1 = not culled) 0b100
	 * the second bit represents visibility (0 = not visible, 1 = visible) 0b010
	 * the first bit represents renderable (0 = not renderable, 1 = renderable) 0b001
	 * @internal
	 * @ignore
	 */
	localDisplayStatus: number;
	/**
	 * @internal
	 * @ignore
	 */
	globalDisplayStatus: number;
	readonly renderPipeId: string;
	/**
	 * An optional bounds area for this container. Setting this rectangle will stop the renderer
	 * from recursively measuring the bounds of each children and instead use this single boundArea.
	 * This is great for optimisation! If for example you have a 1000 spinning particles and you know they all sit
	 * within a specific bounds, then setting it will mean the renderer will not need to measure the
	 * 1000 children to find the bounds. Instead it will just use the bounds you set.
	 */
	boundsArea: Rectangle;
	/**
	 * A value that increments each time the containe is modified
	 * eg children added, removed etc
	 * @ignore
	 */
	_didContainerChangeTick: number;
	/**
	 * A value that increments each time the container view is modified
	 * eg texture swap, geometry change etc
	 * @ignore
	 */
	_didViewChangeTick: number;
	layerParentId: string;
	/**
	 * We now use the _didContainerChangeTick and _didViewChangeTick to track changes
	 * @deprecated since 8.2.6
	 * @ignore
	 */
	set _didChangeId(value: number);
	get _didChangeId(): number;
	/**
	 * property that tracks if the container transform has changed
	 * @ignore
	 */
	private _didLocalTransformChangeId;
	constructor(options?: ContainerOptions<C>);
	/**
	 * Adds one or more children to the container.
	 *
	 * Multiple items can be added like so: \`myContainer.addChild(thingOne, thingTwo, thingThree)\`
	 * @param {...Container} children - The Container(s) to add to the container
	 * @returns {Container} - The first child that was added.
	 */
	addChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
	/**
	 * Removes one or more children from the container.
	 * @param {...Container} children - The Container(s) to remove
	 * @returns {Container} The first child that was removed.
	 */
	removeChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
	/** @ignore */
	_onUpdate(point?: ObservablePoint): void;
	set isRenderGroup(value: boolean);
	/**
	 * Returns true if this container is a render group.
	 * This means that it will be rendered as a separate pass, with its own set of instructions
	 */
	get isRenderGroup(): boolean;
	/**
	 * Calling this enables a render group for this container.
	 * This means it will be rendered as a separate set of instructions.
	 * The transform of the container will also be handled on the GPU rather than the CPU.
	 */
	enableRenderGroup(): void;
	/** This will disable the render group for this container. */
	disableRenderGroup(): void;
	/** @ignore */
	_updateIsSimple(): void;
	/**
	 * Current transform of the object based on world (parent) factors.
	 * @readonly
	 */
	get worldTransform(): Matrix;
	/**
	 * The position of the container on the x axis relative to the local coordinates of the parent.
	 * An alias to position.x
	 */
	get x(): number;
	set x(value: number);
	/**
	 * The position of the container on the y axis relative to the local coordinates of the parent.
	 * An alias to position.y
	 */
	get y(): number;
	set y(value: number);
	/**
	 * The coordinate of the object relative to the local coordinates of the parent.
	 * @since 4.0.0
	 */
	get position(): ObservablePoint;
	set position(value: PointData);
	/**
	 * The rotation of the object in radians.
	 * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
	 */
	get rotation(): number;
	set rotation(value: number);
	/**
	 * The angle of the object in degrees.
	 * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
	 */
	get angle(): number;
	set angle(value: number);
	/**
	 * The center of rotation, scaling, and skewing for this display object in its local space. The \`position\`
	 * is the projection of \`pivot\` in the parent's local space.
	 *
	 * By default, the pivot is the origin (0, 0).
	 * @since 4.0.0
	 */
	get pivot(): ObservablePoint;
	set pivot(value: PointData | number);
	/**
	 * The skew factor for the object in radians.
	 * @since 4.0.0
	 */
	get skew(): ObservablePoint;
	set skew(value: PointData);
	/**
	 * The scale factors of this object along the local coordinate axes.
	 *
	 * The default scale is (1, 1).
	 * @since 4.0.0
	 */
	get scale(): ObservablePoint;
	set scale(value: PointData | number);
	/**
	 * The width of the Container, setting this will actually modify the scale to achieve the value set.
	 * @memberof scene.Container#
	 */
	get width(): number;
	set width(value: number);
	/**
	 * The height of the Container, setting this will actually modify the scale to achieve the value set.
	 * @memberof scene.Container#
	 */
	get height(): number;
	set height(value: number);
	/**
	 * Retrieves the size of the container as a [Size]{@link Size} object.
	 * This is faster than get the width and height separately.
	 * @param out - Optional object to store the size in.
	 * @returns - The size of the container.
	 * @memberof scene.Container#
	 */
	getSize(out?: Size): Size;
	/**
	 * Sets the size of the container to the specified width and height.
	 * This is faster than setting the width and height separately.
	 * @param value - This can be either a number or a [Size]{@link Size} object.
	 * @param height - The height to set. Defaults to the value of \`width\` if not provided.
	 * @memberof scene.Container#
	 */
	setSize(value: number | Optional<Size, "height">, height?: number): void;
	/** Called when the skew or the rotation changes. */
	private _updateSkew;
	/**
	 * Updates the transform properties of the container (accepts partial values).
	 * @param {object} opts - The options for updating the transform.
	 * @param {number} opts.x - The x position of the container.
	 * @param {number} opts.y - The y position of the container.
	 * @param {number} opts.scaleX - The scale factor on the x-axis.
	 * @param {number} opts.scaleY - The scale factor on the y-axis.
	 * @param {number} opts.rotation - The rotation of the container, in radians.
	 * @param {number} opts.skewX - The skew factor on the x-axis.
	 * @param {number} opts.skewY - The skew factor on the y-axis.
	 * @param {number} opts.pivotX - The x coordinate of the pivot point.
	 * @param {number} opts.pivotY - The y coordinate of the pivot point.
	 */
	updateTransform(opts: Partial<UpdateTransformOptions>): this;
	/**
	 * Updates the local transform using the given matrix.
	 * @param matrix - The matrix to use for updating the transform.
	 */
	setFromMatrix(matrix: Matrix): void;
	/** Updates the local transform. */
	updateLocalTransform(): void;
	set alpha(value: number);
	/** The opacity of the object. */
	get alpha(): number;
	set tint(value: ColorSource);
	/**
	 * The tint applied to the sprite. This is a hex value.
	 *
	 * A value of 0xFFFFFF will remove any tint effect.
	 * @default 0xFFFFFF
	 */
	get tint(): number;
	set blendMode(value: BLEND_MODES);
	/**
	 * The blend mode to be applied to the sprite. Apply a value of \`'normal'\` to reset the blend mode.
	 * @default 'normal'
	 */
	get blendMode(): BLEND_MODES;
	/** The visibility of the object. If false the object will not be drawn, and the transform will not be updated. */
	get visible(): boolean;
	set visible(value: boolean);
	/** @ignore */
	get culled(): boolean;
	/** @ignore */
	set culled(value: boolean);
	/** Can this object be rendered, if false the object will not be drawn but the transform will still be updated. */
	get renderable(): boolean;
	set renderable(value: boolean);
	/** Whether or not the object should be rendered. */
	get isRenderable(): boolean;
	/**
	 * Removes all internal references and listeners as well as removes children from the display list.
	 * Do not use a Container after calling \`destroy\`.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.children=false] - if set to true, all the children will have their destroy
	 *  method called as well. 'options' will be passed on to those calls.
	 * @param {boolean} [options.texture=false] - Only used for children with textures e.g. Sprites. If options.children
	 * is set to true it should destroy the texture of the child sprite
	 * @param {boolean} [options.textureSource=false] - Only used for children with textures e.g. Sprites.
	 * If options.children is set to true it should destroy the texture source of the child sprite
	 * @param {boolean} [options.context=false] - Only used for children with graphicsContexts e.g. Graphics.
	 * If options.children is set to true it should destroy the context of the child graphics
	 */
	destroy(options?: DestroyOptions): void;
}
/**
 * The type of the pointer event to listen for.
 * Can be any of the following:
 * - \`auto\`
 * - \`none\`
 * - \`visiblePainted\`
 * - \`visibleFill\`
 * - \`visibleStroke\`
 * - \`visible\`
 * - \`painted\`
 * - \`fill\`
 * - \`stroke\`
 * - \`all\`
 * - \`inherit\`
 * @memberof accessibility
 * @see https://developer.mozilla.org/en-US/docs/Web/CSS/pointer-events
 */
export type PointerEvents = "auto" | "none" | "visiblePainted" | "visibleFill" | "visibleStroke" | "visible" | "painted" | "fill" | "stroke" | "all" | "inherit";
/**
 * When \`accessible\` is enabled on any display object, these properties will affect its accessibility.
 * @memberof accessibility
 */
export interface AccessibleOptions {
	/**
	 * Flag for if the object is accessible. If true AccessibilityManager will overlay a
	 * shadow div with attributes set
	 * @default false
	 */
	accessible: boolean;
	/**
	 * Sets the title attribute of the shadow div
	 * If accessibleTitle AND accessibleHint has not been this will default to 'container [tabIndex]'
	 * @member {string}
	 */
	accessibleTitle: string | null;
	/** Sets the aria-label attribute of the shadow div */
	accessibleHint: string | null;
	/**
	 * @default 0
	 */
	tabIndex: number;
	/**
	 * Specify the type of div the accessible layer is. Screen readers treat the element differently
	 * depending on this type. Defaults to button.
	 * @default 'button'
	 */
	accessibleType: keyof HTMLElementTagNameMap;
	/**
	 * Specify the pointer-events the accessible div will use
	 * Defaults to auto.
	 * @default 'auto'
	 * @type {accessibility.PointerEvents}
	 */
	/** Sets the text content of the shadow div */
	accessibleText: string | null;
	accessiblePointerEvents: PointerEvents;
	/**
	 * Setting to false will prevent any children inside this container to
	 * be accessible. Defaults to true.
	 * @default true
	 */
	accessibleChildren: boolean;
}
/**
 * The Accessibility object is attached to the {@link Container}.
 * @private
 */
export interface AccessibleTarget extends AccessibleOptions {
	_accessibleActive: boolean;
	_accessibleDiv: AccessibleHTMLElement | null;
	_renderId: number;
}
export interface AccessibleHTMLElement extends HTMLElement {
	type?: string;
	container?: Container;
}
/**
 * Default property values of accessible objects
 * used by {@link AccessibilitySystem}.
 * @private
 * @example
 * import { accessibleTarget } from 'pixi.js';
 *
 * function MyObject() {}
 * Object.assign(MyObject.prototype, accessibleTarget);
 */
export declare const accessibilityTarget: AccessibleTarget;
/**
 * The result of the {@link utils.isMobile} function.
 * @ignore
 * @memberof utils
 */
export type isMobileResult = {
	/**
	 * Whether the device is an Apple device.
	 * @memberof utils.isMobile
	 */
	apple: {
		phone: boolean;
		ipod: boolean;
		tablet: boolean;
		universal: boolean;
		device: boolean;
	};
	/**
	 * Whether the device is an Amazon device.
	 * @memberof utils.isMobile
	 */
	amazon: {
		phone: boolean;
		tablet: boolean;
		device: boolean;
	};
	/**
	 * Whether the device is an Android device.
	 * @memberof utils.isMobile
	 */
	android: {
		phone: boolean;
		tablet: boolean;
		device: boolean;
	};
	/**
	 * Whether the device is a Windows device.
	 * @memberof utils.isMobile
	 */
	windows: {
		phone: boolean;
		tablet: boolean;
		device: boolean;
	};
	/**
	 * Whether the device is a specific device.
	 * @memberof utils.isMobile
	 */
	other: {
		blackberry: boolean;
		blackberry10: boolean;
		opera: boolean;
		firefox: boolean;
		chrome: boolean;
		device: boolean;
	};
	/**
	 * Whether the device is a phone device.
	 * @memberof utils.isMobile
	 */
	phone: boolean;
	/**
	 * Whether the device is a tablet device.
	 * @memberof utils.isMobile
	 */
	tablet: boolean;
	/**
	 * Whether the device is any kind of device.
	 * @memberof utils.isMobile
	 */
	any: boolean;
};
/**
 * Detects whether the device is mobile and what type of mobile device it is.
 * \`\`\`js
 * import { isMobile } from 'pixi.js';
 *
 * if (isMobile.apple.tablet) {
 *    // The device is an Apple tablet device.
 * }
 * \`\`\`
 * @memberof utils
 */
export declare const isMobile: isMobileResult;
/** @ignore */
export interface AccessibilitySystemOptions {
	accessibilityOptions?: AccessibilityOptions;
}
/** @ignore */
export interface AccessibilityOptions {
	/** Whether to enable accessibility features on initialization instead of waiting for tab key */
	enabledByDefault?: boolean;
	/** Whether to visually show the accessibility divs for debugging */
	debug?: boolean;
	/** Whether to allow tab key press to activate accessibility features */
	activateOnTab?: boolean;
	/** Whether to deactivate accessibility when mouse moves */
	deactivateOnMouseMove?: boolean;
}
/**
 * The Accessibility system provides screen reader and keyboard navigation support for PixiJS content.
 * It creates an accessible DOM layer over the canvas that can be controlled programmatically or through user interaction.
 *
 * By default, the system activates when users press the tab key. This behavior can be customized through options:
 * \`\`\`js
 * const app = new Application({
 *     accessibilityOptions: {
 *         enabledByDefault: true,    // Enable immediately instead of waiting for tab
 *         activateOnTab: false,      // Disable tab key activation
 *         debug: false,               // Show/hide accessibility divs
 *         deactivateOnMouseMove: false, // Prevent accessibility from being deactivated when mouse moves
 *     }
 * });
 * \`\`\`
 *
 * The system can also be controlled programmatically:
 * \`\`\`js
 * app.renderer.accessibility.setAccessibilityEnabled(true);
 * \`\`\`
 *
 * To make individual containers accessible:
 * \`\`\`js
 * container.accessible = true;
 * \`\`\`
 *
 * An instance of this class is automatically created at \`renderer.accessibility\`
 * @memberof accessibility
 */
export declare class AccessibilitySystem implements System<AccessibilitySystemOptions> {
	private readonly _mobileInfo;
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "accessibility";
	};
	/** default options used by the system */
	static defaultOptions: AccessibilityOptions;
	/** Whether accessibility divs are visible for debugging */
	debug: boolean;
	/** Whether to activate on tab key press */
	private _activateOnTab;
	/** Whether to deactivate accessibility when mouse moves */
	private _deactivateOnMouseMove;
	/**
	 * The renderer this accessibility manager works for.
	 * @type {WebGLRenderer|WebGPURenderer}
	 */
	private _renderer;
	/** Internal variable, see isActive getter. */
	private _isActive;
	/** Internal variable, see isMobileAccessibility getter. */
	private _isMobileAccessibility;
	/** Button element for handling touch hooks. */
	private _hookDiv;
	/** This is the dom element that will sit over the PixiJS element. This is where the div overlays will go. */
	private _div;
	/** A simple pool for storing divs. */
	private _pool;
	/** This is a tick used to check if an object is no longer being rendered. */
	private _renderId;
	/** The array of currently active accessible items. */
	private _children;
	/** Count to throttle div updates on android devices. */
	private _androidUpdateCount;
	/**  The frequency to update the div elements. */
	private readonly _androidUpdateFrequency;
	/**
	 * @param {WebGLRenderer|WebGPURenderer} renderer - A reference to the current renderer
	 */
	constructor(renderer: Renderer, _mobileInfo?: isMobileResult);
	/**
	 * Value of \`true\` if accessibility is currently active and accessibility layers are showing.
	 * @member {boolean}
	 * @readonly
	 */
	get isActive(): boolean;
	/**
	 * Value of \`true\` if accessibility is enabled for touch devices.
	 * @member {boolean}
	 * @readonly
	 */
	get isMobileAccessibility(): boolean;
	get hookDiv(): HTMLElement;
	/**
	 * Creates the touch hooks.
	 * @private
	 */
	private _createTouchHook;
	/**
	 * Destroys the touch hooks.
	 * @private
	 */
	private _destroyTouchHook;
	/**
	 * Activating will cause the Accessibility layer to be shown.
	 * This is called when a user presses the tab key.
	 * @private
	 */
	private _activate;
	private _initAccessibilitySetup;
	/**
	 * Deactivates the accessibility system. Removes listeners and accessibility elements.
	 * @private
	 */
	private _deactivate;
	/**
	 * This recursive function will run through the scene graph and add any new accessible objects to the DOM layer.
	 * @private
	 * @param {Container} container - The Container to check.
	 */
	private _updateAccessibleObjects;
	/**
	 * Runner init called, view is available at this point.
	 * @ignore
	 */
	init(options?: AccessibilitySystemOptions): void;
	/**
	 * Updates the accessibility layer during rendering.
	 * - Removes divs for containers no longer in the scene
	 * - Updates the position and dimensions of the root div
	 * - Updates positions of active accessibility divs
	 * Only fires while the accessibility system is active.
	 * @ignore
	 */
	postrender(): void;
	/**
	 * private function that will visually add the information to the
	 * accessibility div
	 * @param {HTMLElement} div -
	 */
	private _updateDebugHTML;
	/**
	 * Adjust the hit area based on the bounds of a display object
	 * @param {Rectangle} hitArea - Bounds of the child
	 */
	private _capHitArea;
	/**
	 * Creates or reuses a div element for a Container and adds it to the accessibility layer.
	 * Sets up ARIA attributes, event listeners, and positioning based on the container's properties.
	 * @private
	 * @param {Container} container - The child to make accessible.
	 */
	private _addChild;
	/**
	 * Dispatch events with the EventSystem.
	 * @param e
	 * @param type
	 * @private
	 */
	private _dispatchEvent;
	/**
	 * Maps the div button press to pixi's EventSystem (click)
	 * @private
	 * @param {MouseEvent} e - The click event.
	 */
	private _onClick;
	/**
	 * Maps the div focus events to pixi's EventSystem (mouseover)
	 * @private
	 * @param {FocusEvent} e - The focus event.
	 */
	private _onFocus;
	/**
	 * Maps the div focus events to pixi's EventSystem (mouseout)
	 * @private
	 * @param {FocusEvent} e - The focusout event.
	 */
	private _onFocusOut;
	/**
	 * Is called when a key is pressed
	 * @private
	 * @param {KeyboardEvent} e - The keydown event.
	 */
	private _onKeyDown;
	/**
	 * Is called when the mouse moves across the renderer element
	 * @private
	 * @param {MouseEvent} e - The mouse event.
	 */
	private _onMouseMove;
	/** Destroys the accessibility system. Removes all elements and listeners. */
	destroy(): void;
	/**
	 * Enables or disables the accessibility system.
	 * @param enabled - Whether to enable or disable accessibility.
	 */
	setAccessibilityEnabled(enabled: boolean): void;
}
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface Container extends Partial<AccessibleTarget> {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ContainerOptions extends Partial<AccessibleOptions> {
		}
		interface RendererSystems {
			accessibility: AccessibilitySystem;
		}
	}
}
/**
 * A callback which can be added to a ticker.
 * \`\`\`js
 * ticker.add(() => {
 *    // do something every frame
 * });
 * \`\`\`
 * @memberof ticker
 */
export type TickerCallback<T> = (this: T, ticker: Ticker) => any;
/**
 * {@link ticker.Ticker|Tickers} provide periodic callbacks based on the system clock.
 * Your game update logic will generally be run in response to a tick once per frame.
 * You can have multiple tickers in use at one time.
 * \`\`\`js
 * import { Ticker } from 'pixi.js';
 *
 * const callback = (ticker: Ticker) => {
 *    // do something on the next animation frame
 * };
 *
 * // create a ticker
 * const ticker = new Ticker();
 *
 * // register the callback and start the ticker
 * ticker.add(callback);
 * ticker.start();
 * \`\`\`
 *
 * You can always use the {@link ticker.Ticker.shared|shared} ticker that Pixi renders with by default.
 * \`\`\`js
 * Ticker.shared.add(callback);
 * \`\`\`
 * @namespace ticker
 */
/**
 * A Ticker class that runs an update loop that other objects listen to.
 *
 * This class is composed around listeners meant for execution on the next requested animation frame.
 * Animation frames are requested only when necessary, e.g. When the ticker is started and the emitter has listeners.
 * @class
 * @memberof ticker
 */
export declare class Ticker {
	/**
	 * Target frames per millisecond.
	 * @static
	 */
	static targetFPMS: number;
	/** The private shared ticker instance */
	private static _shared;
	/** The private system ticker instance  */
	private static _system;
	/**
	 * Whether or not this ticker should invoke the method
	 * {@link ticker.Ticker#start|start} automatically when a listener is added.
	 */
	autoStart: boolean;
	/**
	 * Scalar time value from last frame to this frame.
	 * This value is capped by setting {@link ticker.Ticker#minFPS|minFPS}
	 * and is scaled with {@link ticker.Ticker#speed|speed}.
	 * **Note:** The cap may be exceeded by scaling.
	 */
	deltaTime: number;
	/**
	 * Scalar time elapsed in milliseconds from last frame to this frame.
	 * This value is capped by setting {@link ticker.Ticker#minFPS|minFPS}
	 * and is scaled with {@link ticker.Ticker#speed|speed}.
	 * **Note:** The cap may be exceeded by scaling.
	 * If the platform supports DOMHighResTimeStamp,
	 * this value will have a precision of 1 µs.
	 * Defaults to target frame time
	 * @default 16.66
	 */
	deltaMS: number;
	/**
	 * Time elapsed in milliseconds from last frame to this frame.
	 * Opposed to what the scalar {@link ticker.Ticker#deltaTime|deltaTime}
	 * is based, this value is neither capped nor scaled.
	 * If the platform supports DOMHighResTimeStamp,
	 * this value will have a precision of 1 µs.
	 * Defaults to target frame time
	 * @default 16.66
	 */
	elapsedMS: number;
	/**
	 * The last time {@link ticker.Ticker#update|update} was invoked.
	 * This value is also reset internally outside of invoking
	 * update, but only when a new animation frame is requested.
	 * If the platform supports DOMHighResTimeStamp,
	 * this value will have a precision of 1 µs.
	 */
	lastTime: number;
	/**
	 * Factor of current {@link ticker.Ticker#deltaTime|deltaTime}.
	 * @example
	 * // Scales ticker.deltaTime to what would be
	 * // the equivalent of approximately 120 FPS
	 * ticker.speed = 2;
	 */
	speed: number;
	/**
	 * Whether or not this ticker has been started.
	 * \`true\` if {@link ticker.Ticker#start|start} has been called.
	 * \`false\` if {@link ticker.Ticker#stop|Stop} has been called.
	 * While \`false\`, this value may change to \`true\` in the
	 * event of {@link ticker.Ticker#autoStart|autoStart} being \`true\`
	 * and a listener is added.
	 */
	started: boolean;
	/** The first listener. All new listeners added are chained on this. */
	private _head;
	/** Internal current frame request ID */
	private _requestId;
	/**
	 * Internal value managed by minFPS property setter and getter.
	 * This is the maximum allowed milliseconds between updates.
	 */
	private _maxElapsedMS;
	/**
	 * Internal value managed by minFPS property setter and getter.
	 * This is the minimum allowed milliseconds between updates.
	 */
	private _minElapsedMS;
	/** If enabled, deleting is disabled.*/
	private _protected;
	/** The last time keyframe was executed. Maintains a relatively fixed interval with the previous value. */
	private _lastFrame;
	/**
	 * Internal tick method bound to ticker instance.
	 * This is because in early 2015, Function.bind
	 * is still 60% slower in high performance scenarios.
	 * Also separating frame requests from update method
	 * so listeners may be called at any time and with
	 * any animation API, just invoke ticker.update(time).
	 * @param time - Time since last tick.
	 */
	private readonly _tick;
	constructor();
	/**
	 * Conditionally requests a new animation frame.
	 * If a frame has not already been requested, and if the internal
	 * emitter has listeners, a new frame is requested.
	 * @private
	 */
	private _requestIfNeeded;
	/**
	 * Conditionally cancels a pending animation frame.
	 * @private
	 */
	private _cancelIfNeeded;
	/**
	 * Conditionally requests a new animation frame.
	 * If the ticker has been started it checks if a frame has not already
	 * been requested, and if the internal emitter has listeners. If these
	 * conditions are met, a new frame is requested. If the ticker has not
	 * been started, but autoStart is \`true\`, then the ticker starts now,
	 * and continues with the previous conditions to request a new frame.
	 * @private
	 */
	private _startIfPossible;
	/**
	 * Register a handler for tick events. Calls continuously unless
	 * it is removed or the ticker is stopped.
	 * @param fn - The listener function to be added for updates
	 * @param context - The listener context
	 * @param {number} [priority=UPDATE_PRIORITY.NORMAL] - The priority for emitting
	 * @returns This instance of a ticker
	 */
	add<T = any>(fn: TickerCallback<T>, context?: T, priority?: number): this;
	/**
	 * Add a handler for the tick event which is only execute once.
	 * @param fn - The listener function to be added for one update
	 * @param context - The listener context
	 * @param {number} [priority=UPDATE_PRIORITY.NORMAL] - The priority for emitting
	 * @returns This instance of a ticker
	 */
	addOnce<T = any>(fn: TickerCallback<T>, context?: T, priority?: number): this;
	/**
	 * Internally adds the event handler so that it can be sorted by priority.
	 * Priority allows certain handler (user, AnimatedSprite, Interaction) to be run
	 * before the rendering.
	 * @private
	 * @param listener - Current listener being added.
	 * @returns This instance of a ticker
	 */
	private _addListener;
	/**
	 * Removes any handlers matching the function and context parameters.
	 * If no handlers are left after removing, then it cancels the animation frame.
	 * @param fn - The listener function to be removed
	 * @param context - The listener context to be removed
	 * @returns This instance of a ticker
	 */
	remove<T = any>(fn: TickerCallback<T>, context?: T): this;
	/**
	 * The number of listeners on this ticker, calculated by walking through linked list
	 * @readonly
	 * @member {number}
	 */
	get count(): number;
	/** Starts the ticker. If the ticker has listeners a new animation frame is requested at this point. */
	start(): void;
	/** Stops the ticker. If the ticker has requested an animation frame it is canceled at this point. */
	stop(): void;
	/** Destroy the ticker and don't use after this. Calling this method removes all references to internal events. */
	destroy(): void;
	/**
	 * Triggers an update. An update entails setting the
	 * current {@link ticker.Ticker#elapsedMS|elapsedMS},
	 * the current {@link ticker.Ticker#deltaTime|deltaTime},
	 * invoking all listeners with current deltaTime,
	 * and then finally setting {@link ticker.Ticker#lastTime|lastTime}
	 * with the value of currentTime that was provided.
	 * This method will be called automatically by animation
	 * frame callbacks if the ticker instance has been started
	 * and listeners are added.
	 * @param {number} [currentTime=performance.now()] - the current time of execution
	 */
	update(currentTime?: number): void;
	/**
	 * The frames per second at which this ticker is running.
	 * The default is approximately 60 in most modern browsers.
	 * **Note:** This does not factor in the value of
	 * {@link ticker.Ticker#speed|speed}, which is specific
	 * to scaling {@link ticker.Ticker#deltaTime|deltaTime}.
	 * @member {number}
	 * @readonly
	 */
	get FPS(): number;
	/**
	 * Manages the maximum amount of milliseconds allowed to
	 * elapse between invoking {@link ticker.Ticker#update|update}.
	 * This value is used to cap {@link ticker.Ticker#deltaTime|deltaTime},
	 * but does not effect the measured value of {@link ticker.Ticker#FPS|FPS}.
	 * When setting this property it is clamped to a value between
	 * \`0\` and \`Ticker.targetFPMS * 1000\`.
	 * @member {number}
	 * @default 10
	 */
	get minFPS(): number;
	set minFPS(fps: number);
	/**
	 * Manages the minimum amount of milliseconds required to
	 * elapse between invoking {@link ticker.Ticker#update|update}.
	 * This will effect the measured value of {@link ticker.Ticker#FPS|FPS}.
	 * If it is set to \`0\`, then there is no limit; PixiJS will render as many frames as it can.
	 * Otherwise it will be at least \`minFPS\`
	 * @member {number}
	 * @default 0
	 */
	get maxFPS(): number;
	set maxFPS(fps: number);
	/**
	 * The shared ticker instance used by {@link AnimatedSprite} and by
	 * {@link VideoResource} to update animation frames / video textures.
	 *
	 * It may also be used by {@link Application} if created with the \`sharedTicker\` option property set to true.
	 *
	 * The property {@link ticker.Ticker#autoStart|autoStart} is set to \`true\` for this instance.
	 * Please follow the examples for usage, including how to opt-out of auto-starting the shared ticker.
	 * @example
	 * import { Ticker } from 'pixi.js';
	 *
	 * const ticker = Ticker.shared;
	 * // Set this to prevent starting this ticker when listeners are added.
	 * // By default this is true only for the Ticker.shared instance.
	 * ticker.autoStart = false;
	 *
	 * // FYI, call this to ensure the ticker is stopped. It should be stopped
	 * // if you have not attempted to render anything yet.
	 * ticker.stop();
	 *
	 * // Call this when you are ready for a running shared ticker.
	 * ticker.start();
	 * @example
	 * import { autoDetectRenderer, Container } from 'pixi.js';
	 *
	 * // You may use the shared ticker to render...
	 * const renderer = autoDetectRenderer();
	 * const stage = new Container();
	 * document.body.appendChild(renderer.view);
	 * ticker.add((time) => renderer.render(stage));
	 *
	 * // Or you can just update it manually.
	 * ticker.autoStart = false;
	 * ticker.stop();
	 * const animate = (time) => {
	 *     ticker.update(time);
	 *     renderer.render(stage);
	 *     requestAnimationFrame(animate);
	 * };
	 * animate(performance.now());
	 * @member {ticker.Ticker}
	 * @readonly
	 * @static
	 */
	static get shared(): Ticker;
	/**
	 * The system ticker instance used by {@link BasePrepare} for core timing
	 * functionality that shouldn't usually need to be paused, unlike the \`shared\`
	 * ticker which drives visual animations and rendering which may want to be paused.
	 *
	 * The property {@link ticker.Ticker#autoStart|autoStart} is set to \`true\` for this instance.
	 * @member {ticker.Ticker}
	 * @readonly
	 * @static
	 */
	static get system(): Ticker;
}
type ResizeableRenderer = Pick<Renderer, "resize">;
/**
 * Application options for the {@link app.ResizePlugin}.
 * @memberof app
 * @property {Window|HTMLElement} [resizeTo=window] - Element to automatically resize the renderer to.
 */
export interface ResizePluginOptions {
	/**
	 * Element to automatically resize the renderer to.
	 * @memberof app.ApplicationOptions
	 */
	resizeTo?: Window | HTMLElement;
}
/**
 * Middleware for Application's resize functionality.
 *
 * Adds the following methods to {@link app.Application}:
 * * {@link app.Application#resizeTo}
 * * {@link app.Application#resize}
 * * {@link app.Application#queueResize}
 * * {@link app.Application#cancelResize}
 * @example
 * import { extensions, ResizePlugin } from 'pixi.js';
 *
 * extensions.add(ResizePlugin);
 * @memberof app
 */
export declare class ResizePlugin {
	/** @ignore */
	static extension: ExtensionMetadata;
	static resizeTo: Window | HTMLElement;
	static resize: () => void;
	static renderer: ResizeableRenderer;
	static queueResize: () => void;
	static render: () => void;
	private static _resizeId;
	private static _resizeTo;
	private static _cancelResize;
	/**
	 * Initialize the plugin with scope of application instance
	 * @static
	 * @private
	 * @param {object} [options] - See application options
	 */
	static init(options: ResizePluginOptions): void;
	/**
	 * Clean up the ticker, scoped to application
	 * @static
	 * @private
	 */
	static destroy(): void;
}
/**
 * Application options for the {@link app.TickerPlugin}.
 * @memberof app
 * @property {boolean} [autoStart=true] - Automatically starts the rendering after the construction.
 * **Note**: Setting this parameter to \`false\` does NOT stop the shared ticker even if you set
 * \`options.sharedTicker\` to \`true\` in case that it is already started. Stop it by your own.
 * @property {boolean} [sharedTicker=false] - Set\`true\` to use \`Ticker.shared\`, \`false\` to create new ticker.
 * If set to \`false\`, you cannot register a handler to occur before anything that runs on the shared ticker.
 * The system ticker will always run before both the shared ticker and the app ticker.
 */
export interface TickerPluginOptions {
	/**
	 * Automatically starts the rendering after the construction.
	 *  **Note**: Setting this parameter to \`false\` does NOT stop the shared ticker even if you set
	 *  \`options.sharedTicker\` to \`true\` in case that it is already started. Stop it by your own.
	 * @memberof app.ApplicationOptions
	 * @default true
	 */
	autoStart?: boolean;
	/**
	 * Set\`true\` to use \`Ticker.shared\`, \`false\` to create new ticker.
	 *  If set to \`false\`, you cannot register a handler to occur before anything that runs on the shared ticker.
	 *  The system ticker will always run before both the shared ticker and the app ticker.
	 * @memberof app.ApplicationOptions
	 * @default false
	 */
	sharedTicker?: boolean;
}
/**
 * Middleware for Application's {@link ticker.Ticker} functionality.
 *
 * Adds the following methods to {@link app.Application}:
 * * {@link app.Application#start}
 * * {@link app.Application#stop}
 * * {@link app.Application#ticker}
 * @example
 * import { extensions, TickerPlugin } from 'pixi.js';
 *
 * extensions.add(TickerPlugin);
 * @memberof app
 */
export declare class TickerPlugin {
	/** @ignore */
	static extension: ExtensionMetadata;
	static start: () => void;
	static stop: () => void;
	private static _ticker;
	static ticker: Ticker;
	/**
	 * Initialize the plugin with scope of application instance
	 * @static
	 * @private
	 * @param {object} [options] - See application options
	 */
	static init(options?: PixiMixins.ApplicationOptions): void;
	/**
	 * Clean up the ticker, scoped to application.
	 * @static
	 * @private
	 */
	static destroy(): void;
}
declare global {
	namespace PixiMixins {
		// Extend the Application interface with resize and ticker functionalities
		interface Application {
			resizeTo: Window | HTMLElement;
			resize(): void;
			queueResize(): void;
			cancelResize(): void;
			ticker: Ticker;
			stop(): void;
			start(): void;
		}
		// Combine ResizePluginOptions and TickerPluginOptions into ApplicationOptions
		interface ApplicationOptions extends ResizePluginOptions, TickerPluginOptions {
		}
	}
}
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface AssetsPreferences {
		}
	}
}
export interface CullingMixinConstructor {
	/**
	 * If set, this shape is used for culling instead of the bounds of this object.
	 * It can improve the culling performance of objects with many children.
	 * The culling area is defined in local space.
	 * @memberof scene.Container#
	 */
	cullArea: Rectangle;
	/**
	 * Should this object be rendered if the bounds of this object are out of frame?
	 *
	 * Culling has no effect on whether updateTransform is called.
	 * @default false
	 * @memberof scene.Container#
	 */
	cullable: boolean;
	/**
	 * Determines if the children to the container can be culled
	 * Setting this to false allows PixiJS to bypass a recursive culling function
	 * Which can help to optimize very complex scenes
	 * @default true
	 * @memberof scene.Container#
	 */
	cullableChildren: boolean;
}
export declare const cullingMixin: CullingMixinConstructor;
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface Container extends Partial<CullingMixinConstructor> {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ContainerOptions extends Partial<CullingMixinConstructor> {
		}
	}
}
/**
 * Options for the {@link scene.DOMContainer} constructor.
 * @memberof scene
 */
export interface DOMContainerOptions extends ViewContainerOptions {
	/** The DOM element to use for the container. */
	element?: HTMLElement;
	/** The anchor point of the container. */
	anchor?: PointData | number;
}
/**
 * The DOMContainer object is used to render DOM elements within the PixiJS scene graph.
 * It allows you to integrate HTML elements into your PixiJS application.
 *
 * DOMContainer is especially useful for rendering standard DOM elements
 * that handle user input, such as \`<input>\` or \`<textarea>\`.
 * This is often simpler and more flexible than trying to implement text input
 * directly in PixiJS. For instance, if you need text fields or text areas,
 * you can embed them through this container for native browser text handling.
 *
 * --------- EXPERIMENTAL ---------
 *
 * This is a new API, things may change and it may not work as expected.
 * We want to hear your feedback as we go!
 *
 * --------------------------------
 * @example
 * \`\`\`js
 * import { DOMContainer } from 'pixi.js';
 *
 * const element = document.createElement('div');
 * element.innerHTML = 'Hello World!';
 *
 * const domContainer = new DOMContainer({ element });
 * \`\`\`
 * @memberof scene
 * @extends scene.ViewContainer
 */
export declare class DOMContainer extends ViewContainer {
	/** @private */
	readonly renderPipeId: string;
	/** @private */
	batched: boolean;
	/**
	 * The anchor point of the container.
	 * @private
	 */
	readonly _anchor: Point;
	/** The DOM element that this container is using. */
	private _element;
	/**
	 * @param options - The options for creating the DOM container.
	 */
	constructor(options?: DOMContainerOptions);
	/**
	 * The anchor sets the origin point of the container.
	 * The default is \`(0,0)\`, this means the container's origin is the top left.
	 *
	 * Setting the anchor to \`(0.5,0.5)\` means the container's origin is centered.
	 * Setting the anchor to \`(1,1)\` would mean the container's origin point will be the bottom right corner.
	 *
	 * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
	 */
	get anchor(): Point;
	set anchor(value: PointData | number);
	set element(value: HTMLElement);
	/** The DOM element that this container is using. */
	get element(): HTMLElement;
	/** @private */
	protected updateBounds(): void;
	/**
	 * Destroys this DOM container.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 */
	destroy(options?: boolean): void;
}
/**
 * The DOMPipe class is responsible for managing and rendering DOM elements within a PixiJS scene.
 * It maps dom elements to the canvas and ensures they are correctly positioned and visible.
 */
export declare class DOMPipe implements RenderPipe<DOMContainer> {
	/**
	 * Static property defining the extension type and name for the DOMPipe.
	 * This is used to register the DOMPipe with different rendering pipelines.
	 */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "dom";
	};
	private _renderer;
	private readonly _destroyRenderableBound;
	/** Array to keep track of attached DOM elements */
	private readonly _attachedDomElements;
	/** The main DOM element that acts as a container for other DOM elements */
	private readonly _domElement;
	/**
	 * Constructor for the DOMPipe class.
	 * @param renderer - The renderer instance that this DOMPipe will be associated with.
	 */
	constructor(renderer: Renderer);
	/**
	 * Adds a renderable DOM container to the list of attached elements.
	 * @param domContainer - The DOM container to be added.
	 * @param _instructionSet - The instruction set (unused).
	 */
	addRenderable(domContainer: DOMContainer, _instructionSet: InstructionSet): void;
	/**
	 * Updates a renderable DOM container.
	 * @param _domContainer - The DOM container to be updated (unused).
	 */
	updateRenderable(_domContainer: DOMContainer): void;
	/**
	 * Validates a renderable DOM container.
	 * @param _domContainer - The DOM container to be validated (unused).
	 * @returns Always returns true as validation is not required.
	 */
	validateRenderable(_domContainer: DOMContainer): boolean;
	/**
	 * Destroys a renderable DOM container, removing it from the list of attached elements.
	 * @param domContainer - The DOM container to be destroyed.
	 */
	destroyRenderable(domContainer: DOMContainer): void;
	/** Handles the post-rendering process, ensuring DOM elements are correctly positioned and visible. */
	postrender(): void;
	/** Destroys the DOMPipe, removing all attached DOM elements and cleaning up resources. */
	destroy(): void;
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			dom: DOMPipe;
		}
	}
}
/**
 * A {@link FederatedEvent} for wheel events.
 * @memberof events
 */
export declare class FederatedWheelEvent extends FederatedMouseEvent implements WheelEvent {
	/**
	 * The units of \`deltaX\`, \`deltaY\`, and \`deltaZ\`. This is one of \`DOM_DELTA_LINE\`,
	 * \`DOM_DELTA_PAGE\`, \`DOM_DELTA_PIXEL\`.
	 */
	deltaMode: number;
	/** Horizontal scroll amount */
	deltaX: number;
	/** Vertical scroll amount */
	deltaY: number;
	/** z-axis scroll amount. */
	deltaZ: number;
	/** Units specified in pixels. */
	static readonly DOM_DELTA_PIXEL = 0;
	/** Units specified in pixels. */
	readonly DOM_DELTA_PIXEL = 0;
	/** Units specified in lines. */
	static readonly DOM_DELTA_LINE = 1;
	/** Units specified in lines. */
	readonly DOM_DELTA_LINE = 1;
	/** Units specified in pages. */
	static readonly DOM_DELTA_PAGE = 2;
	/** Units specified in pages. */
	readonly DOM_DELTA_PAGE = 2;
}
/**
 * The tracking data for each pointer held in the state of an {@link EventBoundary}.
 *
 * \`\`\`ts
 * pressTargetsByButton: {
 *     [id: number]: Container[];
 * };
 * clicksByButton: {
 *     [id: number]: {
 *         clickCount: number;
 *         target: Container;
 *         timeStamp: number;
 *     };
 * };
 * overTargets: Container[];
 * \`\`\`
 * @typedef {object} TrackingData
 * @property {Record.<number, Container>} pressTargetsByButton - The pressed containers'
 *  propagation paths by each button of the pointer.
 * @property {Record.<number, object>} clicksByButton - Holds clicking data for each button of the pointer.
 * @property {Container[]} overTargets - The Container propagation path over which the pointer is hovering.
 * @memberof events
 */
export type TrackingData = {
	pressTargetsByButton: {
		[id: number]: Container[];
	};
	clicksByButton: {
		[id: number]: {
			clickCount: number;
			target: Container;
			timeStamp: number;
		};
	};
	overTargets: Container[];
};
type EmitterListener = {
	fn(...args: any[]): any;
	context: any;
	once: boolean;
};
/**
 * Internal storage of event listeners in EventEmitter.
 * @ignore
 */
export type EmitterListeners = Record<string, EmitterListener | EmitterListener[]>;
/**
 * The type of cursor to use when the mouse pointer is hovering over.
 * @see https://developer.mozilla.org/en-US/docs/Web/CSS/cursor
 *
 * Can be any valid CSS cursor value:
 * \`auto\`, \`default\`, \`none\`, \`context-menu\`, \`help\`, \`pointer\`, \`progress\`,
 * \`wait\`, \`cell\`, \`crosshair\`, \`text\`, \`verticaltext\`, \`alias\`, \`copy\`, \`move\`,
 * \`nodrop\`, \`notallowed\`, \`eresize\`, \`nresize\`, \`neresize\`, \`nwresize\`, \`sresize\`,
 *  \`seresize\`, \`swresize\`, \`wresize\`, \`nsresize\`, \`ewresize\`, \`neswresize\`, \`colresize\`,
 *  \`nwseresize\`, \`rowresize\`, \`allscroll\`, \`zoomin\`, \`zoomout\`, \`grab\`, \`grabbing\`
 * @memberof events
 */
export type Cursor = "auto" | "default" | "none" | "context-menu" | "help" | "pointer" | "progress" | "wait" | "cell" | "crosshair" | "text" | "vertical-text" | "alias" | "copy" | "move" | "no-drop" | "not-allowed" | "e-resize" | "n-resize" | "ne-resize" | "nw-resize" | "s-resize" | "se-resize" | "sw-resize" | "w-resize" | "ns-resize" | "ew-resize" | "nesw-resize" | "col-resize" | "nwse-resize" | "row-resize" | "all-scroll" | "zoom-in" | "zoom-out" | "grab" | "grabbing";
/**
 * The hit area specifies the area for which pointer events should be captured by this event target.
 * @memberof events
 */
export interface IHitArea {
	/**
	 * Checks if the x and y coordinates given are contained within this hit area.
	 * @returns Whether the x and y coordinates are contained within this hit area.
	 */
	contains(x: number, y: number): boolean;
}
/**
 * Function type for handlers, e.g., onclick
 * @memberof events
 */
export type FederatedEventHandler<T = FederatedPointerEvent> = (event: T) => void;
/**
 * The type of interaction a Container can be.
 * This is the {@link scene.Container#eventMode|Container.eventMode} property of any {@link scene.Container}.
 *
 * Can be one of the following:
 * - \`'none'\`: Ignores all interaction events, even on its children.
 * - \`'passive'\`: **(default)** Does not emit events and ignores all hit testing on itself and non-interactive children.
 * Interactive children will still emit events.
 * - \`'auto'\`: Does not emit events but is hit tested if parent is interactive. Same as \`interactive = false\` in v7
 * - \`'static'\`: Emit events and is hit tested. Same as \`interaction = true\` in v7
 * - \`'dynamic'\`: Emits events and is hit tested but will also receive mock interaction events fired from a ticker to
 * allow for interaction when the mouse isn't moving
 *
 * \`none\` and \`passive\` are useful for optimizing interaction events on objects as it reduces the number of hit tests
 * PixiJS has to do. \`auto\` is useful for when you want to recreate how the DOM handles interaction events with
 * \`pointer-events: auto\`.
 * @since 7.2.0
 * @memberof events
 */
export type EventMode = "none" | "passive" | "auto" | "static" | "dynamic";
/**
 * The properties available for any interactive object.
 * @memberof events
 */
export interface FederatedOptions {
	/** The cursor preferred when the mouse pointer is hovering over. */
	cursor?: Cursor | string;
	/** The mode of interaction for this object */
	eventMode?: EventMode;
	/** Whether this event target should fire UI events. */
	interactive?: boolean;
	/** Whether this event target has any children that need UI events. This can be used optimize event propagation. */
	interactiveChildren?: boolean;
	/** The hit-area specifies the area for which pointer events should be captured by this event target. */
	hitArea?: IHitArea | null;
	/** Handler for 'click' event */
	onclick?: FederatedEventHandler | null;
	/** Handler for 'mousedown' event */
	onmousedown?: FederatedEventHandler | null;
	/** Handler for 'mouseenter' event */
	onmouseenter?: FederatedEventHandler | null;
	/** Handler for 'mouseleave' event */
	onmouseleave?: FederatedEventHandler | null;
	/** Handler for 'mousemove' event */
	onmousemove?: FederatedEventHandler | null;
	/** Handler for 'globalmousemove' event */
	onglobalmousemove?: FederatedEventHandler | null;
	/** Handler for 'mouseout' event */
	onmouseout?: FederatedEventHandler | null;
	/** Handler for 'mouseover' event */
	onmouseover?: FederatedEventHandler | null;
	/** Handler for 'mouseup' event */
	onmouseup?: FederatedEventHandler | null;
	/** Handler for 'mouseupoutside' event */
	onmouseupoutside?: FederatedEventHandler | null;
	/** Handler for 'pointercancel' event */
	onpointercancel?: FederatedEventHandler | null;
	/** Handler for 'pointerdown' event */
	onpointerdown?: FederatedEventHandler | null;
	/** Handler for 'pointerenter' event */
	onpointerenter?: FederatedEventHandler | null;
	/** Handler for 'pointerleave' event */
	onpointerleave?: FederatedEventHandler | null;
	/** Handler for 'pointermove' event */
	onpointermove?: FederatedEventHandler | null;
	/** Handler for 'globalpointermove' event */
	onglobalpointermove?: FederatedEventHandler | null;
	/** Handler for 'pointerout' event */
	onpointerout?: FederatedEventHandler | null;
	/** Handler for 'pointerover' event */
	onpointerover?: FederatedEventHandler | null;
	/** Handler for 'pointertap' event */
	onpointertap?: FederatedEventHandler | null;
	/** Handler for 'pointerup' event */
	onpointerup?: FederatedEventHandler | null;
	/** Handler for 'pointerupoutside' event */
	onpointerupoutside?: FederatedEventHandler | null;
	/** Handler for 'rightclick' event */
	onrightclick?: FederatedEventHandler | null;
	/** Handler for 'rightdown' event */
	onrightdown?: FederatedEventHandler | null;
	/** Handler for 'rightup' event */
	onrightup?: FederatedEventHandler | null;
	/** Handler for 'rightupoutside' event */
	onrightupoutside?: FederatedEventHandler | null;
	/** Handler for 'tap' event */
	ontap?: FederatedEventHandler | null;
	/** Handler for 'touchcancel' event */
	ontouchcancel?: FederatedEventHandler | null;
	/** Handler for 'touchend' event */
	ontouchend?: FederatedEventHandler | null;
	/** Handler for 'touchendoutside' event */
	ontouchendoutside?: FederatedEventHandler | null;
	/** Handler for 'touchmove' event */
	ontouchmove?: FederatedEventHandler | null;
	/** Handler for 'globaltouchmove' event */
	onglobaltouchmove?: FederatedEventHandler | null;
	/** Handler for 'touchstart' event */
	ontouchstart?: FederatedEventHandler | null;
	/** Handler for 'wheel' event */
	onwheel?: FederatedEventHandler<FederatedWheelEvent> | null;
}
type AddListenerOptions = boolean | AddEventListenerOptions;
type RemoveListenerOptions = boolean | EventListenerOptions;
export interface IFederatedContainer extends FederatedOptions {
	/** The parent of this event target. */
	readonly parent?: Container;
	/** The children of this event target. */
	readonly children?: ReadonlyArray<Container>;
	_internalEventMode: EventMode;
	/** Returns true if the Container has interactive 'static' or 'dynamic' */
	isInteractive: () => boolean;
	addEventListener<K extends keyof AllFederatedEventMap>(type: K, listener: (e: AllFederatedEventMap[K]) => any, options?: AddListenerOptions): void;
	addEventListener(type: string, listener: EventListenerOrEventListenerObject, options?: AddListenerOptions): void;
	removeEventListener<K extends keyof AllFederatedEventMap>(type: K, listener: (e: AllFederatedEventMap[K]) => any, options?: RemoveListenerOptions): void;
	removeEventListener(type: string, listener: EventListenerOrEventListenerObject, options?: RemoveListenerOptions): void;
	dispatchEvent(e: FederatedEvent): boolean;
}
export declare const FederatedContainer: IFederatedContainer;
/**
 * Event boundaries are "barriers" where events coming from an upstream scene are modified before downstream propagation.
 *
 * ## Root event boundary
 *
 * The {@link EventSystem#rootBoundary rootBoundary} handles events coming from the &lt;canvas /&gt;.
 * {@link EventSystem} handles the normalization from native {@link https://dom.spec.whatwg.org/#event Events}
 * into {@link FederatedEvent FederatedEvents}. The rootBoundary then does the hit-testing and event dispatch
 * for the upstream normalized event.
 *
 * ## Additional event boundaries
 *
 * An additional event boundary may be desired within an application's scene graph. For example, if a portion of the scene is
 * is flat with many children at one level - a spatial hash maybe needed to accelerate hit testing. In this scenario, the
 * container can be detached from the scene and glued using a custom event boundary.
 *
 * \`\`\`ts
 * import { Container } from 'pixi.js';
 * import { EventBoundary } from 'pixi.js';
 * import { SpatialHash } from 'pixi-spatial-hash';
 *
 * class HashedHitTestingEventBoundary
 * {
 *     private spatialHash: SpatialHash;
 *
 *     constructor(scene: Container, spatialHash: SpatialHash)
 *     {
 *         super(scene);
 *         this.spatialHash = spatialHash;
 *     }
 *
 *     hitTestRecursive(...)
 *     {
 *         // TODO: If target === this.rootTarget, then use spatial hash to get a
 *         // list of possible children that match the given (x,y) coordinates.
 *     }
 * }
 *
 * class VastScene extends Container
 * {
 *     protected eventBoundary: EventBoundary;
 *     protected scene: Container;
 *     protected spatialHash: SpatialHash;
 *
 *     constructor()
 *     {
 *         this.scene = new Container();
 *         this.spatialHash = new SpatialHash();
 *         this.eventBoundary = new HashedHitTestingEventBoundary(this.scene, this.spatialHash);
 *
 *         // Populate this.scene with a ton of children, while updating this.spatialHash
 *     }
 * }
 * \`\`\`
 * @memberof events
 */
export declare class EventBoundary {
	/**
	 * The root event-target residing below the event boundary.
	 * All events are dispatched trickling down and bubbling up to this \`rootTarget\`.
	 */
	rootTarget: Container;
	/**
	 * Emits events after they were dispatched into the scene graph.
	 *
	 * This can be used for global events listening, regardless of the scene graph being used. It should
	 * not be used by interactive libraries for normal use.
	 *
	 * Special events that do not bubble all the way to the root target are not emitted from here,
	 * e.g. pointerenter, pointerleave, click.
	 */
	dispatch: EventEmitter;
	/** The cursor preferred by the event targets underneath this boundary. */
	cursor: Cursor | string;
	/**
	 * This flag would emit \`pointermove\`, \`touchmove\`, and \`mousemove\` events on all Containers.
	 *
	 * The \`moveOnAll\` semantics mirror those of earlier versions of PixiJS. This was disabled in favor of
	 * the Pointer Event API's approach.
	 */
	moveOnAll: boolean;
	/** Enables the global move events. \`globalpointermove\`, \`globaltouchmove\`, and \`globalmousemove\` */
	enableGlobalMoveEvents: boolean;
	/**
	 * Maps event types to forwarding handles for them.
	 *
	 * {@link EventBoundary EventBoundary} provides mapping for "pointerdown", "pointermove",
	 * "pointerout", "pointerleave", "pointerover", "pointerup", and "pointerupoutside" by default.
	 * @see EventBoundary#addEventMapping
	 */
	protected mappingTable: Record<string, Array<{
		fn: (e: FederatedEvent) => void;
		priority: number;
	}>>;
	/**
	 * State object for mapping methods.
	 * @see EventBoundary#trackingData
	 */
	protected mappingState: Record<string, any>;
	/**
	 * The event pool maps event constructors to an free pool of instances of those specific events.
	 * @see EventBoundary#allocateEvent
	 * @see EventBoundary#freeEvent
	 */
	protected eventPool: Map<typeof FederatedEvent, FederatedEvent[]>;
	/** Every interactive element gathered from the scene. Only used in \`pointermove\` */
	private readonly _allInteractiveElements;
	/** Every element that passed the hit test. Only used in \`pointermove\` */
	private _hitElements;
	/** Whether or not to collect all the interactive elements from the scene. Enabled in \`pointermove\` */
	private _isPointerMoveEvent;
	/**
	 * @param rootTarget - The holder of the event boundary.
	 */
	constructor(rootTarget?: Container);
	/**
	 * Adds an event mapping for the event \`type\` handled by \`fn\`.
	 *
	 * Event mappings can be used to implement additional or custom events. They take an event
	 * coming from the upstream scene (or directly from the {@link EventSystem}) and dispatch new downstream events
	 * generally trickling down and bubbling up to {@link EventBoundary.rootTarget this.rootTarget}.
	 *
	 * To modify the semantics of existing events, the built-in mapping methods of EventBoundary should be overridden
	 * instead.
	 * @param type - The type of upstream event to map.
	 * @param fn - The mapping method. The context of this function must be bound manually, if desired.
	 */
	addEventMapping(type: string, fn: (e: FederatedEvent) => void): void;
	/**
	 * Dispatches the given event
	 * @param e - The event to dispatch.
	 * @param type - The type of event to dispatch. Defaults to \`e.type\`.
	 */
	dispatchEvent(e: FederatedEvent, type?: string): void;
	/**
	 * Maps the given upstream event through the event boundary and propagates it downstream.
	 * @param e - The event to map.
	 */
	mapEvent(e: FederatedEvent): void;
	/**
	 * Finds the Container that is the target of a event at the given coordinates.
	 *
	 * The passed (x,y) coordinates are in the world space above this event boundary.
	 * @param x - The x coordinate of the event.
	 * @param y - The y coordinate of the event.
	 */
	hitTest(x: number, y: number): Container;
	/**
	 * Propagate the passed event from from {@link EventBoundary.rootTarget this.rootTarget} to its
	 * target {@code e.target}.
	 * @param e - The event to propagate.
	 * @param type - The type of event to propagate. Defaults to \`e.type\`.
	 */
	propagate(e: FederatedEvent, type?: string): void;
	/**
	 * Emits the event {@code e} to all interactive containers. The event is propagated in the bubbling phase always.
	 *
	 * This is used in the \`globalpointermove\` event.
	 * @param e - The emitted event.
	 * @param type - The listeners to notify.
	 * @param targets - The targets to notify.
	 */
	all(e: FederatedEvent, type?: string | string[], targets?: Container<ContainerChild>[]): void;
	/**
	 * Finds the propagation path from {@link EventBoundary.rootTarget rootTarget} to the passed
	 * {@code target}. The last element in the path is {@code target}.
	 * @param target - The target to find the propagation path to.
	 */
	propagationPath(target: Container): Container[];
	protected hitTestMoveRecursive(currentTarget: Container, eventMode: EventMode, location: Point, testFn: (object: Container, pt: Point) => boolean, pruneFn: (object: Container, pt: Point) => boolean, ignore?: boolean): Container[];
	/**
	 * Recursive implementation for {@link EventBoundary.hitTest hitTest}.
	 * @param currentTarget - The Container that is to be hit tested.
	 * @param eventMode - The event mode for the \`currentTarget\` or one of its parents.
	 * @param location - The location that is being tested for overlap.
	 * @param testFn - Callback that determines whether the target passes hit testing. This callback
	 *  can assume that \`pruneFn\` failed to prune the container.
	 * @param pruneFn - Callback that determiness whether the target and all of its children
	 *  cannot pass the hit test. It is used as a preliminary optimization to prune entire subtrees
	 *  of the scene graph.
	 * @returns An array holding the hit testing target and all its ancestors in order. The first element
	 *  is the target itself and the last is {@link EventBoundary.rootTarget rootTarget}. This is the opposite
	 *  order w.r.t. the propagation path. If no hit testing target is found, null is returned.
	 */
	protected hitTestRecursive(currentTarget: Container, eventMode: EventMode, location: Point, testFn: (object: Container, pt: Point) => boolean, pruneFn: (object: Container, pt: Point) => boolean): Container[];
	private _isInteractive;
	private _interactivePrune;
	/**
	 * Checks whether the container or any of its children cannot pass the hit test at all.
	 *
	 * {@link EventBoundary}'s implementation uses the {@link Container.hitArea hitArea}
	 * and {@link Container._maskEffect} for pruning.
	 * @param container - The container to prune.
	 * @param location - The location to test for overlap.
	 */
	protected hitPruneFn(container: Container, location: Point): boolean;
	/**
	 * Checks whether the container passes hit testing for the given location.
	 * @param container - The container to test.
	 * @param location - The location to test for overlap.
	 * @returns - Whether \`container\` passes hit testing for \`location\`.
	 */
	protected hitTestFn(container: Container, location: Point): boolean;
	/**
	 * Notify all the listeners to the event's \`currentTarget\`.
	 *
	 * If the \`currentTarget\` contains the property \`on<type>\`, then it is called here,
	 * simulating the behavior from version 6.x and prior.
	 * @param e - The event passed to the target.
	 * @param type - The type of event to notify. Defaults to \`e.type\`.
	 */
	protected notifyTarget(e: FederatedEvent, type?: string): void;
	/**
	 * Maps the upstream \`pointerdown\` events to a downstream \`pointerdown\` event.
	 *
	 * \`touchstart\`, \`rightdown\`, \`mousedown\` events are also dispatched for specific pointer types.
	 * @param from - The upstream \`pointerdown\` event.
	 */
	protected mapPointerDown(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`pointermove\` to downstream \`pointerout\`, \`pointerover\`, and \`pointermove\` events, in that order.
	 *
	 * The tracking data for the specific pointer has an updated \`overTarget\`. \`mouseout\`, \`mouseover\`,
	 * \`mousemove\`, and \`touchmove\` events are fired as well for specific pointer types.
	 * @param from - The upstream \`pointermove\` event.
	 */
	protected mapPointerMove(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`pointerover\` to downstream \`pointerover\` and \`pointerenter\` events, in that order.
	 *
	 * The tracking data for the specific pointer gets a new \`overTarget\`.
	 * @param from - The upstream \`pointerover\` event.
	 */
	protected mapPointerOver(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`pointerout\` to downstream \`pointerout\`, \`pointerleave\` events, in that order.
	 *
	 * The tracking data for the specific pointer is cleared of a \`overTarget\`.
	 * @param from - The upstream \`pointerout\` event.
	 */
	protected mapPointerOut(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`pointerup\` event to downstream \`pointerup\`, \`pointerupoutside\`,
	 * and \`click\`/\`rightclick\`/\`pointertap\` events, in that order.
	 *
	 * The \`pointerupoutside\` event bubbles from the original \`pointerdown\` target to the most specific
	 * ancestor of the \`pointerdown\` and \`pointerup\` targets, which is also the \`click\` event's target. \`touchend\`,
	 * \`rightup\`, \`mouseup\`, \`touchendoutside\`, \`rightupoutside\`, \`mouseupoutside\`, and \`tap\` are fired as well for
	 * specific pointer types.
	 * @param from - The upstream \`pointerup\` event.
	 */
	protected mapPointerUp(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`pointerupoutside\` event to a downstream \`pointerupoutside\` event, bubbling from the original
	 * \`pointerdown\` target to \`rootTarget\`.
	 *
	 * (The most specific ancestor of the \`pointerdown\` event and the \`pointerup\` event must the
	 * \`{@link EventBoundary}'s root because the \`pointerup\` event occurred outside of the boundary.)
	 *
	 * \`touchendoutside\`, \`mouseupoutside\`, and \`rightupoutside\` events are fired as well for specific pointer
	 * types. The tracking data for the specific pointer is cleared of a \`pressTarget\`.
	 * @param from - The upstream \`pointerupoutside\` event.
	 */
	protected mapPointerUpOutside(from: FederatedEvent): void;
	/**
	 * Maps the upstream \`wheel\` event to a downstream \`wheel\` event.
	 * @param from - The upstream \`wheel\` event.
	 */
	protected mapWheel(from: FederatedEvent): void;
	/**
	 * Finds the most specific event-target in the given propagation path that is still mounted in the scene graph.
	 *
	 * This is used to find the correct \`pointerup\` and \`pointerout\` target in the case that the original \`pointerdown\`
	 * or \`pointerover\` target was unmounted from the scene graph.
	 * @param propagationPath - The propagation path was valid in the past.
	 * @returns - The most specific event-target still mounted at the same location in the scene graph.
	 */
	protected findMountedTarget(propagationPath: Container[]): Container;
	/**
	 * Creates an event whose {@code originalEvent} is {@code from}, with an optional \`type\` and \`target\` override.
	 *
	 * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
	 * @param from - The {@code originalEvent} for the returned event.
	 * @param [type=from.type] - The type of the returned event.
	 * @param target - The target of the returned event.
	 */
	protected createPointerEvent(from: FederatedPointerEvent, type?: string, target?: Container): FederatedPointerEvent;
	/**
	 * Creates a wheel event whose {@code originalEvent} is {@code from}.
	 *
	 * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
	 * @param from - The upstream wheel event.
	 */
	protected createWheelEvent(from: FederatedWheelEvent): FederatedWheelEvent;
	/**
	 * Clones the event {@code from}, with an optional {@code type} override.
	 *
	 * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
	 * @param from - The event to clone.
	 * @param [type=from.type] - The type of the returned event.
	 */
	protected clonePointerEvent(from: FederatedPointerEvent, type?: string): FederatedPointerEvent;
	/**
	 * Copies wheel {@link FederatedWheelEvent} data from {@code from} into {@code to}.
	 *
	 * The following properties are copied:
	 * + deltaMode
	 * + deltaX
	 * + deltaY
	 * + deltaZ
	 * @param from - The event to copy data from.
	 * @param to - The event to copy data into.
	 */
	protected copyWheelData(from: FederatedWheelEvent, to: FederatedWheelEvent): void;
	/**
	 * Copies pointer {@link FederatedPointerEvent} data from {@code from} into {@code to}.
	 *
	 * The following properties are copied:
	 * + pointerId
	 * + width
	 * + height
	 * + isPrimary
	 * + pointerType
	 * + pressure
	 * + tangentialPressure
	 * + tiltX
	 * + tiltY
	 * @param from - The event to copy data from.
	 * @param to - The event to copy data into.
	 */
	protected copyPointerData(from: FederatedEvent, to: FederatedEvent): void;
	/**
	 * Copies mouse {@link FederatedMouseEvent} data from {@code from} to {@code to}.
	 *
	 * The following properties are copied:
	 * + altKey
	 * + button
	 * + buttons
	 * + clientX
	 * + clientY
	 * + metaKey
	 * + movementX
	 * + movementY
	 * + pageX
	 * + pageY
	 * + x
	 * + y
	 * + screen
	 * + shiftKey
	 * + global
	 * @param from - The event to copy data from.
	 * @param to - The event to copy data into.
	 */
	protected copyMouseData(from: FederatedEvent, to: FederatedEvent): void;
	/**
	 * Copies base {@link FederatedEvent} data from {@code from} into {@code to}.
	 *
	 * The following properties are copied:
	 * + isTrusted
	 * + srcElement
	 * + timeStamp
	 * + type
	 * @param from - The event to copy data from.
	 * @param to - The event to copy data into.
	 */
	protected copyData(from: FederatedEvent, to: FederatedEvent): void;
	/**
	 * @param id - The pointer ID.
	 * @returns The tracking data stored for the given pointer. If no data exists, a blank
	 *  state will be created.
	 */
	protected trackingData(id: number): TrackingData;
	/**
	 * Allocate a specific type of event from {@link EventBoundary#eventPool this.eventPool}.
	 *
	 * This allocation is constructor-agnostic, as long as it only takes one argument - this event
	 * boundary.
	 * @param constructor - The event's constructor.
	 */
	protected allocateEvent<T extends FederatedEvent>(constructor: {
		new (boundary: EventBoundary): T;
	}): T;
	/**
	 * Frees the event and puts it back into the event pool.
	 *
	 * It is illegal to reuse the event until it is allocated again, using \`this.allocateEvent\`.
	 *
	 * It is also advised that events not allocated from {@link EventBoundary#allocateEvent this.allocateEvent}
	 * not be freed. This is because of the possibility that the same event is freed twice, which can cause
	 * it to be allocated twice & result in overwriting.
	 * @param event - The event to be freed.
	 * @throws Error if the event is managed by another event boundary.
	 */
	protected freeEvent<T extends FederatedEvent>(event: T): void;
	/**
	 * Similar to {@link EventEmitter.emit}, except it stops if the \`propagationImmediatelyStopped\` flag
	 * is set on the event.
	 * @param e - The event to call each listener with.
	 * @param type - The event key.
	 */
	private _notifyListeners;
}
/**
 * A PixiJS compatible {@code Touch} event.
 * @memberof events
 */
export interface PixiTouch extends Touch {
	button: number;
	buttons: number;
	isPrimary: boolean;
	width: number;
	height: number;
	tiltX: number;
	tiltY: number;
	pointerType: string;
	pointerId: number;
	pressure: number;
	twist: number;
	tangentialPressure: number;
	layerX: number;
	layerY: number;
	offsetX: number;
	offsetY: number;
	isNormalized: boolean;
	type: string;
}
/**
 * An DOM-compatible synthetic event implementation that is "forwarded" on behalf of an original
 * FederatedEvent or native {@link https://dom.spec.whatwg.org/#event Event}.
 * @typeParam N - The type of native event held.
 * @memberof events
 */
export declare class FederatedEvent<N extends UIEvent | PixiTouch = UIEvent | PixiTouch> implements UIEvent {
	/** Flags whether this event bubbles. This will take effect only if it is set before propagation. */
	bubbles: boolean;
	/** @deprecated since 7.0.0 */
	cancelBubble: boolean;
	/**
	 * Flags whether this event can be canceled using {@link FederatedEvent.preventDefault}. This is always
	 * false (for now).
	 */
	readonly cancelable = false;
	/**
	 * Flag added for compatibility with DOM {@code Event}. It is not used in the Federated Events
	 * API.
	 * @see https://dom.spec.whatwg.org/#dom-event-composed
	 */
	readonly composed = false;
	/** The listeners of the event target that are being notified. */
	currentTarget: Container;
	/** Flags whether the default response of the user agent was prevent through this event. */
	defaultPrevented: boolean;
	/**
	 * The propagation phase.
	 * @default {@link FederatedEvent.NONE}
	 */
	eventPhase: number;
	/** Flags whether this is a user-trusted event */
	isTrusted: boolean;
	/** @deprecated since 7.0.0 */
	returnValue: boolean;
	/** @deprecated since 7.0.0 */
	srcElement: EventTarget;
	/** The event target that this will be dispatched to. */
	target: Container;
	/** The timestamp of when the event was created. */
	timeStamp: number;
	/** The type of event, e.g. {@code "mouseup"}. */
	type: string;
	/** The native event that caused the foremost original event. */
	nativeEvent: N;
	/** The original event that caused this event, if any. */
	originalEvent: FederatedEvent<N>;
	/** Flags whether propagation was stopped. */
	propagationStopped: boolean;
	/** Flags whether propagation was immediately stopped. */
	propagationImmediatelyStopped: boolean;
	/** The composed path of the event's propagation. The {@code target} is at the end. */
	path: Container[];
	/** The {@link EventBoundary} that manages this event. Null for root events. */
	readonly manager: EventBoundary;
	/** Event-specific detail */
	detail: number;
	/** The global Window object. */
	view: WindowProxy;
	/**
	 * Not supported.
	 * @deprecated since 7.0.0
	 */
	which: number;
	/** The coordinates of the event relative to the nearest DOM layer. This is a non-standard property. */
	layer: Point;
	/** @readonly */
	get layerX(): number;
	/** @readonly */
	get layerY(): number;
	/** The coordinates of the event relative to the DOM document. This is a non-standard property. */
	page: Point;
	/** @readonly */
	get pageX(): number;
	/** @readonly */
	get pageY(): number;
	/**
	 * @param manager - The event boundary which manages this event. Propagation can only occur
	 *  within the boundary's jurisdiction.
	 */
	constructor(manager: EventBoundary);
	/**
	 * Fallback for the deprecated @code{InteractionEvent.data}.
	 * @deprecated since 7.0.0
	 */
	get data(): this;
	/** The propagation path for this event. Alias for {@link EventBoundary.propagationPath}. */
	composedPath(): Container[];
	/**
	 * Unimplemented method included for implementing the DOM interface {@code Event}. It will throw an {@code Error}.
	 * @deprecated
	 * @param _type
	 * @param _bubbles
	 * @param _cancelable
	 */
	initEvent(_type: string, _bubbles?: boolean, _cancelable?: boolean): void;
	/**
	 * Unimplemented method included for implementing the DOM interface {@code UIEvent}. It will throw an {@code Error}.
	 * @deprecated
	 * @param _typeArg
	 * @param _bubblesArg
	 * @param _cancelableArg
	 * @param _viewArg
	 * @param _detailArg
	 */
	initUIEvent(_typeArg: string, _bubblesArg?: boolean, _cancelableArg?: boolean, _viewArg?: Window | null, _detailArg?: number): void;
	/** Prevent default behavior of PixiJS and the user agent. */
	preventDefault(): void;
	/**
	 * Stop this event from propagating to any addition listeners, including on the
	 * {@link FederatedEventTarget.currentTarget currentTarget} and also the following
	 * event targets on the propagation path.
	 */
	stopImmediatePropagation(): void;
	/**
	 * Stop this event from propagating to the next {@link FederatedEventTarget}. The rest of the listeners
	 * on the {@link FederatedEventTarget.currentTarget currentTarget} will still be notified.
	 */
	stopPropagation(): void;
	readonly NONE = 0;
	readonly CAPTURING_PHASE = 1;
	readonly AT_TARGET = 2;
	readonly BUBBLING_PHASE = 3;
}
/**
 * A {@link FederatedEvent} for mouse events.
 * @memberof events
 */
export declare class FederatedMouseEvent extends FederatedEvent<MouseEvent | PointerEvent | PixiTouch> implements MouseEvent {
	/** Whether the "alt" key was pressed when this mouse event occurred. */
	altKey: boolean;
	/** The specific button that was pressed in this mouse event. */
	button: number;
	/** The button depressed when this event occurred. */
	buttons: number;
	/** Whether the "control" key was pressed when this mouse event occurred. */
	ctrlKey: boolean;
	/** Whether the "meta" key was pressed when this mouse event occurred. */
	metaKey: boolean;
	/** This is currently not implemented in the Federated Events API. */
	relatedTarget: EventTarget;
	/** Whether the "shift" key was pressed when this mouse event occurred. */
	shiftKey: boolean;
	/** The coordinates of the mouse event relative to the canvas. */
	client: Point;
	/** @readonly */
	get clientX(): number;
	/** @readonly */
	get clientY(): number;
	/**
	 * Alias for {@link FederatedMouseEvent.clientX this.clientX}.
	 * @readonly
	 */
	get x(): number;
	/**
	 * Alias for {@link FederatedMouseEvent.clientY this.clientY}.
	 * @readonly
	 */
	get y(): number;
	/** This is the number of clicks that occurs in 200ms/click of each other. */
	detail: number;
	/** The movement in this pointer relative to the last \`mousemove\` event. */
	movement: Point;
	/** @readonly */
	get movementX(): number;
	/** @readonly */
	get movementY(): number;
	/** The offset of the pointer coordinates w.r.t. target Container in world space. This is not supported at the moment. */
	offset: Point;
	/** @readonly */
	get offsetX(): number;
	/** @readonly */
	get offsetY(): number;
	/** The pointer coordinates in world space. */
	global: Point;
	/** @readonly */
	get globalX(): number;
	/** @readonly */
	get globalY(): number;
	/**
	 * The pointer coordinates in the renderer's {@link Renderer.screen screen}. This has slightly
	 * different semantics than native PointerEvent screenX/screenY.
	 */
	screen: Point;
	/**
	 * The pointer coordinates in the renderer's screen. Alias for {@code screen.x}.
	 * @readonly
	 */
	get screenX(): number;
	/**
	 * The pointer coordinates in the renderer's screen. Alias for {@code screen.y}.
	 * @readonly
	 */
	get screenY(): number;
	/**
	 * This will return the local coordinates of the specified container for this InteractionData
	 * @param {Container} container - The Container that you would like the local
	 *  coords off
	 * @param {PointData} point - A Point object in which to store the value, optional (otherwise
	 *  will create a new point)
	 * @param {PointData} globalPos - A Point object containing your custom global coords, optional
	 *  (otherwise will use the current global coords)
	 * @returns - A point containing the coordinates of the InteractionData position relative
	 *  to the Container
	 */
	getLocalPosition<P extends PointData = Point>(container: Container, point?: P, globalPos?: PointData): P;
	/**
	 * Whether the modifier key was pressed when this event natively occurred.
	 * @param key - The modifier key.
	 */
	getModifierState(key: string): boolean;
	/**
	 * Not supported.
	 * @param _typeArg
	 * @param _canBubbleArg
	 * @param _cancelableArg
	 * @param _viewArg
	 * @param _detailArg
	 * @param _screenXArg
	 * @param _screenYArg
	 * @param _clientXArg
	 * @param _clientYArg
	 * @param _ctrlKeyArg
	 * @param _altKeyArg
	 * @param _shiftKeyArg
	 * @param _metaKeyArg
	 * @param _buttonArg
	 * @param _relatedTargetArg
	 * @deprecated since 7.0.0
	 */
	initMouseEvent(_typeArg: string, _canBubbleArg: boolean, _cancelableArg: boolean, _viewArg: Window, _detailArg: number, _screenXArg: number, _screenYArg: number, _clientXArg: number, _clientYArg: number, _ctrlKeyArg: boolean, _altKeyArg: boolean, _shiftKeyArg: boolean, _metaKeyArg: boolean, _buttonArg: number, _relatedTargetArg: EventTarget): void;
}
/**
 * A {@link FederatedEvent} for pointer events.
 * @memberof events
 */
export declare class FederatedPointerEvent extends FederatedMouseEvent implements PointerEvent {
	/**
	 * The unique identifier of the pointer.
	 * @see {@link https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerId}
	 */
	pointerId: number;
	/**
	 * The width of the pointer's contact along the x-axis, measured in CSS pixels.
	 * radiusX of TouchEvents will be represented by this value.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/width
	 */
	width: number;
	/**
	 * The angle in radians of a pointer or stylus measuring the vertical angle between
	 * the device's surface to the pointer or stylus.
	 * A stylus at 0 degrees would be directly parallel whereas at π/2 degrees it would be perpendicular.
	 * @see https://developer.mozilla.org/docs/Web/API/PointerEvent/altitudeAngle)
	 */
	altitudeAngle: number;
	/**
	 * The angle in radians of a pointer or stylus measuring an arc from the X axis of the device to
	 * the pointer or stylus projected onto the screen's plane.
	 * A stylus at 0 degrees would be pointing to the "0 o'clock" whereas at π/2 degrees it would be pointing at "6 o'clock".
	 * @see https://developer.mozilla.org/docs/Web/API/PointerEvent/azimuthAngle)
	 */
	azimuthAngle: number;
	/**
	 * The height of the pointer's contact along the y-axis, measured in CSS pixels.
	 * radiusY of TouchEvents will be represented by this value.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/height
	 */
	height: number;
	/**
	 * Indicates whether or not the pointer device that created the event is the primary pointer.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/isPrimary
	 */
	isPrimary: boolean;
	/**
	 * The type of pointer that triggered the event.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerType
	 */
	pointerType: string;
	/**
	 * Pressure applied by the pointing device during the event.
	 *s
	 * A Touch's force property will be represented by this value.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pressure
	 */
	pressure: number;
	/**
	 * Barrel pressure on a stylus pointer.
	 * @see https://w3c.github.io/pointerevents/#pointerevent-interface
	 */
	tangentialPressure: number;
	/**
	 * The angle, in degrees, between the pointer device and the screen.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltX
	 */
	tiltX: number;
	/**
	 * The angle, in degrees, between the pointer device and the screen.
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltY
	 */
	tiltY: number;
	/**
	 * Twist of a stylus pointer.
	 * @see https://w3c.github.io/pointerevents/#pointerevent-interface
	 */
	twist: number;
	/** This is the number of clicks that occurs in 200ms/click of each other. */
	detail: number;
	getCoalescedEvents(): PointerEvent[];
	getPredictedEvents(): PointerEvent[];
}
export type FederatedEventMap = {
	click: FederatedPointerEvent;
	mousedown: FederatedPointerEvent;
	mouseenter: FederatedPointerEvent;
	mouseleave: FederatedPointerEvent;
	mousemove: FederatedPointerEvent;
	mouseout: FederatedPointerEvent;
	mouseover: FederatedPointerEvent;
	mouseup: FederatedPointerEvent;
	mouseupoutside: FederatedPointerEvent;
	pointercancel: FederatedPointerEvent;
	pointerdown: FederatedPointerEvent;
	pointerenter: FederatedPointerEvent;
	pointerleave: FederatedPointerEvent;
	pointermove: FederatedPointerEvent;
	pointerout: FederatedPointerEvent;
	pointerover: FederatedPointerEvent;
	pointertap: FederatedPointerEvent;
	pointerup: FederatedPointerEvent;
	pointerupoutside: FederatedPointerEvent;
	rightclick: FederatedPointerEvent;
	rightdown: FederatedPointerEvent;
	rightup: FederatedPointerEvent;
	rightupoutside: FederatedPointerEvent;
	tap: FederatedPointerEvent;
	touchcancel: FederatedPointerEvent;
	touchend: FederatedPointerEvent;
	touchendoutside: FederatedPointerEvent;
	touchmove: FederatedPointerEvent;
	touchstart: FederatedPointerEvent;
	wheel: FederatedWheelEvent;
};
export type GlobalFederatedEventMap = {
	globalmousemove: FederatedPointerEvent;
	globalpointermove: FederatedPointerEvent;
	globaltouchmove: FederatedPointerEvent;
};
export type AllFederatedEventMap = FederatedEventMap & GlobalFederatedEventMap;
export type FederatedEventEmitterTypes = {
	[K in keyof FederatedEventMap as K | \`\${K}capture\`]: [
		event: FederatedEventMap[K]
	];
} & {
	[K in keyof GlobalFederatedEventMap]: [
		event: GlobalFederatedEventMap[K]
	];
};
/** @ignore */
export interface EventSystemOptions {
	/**
	 * The default event mode mode for all display objects.
	 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
	 */
	eventMode?: EventMode;
	/**
	 * The event features that are enabled by the EventSystem
	 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
	 * @example
	 * const app = new Application({
	 *   view: canvas,
	 *   events: {
	 *     move: true,
	 *     globalMove: false,
	 *     click: true,
	 *     wheel: true,
	 *   },
	 * });
	 */
	eventFeatures?: Partial<EventSystemFeatures>;
}
/**
 * The event features that are enabled by the EventSystem
 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
 * @since 7.2.0
 * @memberof events
 */
export interface EventSystemFeatures {
	/**
	 * Enables pointer events associated with pointer movement:
	 * - \`pointermove\` / \`mousemove\` / \`touchmove\`
	 * - \`pointerout\` / \`mouseout\`
	 * - \`pointerover\` / \`mouseover\`
	 */
	move: boolean;
	/**
	 * Enables global pointer move events:
	 * - \`globalpointermove\`
	 * - \`globalmousemove\`
	 * - \`globaltouchemove\`
	 */
	globalMove: boolean;
	/**
	 * Enables pointer events associated with clicking:
	 * - \`pointerup\` / \`mouseup\` / \`touchend\` / 'rightup'
	 * - \`pointerupoutside\` / \`mouseupoutside\` / \`touchendoutside\` / 'rightupoutside'
	 * - \`pointerdown\` / 'mousedown' / \`touchstart\` / 'rightdown'
	 * - \`click\` / \`tap\`
	 */
	click: boolean;
	/** - Enables wheel events. */
	wheel: boolean;
}
/**
 * The system for handling UI events.
 * @memberof events
 */
export declare class EventSystem implements System<EventSystemOptions> {
	/** @ignore */
	static extension: ExtensionMetadata;
	/**
	 * The event features that are enabled by the EventSystem
	 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
	 * @since 7.2.0
	 */
	static defaultEventFeatures: EventSystemFeatures;
	private static _defaultEventMode;
	/**
	 * The default interaction mode for all display objects.
	 * @see Container.eventMode
	 * @type {EventMode}
	 * @readonly
	 * @since 7.2.0
	 */
	static get defaultEventMode(): EventMode;
	/**
	 * The {@link EventBoundary} for the stage.
	 *
	 * The {@link EventBoundary#rootTarget rootTarget} of this root boundary is automatically set to
	 * the last rendered object before any event processing is initiated. This means the main scene
	 * needs to be rendered atleast once before UI events will start propagating.
	 *
	 * The root boundary should only be changed during initialization. Otherwise, any state held by the
	 * event boundary may be lost (like hovered & pressed Containers).
	 */
	readonly rootBoundary: EventBoundary;
	/** Does the device support touch events https://www.w3.org/TR/touch-events/ */
	readonly supportsTouchEvents: boolean;
	/** Does the device support pointer events https://www.w3.org/Submission/pointer-events/ */
	readonly supportsPointerEvents: boolean;
	/**
	 * Should default browser actions automatically be prevented.
	 * Does not apply to pointer events for backwards compatibility
	 * preventDefault on pointer events stops mouse events from firing
	 * Thus, for every pointer event, there will always be either a mouse of touch event alongside it.
	 * @default true
	 */
	autoPreventDefault: boolean;
	/**
	 * Dictionary of how different cursor modes are handled. Strings are handled as CSS cursor
	 * values, objects are handled as dictionaries of CSS values for {@code domElement},
	 * and functions are called instead of changing the CSS.
	 * Default CSS cursor values are provided for 'default' and 'pointer' modes.
	 */
	cursorStyles: Record<string, string | ((mode: string) => void) | CSSStyleDeclaration>;
	/**
	 * The DOM element to which the root event listeners are bound. This is automatically set to
	 * the renderer's {@link Renderer#view view}.
	 */
	domElement: HTMLElement;
	/** The resolution used to convert between the DOM client space into world space. */
	resolution: number;
	/** The renderer managing this {@link EventSystem}. */
	renderer: Renderer;
	/**
	 * The event features that are enabled by the EventSystem
	 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
	 * @since 7.2.0
	 * @example
	 * const app = new Application()
	 * app.renderer.events.features.globalMove = false
	 *
	 * // to override all features use Object.assign
	 * Object.assign(app.renderer.events.features, {
	 *  move: false,
	 *  globalMove: false,
	 *  click: false,
	 *  wheel: false,
	 * })
	 */
	readonly features: EventSystemFeatures;
	private _currentCursor;
	private readonly _rootPointerEvent;
	private readonly _rootWheelEvent;
	private _eventsAdded;
	/**
	 * @param {Renderer} renderer
	 */
	constructor(renderer: Renderer);
	/**
	 * Runner init called, view is available at this point.
	 * @ignore
	 */
	init(options: EventSystemOptions): void;
	/**
	 * Handle changing resolution.
	 * @ignore
	 */
	resolutionChange(resolution: number): void;
	/** Destroys all event listeners and detaches the renderer. */
	destroy(): void;
	/**
	 * Sets the current cursor mode, handling any callbacks or CSS style changes.
	 * @param mode - cursor mode, a key from the cursorStyles dictionary
	 */
	setCursor(mode: string): void;
	/**
	 * The global pointer event.
	 * Useful for getting the pointer position without listening to events.
	 * @since 7.2.0
	 */
	get pointer(): Readonly<FederatedPointerEvent>;
	/**
	 * Event handler for pointer down events on {@link EventSystem#domElement this.domElement}.
	 * @param nativeEvent - The native mouse/pointer/touch event.
	 */
	private _onPointerDown;
	/**
	 * Event handler for pointer move events on on {@link EventSystem#domElement this.domElement}.
	 * @param nativeEvent - The native mouse/pointer/touch events.
	 */
	private _onPointerMove;
	/**
	 * Event handler for pointer up events on {@link EventSystem#domElement this.domElement}.
	 * @param nativeEvent - The native mouse/pointer/touch event.
	 */
	private _onPointerUp;
	/**
	 * Event handler for pointer over & out events on {@link EventSystem#domElement this.domElement}.
	 * @param nativeEvent - The native mouse/pointer/touch event.
	 */
	private _onPointerOverOut;
	/**
	 * Passive handler for \`wheel\` events on {@link EventSystem.domElement this.domElement}.
	 * @param nativeEvent - The native wheel event.
	 */
	protected onWheel(nativeEvent: WheelEvent): void;
	/**
	 * Sets the {@link EventSystem#domElement domElement} and binds event listeners.
	 *
	 * To deregister the current DOM element without setting a new one, pass {@code null}.
	 * @param element - The new DOM element.
	 */
	setTargetElement(element: HTMLElement): void;
	/** Register event listeners on {@link Renderer#domElement this.domElement}. */
	private _addEvents;
	/** Unregister event listeners on {@link EventSystem#domElement this.domElement}. */
	private _removeEvents;
	/**
	 * Maps x and y coords from a DOM object and maps them correctly to the PixiJS view. The
	 * resulting value is stored in the point. This takes into account the fact that the DOM
	 * element could be scaled and positioned anywhere on the screen.
	 * @param  {PointData} point - the point that the result will be stored in
	 * @param  {number} x - the x coord of the position to map
	 * @param  {number} y - the y coord of the position to map
	 */
	mapPositionToPoint(point: PointData, x: number, y: number): void;
	/**
	 * Ensures that the original event object contains all data that a regular pointer event would have
	 * @param event - The original event data from a touch or mouse event
	 * @returns An array containing a single normalized pointer event, in the case of a pointer
	 *  or mouse event, or a multiple normalized pointer events if there are multiple changed touches
	 */
	private _normalizeToPointerData;
	/**
	 * Normalizes the native {@link https://w3c.github.io/uievents/#interface-wheelevent WheelEvent}.
	 *
	 * The returned {@link FederatedWheelEvent} is a shared instance. It will not persist across
	 * multiple native wheel events.
	 * @param nativeEvent - The native wheel event that occurred on the canvas.
	 * @returns A federated wheel event.
	 */
	protected normalizeWheelEvent(nativeEvent: WheelEvent): FederatedWheelEvent;
	/**
	 * Normalizes the \`nativeEvent\` into a federateed {@link FederatedPointerEvent}.
	 * @param event
	 * @param nativeEvent
	 */
	private _bootstrapEvent;
	/**
	 * Transfers base & mouse event data from the {@code nativeEvent} to the federated event.
	 * @param event
	 * @param nativeEvent
	 */
	private _transferMouseData;
}
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface Container extends IFederatedContainer {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ContainerOptions extends FederatedOptions {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ContainerEvents extends FederatedEventEmitterTypes {
		}
		interface RendererOptions {
			/**
			 * The default event mode for all display objects.
			 * @since 7.2.0
			 */
			eventMode?: EventMode;
			/**
			 * The event features that are enabled by the EventSystem.
			 * @since 7.2.0
			 */
			eventFeatures?: EventSystemOptions["eventFeatures"];
		}
		interface RendererSystems {
			events: EventSystem;
		}
	}
}
export declare class FilterPipe implements InstructionPipe<FilterInstruction> {
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "filter";
	};
	private _renderer;
	constructor(renderer: Renderer);
	push(filterEffect: Effect, container: Container, instructionSet: InstructionSet): void;
	pop(_filterEffect: Effect, _container: Container, instructionSet: InstructionSet): void;
	execute(instruction: FilterInstruction): void;
	destroy(): void;
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			filter: FilterSystem;
		}
		interface RendererPipes {
			filter: FilterPipe;
		}
	}
}
/* eslint-disable max-len */
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface Point extends Vector2Math {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ObservablePoint extends Vector2Math {
		}
		interface Rectangle {
			containsRect(other: Rectangle): boolean;
			equals(other: Rectangle): boolean;
			intersection(other: Rectangle): Rectangle;
			intersection<T extends Rectangle>(other: Rectangle, outRect: T): T;
			union(other: Rectangle): Rectangle;
			union<T extends Rectangle>(other: Rectangle, outRect: T): T;
		}
	}
	interface Vector2Math {
		add(other: PointData): Point;
		add<T extends PointData>(other: PointData, outPoint: T): T;
		subtract(other: PointData): Point;
		subtract<T extends PointData>(other: PointData, outPoint: T): T;
		multiply(other: PointData): Point;
		multiply<T extends PointData>(other: PointData, outPoint: T): T;
		// divide(other: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
		// divide<T extends import('../maths/point/PointData').PointData>(other: import('../maths/point/PointData').PointData, outPoint: T): T;
		multiplyScalar(scalar: number): Point;
		multiplyScalar<T extends PointData>(scalar: number, outPoint: T): T;
		dot(other: PointData): number;
		cross(other: PointData): number;
		normalize(): Point;
		normalize<T extends PointData>(outPoint: T): T;
		magnitude(): number;
		magnitudeSquared(): number;
		project(onto: PointData): Point;
		project<T extends PointData>(onto: PointData, outPoint: T): T;
		reflect(normal: PointData): Point;
		reflect<T extends PointData>(normal: PointData, outPoint: T): T;
	}
}
/**
 * Typed and cleaned up version of:
 * https://stackoverflow.com/questions/44855794/html5-canvas-triangle-with-rounded-corners/44856925#44856925
 * @param g - Graphics to be drawn on.
 * @param points - Corners of the shape to draw. Minimum length is 3.
 * @param radius - Corners default radius.
 * @ignore
 */
export declare function roundedShapeArc(g: ShapePath, points: RoundedPoint[], radius: number): void;
export type RoundedPoint = PointData & {
	radius?: number;
};
/**
 * Typed and cleaned up version of:
 * https://stackoverflow.com/questions/44855794/html5-canvas-triangle-with-rounded-corners/56214413#56214413
 * @param g - Graphics to be drawn on.
 * @param points - Corners of the shape to draw. Minimum length is 3.
 * @param radius - Corners default radius.
 * @ignore
 */
export declare function roundedShapeQuadraticCurve(g: ShapePath, points: RoundedPoint[], radius: number, smoothness?: number): void;
export type ShapePrimitiveWithHoles = {
	shape: ShapePrimitive;
	transform?: Matrix;
	holes?: ShapePrimitiveWithHoles[];
};
/**
 * The \`ShapePath\` class acts as a bridge between high-level drawing commands
 * and the lower-level \`GraphicsContext\` rendering engine.
 * It translates drawing commands, such as those for creating lines, arcs, ellipses, rectangles, and complex polygons, into a
 * format that can be efficiently processed by a \`GraphicsContext\`. This includes handling path starts,
 * ends, and transformations for shapes.
 *
 * It is used internally by \`GraphicsPath\` to build up the path.
 * @memberof scene
 */
export declare class ShapePath {
	/** The list of shape primitives that make up the path. */
	shapePrimitives: ShapePrimitiveWithHoles[];
	private _currentPoly;
	private readonly _graphicsPath2D;
	private readonly _bounds;
	readonly signed: boolean;
	constructor(graphicsPath2D: GraphicsPath);
	/**
	 * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
	 * @param x - The x-coordinate for the starting point.
	 * @param y - The y-coordinate for the starting point.
	 * @returns The instance of the current object for chaining.
	 */
	moveTo(x: number, y: number): this;
	/**
	 * Connects the current point to a new point with a straight line. This method updates the current path.
	 * @param x - The x-coordinate of the new point to connect to.
	 * @param y - The y-coordinate of the new point to connect to.
	 * @returns The instance of the current object for chaining.
	 */
	lineTo(x: number, y: number): this;
	/**
	 * Adds an arc to the path. The arc is centered at (x, y)
	 *  position with radius \`radius\` starting at \`startAngle\` and ending at \`endAngle\`.
	 * @param x - The x-coordinate of the arc's center.
	 * @param y - The y-coordinate of the arc's center.
	 * @param radius - The radius of the arc.
	 * @param startAngle - The starting angle of the arc, in radians.
	 * @param endAngle - The ending angle of the arc, in radians.
	 * @param counterclockwise - Specifies whether the arc should be drawn in the anticlockwise direction. False by default.
	 * @returns The instance of the current object for chaining.
	 */
	arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise: boolean): this;
	/**
	 * Adds an arc to the path with the arc tangent to the line joining two specified points.
	 * The arc radius is specified by \`radius\`.
	 * @param x1 - The x-coordinate of the first point.
	 * @param y1 - The y-coordinate of the first point.
	 * @param x2 - The x-coordinate of the second point.
	 * @param y2 - The y-coordinate of the second point.
	 * @param radius - The radius of the arc.
	 * @returns The instance of the current object for chaining.
	 */
	arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
	/**
	 * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
	 * @param rx - The x-radius of the ellipse.
	 * @param ry - The y-radius of the ellipse.
	 * @param xAxisRotation - The rotation of the ellipse's x-axis relative
	 * to the x-axis of the coordinate system, in degrees.
	 * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
	 * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
	 * @param x - The x-coordinate of the arc's end point.
	 * @param y - The y-coordinate of the arc's end point.
	 * @returns The instance of the current object for chaining.
	 */
	arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
	/**
	 * Adds a cubic Bezier curve to the path.
	 * It requires three points: the first two are control points and the third one is the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the first control point.
	 * @param cp1y - The y-coordinate of the first control point.
	 * @param cp2x - The x-coordinate of the second control point.
	 * @param cp2y - The y-coordinate of the second control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the control point.
	 * @param cp1y - The y-coordinate of the control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothing - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	quadraticCurveTo(cp1x: number, cp1y: number, x: number, y: number, smoothing?: number): this;
	/**
	 * Closes the current path by drawing a straight line back to the start.
	 * If the shape is already closed or there are no points in the path, this method does nothing.
	 * @returns The instance of the current object for chaining.
	 */
	closePath(): this;
	/**
	 * Adds another path to the current path. This method allows for the combination of multiple paths into one.
	 * @param path - The \`GraphicsPath\` object representing the path to add.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the path before adding it.
	 * @returns The instance of the current object for chaining.
	 */
	addPath(path: GraphicsPath, transform?: Matrix): this;
	/**
	 * Finalizes the drawing of the current path. Optionally, it can close the path.
	 * @param closePath - A boolean indicating whether to close the path after finishing. False by default.
	 */
	finish(closePath?: boolean): void;
	/**
	 * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	rect(x: number, y: number, w: number, h: number, transform?: Matrix): this;
	/**
	 * Draws a circle shape. This method adds a new circle path to the current drawing.
	 * @param x - The x-coordinate of the center of the circle.
	 * @param y - The y-coordinate of the center of the circle.
	 * @param radius - The radius of the circle.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the circle.
	 * @returns The instance of the current object for chaining.
	 */
	circle(x: number, y: number, radius: number, transform?: Matrix): this;
	/**
	 * Draws a polygon shape. This method allows for the creation of complex polygons by specifying a sequence of points.
	 * @param points - An array of numbers, or or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
	 * representing the x and y coordinates of the polygon's vertices, in sequence.
	 * @param close - A boolean indicating whether to close the polygon path. True by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining.
	 */
	poly(points: number[] | PointData[], close?: boolean, transform?: Matrix): this;
	/**
	 * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining.
	 */
	regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
	/**
	 * Draws a polygon with rounded corners.
	 * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param corner - The radius of the rounding of the corners.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @param smoothness - Optional parameter to adjust the smoothness of the rounding.
	 * @returns The instance of the current object for chaining.
	 */
	roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number, smoothness?: number): this;
	/**
	 * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
	 * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
	 * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
	 * A minimum of 3 points is required.
	 * @param radius - The default radius for the corners.
	 * This radius is applied to all corners unless overridden in \`points\`.
	 * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
	 *  method instead of an arc method. Defaults to false.
	 * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
	 * Higher values make the curve smoother.
	 * @returns The instance of the current object for chaining.
	 */
	roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
	/**
	 * Draw Rectangle with fillet corners. This is much like rounded rectangle
	 * however it support negative numbers as well for the corner radius.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param fillet - accept negative or positive values
	 */
	filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
	/**
	 * Draw Rectangle with chamfer corners. These are angled corners.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param chamfer - non-zero real number, size of corner cutout
	 * @param transform
	 */
	chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
	/**
	 * Draws an ellipse at the specified location and with the given x and y radii.
	 * An optional transformation can be applied, allowing for rotation, scaling, and translation.
	 * @param x - The x-coordinate of the center of the ellipse.
	 * @param y - The y-coordinate of the center of the ellipse.
	 * @param radiusX - The horizontal radius of the ellipse.
	 * @param radiusY - The vertical radius of the ellipse.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the ellipse. This can include rotations.
	 * @returns The instance of the current object for chaining.
	 */
	ellipse(x: number, y: number, radiusX: number, radiusY: number, transform?: Matrix): this;
	/**
	 * Draws a rectangle with rounded corners.
	 * The corner radius can be specified to determine how rounded the corners should be.
	 * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	roundRect(x: number, y: number, w: number, h: number, radius?: number, transform?: Matrix): this;
	/**
	 * Draws a given shape on the canvas.
	 * This is a generic method that can draw any type of shape specified by the \`ShapePrimitive\` parameter.
	 * An optional transformation matrix can be applied to the shape, allowing for complex transformations.
	 * @param shape - The shape to draw, defined as a \`ShapePrimitive\` object.
	 * @param matrix - An optional \`Matrix\` for transforming the shape. This can include rotations,
	 * scaling, and translations.
	 * @returns The instance of the current object for chaining.
	 */
	drawShape(shape: ShapePrimitive, matrix?: Matrix): this;
	/**
	 * Starts a new polygon path from the specified starting point.
	 * This method initializes a new polygon or ends the current one if it exists.
	 * @param x - The x-coordinate of the starting point of the new polygon.
	 * @param y - The y-coordinate of the starting point of the new polygon.
	 * @returns The instance of the current object for chaining.
	 */
	startPoly(x: number, y: number): this;
	/**
	 * Ends the current polygon path. If \`closePath\` is set to true,
	 * the path is closed by connecting the last point to the first one.
	 * This method finalizes the current polygon and prepares it for drawing or adding to the shape primitives.
	 * @param closePath - A boolean indicating whether to close the polygon by connecting the last point
	 *  back to the starting point. False by default.
	 * @returns The instance of the current object for chaining.
	 */
	endPoly(closePath?: boolean): this;
	private _ensurePoly;
	/** Builds the path. */
	buildPath(): void;
	/** Gets the bounds of the path. */
	get bounds(): Bounds;
}
export interface PathInstruction {
	action: "moveTo" | "lineTo" | "quadraticCurveTo" | "bezierCurveTo" | "arc" | "closePath" | "addPath" | "arcTo" | "ellipse" | "rect" | "roundRect" | "arcToSvg" | "poly" | "circle" | "regularPoly" | "roundPoly" | "roundShape" | "filletRect" | "chamferRect";
	data: any[];
}
/**
 * The \`GraphicsPath\` class is designed to represent a graphical path consisting of multiple drawing instructions.
 * This class serves as a collection of drawing commands that can be executed to render shapes and paths on a canvas or
 * similar graphical context. It supports high-level drawing operations like lines, arcs, curves, and more, enabling
 * complex graphic constructions with relative ease.
 * @memberof scene
 */
export declare class GraphicsPath {
	instructions: PathInstruction[];
	/** unique id for this graphics path */
	readonly uid: number;
	private _dirty;
	private _shapePath;
	/**
	 * Controls whether shapes in this path should be checked for holes using the non-zero fill rule.
	 * When true, any closed shape that is fully contained within another shape will become
	 * a hole in that shape during filling operations.
	 *
	 * This follows SVG's non-zero fill rule where:
	 * 1. Shapes are analyzed to find containment relationships
	 * 2. If Shape B is fully contained within Shape A, Shape B becomes a hole in Shape A
	 * 3. Multiple nested holes are supported
	 *
	 * Mainly used internally by the SVG parser to correctly handle holes in complex paths.
	 * When false, all shapes are filled independently without checking for holes.
	 */
	checkForHoles: boolean;
	/**
	 * Provides access to the internal shape path, ensuring it is up-to-date with the current instructions.
	 * @returns The \`ShapePath\` instance associated with this \`GraphicsPath\`.
	 */
	get shapePath(): ShapePath;
	/**
	 * Creates a \`GraphicsPath\` instance optionally from an SVG path string or an array of \`PathInstruction\`.
	 * @param instructions - An SVG path string or an array of \`PathInstruction\` objects.
	 * @param signed
	 */
	constructor(instructions?: string | PathInstruction[], signed?: boolean);
	/**
	 * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
	 * @param path - The \`GraphicsPath\` to add.
	 * @param transform - An optional transformation to apply to the added path.
	 * @returns The instance of the current object for chaining.
	 */
	addPath(path: GraphicsPath, transform?: Matrix): this;
	/**
	 * Adds an arc to the path. The arc is centered at (x, y)
	 *  position with radius \`radius\` starting at \`startAngle\` and ending at \`endAngle\`.
	 * @param x - The x-coordinate of the arc's center.
	 * @param y - The y-coordinate of the arc's center.
	 * @param radius - The radius of the arc.
	 * @param startAngle - The starting angle of the arc, in radians.
	 * @param endAngle - The ending angle of the arc, in radians.
	 * @param counterclockwise - Specifies whether the arc should be drawn in the anticlockwise direction. False by default.
	 * @returns The instance of the current object for chaining.
	 */
	arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
	/**
	 * Adds an arc to the path with the arc tangent to the line joining two specified points.
	 * The arc radius is specified by \`radius\`.
	 * @param x1 - The x-coordinate of the first point.
	 * @param y1 - The y-coordinate of the first point.
	 * @param x2 - The x-coordinate of the second point.
	 * @param y2 - The y-coordinate of the second point.
	 * @param radius - The radius of the arc.
	 * @returns The instance of the current object for chaining.
	 */
	arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
	/**
	 * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
	 * @param rx - The x-radius of the ellipse.
	 * @param ry - The y-radius of the ellipse.
	 * @param xAxisRotation - The rotation of the ellipse's x-axis relative
	 * to the x-axis of the coordinate system, in degrees.
	 * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
	 * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
	 * @param x - The x-coordinate of the arc's end point.
	 * @param y - The y-coordinate of the arc's end point.
	 * @returns The instance of the current object for chaining.
	 */
	arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
	/**
	 * Adds a cubic Bezier curve to the path.
	 * It requires three points: the first two are control points and the third one is the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the first control point.
	 * @param cp1y - The y-coordinate of the first control point.
	 * @param cp2x - The x-coordinate of the second control point.
	 * @param cp2y - The y-coordinate of the second control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Adds a cubic Bezier curve to the path.
	 * It requires two points: the second control point and the end point. The first control point is assumed to be
	 * The starting point is the last point in the current path.
	 * @param cp2x - The x-coordinate of the second control point.
	 * @param cp2y - The y-coordinate of the second control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	bezierCurveToShort(cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Closes the current path by drawing a straight line back to the start.
	 * If the shape is already closed or there are no points in the path, this method does nothing.
	 * @returns The instance of the current object for chaining.
	 */
	closePath(): this;
	/**
	 * Draws an ellipse at the specified location and with the given x and y radii.
	 * An optional transformation can be applied, allowing for rotation, scaling, and translation.
	 * @param x - The x-coordinate of the center of the ellipse.
	 * @param y - The y-coordinate of the center of the ellipse.
	 * @param radiusX - The horizontal radius of the ellipse.
	 * @param radiusY - The vertical radius of the ellipse.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the ellipse. This can include rotations.
	 * @returns The instance of the current object for chaining.
	 */
	ellipse(x: number, y: number, radiusX: number, radiusY: number, matrix?: Matrix): this;
	/**
	 * Connects the current point to a new point with a straight line. This method updates the current path.
	 * @param x - The x-coordinate of the new point to connect to.
	 * @param y - The y-coordinate of the new point to connect to.
	 * @returns The instance of the current object for chaining.
	 */
	lineTo(x: number, y: number): this;
	/**
	 * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
	 * @param x - The x-coordinate for the starting point.
	 * @param y - The y-coordinate for the starting point.
	 * @returns The instance of the current object for chaining.
	 */
	moveTo(x: number, y: number): this;
	/**
	 * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the control point.
	 * @param cp1y - The y-coordinate of the control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Adds a quadratic curve to the path. It uses the previous point as the control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	quadraticCurveToShort(x: number, y: number, smoothness?: number): this;
	/**
	 * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	rect(x: number, y: number, w: number, h: number, transform?: Matrix): this;
	/**
	 * Draws a circle shape. This method adds a new circle path to the current drawing.
	 * @param x - The x-coordinate of the center of the circle.
	 * @param y - The y-coordinate of the center of the circle.
	 * @param radius - The radius of the circle.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the circle.
	 * @returns The instance of the current object for chaining.
	 */
	circle(x: number, y: number, radius: number, transform?: Matrix): this;
	/**
	 * Draws a rectangle with rounded corners.
	 * The corner radius can be specified to determine how rounded the corners should be.
	 * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	roundRect(x: number, y: number, w: number, h: number, radius?: number, transform?: Matrix): this;
	/**
	 * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
	 * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
	 * rotated, or translated as needed.
	 * @param points - An array of numbers representing the x and y coordinates of the polygon's vertices, in sequence.
	 * @param close - A boolean indicating whether to close the polygon path. True by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining further drawing commands.
	 */
	poly(points: number[] | PointData[], close?: boolean, transform?: Matrix): this;
	/**
	 * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining.
	 */
	regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
	/**
	 * Draws a polygon with rounded corners.
	 * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param corner - The radius of the rounding of the corners.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @returns The instance of the current object for chaining.
	 */
	roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
	/**
	 * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
	 * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
	 * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
	 * A minimum of 3 points is required.
	 * @param radius - The default radius for the corners.
	 * This radius is applied to all corners unless overridden in \`points\`.
	 * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
	 *  method instead of an arc method. Defaults to false.
	 * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
	 * Higher values make the curve smoother.
	 * @returns The instance of the current object for chaining.
	 */
	roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
	/**
	 * Draw Rectangle with fillet corners. This is much like rounded rectangle
	 * however it support negative numbers as well for the corner radius.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param fillet - accept negative or positive values
	 */
	filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
	/**
	 * Draw Rectangle with chamfer corners. These are angled corners.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param chamfer - non-zero real number, size of corner cutout
	 * @param transform
	 */
	chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
	/**
	 * Draws a star shape centered at a specified location. This method allows for the creation
	 *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
	 * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
	 * An optional transformation can be applied to scale, rotate, or translate the star as needed.
	 * @param x - The x-coordinate of the center of the star.
	 * @param y - The y-coordinate of the center of the star.
	 * @param points - The number of points of the star.
	 * @param radius - The outer radius of the star (distance from the center to the outer points).
	 * @param innerRadius - Optional. The inner radius of the star
	 * (distance from the center to the inner points between the outer points).
	 * If not provided, defaults to half of the \`radius\`.
	 * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
	 * Defaults to 0, meaning one point is directly upward.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the star.
	 * This can include rotations, scaling, and translations.
	 * @returns The instance of the current object for chaining further drawing commands.
	 */
	star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number, transform?: Matrix): this;
	/**
	 * Creates a copy of the current \`GraphicsPath\` instance. This method supports both shallow and deep cloning.
	 * A shallow clone copies the reference of the instructions array, while a deep clone creates a new array and
	 * copies each instruction individually, ensuring that modifications to the instructions of the cloned \`GraphicsPath\`
	 * do not affect the original \`GraphicsPath\` and vice versa.
	 * @param deep - A boolean flag indicating whether the clone should be deep.
	 * @returns A new \`GraphicsPath\` instance that is a clone of the current instance.
	 */
	clone(deep?: boolean): GraphicsPath;
	clear(): this;
	/**
	 * Applies a transformation matrix to all drawing instructions within the \`GraphicsPath\`.
	 * This method enables the modification of the path's geometry according to the provided
	 * transformation matrix, which can include translations, rotations, scaling, and skewing.
	 *
	 * Each drawing instruction in the path is updated to reflect the transformation,
	 * ensuring the visual representation of the path is consistent with the applied matrix.
	 *
	 * Note: The transformation is applied directly to the coordinates and control points of the drawing instructions,
	 * not to the path as a whole. This means the transformation's effects are baked into the individual instructions,
	 * allowing for fine-grained control over the path's appearance.
	 * @param matrix - A \`Matrix\` object representing the transformation to apply.
	 * @returns The instance of the current object for chaining further operations.
	 */
	transform(matrix: Matrix): this;
	get bounds(): Bounds;
	/**
	 * Retrieves the last point from the current drawing instructions in the \`GraphicsPath\`.
	 * This method is useful for operations that depend on the path's current endpoint,
	 * such as connecting subsequent shapes or paths. It supports various drawing instructions,
	 * ensuring the last point's position is accurately determined regardless of the path's complexity.
	 *
	 * If the last instruction is a \`closePath\`, the method iterates backward through the instructions
	 *  until it finds an actionable instruction that defines a point (e.g., \`moveTo\`, \`lineTo\`,
	 * \`quadraticCurveTo\`, etc.). For compound paths added via \`addPath\`, it recursively retrieves
	 * the last point from the nested path.
	 * @param out - A \`Point\` object where the last point's coordinates will be stored.
	 * This object is modified directly to contain the result.
	 * @returns The \`Point\` object containing the last point's coordinates.
	 */
	getLastPoint(out: Point): Point;
}
export type LineCap = "butt" | "round" | "square";
export type LineJoin = "round" | "bevel" | "miter";
export declare const closePointEps = 0.0001;
export declare const curveEps = 0.0001;
export type GradientType = "linear" | "radial";
/**
 * Represents the style options for a linear gradient fill.
 * @memberof scene
 */
export interface BaseGradientOptions {
	/** The type of gradient */
	type?: GradientType;
	/** Array of colors stops to use in the gradient */
	colorStops?: {
		offset: number;
		color: ColorSource;
	}[];
	/** Whether coordinates are 'global' or 'local' */
	textureSpace?: TextureSpace;
	/**
	 * The size of the texture to use for the gradient - this is for advanced usage.
	 * The texture size does not need to match the size of the object being drawn.
	 * Due to GPU interpolation, gradient textures can be relatively small!
	 * Consider using a larger texture size if your gradient has a lot of very tight color steps
	 */
	textureSize?: number;
}
/**
 * Options specific to linear gradients.
 * A linear gradient creates a smooth transition between colors along a straight line defined by start and end points.
 * @memberof scene
 */
export interface LinearGradientOptions extends BaseGradientOptions {
	/** The type of gradient. Must be 'linear' for linear gradients. */
	type?: "linear";
	/**
	 * The start point of the gradient.
	 * This point defines where the gradient begins.
	 * It is represented as a PointData object containing x and y coordinates.
	 * The coordinates are in local space by default (0-1), but can be in global space if specified.
	 */
	start?: PointData;
	/**
	 * The end point of the gradient.
	 * This point defines where the gradient ends.
	 * It is represented as a PointData object containing x and y coordinates.
	 * The coordinates are in local space by default (0-1), but can be in global space if specified.
	 */
	end?: PointData;
}
/**
 * Options specific to radial gradients.
 * A radial gradient creates a smooth transition between colors that radiates outward in a circular pattern.
 * The gradient is defined by inner and outer circles, each with their own radius.
 * @memberof scene
 */
export interface RadialGradientOptions extends BaseGradientOptions {
	/** The type of gradient. Must be 'radial' for radial gradients. */
	type?: "radial";
	/** The center point of the inner circle where the gradient begins. In local coordinates by default (0-1). */
	center?: PointData;
	/** The radius of the inner circle where the gradient begins. */
	innerRadius?: number;
	/** The center point of the outer circle where the gradient ends. In local coordinates by default (0-1). */
	outerCenter?: PointData;
	/** The radius of the outer circle where the gradient ends. */
	outerRadius?: number;
	/**
	 * The y scale of the gradient, use this to make the gradient elliptical.
	 * NOTE: Only applied to radial gradients used with Graphics.
	 */
	scale?: number;
	/**
	 * The rotation of the gradient in radians, useful for making the gradient elliptical.
	 * NOTE: Only applied to radial gradients used with Graphics.
	 */
	rotation?: number;
}
/**
 * Options for creating a gradient fill.
 * @memberof scene
 */
export type GradientOptions = LinearGradientOptions | RadialGradientOptions;
/**
 * Class representing a gradient fill that can be used to fill shapes and text.
 * Supports both linear and radial gradients with multiple color stops.
 *
 * For linear gradients, color stops define colors and positions (0 to 1) along a line from start point (x0,y0)
 * to end point (x1,y1).
 *
 * For radial gradients, color stops define colors between two circles - an inner circle centered at (x0,y0) with radius r0,
 * and an outer circle centered at (x1,y1) with radius r1.
 * @example
 * \`\`\`ts
 * // Create a vertical linear gradient from red to blue
 * const linearGradient = new FillGradient({
 *     type: 'linear',
 *     start: { x: 0, y: 0 },  // Start at top
 *     end: { x: 0, y: 1 },    // End at bottom
 *     colorStops: [
 *         { offset: 0, color: 'red' },   // Red at start
 *         { offset: 1, color: 'blue' }   // Blue at end
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 *
 * // Create a radial gradient from yellow center to green edge
 * const radialGradient = new FillGradient({
 *     type: 'radial',
 *     center: { x: 0.5, y: 0.5 },
 *     innerRadius: 0,
 *     outerCenter: { x: 0.5, y: 0.5 },
 *     outerRadius: 0.5,
 *     colorStops: [
 *         { offset: 0, color: 'yellow' }, // Center color
 *         { offset: 1, color: 'green' }   // Edge color
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 *
 * // Create a rainbow linear gradient in global coordinates
 * const globalGradient = new FillGradient({
 *     type: 'linear',
 *     start: { x: 0, y: 0 },
 *     end: { x: 100, y: 0 },
 *     colorStops: [
 *         { offset: 0, color: 0xff0000 },    // Red
 *         { offset: 0.33, color: 0x00ff00 }, // Green
 *         { offset: 0.66, color: 0x0000ff }, // Blue
 *         { offset: 1, color: 0xff00ff }     // Purple
 *     ],
 *     textureSpace: 'global'  // Use world coordinates
 * });
 *
 * // Create an offset radial gradient
 * const offsetRadial = new FillGradient({
 *     type: 'radial',
 *     center: { x: 0.3, y: 0.3 },
 *     innerRadius: 0.1,
 *     outerCenter: { x: 0.5, y: 0.5 },
 *     outerRadius: 0.5,
 *     colorStops: [
 *         { offset: 0, color: 'white' },
 *         { offset: 1, color: 'black' }
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 * \`\`\`
 *
 * Internally this creates a  texture of the gradient then applies a
 * transform to it to give it the correct size and angle.
 *
 * This means that it's important to destroy a gradient when it is no longer needed
 * to avoid memory leaks.
 *
 * If you want to animate a gradient then it's best to modify and update an existing one
 * rather than creating a whole new one each time. That or use a custom shader.
 * @memberof scene
 * @implements {CanvasGradient}
 */
export declare class FillGradient implements CanvasGradient {
	/**
	 * Default options for creating a gradient fill
	 * @property {PointData} start - Start point of the gradient (default: { x: 0, y: 0 })
	 * @property {PointData} end - End point of the gradient (default: { x: 0, y: 1 })
	 * @property {TextureSpace} textureSpace - Whether coordinates are 'global' or 'local' (default: 'local')
	 * @property {number} textureSize - The size of the texture to use for the gradient (default: 256)
	 * @property {Array<{offset: number, color: ColorSource}>} colorStops - Array of color stops (default: empty array)
	 * @property {GradientType} type - Type of gradient (default: 'linear')
	 */
	static readonly defaultLinearOptions: LinearGradientOptions;
	/**
	 * Default options for creating a radial gradient fill
	 * @property {PointData} innerCenter - Center of the inner circle (default: { x: 0.5, y: 0.5 })
	 * @property {number} innerRadius - Radius of the inner circle (default: 0)
	 * @property {PointData} outerCenter - Center of the outer circle (default: { x: 0.5, y: 0.5 })
	 * @property {number} outerRadius - Radius of the outer circle (default: 0.5)
	 * @property {TextureSpace} textureSpace - Whether coordinates are 'global' or 'local' (default: 'local')
	 * @property {number} textureSize - The size of the texture to use for the gradient (default: 256)
	 * @property {Array<{offset: number, color: ColorSource}>} colorStops - Array of color stops (default: empty array)
	 * @property {GradientType} type - Type of gradient (default: 'radial')
	 */
	static readonly defaultRadialOptions: RadialGradientOptions;
	/** Unique identifier for this gradient instance */
	readonly uid: number;
	/** Type of gradient - currently only supports 'linear' */
	readonly type: GradientType;
	/** Internal texture used to render the gradient */
	texture: Texture;
	/** Transform matrix for positioning the gradient */
	transform: Matrix;
	/** Array of color stops defining the gradient */
	colorStops: Array<{
		offset: number;
		color: string;
	}>;
	/** Whether gradient coordinates are in local or global space */
	textureSpace: TextureSpace;
	private readonly _textureSize;
	/** The start point of the linear gradient */
	start: PointData;
	/** The end point of the linear gradient */
	end: PointData;
	/** The center point of the inner circle of the radial gradient */
	center: PointData;
	/** The center point of the outer circle of the radial gradient */
	outerCenter: PointData;
	/** The radius of the inner circle of the radial gradient */
	innerRadius: number;
	/** The radius of the outer circle of the radial gradient */
	outerRadius: number;
	/** The scale of the radial gradient */
	scale: number;
	/** The rotation of the radial gradient */
	rotation: number;
	/**
	 * Creates a new gradient fill. The constructor behavior changes based on the gradient type.
	 *
	 * For linear gradients:
	 * @param {GradientOptions} options - The options for the gradient
	 * @param {PointData} [options.start] - The start point of the linear gradient
	 * @param {PointData} [options.end] - The end point of the linear gradient
	 *
	 * For radial gradients:
	 * @param {PointData} [options.innerCenter] - The center point of the inner circle of the radial gradient
	 * @param {number} [options.innerRadius] - The radius of the inner circle of the radial gradient
	 * @param {PointData} [options.outerCenter] - The center point of the outer circle of the radial gradient
	 * @param {number} [options.outerRadius] - The radius of the outer circle of the radial gradient
	 *
	 * Common options for both gradient types:
	 * @param {TextureSpace} [options.textureSpace='local'] - Whether coordinates are 'global' or 'local'
	 * @param {number} [options.textureSize=256] - The size of the texture to use for the gradient
	 * @param {Array<{offset: number, color: ColorSource}>} [options.colorStops=[]] - Array of color stops
	 * @param {GradientType} [options.type='linear'] - Type of gradient
	 */
	constructor(options: GradientOptions);
	/** @deprecated since 8.5.2 */
	constructor(x0?: number, y0?: number, x1?: number, y1?: number, textureSpace?: TextureSpace, textureSize?: number);
	/**
	 * Adds a color stop to the gradient
	 * @param offset - Position of the stop (0-1)
	 * @param color - Color of the stop
	 * @returns This gradient instance for chaining
	 */
	addColorStop(offset: number, color: ColorSource): this;
	/**
	 * Builds the internal texture and transform for the gradient.
	 * Called automatically when the gradient is first used.
	 * @internal
	 */
	buildLinearGradient(): void;
	buildGradient(): void;
	buildRadialGradient(): void;
	/**
	 * Gets a unique key representing the current state of the gradient.
	 * Used internally for caching.
	 * @returns Unique string key
	 */
	get styleKey(): number;
	destroy(): void;
}
export type PatternRepetition = "repeat" | "repeat-x" | "repeat-y" | "no-repeat";
export declare class FillPattern implements CanvasPattern {
	/** unique id for this fill pattern */
	readonly uid: number;
	texture: Texture;
	transform: Matrix;
	private _styleKey;
	constructor(texture: Texture, repetition?: PatternRepetition);
	setTransform(transform?: Matrix): void;
	get styleKey(): string;
}
/**
 * Determines how texture coordinates are calculated
 * Local Space:              Global Space:
 * ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐
 * │ A   B   │  │ A   B   │  │ A...B   │  │ ...B... │
 * │         │  │         │  │         │  │         │
 * │ C   D   │  │ C   D   │  │ C...D   │  │ ...D... │
 * └─────────┘  └─────────┘  └─────────┘  └─────────┘
 * (Each shape   (Each shape  (Texture continues across
 * gets full     gets full    shapes as if they're texture)      texture)     windows to same texture)
 * @memberof scene
 */
export type TextureSpace = 
/**
 * 'local' - Texture coordinates are relative to the shape's bounds.
 * The texture will stretch/fit to each individual shape's boundaries.
 * Think of it like the shape having its own coordinate system.
 */
"local"
/**
 * 'global' - Texture coordinates are in world space.
 * The texture position is consistent across all shapes,
 * as if the texture was laid down first and shapes were cut out of it.
 * Think of it like wallpaper that shows through shaped holes.
 */
 | "global";
/**
 * A fill style object.
 * @memberof scene
 */
export interface FillStyle {
	/** The color to use for the fill. */
	color?: ColorSource;
	/** The alpha value to use for the fill. */
	alpha?: number;
	/** The texture to use for the fill. */
	texture?: Texture | null;
	/** The matrix to apply. */
	matrix?: Matrix | null;
	/** The fill pattern to use. */
	fill?: FillPattern | FillGradient | null;
	/** The fill units to use. */
	textureSpace?: TextureSpace;
}
/**
 * A stroke attribute object, used to define properties for a stroke.
 * @memberof scene
 */
export interface StrokeAttributes {
	/** The width of the stroke. */
	width?: number;
	/** The alignment of the stroke. */
	alignment?: number;
	/** The line cap style to use. */
	cap?: LineCap;
	/** The line join style to use. */
	join?: LineJoin;
	/** The miter limit to use. */
	miterLimit?: number;
	/** If the stroke is a pixel line. NOTE: this is only available for Graphic fills */
	pixelLine?: boolean;
}
/**
 * A stroke style object.
 * @memberof scene
 */
export interface StrokeStyle extends FillStyle, StrokeAttributes {
}
/**
 * These can be directly used as a fill or a stroke
 * \`\`\`ts
 * graphics.fill(0xff0000);
 * graphics.fill(new FillPattern(texture));
 * graphics.fill(new FillGradient(0, 0, 200, 0));
 * graphics.fill({
 *   color: 0xff0000,
 *   alpha: 0.5,
 *   texture?: null,
 *   matrix?: null,
 * });
 * graphics.fill({
 *   fill: new FillPattern(texture),
 * });
 * graphics.fill({
 *   fill: new FillGradient(0, 0, 200, 0),
 * });
 * \`\`\`
 * @memberof scene
 */
export type FillInput = ColorSource | FillGradient | FillPattern | FillStyle | Texture;
/**
 * These can be directly used as a stroke
 * \`\`\`ts
 * graphics.stroke(0xff0000);
 * graphics.stroke(new FillPattern(texture));
 * graphics.stroke(new FillGradient(0, 0, 200, 0));
 * graphics.stroke({
 *   color: 0xff0000,
 *   width?: 1,
 *   alignment?: 0.5,
 * });
 * graphics.stroke({
 *   fill: new FillPattern(texture),
 *   width: 1,
 *   alignment: 0.5,
 * });
 * graphics.stroke({
 *   fill: new FillGradient(0, 0, 200, 0),
 *   width: 1,
 *   alignment: 0.5,
 * });
 * \`\`\`
 * @memberof scene
 */
export type StrokeInput = ColorSource | FillGradient | FillPattern | StrokeStyle;
export type ConvertedFillStyle = Omit<Required<FillStyle>, "color"> & {
	color: number;
};
export type ConvertedStrokeStyle = ConvertedFillStyle & Required<StrokeAttributes>;
/**
 * @deprecated since v8.1.6
 * @see scene.FillInput
 */
export type FillStyleInputs = ColorSource | FillGradient | FillPattern | FillStyle | ConvertedFillStyle | StrokeStyle | ConvertedStrokeStyle;
export type BatchMode = "auto" | "batch" | "no-batch";
export interface FillInstruction {
	action: "fill" | "cut";
	data: {
		style: ConvertedFillStyle;
		path: GraphicsPath;
		hole?: GraphicsPath;
	};
}
export interface StrokeInstruction {
	action: "stroke";
	data: {
		style: ConvertedStrokeStyle;
		path: GraphicsPath;
		hole?: GraphicsPath;
	};
}
export interface TextureInstruction {
	action: "texture";
	data: {
		image: Texture;
		dx: number;
		dy: number;
		dw: number;
		dh: number;
		transform: Matrix;
		alpha: number;
		style: number;
	};
}
export type GraphicsInstructions = FillInstruction | StrokeInstruction | TextureInstruction;
/**
 * The GraphicsContext class allows for the creation of lightweight objects that contain instructions for drawing shapes and paths.
 * It is used internally by the Graphics class to draw shapes and paths, and can be used directly and shared between Graphics objects,
 *
 * This sharing of a \`GraphicsContext\` means that the intensive task of converting graphics instructions into GPU-ready geometry is done once, and the results are reused,
 * much like sprites reusing textures.
 * @memberof scene
 */
export declare class GraphicsContext extends EventEmitter<{
	update: GraphicsContext;
	destroy: GraphicsContext;
}> {
	/** The default fill style to use when none is provided. */
	static defaultFillStyle: ConvertedFillStyle;
	/** The default stroke style to use when none is provided. */
	static defaultStrokeStyle: ConvertedStrokeStyle;
	/** unique id for this graphics context */
	readonly uid: number;
	dirty: boolean;
	batchMode: BatchMode;
	instructions: GraphicsInstructions[];
	customShader?: Shader;
	private _activePath;
	private _transform;
	private _fillStyle;
	private _strokeStyle;
	private _stateStack;
	private _tick;
	private _bounds;
	private _boundsDirty;
	/**
	 * Creates a new GraphicsContext object that is a clone of this instance, copying all properties,
	 * including the current drawing state, transformations, styles, and instructions.
	 * @returns A new GraphicsContext instance with the same properties and state as this one.
	 */
	clone(): GraphicsContext;
	/**
	 * The current fill style of the graphics context. This can be a color, gradient, pattern, or a more complex style defined by a FillStyle object.
	 */
	get fillStyle(): ConvertedFillStyle;
	set fillStyle(value: FillInput);
	/**
	 * The current stroke style of the graphics context. Similar to fill styles, stroke styles can encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
	 */
	get strokeStyle(): ConvertedStrokeStyle;
	set strokeStyle(value: FillInput);
	/**
	 * Sets the current fill style of the graphics context. The fill style can be a color, gradient,
	 * pattern, or a more complex style defined by a FillStyle object.
	 * @param style - The fill style to apply. This can be a simple color, a gradient or pattern object,
	 *                or a FillStyle or ConvertedFillStyle object.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setFillStyle(style: FillInput): this;
	/**
	 * Sets the current stroke style of the graphics context. Similar to fill styles, stroke styles can
	 * encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
	 * @param style - The stroke style to apply. Can be defined as a color, a gradient or pattern,
	 *                or a StrokeStyle or ConvertedStrokeStyle object.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setStrokeStyle(style: StrokeInput): this;
	/**
	 * Adds a texture to the graphics context. This method supports multiple overloads for specifying the texture, tint, and dimensions.
	 * If only a texture is provided, it uses the texture's width and height for drawing. Additional parameters allow for specifying
	 * a tint color, and custom dimensions for the texture drawing area.
	 * @param texture - The Texture object to use.
	 * @param tint - (Optional) A ColorSource to tint the texture. If not provided, defaults to white (0xFFFFFF).
	 * @param dx - (Optional) The x-coordinate in the destination canvas at which to place the top-left corner of the source image.
	 * @param dy - (Optional) The y-coordinate in the destination canvas at which to place the top-left corner of the source image.
	 * @param dw - (Optional) The width of the rectangle within the source image to draw onto the destination canvas. If not provided, uses the texture's frame width.
	 * @param dh - (Optional) The height of the rectangle within the source image to draw onto the destination canvas. If not provided, uses the texture's frame height.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	texture(texture: Texture): this;
	texture(texture: Texture, tint: ColorSource): this;
	texture(texture: Texture, tint: ColorSource, dx: number, dy: number): this;
	texture(texture: Texture, tint: ColorSource, dx: number, dy: number, dw: number, dh: number): this;
	/**
	 * Resets the current path. Any previous path and its commands are discarded and a new path is
	 * started. This is typically called before beginning a new shape or series of drawing commands.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	beginPath(): this;
	/**
	 * Fills the current or given path with the current fill style. This method can optionally take
	 * a color and alpha for a simple fill, or a more complex FillInput object for advanced fills.
	 * @param style - (Optional) The style to fill the path with. Can be a color, gradient, pattern, or a complex style object. If omitted, uses the current fill style.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	fill(style?: FillInput): this;
	/** @deprecated 8.0.0 */
	fill(color: ColorSource, alpha: number): this;
	private _initNextPathLocation;
	/**
	 * Strokes the current path with the current stroke style. This method can take an optional
	 * FillInput parameter to define the stroke's appearance, including its color, width, and other properties.
	 * @param style - (Optional) The stroke style to apply. Can be defined as a simple color or a more complex style object. If omitted, uses the current stroke style.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	stroke(style?: StrokeInput): this;
	/**
	 * Applies a cutout to the last drawn shape. This is used to create holes or complex shapes by
	 * subtracting a path from the previously drawn path. If a hole is not completely in a shape, it will
	 * fail to cut correctly!
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	cut(): this;
	/**
	 * Adds an arc to the current path, which is centered at (x, y) with the specified radius,
	 * starting and ending angles, and direction.
	 * @param x - The x-coordinate of the arc's center.
	 * @param y - The y-coordinate of the arc's center.
	 * @param radius - The arc's radius.
	 * @param startAngle - The starting angle, in radians.
	 * @param endAngle - The ending angle, in radians.
	 * @param counterclockwise - (Optional) Specifies whether the arc is drawn counterclockwise (true) or clockwise (false). Defaults to false.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
	/**
	 * Adds an arc to the current path with the given control points and radius, connected to the previous point
	 * by a straight line if necessary.
	 * @param x1 - The x-coordinate of the first control point.
	 * @param y1 - The y-coordinate of the first control point.
	 * @param x2 - The x-coordinate of the second control point.
	 * @param y2 - The y-coordinate of the second control point.
	 * @param radius - The arc's radius.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
	/**
	 * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
	 * @param rx - The x-radius of the ellipse.
	 * @param ry - The y-radius of the ellipse.
	 * @param xAxisRotation - The rotation of the ellipse's x-axis relative
	 * to the x-axis of the coordinate system, in degrees.
	 * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
	 * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
	 * @param x - The x-coordinate of the arc's end point.
	 * @param y - The y-coordinate of the arc's end point.
	 * @returns The instance of the current object for chaining.
	 */
	arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
	/**
	 * Adds a cubic Bezier curve to the path.
	 * It requires three points: the first two are control points and the third one is the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the first control point.
	 * @param cp1y - The y-coordinate of the first control point.
	 * @param cp2x - The x-coordinate of the second control point.
	 * @param cp2y - The y-coordinate of the second control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Closes the current path by drawing a straight line back to the start.
	 * If the shape is already closed or there are no points in the path, this method does nothing.
	 * @returns The instance of the current object for chaining.
	 */
	closePath(): this;
	/**
	 * Draws an ellipse at the specified location and with the given x and y radii.
	 * An optional transformation can be applied, allowing for rotation, scaling, and translation.
	 * @param x - The x-coordinate of the center of the ellipse.
	 * @param y - The y-coordinate of the center of the ellipse.
	 * @param radiusX - The horizontal radius of the ellipse.
	 * @param radiusY - The vertical radius of the ellipse.
	 * @returns The instance of the current object for chaining.
	 */
	ellipse(x: number, y: number, radiusX: number, radiusY: number): this;
	/**
	 * Draws a circle shape. This method adds a new circle path to the current drawing.
	 * @param x - The x-coordinate of the center of the circle.
	 * @param y - The y-coordinate of the center of the circle.
	 * @param radius - The radius of the circle.
	 * @returns The instance of the current object for chaining.
	 */
	circle(x: number, y: number, radius: number): this;
	/**
	 * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
	 * @param path - The \`GraphicsPath\` to add.
	 * @returns The instance of the current object for chaining.
	 */
	path(path: GraphicsPath): this;
	/**
	 * Connects the current point to a new point with a straight line. This method updates the current path.
	 * @param x - The x-coordinate of the new point to connect to.
	 * @param y - The y-coordinate of the new point to connect to.
	 * @returns The instance of the current object for chaining.
	 */
	lineTo(x: number, y: number): this;
	/**
	 * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
	 * @param x - The x-coordinate for the starting point.
	 * @param y - The y-coordinate for the starting point.
	 * @returns The instance of the current object for chaining.
	 */
	moveTo(x: number, y: number): this;
	/**
	 * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
	 * The starting point is the last point in the current path.
	 * @param cpx - The x-coordinate of the control point.
	 * @param cpy - The y-coordinate of the control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	rect(x: number, y: number, w: number, h: number): this;
	/**
	 * Draws a rectangle with rounded corners.
	 * The corner radius can be specified to determine how rounded the corners should be.
	 * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
	 * @returns The instance of the current object for chaining.
	 */
	roundRect(x: number, y: number, w: number, h: number, radius?: number): this;
	/**
	 * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
	 * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
	 * rotated, or translated as needed.
	 * @param points - An array of numbers, or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
	 * representing the x and y coordinates, of the polygon's vertices, in sequence.
	 * @param close - A boolean indicating whether to close the polygon path. True by default.
	 */
	poly(points: number[] | PointData[], close?: boolean): this;
	/**
	 * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining.
	 */
	regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
	/**
	 * Draws a polygon with rounded corners.
	 * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param corner - The radius of the rounding of the corners.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @returns The instance of the current object for chaining.
	 */
	roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
	/**
	 * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
	 * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
	 * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
	 * A minimum of 3 points is required.
	 * @param radius - The default radius for the corners.
	 * This radius is applied to all corners unless overridden in \`points\`.
	 * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
	 *  method instead of an arc method. Defaults to false.
	 * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
	 * Higher values make the curve smoother.
	 * @returns The instance of the current object for chaining.
	 */
	roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
	/**
	 * Draw Rectangle with fillet corners. This is much like rounded rectangle
	 * however it support negative numbers as well for the corner radius.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param fillet - accept negative or positive values
	 */
	filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
	/**
	 * Draw Rectangle with chamfer corners. These are angled corners.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param chamfer - non-zero real number, size of corner cutout
	 * @param transform
	 */
	chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
	/**
	 * Draws a star shape centered at a specified location. This method allows for the creation
	 *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
	 * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
	 * An optional transformation can be applied to scale, rotate, or translate the star as needed.
	 * @param x - The x-coordinate of the center of the star.
	 * @param y - The y-coordinate of the center of the star.
	 * @param points - The number of points of the star.
	 * @param radius - The outer radius of the star (distance from the center to the outer points).
	 * @param innerRadius - Optional. The inner radius of the star
	 * (distance from the center to the inner points between the outer points).
	 * If not provided, defaults to half of the \`radius\`.
	 * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
	 * Defaults to 0, meaning one point is directly upward.
	 * @returns The instance of the current object for chaining further drawing commands.
	 */
	star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number): this;
	/**
	 * Parses and renders an SVG string into the graphics context. This allows for complex shapes and paths
	 * defined in SVG format to be drawn within the graphics context.
	 * @param svg - The SVG string to be parsed and rendered.
	 */
	svg(svg: string): this;
	/**
	 * Restores the most recently saved graphics state by popping the top of the graphics state stack.
	 * This includes transformations, fill styles, and stroke styles.
	 */
	restore(): this;
	/** Saves the current graphics state, including transformations, fill styles, and stroke styles, onto a stack. */
	save(): this;
	/**
	 * Returns the current transformation matrix of the graphics context.
	 * @returns The current transformation matrix.
	 */
	getTransform(): Matrix;
	/**
	 * Resets the current transformation matrix to the identity matrix, effectively removing any transformations (rotation, scaling, translation) previously applied.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	resetTransform(): this;
	/**
	 * Applies a rotation transformation to the graphics context around the current origin.
	 * @param angle - The angle of rotation in radians.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	rotate(angle: number): this;
	/**
	 * Applies a scaling transformation to the graphics context, scaling drawings by x horizontally and by y vertically.
	 * @param x - The scale factor in the horizontal direction.
	 * @param y - (Optional) The scale factor in the vertical direction. If not specified, the x value is used for both directions.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	scale(x: number, y?: number): this;
	/**
	 * Sets the current transformation matrix of the graphics context to the specified matrix or values.
	 * This replaces the current transformation matrix.
	 * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
	 * @param b - The value for the b property of the matrix.
	 * @param c - The value for the c property of the matrix.
	 * @param d - The value for the d property of the matrix.
	 * @param dx - The value for the tx (translate x) property of the matrix.
	 * @param dy - The value for the ty (translate y) property of the matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setTransform(transform: Matrix): this;
	setTransform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
	/**
	 * Applies the specified transformation matrix to the current graphics context by multiplying the current matrix with the specified matrix.
	 * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
	 * @param b - The value for the b property of the matrix.
	 * @param c - The value for the c property of the matrix.
	 * @param d - The value for the d property of the matrix.
	 * @param dx - The value for the tx (translate x) property of the matrix.
	 * @param dy - The value for the ty (translate y) property of the matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	transform(transform: Matrix): this;
	transform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
	/**
	 * Applies a translation transformation to the graphics context, moving the origin by the specified amounts.
	 * @param x - The amount to translate in the horizontal direction.
	 * @param y - (Optional) The amount to translate in the vertical direction. If not specified, the x value is used for both directions.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	translate(x: number, y?: number): this;
	/**
	 * Clears all drawing commands from the graphics context, effectively resetting it. This includes clearing the path,
	 * and optionally resetting transformations to the identity matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	clear(): this;
	protected onUpdate(): void;
	/** The bounds of the graphic shape. */
	get bounds(): Bounds;
	/**
	 * Check to see if a point is contained within this geometry.
	 * @param point - Point to check if it's contained.
	 * @returns {boolean} \`true\` if the point is contained within geometry.
	 */
	containsPoint(point: PointData): boolean;
	/**
	 * Destroys the GraphicsData object.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the fill/stroke style?
	 * @param {boolean} [options.textureSource=false] - Should it destroy the texture source of the fill/stroke style?
	 */
	destroy(options?: TypeOrBool<TextureDestroyOptions>): void;
}
export type TextStyleAlign = "left" | "center" | "right" | "justify";
export type TextStyleFill = string | string[] | number | number[] | CanvasGradient | CanvasPattern;
export type TextStyleFontStyle = "normal" | "italic" | "oblique";
export type TextStyleFontVariant = "normal" | "small-caps";
export type TextStyleFontWeight = "normal" | "bold" | "bolder" | "lighter" | "100" | "200" | "300" | "400" | "500" | "600" | "700" | "800" | "900";
export type TextStyleLineJoin = "miter" | "round" | "bevel";
export type TextStyleTextBaseline = "alphabetic" | "top" | "hanging" | "middle" | "ideographic" | "bottom";
export type TextStyleWhiteSpace = "normal" | "pre" | "pre-line";
/**
 * A collection of text related classes.
 * @namespace text
 */
/**
 * A drop shadow effect.
 * @memberof text
 */
export type TextDropShadow = {
	/** Set alpha for the drop shadow  */
	alpha: number;
	/** Set a angle of the drop shadow */
	angle: number;
	/** Set a shadow blur radius */
	blur: number;
	/** A fill style to be used on the  e.g., 'red', '#00FF00' */
	color: ColorSource;
	/** Set a distance of the drop shadow */
	distance: number;
};
/**
 * Constructor options used for \`TextStyle\` instances.
 * \`\`\`js
 * const textStyle = new TextStyle({
 *    fontSize: 12,
 *    fill: 'black',
 * });
 * \`\`\`
 * @see {@link text.TextStyle}
 * @memberof text
 */
export interface TextStyleOptions {
	/**
	 * Alignment for multiline text, does not affect single line text
	 * @type {'left'|'center'|'right'|'justify'}
	 */
	align?: TextStyleAlign;
	/** Indicates if lines can be wrapped within words, it needs \`wordWrap\` to be set to \`true\` */
	breakWords?: boolean;
	/** Set a drop shadow for the text */
	dropShadow?: boolean | Partial<TextDropShadow>;
	/**
	 * A canvas fillstyle that will be used on the text e.g., 'red', '#00FF00'.
	 * Can be an array to create a gradient, e.g., \`['#000000','#FFFFFF']\`
	 * {@link https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/fillStyle|MDN}
	 * @type {string|string[]|number|number[]|CanvasGradient|CanvasPattern}
	 */
	fill?: FillInput;
	/** The font family, can be a single font name, or a list of names where the first is the preferred font. */
	fontFamily?: string | string[];
	/** The font size (as a number it converts to px, but as a string, equivalents are '26px','20pt','160%' or '1.6em') */
	fontSize?: number | string;
	/**
	 * The font style.
	 * @type {'normal'|'italic'|'oblique'}
	 */
	fontStyle?: TextStyleFontStyle;
	/**
	 * The font variant.
	 * @type {'normal'|'small-caps'}
	 */
	fontVariant?: TextStyleFontVariant;
	/**
	 * The font weight.
	 * @type {'normal'|'bold'|'bolder'|'lighter'|'100'|'200'|'300'|'400'|'500'|'600'|'700'|'800'|'900'}
	 */
	fontWeight?: TextStyleFontWeight;
	/** The height of the line, a number that represents the vertical space that a letter uses. */
	leading?: number;
	/** The amount of spacing between letters, default is 0 */
	letterSpacing?: number;
	/** The line height, a number that represents the vertical space that a letter uses */
	lineHeight?: number;
	/**
	 * Occasionally some fonts are cropped. Adding some padding will prevent this from
	 * happening by adding padding to all sides of the text.
	 */
	padding?: number;
	/** A canvas fillstyle that will be used on the text stroke, e.g., 'blue', '#FCFF00' */
	stroke?: StrokeInput;
	/**
	 * The baseline of the text that is rendered.
	 * @type {'alphabetic'|'top'|'hanging'|'middle'|'ideographic'|'bottom'}
	 */
	textBaseline?: TextStyleTextBaseline;
	trim?: boolean;
	/**
	 * Determines whether newlines & spaces are collapsed or preserved "normal"
	 * (collapse, collapse), "pre" (preserve, preserve) | "pre-line" (preserve,
	 * collapse). It needs wordWrap to be set to true.
	 * @type {'normal'|'pre'|'pre-line'}
	 */
	whiteSpace?: TextStyleWhiteSpace;
	/** Indicates if word wrap should be used */
	wordWrap?: boolean;
	/** The width at which text will wrap, it needs wordWrap to be set to true */
	wordWrapWidth?: number;
}
/**
 * A TextStyle Object contains information to decorate a Text objects.
 *
 * An instance can be shared between multiple Text objects; then changing the style will update all text objects using it.
 * @memberof text
 * @example
 * import { TextStyle } from 'pixi.js';
 * const style = new TextStyle({
 *   fontFamily: ['Helvetica', 'Arial', 'sans-serif'],
 *   fontSize: 36,
 * });
 */
export declare class TextStyle extends EventEmitter<{
	update: TextDropShadow;
}> {
	/** The default drop shadow settings */
	static defaultDropShadow: TextDropShadow;
	/** The default text style settings */
	static defaultTextStyle: TextStyleOptions;
	_fill: ConvertedFillStyle;
	private _originalFill;
	_stroke: ConvertedStrokeStyle;
	private _originalStroke;
	private _dropShadow;
	private _fontFamily;
	private _fontSize;
	private _fontStyle;
	private _fontVariant;
	private _fontWeight;
	private _breakWords;
	private _align;
	private _leading;
	private _letterSpacing;
	private _lineHeight;
	private _textBaseline;
	private _whiteSpace;
	private _wordWrap;
	private _wordWrapWidth;
	private _padding;
	protected _styleKey: string;
	private _trim;
	constructor(style?: Partial<TextStyleOptions>);
	/**
	 * Alignment for multiline text, does not affect single line text.
	 * @member {'left'|'center'|'right'|'justify'}
	 */
	get align(): TextStyleAlign;
	set align(value: TextStyleAlign);
	/** Indicates if lines can be wrapped within words, it needs wordWrap to be set to true. */
	get breakWords(): boolean;
	set breakWords(value: boolean);
	/** Set a drop shadow for the text. */
	get dropShadow(): TextDropShadow;
	set dropShadow(value: boolean | TextDropShadow);
	/** The font family, can be a single font name, or a list of names where the first is the preferred font. */
	get fontFamily(): string | string[];
	set fontFamily(value: string | string[]);
	/** The font size (as a number it converts to px, but as a string, equivalents are '26px','20pt','160%' or '1.6em') */
	get fontSize(): number;
	set fontSize(value: string | number);
	/**
	 * The font style.
	 * @member {'normal'|'italic'|'oblique'}
	 */
	get fontStyle(): TextStyleFontStyle;
	set fontStyle(value: TextStyleFontStyle);
	/**
	 * The font variant.
	 * @member {'normal'|'small-caps'}
	 */
	get fontVariant(): TextStyleFontVariant;
	set fontVariant(value: TextStyleFontVariant);
	/**
	 * The font weight.
	 * @member {'normal'|'bold'|'bolder'|'lighter'|'100'|'200'|'300'|'400'|'500'|'600'|'700'|'800'|'900'}
	 */
	get fontWeight(): TextStyleFontWeight;
	set fontWeight(value: TextStyleFontWeight);
	/** The space between lines. */
	get leading(): number;
	set leading(value: number);
	/** The amount of spacing between letters, default is 0. */
	get letterSpacing(): number;
	set letterSpacing(value: number);
	/** The line height, a number that represents the vertical space that a letter uses. */
	get lineHeight(): number;
	set lineHeight(value: number);
	/**
	 * Occasionally some fonts are cropped. Adding some padding will prevent this from happening
	 * by adding padding to all sides of the text.
	 */
	get padding(): number;
	set padding(value: number);
	/** Trim transparent borders. This is an expensive operation so only use this if you have to! */
	get trim(): boolean;
	set trim(value: boolean);
	/**
	 * The baseline of the text that is rendered.
	 * @member {'alphabetic'|'top'|'hanging'|'middle'|'ideographic'|'bottom'}
	 */
	get textBaseline(): TextStyleTextBaseline;
	set textBaseline(value: TextStyleTextBaseline);
	/**
	 * How newlines and spaces should be handled.
	 * Default is 'pre' (preserve, preserve).
	 *
	 *  value       | New lines     |   Spaces
	 *  ---         | ---           |   ---
	 * 'normal'     | Collapse      |   Collapse
	 * 'pre'        | Preserve      |   Preserve
	 * 'pre-line'   | Preserve      |   Collapse
	 * @member {'normal'|'pre'|'pre-line'}
	 */
	get whiteSpace(): TextStyleWhiteSpace;
	set whiteSpace(value: TextStyleWhiteSpace);
	/** Indicates if word wrap should be used. */
	get wordWrap(): boolean;
	set wordWrap(value: boolean);
	/** The width at which text will wrap, it needs wordWrap to be set to true. */
	get wordWrapWidth(): number;
	set wordWrapWidth(value: number);
	/**
	 * The fill style that will be used to color the text.
	 * This can be:
	 * - A color string like 'red', '#00FF00', or 'rgba(255,0,0,0.5)'
	 * - A hex number like 0xff0000 for red
	 * - A FillStyle object with properties like { color: 0xff0000, alpha: 0.5 }
	 * - A FillGradient for gradient fills
	 * - A FillPattern for pattern/texture fills
	 *
	 * When using a FillGradient, vertical gradients (angle of 90 degrees) are applied per line of text,
	 * while gradients at any other angle are spread across the entire text body as a whole.
	 * @example
	 * // Vertical gradient applied per line
	 * const verticalGradient = new FillGradient(0, 0, 0, 1)
	 *     .addColorStop(0, 0xff0000)
	 *     .addColorStop(1, 0x0000ff);
	 *
	 * const text = new Text({
	 *     text: 'Line 1\\nLine 2',
	 *     style: { fill: verticalGradient }
	 * });
	 *
	 * To manage the gradient in a global scope, set the textureSpace property of the FillGradient to 'global'.
	 * @type {string|number|FillStyle|FillGradient|FillPattern}
	 */
	get fill(): FillInput;
	set fill(value: FillInput);
	/** A fillstyle that will be used on the text stroke, e.g., 'blue', '#FCFF00'. */
	get stroke(): StrokeInput;
	set stroke(value: StrokeInput);
	protected _generateKey(): string;
	update(): void;
	/** Resets all properties to the default values */
	reset(): void;
	get styleKey(): string;
	/**
	 * Creates a new TextStyle object with the same values as this one.
	 * @returns New cloned TextStyle object
	 */
	clone(): TextStyle;
	/**
	 * Destroys this text style.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the texture of the this style
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the this style
	 */
	destroy(options?: TypeOrBool<TextureDestroyOptions>): void;
	private _createProxy;
	private _isFillStyle;
}
/**
 * Options for HTML text style, extends {@link TextStyle}.
 * @memberof text
 * @extends text.TextStyleOptions
 * @property {string[]} [cssOverrides] - CSS style(s) to add.
 * @property {Record<string, text.HTMLTextStyleOptions>} [tagStyles] - Tag styles.
 */
export interface HTMLTextStyleOptions extends Omit<TextStyleOptions, "leading" | "textBaseline" | "trim"> {
	cssOverrides?: string[];
	tagStyles?: Record<string, HTMLTextStyleOptions>;
}
/**
 * A TextStyle object rendered by the HTMLTextSystem.
 * @memberof text
 */
export declare class HTMLTextStyle extends TextStyle {
	private _cssOverrides;
	private _cssStyle;
	/**
	 * List of styles per tag.
	 * @example
	 * new HTMLText({
	 *   text:'<red>Red</red>,<blue>Blue</blue>,<green>Green</green>',
	 *   style:{
	 *       fontFamily: 'DM Sans',
	 *       fill: 'white',
	 *       fontSize:100,
	 *       tagStyles:{
	 *           red:{
	 *               fill:'red',
	 *           },
	 *           blue:{
	 *               fill:'blue',
	 *           },
	 *           green:{
	 *               fill:'green',
	 *           }
	 *       }
	 *   }
	 * );
	 */
	tagStyles: Record<string, HTMLTextStyleOptions>;
	constructor(options?: HTMLTextStyleOptions);
	/** List of style overrides that will be applied to the HTML text. */
	set cssOverrides(value: string | string[]);
	get cssOverrides(): string[];
	protected _generateKey(): string;
	update(): void;
	/**
	 * Creates a new HTMLTextStyle object with the same values as this one.
	 * @returns New cloned HTMLTextStyle object
	 */
	clone(): HTMLTextStyle;
	get cssStyle(): string;
	/**
	 * Add a style override, this can be any CSS property
	 * it will override any built-in style. This is the
	 * property and the value as a string (e.g., \`color: red\`).
	 * This will override any other internal style.
	 * @param {string} value - CSS style(s) to add.
	 * @example
	 * style.addOverride('background-color: red');
	 */
	addOverride(...value: string[]): void;
	/**
	 * Remove any overrides that match the value.
	 * @param {string} value - CSS style to remove.
	 * @example
	 * style.removeOverride('background-color: red');
	 */
	removeOverride(...value: string[]): void;
	set fill(value: FillInput);
	set stroke(value: StrokeInput);
}
/**
 * A string or number that can be used as text.
 * @memberof text
 */
export type TextString = string | number | {
	toString: () => string;
};
/**
 * A union of all text styles, including HTML, Bitmap and Canvas text styles.
 * @memberof text
 * @see text.TextStyle
 * @see text.HTMLTextStyle
 */
export type AnyTextStyle = TextStyle | HTMLTextStyle;
/**
 * A union of all text style options, including HTML, Bitmap and Canvas text style options.
 * @memberof text
 * @see text.TextStyleOptions
 * @see text.HTMLTextStyleOptions
 */
export type AnyTextStyleOptions = TextStyleOptions | HTMLTextStyleOptions;
/**
 * Options for the {@link scene.Text} class.
 * @example
 * const text = new Text({
 *    text: 'Hello Pixi!',
 *    style: {
 *       fontFamily: 'Arial',
 *       fontSize: 24,
 *    fill: 0xff1010,
 *    align: 'center',
 *  }
 * });
 * @memberof text
 */
export interface TextOptions<TEXT_STYLE extends TextStyle = TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions = TextStyleOptions> extends PixiMixins.TextOptions, ViewContainerOptions {
	/** The anchor point of the text. */
	anchor?: PointData | number;
	/** The copy for the text object. To split a line you can use '\\n'. */
	text?: TextString;
	/** The resolution of the text. */
	resolution?: number;
	/**
	 * The text style
	 * @type {
	 * text.TextStyle |
	 * Partial<text.TextStyle> |
	 * text.TextStyleOptions |
	 * text.HTMLTextStyle |
	 * Partial<text.HTMLTextStyle> |
	 * text.HTMLTextStyleOptions
	 * }
	 */
	style?: TEXT_STYLE | TEXT_STYLE_OPTIONS;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
}
/**
 * An abstract Text class, used by all text type in Pixi. This includes Canvas, HTML, and Bitmap Text.
 * @see scene.Text
 * @see scene.BitmapText
 * @see scene.HTMLText
 * @memberof scene
 */
export declare abstract class AbstractText<TEXT_STYLE extends TextStyle = TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions = TextStyleOptions> extends ViewContainer implements View {
	batched: boolean;
	_anchor: ObservablePoint;
	_resolution: number;
	_autoResolution: boolean;
	_style: TEXT_STYLE;
	_didTextUpdate: boolean;
	protected _text: string;
	private readonly _styleClass;
	constructor(options: TextOptions<TEXT_STYLE, TEXT_STYLE_OPTIONS>, styleClass: new (options: TEXT_STYLE_OPTIONS) => TEXT_STYLE);
	/**
	 * The anchor sets the origin point of the text.
	 * The default is \`(0,0)\`, this means the text's origin is the top left.
	 *
	 * Setting the anchor to \`(0.5,0.5)\` means the text's origin is centered.
	 *
	 * Setting the anchor to \`(1,1)\` would mean the text's origin point will be the bottom right corner.
	 *
	 * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
	 * @example
	 * import { Text } from 'pixi.js';
	 *
	 * const text = new Text('hello world');
	 * text.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
	 */
	get anchor(): ObservablePoint;
	set anchor(value: PointData | number);
	/** Set the copy for the text object. To split a line you can use '\\n'. */
	set text(value: TextString);
	get text(): string;
	/**
	 * The resolution / device pixel ratio of the canvas.
	 * @default 1
	 */
	set resolution(value: number);
	get resolution(): number;
	get style(): TEXT_STYLE;
	/**
	 * Set the style of the text.
	 *
	 * Set up an event listener to listen for changes on the style object and mark the text as dirty.
	 *
	 * If setting the \`style\` can also be partial {@link AnyTextStyleOptions}.
	 * @type {
	 * text.TextStyle |
	 * Partial<text.TextStyle> |
	 * text.TextStyleOptions |
	 * text.HTMLTextStyle |
	 * Partial<text.HTMLTextStyle> |
	 * text.HTMLTextStyleOptions
	 * }
	 */
	set style(style: TEXT_STYLE | Partial<TEXT_STYLE> | TEXT_STYLE_OPTIONS);
	/** The width of the sprite, setting this will actually modify the scale to achieve the value set. */
	get width(): number;
	set width(value: number);
	/** The height of the sprite, setting this will actually modify the scale to achieve the value set. */
	get height(): number;
	set height(value: number);
	/**
	 * Retrieves the size of the Text as a [Size]{@link Size} object.
	 * This is faster than get the width and height separately.
	 * @param out - Optional object to store the size in.
	 * @returns - The size of the Text.
	 */
	getSize(out?: Size): Size;
	/**
	 * Sets the size of the Text to the specified width and height.
	 * This is faster than setting the width and height separately.
	 * @param value - This can be either a number or a [Size]{@link Size} object.
	 * @param height - The height to set. Defaults to the value of \`width\` if not provided.
	 */
	setSize(value: number | Optional<Size, "height">, height?: number): void;
	/**
	 * Checks if the text contains the given point.
	 * @param point - The point to check
	 */
	containsPoint(point: PointData): boolean;
	onViewUpdate(): void;
	_getKey(): string;
	/**
	 * Destroys this text renderable and optionally its style texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the texture of the text style
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the text style
	 * @param {boolean} [options.style=false] - Should it destroy the style of the text
	 */
	destroy(options?: DestroyOptions): void;
}
/**
 * Helper function to ensure consistent handling of text options across different text classes.
 * This function handles both the new options object format and the deprecated parameter format.
 * @example
 * // New recommended way:
 * const options = ensureTextOptions([{
 *     text: "Hello",
 *     style: { fontSize: 20 }
 * }], "Text");
 *
 * // Deprecated way (will show warning in debug):
 * const options = ensureTextOptions(["Hello", { fontSize: 20 }], "Text");
 * @param args - Arguments passed to text constructor
 * @param name - Name of the text class (used in deprecation warning)
 * @returns Normalized text options object
 * @template TEXT_STYLE - The specific TextStyle class being used
 * @template TEXT_STYLE_OPTIONS - The options type for the TextStyle
 * @internal
 */
export declare function ensureTextOptions<TEXT_STYLE extends TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions>(args: any[], name: string): TextOptions<TEXT_STYLE, TEXT_STYLE_OPTIONS>;
interface Text$1 extends PixiMixins.Text, AbstractText<TextStyle, TextStyleOptions> {
}
/**
 * A Text Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and givae the \`wordWrapWidth\` property a value.
 *
 * The primary advantage of this class over BitmapText is that you have great control over the style of the text,
 * which you can change at runtime.
 *
 * The primary disadvantages is that each piece of text has it's own texture, which can use more memory.
 * When text changes, this texture has to be re-generated and re-uploaded to the GPU, taking up time.
 * @example
 * import { Text } from 'pixi.js';
 *
 * const text = new Text({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 * @memberof scene
 */
declare class Text$1 extends AbstractText<TextStyle, TextStyleOptions> implements View {
	readonly renderPipeId: string;
	/**
	 * @param {text.TextOptions} options - The options of the text.
	 */
	constructor(options?: TextOptions);
	/** @deprecated since 8.0.0 */
	constructor(text?: TextString, options?: Partial<TextStyle>);
	/** @private */
	protected updateBounds(): void;
}
/** The accepted types to pass to the prepare system */
export type PrepareSourceItem = Container | TextureSource | Texture | GraphicsContext;
/** The valid types resolved to the queue ready for upload */
export type PrepareQueueItem = TextureSource | Text$1 | GraphicsContext;
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class provides the base functionality and handles processing the queue asynchronously.
 * @memberof rendering
 */
export declare abstract class PrepareBase {
	/** The number of uploads to process per frame */
	static uploadsPerFrame: number;
	/** Reference to the renderer */
	protected renderer: Renderer;
	/** The queue to process over a async timer */
	protected queue: PrepareQueueItem[];
	/** Collection of callbacks to call when the uploads are finished */
	protected resolves: ((value: void | PromiseLike<void>) => void)[];
	/** Timeout id for next processing call */
	protected timeout?: number;
	/**
	 * @param {rendering.Renderer} renderer - A reference to the current renderer
	 */
	constructor(renderer: Renderer);
	/** Resolve the given resource type and return an item for the queue */
	protected abstract resolveQueueItem(source: PrepareSourceItem, queue: PrepareQueueItem[]): void;
	protected abstract uploadQueueItem(item: PrepareQueueItem): void;
	/**
	 * Return a copy of the queue
	 * @returns {PrepareQueueItem[]} The queue
	 */
	getQueue(): PrepareQueueItem[];
	/**
	 * Add a textures or graphics resource to the queue
	 * @param {PrepareSourceItem | PrepareSourceItem[]} resource
	 */
	add(resource: PrepareSourceItem | PrepareSourceItem[]): this;
	/**
	 * Recursively add a container and its children to the queue
	 * @param {Container} container - The container to add to the queue
	 */
	private _addContainer;
	/**
	 * Upload all the textures and graphics to the GPU (optionally add more resources to the queue first)
	 * @param {PrepareSourceItem | PrepareSourceItem[] | undefined} resource
	 */
	upload(resource?: PrepareSourceItem | PrepareSourceItem[]): Promise<void>;
	/** eliminate duplicates before processing */
	dedupeQueue(): void;
	/** called per frame by the ticker, defer processing to next tick */
	private readonly _tick;
	/** process the queue up to max item limit per frame */
	private readonly _processQueue;
	/** Call all the resolve callbacks */
	private _resolve;
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			prepare: PrepareBase;
		}
	}
}
declare global {
	namespace PixiMixins {
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface ICanvas {
		}
		interface RendererOptions {
			resolution?: number;
			failIfMajorPerformanceCaveat?: boolean;
			roundPixels?: boolean;
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGLOptions {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGPUOptions {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface RendererSystems {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGLSystems {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGPUSystems {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface CanvasSystems {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface RendererPipes {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGLPipes {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface WebGPUPipes {
		}
		// eslint-disable-next-line @typescript-eslint/no-empty-object-type
		interface CanvasPipes {
		}
	}
}
/**
 * Constructor options used for \`Graphics\` instances.
 * \`\`\`js
 * const graphics = new Graphics({
 *    fillStyle: { color: 0xff0000, alpha: 0.5 },
 *    strokeStyle: { color: 0x00ff00, width: 2 },
 * });
 * \`\`\`
 * @see {@link scene.Graphics}
 * @memberof scene
 */
export interface GraphicsOptions extends PixiMixins.GraphicsOptions, ViewContainerOptions {
	/** The GraphicsContext to use, useful for reuse and optimisation */
	context?: GraphicsContext;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
}
export interface Graphics extends PixiMixins.Graphics, ViewContainer {
}
/**
 * The Graphics class is primarily used to render primitive shapes such as lines, circles and
 * rectangles to the display, and to color and fill them.  However, you can also use a Graphics
 * object to build a list of primitives to use as a mask, or as a complex hitArea.
 * @memberof scene
 * @extends scene.Container
 */
export declare class Graphics extends ViewContainer implements Instruction {
	readonly renderPipeId: string;
	batched: boolean;
	private _context;
	private readonly _ownedContext;
	/**
	 * @param options - Options for the Graphics.
	 */
	constructor(options?: GraphicsOptions | GraphicsContext);
	set context(context: GraphicsContext);
	get context(): GraphicsContext;
	/**
	 * The local bounds of the graphic.
	 * @type {rendering.Bounds}
	 */
	get bounds(): Bounds;
	/**
	 * Graphics objects do not need to update their bounds as the context handles this.
	 * @private
	 */
	protected updateBounds(): void;
	/**
	 * Checks if the object contains the given point.
	 * @param point - The point to check
	 */
	containsPoint(point: PointData): boolean;
	/**
	 * Destroys this graphics renderable and optionally its context.
	 * @param options - Options parameter. A boolean will act as if all options
	 *
	 * If the context was created by this graphics and \`destroy(false)\` or \`destroy()\` is called
	 * then the context will still be destroyed.
	 *
	 * If you want to explicitly not destroy this context that this graphics created,
	 * then you should pass destroy({ context: false })
	 *
	 * If the context was passed in as an argument to the constructor then it will not be destroyed
	 * @param {boolean} [options.texture=false] - Should destroy the texture of the graphics context
	 * @param {boolean} [options.textureSource=false] - Should destroy the texture source of the graphics context
	 * @param {boolean} [options.context=false] - Should destroy the context
	 */
	destroy(options?: DestroyOptions): void;
	private _callContextMethod;
	/**
	 * Sets the current fill style of the graphics context. The fill style can be a color, gradient,
	 * pattern, or a more complex style defined by a FillStyle object.
	 * @param {FillInput} args - The fill style to apply. This can be a simple color, a gradient or
	 * pattern object, or a FillStyle or ConvertedFillStyle object.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setFillStyle(...args: Parameters<GraphicsContext["setFillStyle"]>): this;
	/**
	 * Sets the current stroke style of the graphics context. Similar to fill styles, stroke styles can
	 * encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
	 * @param {StrokeInput} args - The stroke style to apply. Can be defined as a color, a gradient or pattern,
	 * or a StrokeStyle or ConvertedStrokeStyle object.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setStrokeStyle(...args: Parameters<GraphicsContext["setStrokeStyle"]>): this;
	/**
	 * Fills the current or given path with the current fill style. This method can optionally take
	 * a color and alpha for a simple fill, or a more complex FillStyle object for advanced fills.
	 * @param {FillInput} style - (Optional) The style to fill the path with. Can be a color, gradient, pattern, or a
	 * complex style object. If omitted, uses the current fill style.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	fill(style?: FillInput): this;
	/** @deprecated 8.0.0 */
	fill(color: ColorSource, alpha?: number): this;
	/**
	 * Strokes the current path with the current stroke style. This method can take an optional
	 * FillStyle parameter to define the stroke's appearance, including its color, width, and other properties.
	 * @param {FillStyle} args - (Optional) The stroke style to apply. Can be defined as a simple color or a more
	 * complex style object. If omitted, uses the current stroke style.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	stroke(...args: Parameters<GraphicsContext["stroke"]>): this;
	/**
	 * Adds a texture to the graphics context. This method supports multiple overloads for specifying the texture,
	 * tint, and dimensions. If only a texture is provided, it uses the texture's width and height for drawing.
	 * Additional parameters allow for specifying a tint color, and custom dimensions for the texture drawing area.
	 * @param texture - The Texture object to use.
	 * @param tint - (Optional) A ColorSource to tint the texture. If not provided, defaults to white (0xFFFFFF).
	 * @param dx - (Optional) The x-coordinate in the destination canvas at which to place the top-left corner of
	 * the source image.
	 * @param dy - (Optional) The y-coordinate in the destination canvas at which to place the top-left corner of
	 * the source image.
	 * @param dw - (Optional) The width of the rectangle within the source image to draw onto the destination canvas.
	 * If not provided, uses the texture's frame width.
	 * @param dh - (Optional) The height of the rectangle within the source image to draw onto the destination canvas.
	 * If not provided, uses the texture's frame height.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	texture(texture: Texture, tint?: ColorSource, dx?: number, dy?: number, dw?: number, dh?: number): this;
	texture(texture: Texture): this;
	/**
	 * Resets the current path. Any previous path and its commands are discarded and a new path is
	 * started. This is typically called before beginning a new shape or series of drawing commands.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	beginPath(): this;
	/**
	 * Applies a cutout to the last drawn shape. This is used to create holes or complex shapes by
	 * subtracting a path from the previously drawn path. If a hole is not completely in a shape, it will
	 * fail to cut correctly!
	 */
	cut(): this;
	/**
	 * Adds an arc to the current path, which is centered at (x, y) with the specified radius,
	 * starting and ending angles, and direction.
	 * @param x - The x-coordinate of the arc's center.
	 * @param y - The y-coordinate of the arc's center.
	 * @param radius - The arc's radius.
	 * @param startAngle - The starting angle, in radians.
	 * @param endAngle - The ending angle, in radians.
	 * @param counterclockwise - (Optional) Specifies whether the arc is drawn counterclockwise (true) or clockwise
	 * (false). Defaults to false.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
	/**
	 * Adds an arc to the current path with the given control points and radius, connected to the previous point
	 * by a straight line if necessary.
	 * @param x1 - The x-coordinate of the first control point.
	 * @param y1 - The y-coordinate of the first control point.
	 * @param x2 - The x-coordinate of the second control point.
	 * @param y2 - The y-coordinate of the second control point.
	 * @param radius - The arc's radius.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
	/**
	 * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
	 * @param rx - The x-radius of the ellipse.
	 * @param ry - The y-radius of the ellipse.
	 * @param xAxisRotation - The rotation of the ellipse's x-axis relative
	 * to the x-axis of the coordinate system, in degrees.
	 * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
	 * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
	 * @param x - The x-coordinate of the arc's end point.
	 * @param y - The y-coordinate of the arc's end point.
	 * @returns The instance of the current object for chaining.
	 */
	arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
	/**
	 * Adds a cubic Bezier curve to the path.
	 * It requires three points: the first two are control points and the third one is the end point.
	 * The starting point is the last point in the current path.
	 * @param cp1x - The x-coordinate of the first control point.
	 * @param cp1y - The y-coordinate of the first control point.
	 * @param cp2x - The x-coordinate of the second control point.
	 * @param cp2y - The y-coordinate of the second control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Closes the current path by drawing a straight line back to the start.
	 * If the shape is already closed or there are no points in the path, this method does nothing.
	 * @returns The instance of the current object for chaining.
	 */
	closePath(): this;
	/**
	 * Draws an ellipse at the specified location and with the given x and y radii.
	 * An optional transformation can be applied, allowing for rotation, scaling, and translation.
	 * @param x - The x-coordinate of the center of the ellipse.
	 * @param y - The y-coordinate of the center of the ellipse.
	 * @param radiusX - The horizontal radius of the ellipse.
	 * @param radiusY - The vertical radius of the ellipse.
	 * @returns The instance of the current object for chaining.
	 */
	ellipse(x: number, y: number, radiusX: number, radiusY: number): this;
	/**
	 * Draws a circle shape. This method adds a new circle path to the current drawing.
	 * @param x - The x-coordinate of the center of the circle.
	 * @param y - The y-coordinate of the center of the circle.
	 * @param radius - The radius of the circle.
	 * @returns The instance of the current object for chaining.
	 */
	circle(x: number, y: number, radius: number): this;
	/**
	 * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
	 * @param path - The \`GraphicsPath\` to add.
	 * @returns The instance of the current object for chaining.
	 */
	path(path: GraphicsPath): this;
	/**
	 * Connects the current point to a new point with a straight line. This method updates the current path.
	 * @param x - The x-coordinate of the new point to connect to.
	 * @param y - The y-coordinate of the new point to connect to.
	 * @returns The instance of the current object for chaining.
	 */
	lineTo(x: number, y: number): this;
	/**
	 * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
	 * @param x - The x-coordinate for the starting point.
	 * @param y - The y-coordinate for the starting point.
	 * @returns The instance of the current object for chaining.
	 */
	moveTo(x: number, y: number): this;
	/**
	 * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
	 * The starting point is the last point in the current path.
	 * @param cpx - The x-coordinate of the control point.
	 * @param cpy - The y-coordinate of the control point.
	 * @param x - The x-coordinate of the end point.
	 * @param y - The y-coordinate of the end point.
	 * @param smoothness - Optional parameter to adjust the smoothness of the curve.
	 * @returns The instance of the current object for chaining.
	 */
	quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
	/**
	 * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @returns The instance of the current object for chaining.
	 */
	rect(x: number, y: number, w: number, h: number): this;
	/**
	 * Draws a rectangle with rounded corners.
	 * The corner radius can be specified to determine how rounded the corners should be.
	 * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
	 * @param x - The x-coordinate of the top-left corner of the rectangle.
	 * @param y - The y-coordinate of the top-left corner of the rectangle.
	 * @param w - The width of the rectangle.
	 * @param h - The height of the rectangle.
	 * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
	 * @returns The instance of the current object for chaining.
	 */
	roundRect(x: number, y: number, w: number, h: number, radius?: number): this;
	/**
	 * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
	 * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
	 * rotated, or translated as needed.
	 * @param points - An array of numbers, or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
	 * representing the x and y coordinates, of the polygon's vertices, in sequence.
	 * @param close - A boolean indicating whether to close the polygon path. True by default.
	 * @returns The instance of the current object for chaining further drawing commands.
	 */
	poly(points: number[] | PointData[], close?: boolean): this;
	/**
	 * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
	 * @returns The instance of the current object for chaining.
	 */
	regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
	/**
	 * Draws a polygon with rounded corners.
	 * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
	 * @param x - The x-coordinate of the center of the polygon.
	 * @param y - The y-coordinate of the center of the polygon.
	 * @param radius - The radius of the circumscribed circle of the polygon.
	 * @param sides - The number of sides of the polygon. Must be 3 or more.
	 * @param corner - The radius of the rounding of the corners.
	 * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
	 * @returns The instance of the current object for chaining.
	 */
	roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
	/**
	 * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
	 * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
	 * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
	 * A minimum of 3 points is required.
	 * @param radius - The default radius for the corners.
	 * This radius is applied to all corners unless overridden in \`points\`.
	 * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
	 *  method instead of an arc method. Defaults to false.
	 * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
	 * Higher values make the curve smoother.
	 * @returns The instance of the current object for chaining.
	 */
	roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
	/**
	 * Draw Rectangle with fillet corners. This is much like rounded rectangle
	 * however it support negative numbers as well for the corner radius.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param fillet - accept negative or positive values
	 */
	filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
	/**
	 * Draw Rectangle with chamfer corners. These are angled corners.
	 * @param x - Upper left corner of rect
	 * @param y - Upper right corner of rect
	 * @param width - Width of rect
	 * @param height - Height of rect
	 * @param chamfer - non-zero real number, size of corner cutout
	 * @param transform
	 */
	chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
	/**
	 * Draws a star shape centered at a specified location. This method allows for the creation
	 *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
	 * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
	 * An optional transformation can be applied to scale, rotate, or translate the star as needed.
	 * @param x - The x-coordinate of the center of the star.
	 * @param y - The y-coordinate of the center of the star.
	 * @param points - The number of points of the star.
	 * @param radius - The outer radius of the star (distance from the center to the outer points).
	 * @param innerRadius - Optional. The inner radius of the star
	 * (distance from the center to the inner points between the outer points).
	 * If not provided, defaults to half of the \`radius\`.
	 * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
	 * Defaults to 0, meaning one point is directly upward.
	 * @returns The instance of the current object for chaining further drawing commands.
	 */
	star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number): this;
	/**
	 * Parses and renders an SVG string into the graphics context. This allows for complex shapes and paths
	 * defined in SVG format to be drawn within the graphics context.
	 * @param svg - The SVG string to be parsed and rendered.
	 */
	svg(svg: string): this;
	/**
	 * Restores the most recently saved graphics state by popping the top of the graphics state stack.
	 * This includes transformations, fill styles, and stroke styles.
	 */
	restore(): this;
	/** Saves the current graphics state, including transformations, fill styles, and stroke styles, onto a stack. */
	save(): this;
	/**
	 * Returns the current transformation matrix of the graphics context.
	 * @returns The current transformation matrix.
	 */
	getTransform(): Matrix;
	/**
	 * Resets the current transformation matrix to the identity matrix, effectively removing
	 * any transformations (rotation, scaling, translation) previously applied.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	resetTransform(): this;
	/**
	 * Applies a rotation transformation to the graphics context around the current origin.
	 * @param angle - The angle of rotation in radians.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	rotateTransform(angle: number): this;
	/**
	 * Applies a scaling transformation to the graphics context, scaling drawings by x horizontally and by y vertically.
	 * @param x - The scale factor in the horizontal direction.
	 * @param y - (Optional) The scale factor in the vertical direction.
	 * If not specified, the x value is used for both directions.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	scaleTransform(x: number, y?: number): this;
	/**
	 * Sets the current transformation matrix of the graphics context to the specified matrix or values.
	 * This replaces the current transformation matrix.
	 * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
	 * @param b - The value for the b property of the matrix.
	 * @param c - The value for the c property of the matrix.
	 * @param d - The value for the d property of the matrix.
	 * @param dx - The value for the tx (translate x) property of the matrix.
	 * @param dy - The value for the ty (translate y) property of the matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	setTransform(transform: Matrix): this;
	setTransform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
	setTransform(a: number | Matrix, b?: number, c?: number, d?: number, dx?: number, dy?: number): this;
	/**
	 * Applies the specified transformation matrix to the current graphics context by multiplying
	 * the current matrix with the specified matrix.
	 * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
	 * @param b - The value for the b property of the matrix.
	 * @param c - The value for the c property of the matrix.
	 * @param d - The value for the d property of the matrix.
	 * @param dx - The value for the tx (translate x) property of the matrix.
	 * @param dy - The value for the ty (translate y) property of the matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	transform(transform: Matrix): this;
	transform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
	transform(a: number | Matrix, b?: number, c?: number, d?: number, dx?: number, dy?: number): this;
	/**
	 * Applies a translation transformation to the graphics context, moving the origin by the specified amounts.
	 * @param x - The amount to translate in the horizontal direction.
	 * @param y - (Optional) The amount to translate in the vertical direction. If not specified,
	 * the x value is used for both directions.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	translateTransform(x: number, y?: number): this;
	/**
	 * Clears all drawing commands from the graphics context, effectively resetting it. This includes clearing the path,
	 * and optionally resetting transformations to the identity matrix.
	 * @returns The instance of the current GraphicsContext for method chaining.
	 */
	clear(): this;
	/**
	 * The fill style to use.
	 * @type {ConvertedFillStyle}
	 */
	get fillStyle(): GraphicsContext["fillStyle"];
	set fillStyle(value: FillInput);
	/**
	 * The stroke style to use.
	 * @type {ConvertedStrokeStyle}
	 */
	get strokeStyle(): GraphicsContext["strokeStyle"];
	set strokeStyle(value: StrokeStyle);
	/**
	 * Creates a new Graphics object.
	 * Note that only the context of the object is cloned, not its transform (position,scale,etc)
	 * @param deep - Whether to create a deep clone of the graphics object. If false, the context
	 * will be shared between the two objects (default false). If true, the context will be
	 * cloned (recommended if you need to modify the context in any way).
	 * @returns - A clone of the graphics object
	 */
	clone(deep?: boolean): Graphics;
	/**
	 * @param width
	 * @param color
	 * @param alpha
	 * @deprecated since 8.0.0 Use {@link Graphics#setStrokeStyle} instead
	 */
	lineStyle(width?: number, color?: ColorSource, alpha?: number): this;
	/**
	 * @param color
	 * @param alpha
	 * @deprecated since 8.0.0 Use {@link Graphics#fill} instead
	 */
	beginFill(color: ColorSource, alpha?: number): this;
	/**
	 * @deprecated since 8.0.0 Use {@link Graphics#fill} instead
	 */
	endFill(): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#circle} instead
	 */
	drawCircle(...args: Parameters<GraphicsContext["circle"]>): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#ellipse} instead
	 */
	drawEllipse(...args: Parameters<GraphicsContext["ellipse"]>): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#poly} instead
	 */
	drawPolygon(...args: Parameters<GraphicsContext["poly"]>): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#rect} instead
	 */
	drawRect(...args: Parameters<GraphicsContext["rect"]>): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#roundRect} instead
	 */
	drawRoundedRect(...args: Parameters<GraphicsContext["roundRect"]>): this;
	/**
	 * @param {...any} args
	 * @deprecated since 8.0.0 Use {@link Graphics#star} instead
	 */
	drawStar(...args: Parameters<GraphicsContext["star"]>): this;
}
/**
 * A batchable graphics object.
 * @ignore
 */
export declare class BatchableGraphics implements DefaultBatchableMeshElement {
	readonly packAsQuad = false;
	batcherName: string;
	texture: Texture;
	topology: Topology;
	renderable: Graphics;
	indexOffset: number;
	indexSize: number;
	attributeOffset: number;
	attributeSize: number;
	baseColor: number;
	alpha: number;
	applyTransform: boolean;
	roundPixels: 0 | 1;
	_indexStart: number;
	_textureId: number;
	_attributeStart: number;
	_batcher: Batcher;
	_batch: Batch;
	geometryData: {
		vertices: number[];
		uvs: number[];
		indices: number[];
	};
	get uvs(): number[];
	get positions(): number[];
	get indices(): number[];
	get blendMode(): BLEND_MODES;
	get color(): number;
	get transform(): Matrix;
	copyTo(gpuBuffer: BatchableGraphics): void;
	reset(): void;
}
interface GeometryData {
	vertices: number[];
	uvs: number[];
	indices: number[];
}
/**
 * A class that holds batchable graphics data for a GraphicsContext.
 * @memberof rendering
 * @ignore
 */
export declare class GpuGraphicsContext {
	isBatchable: boolean;
	context: GraphicsContext;
	batches: BatchableGraphics[];
	geometryData: GeometryData;
	graphicsData: GraphicsContextRenderData;
}
/**
 * A class that holds the render data for a GraphicsContext.
 * @memberof rendering
 * @ignore
 */
export declare class GraphicsContextRenderData {
	batcher: Batcher;
	instructions: InstructionSet;
	init(): void;
	/**
	 * @deprecated since version 8.0.0
	 * Use \`batcher.geometry\` instead.
	 * @see {Batcher#geometry}
	 */
	get geometry(): Geometry;
}
/**
 * Options for the GraphicsContextSystem.
 * @memberof rendering
 */
export interface GraphicsContextSystemOptions {
	/** A value from 0 to 1 that controls the smoothness of bezier curves (the higher the smoother) */
	bezierSmoothness?: number;
}
/**
 * A system that manages the rendering of GraphicsContexts.
 * @memberof rendering
 */
export declare class GraphicsContextSystem implements System<GraphicsContextSystemOptions> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "graphicsContext";
	};
	/** The default options for the GraphicsContextSystem. */
	static readonly defaultOptions: GraphicsContextSystemOptions;
	private _gpuContextHash;
	private _graphicsDataContextHash;
	constructor(renderer: Renderer);
	/**
	 * Runner init called, update the default options
	 * @ignore
	 */
	init(options?: GraphicsContextSystemOptions): void;
	getContextRenderData(context: GraphicsContext): GraphicsContextRenderData;
	updateGpuContext(context: GraphicsContext): GpuGraphicsContext;
	getGpuContext(context: GraphicsContext): GpuGraphicsContext;
	private _initContextRenderData;
	private _initContext;
	protected onGraphicsContextDestroy(context: GraphicsContext): void;
	private _cleanGraphicsContextData;
	destroy(): void;
}
export interface GraphicsAdaptor {
	shader: Shader;
	init(): void;
	execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
	destroy(): void;
}
export interface GraphicsSystem {
	graphicsContext: GraphicsContextSystem;
	renderableGC: RenderableGCSystem;
	renderPipes: {
		batch: BatchPipe;
	};
	_roundPixels: 0 | 1;
}
export declare class GraphicsPipe implements RenderPipe<Graphics> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "graphics";
	};
	renderer: GraphicsSystem;
	state: State;
	private _graphicsBatchesHash;
	private _adaptor;
	private readonly _destroyRenderableBound;
	constructor(renderer: GraphicsSystem, adaptor: GraphicsAdaptor);
	validateRenderable(graphics: Graphics): boolean;
	addRenderable(graphics: Graphics, instructionSet: InstructionSet): void;
	updateRenderable(graphics: Graphics): void;
	destroyRenderable(graphics: Graphics): void;
	execute(graphics: Graphics): void;
	private _rebuild;
	private _addToBatcher;
	private _getBatchesForRenderable;
	private _initBatchesForRenderable;
	private _removeBatchForRenderable;
	destroy(): void;
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			graphicsContext: GraphicsContextSystem;
		}
		interface RendererPipes {
			graphics: GraphicsPipe;
		}
		interface RendererOptions {
			/**
			 * A value from 0 to 1 that controls the smoothness of bezier curves (the higher the smoother)
			 * @default 0.5
			 */
			bezierSmoothness: number;
		}
	}
}
/**
 * Options for the mesh geometry.
 * @memberof scene
 */
export interface MeshGeometryOptions {
	/** The positions of the mesh. */
	positions?: Float32Array;
	/** The UVs of the mesh. If not provided, they will be filled with 0 and match the size of the positions. */
	uvs?: Float32Array;
	/** The indices of the mesh. */
	indices?: Uint32Array;
	/** The topology of the mesh. */
	topology?: Topology;
	/** Whether to shrink the buffers to fit the data. */
	shrinkBuffersToFit?: boolean;
}
/**
 * A geometry used to batch multiple meshes with the same texture.
 * @memberof scene
 */
export declare class MeshGeometry extends Geometry {
	static defaultOptions: MeshGeometryOptions;
	batchMode: BatchMode;
	/**
	 * @param {scene.MeshGeometryOptions} options - The options of the mesh geometry.
	 */
	constructor(options: MeshGeometryOptions);
	/** @deprecated since 8.0.0 */
	constructor(positions: Float32Array, uvs: Float32Array, indices: Uint32Array);
	/** The positions of the mesh. */
	get positions(): Float32Array;
	/**
	 * Set the positions of the mesh.
	 * When setting the positions, its important that the uvs array is at least as long as the positions array.
	 * otherwise the geometry will not be valid.
	 * @param {Float32Array} value - The positions of the mesh.
	 */
	set positions(value: Float32Array);
	/** The UVs of the mesh. */
	get uvs(): Float32Array;
	/**
	 * Set the UVs of the mesh.
	 * Its important that the uvs array you set is at least as long as the positions array.
	 * otherwise the geometry will not be valid.
	 * @param {Float32Array} value - The UVs of the mesh.
	 */
	set uvs(value: Float32Array);
	/** The indices of the mesh. */
	get indices(): Uint32Array;
	set indices(value: Uint32Array);
}
/**
 * Does exactly the same as getGlobalBounds, but does instead makes use of transforming AABBs
 * of the various children within the scene graph. This is much faster, but less accurate.
 *
 * Deprecated, use container.getFastGlobalBounds() instead.
 *
 * the result will never be smaller - only ever slightly larger (in most cases, it will be the same).
 * @param target - The target container to get the bounds from
 * @param bounds - The output bounds object.
 * @returns The bounds.
 * @deprecated since 8.7.0
 * @see container.getFastGlobalBounds
 */
export declare function getFastGlobalBounds(target: Container, bounds: Bounds): Bounds;
export declare function getGlobalBounds(target: Container, skipUpdateTransform: boolean, bounds: Bounds): Bounds;
export declare function _getGlobalBounds(target: Container, bounds: Bounds, parentTransform: Matrix, skipUpdateTransform: boolean): void;
export declare function updateTransformBackwards(target: Container, parentTransform: Matrix): Matrix;
export declare function getLocalBounds(target: Container, bounds: Bounds, relativeMatrix?: Matrix): Bounds;
export declare function getParent(target: Container, root: Container, matrix: Matrix): void;
export declare function getGlobalRenderableBounds(renderables: Renderable[], bounds: Bounds): Bounds;
type MatrixPoolItem = Matrix & PoolItem;
type BoundsPoolItem = Bounds & PoolItem;
export declare const matrixPool: Pool<MatrixPoolItem>;
export declare const boundsPool: Pool<BoundsPoolItem>;
export interface CacheAsTextureMixinConstructor {
	cacheAsTexture?: (val: boolean | CacheAsTextureOptions) => void;
}
export interface CacheAsTextureMixin extends Required<CacheAsTextureMixinConstructor> {
	/**
	 * Caches this container as a texture. This allows the container to be rendered as a single texture,
	 * which can improve performance for complex static containers.
	 * @param val - If true, enables caching with default options. If false, disables caching.
	 * Can also pass options object to configure caching behavior.
	 * @memberof scene.Container#
	 */
	cacheAsTexture: (val: boolean | CacheAsTextureOptions) => void;
	/**
	 * Updates the cached texture of this container. This will flag the container's cached texture
	 * to be redrawn on the next render.
	 * @memberof scene.Container#
	 */
	updateCacheTexture: () => void;
	/**
	 * Legacy property for backwards compatibility with PixiJS v7 and below.
	 * Use \`cacheAsTexture\` instead.
	 * @deprecated Since PixiJS v8
	 * @memberof scene.Container#
	 */
	cacheAsBitmap: boolean;
	/**
	 * Whether this container is currently cached as a texture.
	 * @readonly
	 * @memberof scene.Container#
	 */
	readonly isCachedAsTexture: boolean;
}
export declare const cacheAsTextureMixin: Partial<Container>;
export interface ChildrenHelperMixin<C = ContainerChild> {
	allowChildren: boolean;
	addChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
	removeChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
	removeChildren(beginIndex?: number, endIndex?: number): C[];
	removeChildAt<U extends (C | IRenderLayer)>(index: number): U;
	getChildAt<U extends (C | IRenderLayer)>(index: number): U;
	setChildIndex(child: C | IRenderLayer, index: number): void;
	getChildIndex(child: C | IRenderLayer): number;
	addChildAt<U extends (C | IRenderLayer)>(child: U, index: number): U;
	swapChildren<U extends (C | IRenderLayer)>(child: U, child2: U): void;
	removeFromParent(): void;
	reparentChild<U extends C[]>(...child: U): U[0];
	reparentChildAt<U extends C>(child: U, index: number): U;
}
export declare const childrenHelperMixin: ChildrenHelperMixin<ContainerChild>;
/**
 * The CollectRenderablesMixin interface defines methods for collecting renderable objects
 * from a container and its children. These methods add the renderables to an instruction set,
 * which is used by the renderer to process and display the scene.
 */
export interface CollectRenderablesMixin {
	/**
	 * Collects all renderables from the container and its children, adding them to the instruction set.
	 * This method decides whether to use a simple or advanced collection method based on the container's properties.
	 * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
	 * @param {Renderer} renderer - The renderer responsible for rendering the scene.
	 * @param {IRenderLayer} currentLayer - The current render layer being processed.
	 * @memberof scene.Container#
	 */
	collectRenderables(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
	/**
	 * Collects renderables using a simple method, suitable for containers marked as simple.
	 * This method iterates over the container's children and adds their renderables to the instruction set.
	 * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
	 * @param {Renderer} renderer - The renderer responsible for rendering the scene.
	 * @param {IRenderLayer} currentLayer - The current render layer being processed.
	 * @memberof scene.Container#
	 */
	collectRenderablesSimple(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
	/**
	 * Collects renderables using an advanced method, suitable for containers with complex processing needs.
	 * This method handles additional effects and transformations that may be applied to the renderables.
	 * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
	 * @param {Renderer} renderer - The renderer responsible for rendering the scene.
	 * @param {IRenderLayer} currentLayer - The current render layer being processed.
	 * @memberof scene.Container#
	 */
	collectRenderablesWithEffects(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
}
/**
 * The collectRenderablesMixin provides implementations for the methods defined in the CollectRenderablesMixin interface.
 * It includes logic to determine the appropriate method for collecting renderables based on the container's properties.
 */
export declare const collectRenderablesMixin: Partial<Container>;
export interface EffectsMixinConstructor {
	mask?: Mask;
	setMask?: (options: Partial<MaskOptionsAndMask>) => void;
	filters?: Filter | Filter[];
}
export type Mask = number | Container | null;
export interface MaskOptions {
	inverse: boolean;
}
export interface MaskOptionsAndMask extends MaskOptions {
	mask: Mask;
}
export interface EffectsMixin extends Required<EffectsMixinConstructor> {
	_maskEffect?: MaskEffect;
	_maskOptions?: MaskOptions;
	_filterEffect?: FilterEffect;
	filterArea?: Rectangle;
	effects?: Effect[];
	_markStructureAsChanged(): void;
	addEffect(effect: Effect): void;
	removeEffect(effect: Effect): void;
}
export declare const effectsMixin: Partial<Container>;
export interface FindMixinConstructor {
	label?: string;
}
export interface FindMixin extends Required<FindMixinConstructor> {
	/**
	 * @deprecated since 8.0.0
	 * @see Container#label
	 */
	name: string;
	getChildByName(label: RegExp | string, deep?: boolean): Container | null;
	getChildByLabel(label: RegExp | string, deep?: boolean): Container | null;
	getChildrenByLabel(label: RegExp | string, deep?: boolean, out?: Container[]): Container[];
}
export declare const findMixin: Partial<Container>;
/**
 * Interface for the GetFastGlobalBoundsMixin, which provides methods to compute
 * an approximate global bounding box for a container and its children.
 */
export interface GetFastGlobalBoundsMixin {
	/**
	 * Computes an approximate global bounding box for the container and its children.
	 * This method is optimized for speed by using axis-aligned bounding boxes (AABBs),
	 * and uses the last render results from when it updated the transforms. This function does not update them.
	 * which may result in slightly larger bounds but never smaller than the actual bounds.
	 *
	 * for accurate (but less performant) results use \`container.getGlobalBounds\`
	 * @param {boolean} [factorRenderLayers] - A flag indicating whether to consider render layers in the calculation.
	 * @param {Bounds} [bounds] - The output bounds object to store the result. If not provided, a new one is created.
	 * @returns {Bounds} The computed bounds.
	 * @memberof scene.Container#
	 */
	getFastGlobalBounds(factorRenderLayers?: boolean, bounds?: Bounds): Bounds;
	/**
	 * Recursively calculates the global bounds for the container and its children.
	 * This method is used internally by getFastGlobalBounds to traverse the scene graph.
	 * @param {boolean} factorRenderLayers - A flag indicating whether to consider render layers in the calculation.
	 * @param {Bounds} bounds - The bounds object to update with the calculated values.
	 * @param {IRenderLayer} currentLayer - The current render layer being processed.
	 * @memberof scene.Container#
	 */
	_getGlobalBoundsRecursive(factorRenderLayers: boolean, bounds: Bounds, currentLayer: IRenderLayer): void;
}
/**
 * Mixin providing the implementation of the GetFastGlobalBoundsMixin interface.
 * It includes methods to compute and recursively calculate global bounds for containers.
 */
export declare const getFastGlobalBoundsMixin: Partial<Container>;
export declare function bgr2rgb(color: number): number;
export interface GetGlobalMixin {
	getGlobalAlpha(skipUpdate: boolean): number;
	getGlobalTransform(matrix: Matrix, skipUpdate: boolean): Matrix;
	getGlobalTint(skipUpdate?: boolean): number;
}
export declare const getGlobalMixin: Partial<Container>;
export interface OnRenderMixinConstructor {
	onRender?: ((renderer: Renderer) => void | null);
}
export interface OnRenderMixin extends Required<OnRenderMixinConstructor> {
	_onRender: ((renderer: Renderer) => void) | null;
}
export declare const onRenderMixin: Partial<Container>;
export interface SortMixinConstructor {
	zIndex?: number;
	sortDirty?: boolean;
	sortableChildren?: boolean;
}
export interface SortMixin extends Required<SortMixinConstructor> {
	_zIndex: number;
	sortChildren: () => void;
	depthOfChildModified: () => void;
}
export declare const sortMixin: Partial<Container>;
export interface ToLocalGlobalMixin {
	getGlobalPosition(point?: Point, skipUpdate?: boolean): Point;
	toGlobal<P extends PointData = Point>(position: PointData, point?: P, skipUpdate?: boolean): P;
	toLocal<P extends PointData = Point>(position: PointData, from?: Container, point?: P, skipUpdate?: boolean): P;
}
export declare const toLocalGlobalMixin: Partial<Container>;
/**
 * Assigns properties from one object to another, using an optional array of property names to ignore.
 * @param target - The target object to assign properties to.
 * @param options - The object to assign properties from.
 * @param ignore - An object of property names to ignore ({ propToIgnore: true }).
 */
export declare function assignWithIgnore<T extends Record<string, any>>(target: T, options: T, ignore?: Record<string, boolean>): void;
/**
 * This function will crawl through the container essentially check if the children have changed.
 *
 * This function checkChildrenDidChange recursively checks if any child in a Container
 * or its children has changed. It does this by comparing a generated changeId for each
 * child against a stored value in previousData.
 * The changeId is a combination of the child's uid and _didChangeId, bitwise manipulated for uniqueness.
 * If a change is detected, it updates previousData and sets didChange to true.
 * The function returns a boolean indicating if any change was detected in the entire hierarchy of children.
 * @param container - the container to check for changes
 * @param previousData - the previous data from the last check made
 * @param previousData.data - the data array
 * @param previousData.index - the index of the data array
 * @param previousData.didChange - did the data change
 */
export declare function checkChildrenDidChange(container: Container, previousData: {
	data: number[];
	index: number;
	didChange: boolean;
}): boolean;
/**
 * nulls all slots in an array from a certain index.
 * assume that when a null item is hit, the rest are also null.
 * Which will be the case for where this is used!
 * @param list - the array to clean
 * @param index - the index to start from
 */
export declare function clearList(list: Array<unknown>, index?: number): void;
/**
 * Deprecated, please use container.collectRenderables instead.
 * @param container - The container to collect renderables from.
 * @param instructionSet - The instruction set to add the renderables to.
 * @param rendererOrPipes - The renderer to collect the renderables from.
 * @deprecated since version 8.7.0
 * @see container.collectRenderables
 */
export declare function collectAllRenderables(container: Container, instructionSet: InstructionSet, rendererOrPipes: Renderer | RenderPipes): void;
/**
 * Returns a new object with all properties from the input object that have defined values.
 * @template T - The type of the input object.
 * @param {T} obj - The input object.
 * @returns {T} - A new object with only the defined properties from the input object.
 * @memberof utils
 * @ignore
 */
export declare function definedProps<T extends Record<string, any>>(obj: T): T;
export declare function executeInstructions(renderGroup: RenderGroup, renderer: RenderPipes): void;
export declare function mixHexColors(color1: number, color2: number, ratio: number): number;
export declare function multiplyColors(localBGRColor: number, parentBGRColor: number): number;
export declare function multiplyHexColors(color1: number, color2: number): number;
export declare function updateLocalTransform(lt: Matrix, container: Container): void;
export declare function updateRenderGroupTransforms(renderGroup: RenderGroup, updateChildRenderGroups?: boolean): void;
export declare function updateRenderGroupTransform(renderGroup: RenderGroup): void;
export declare function updateTransformAndChildren(container: Container, updateTick: number, updateFlags: number): void;
export declare function updateWorldTransform(local: Matrix, parent: Matrix, world: Matrix): void;
export declare function validateRenderables(renderGroup: RenderGroup, renderPipes: RenderPipes): boolean;
/**
 * A GraphicsAdaptor that uses WebGL to render graphics.
 * @memberof rendering
 * @ignore
 */
export declare class GlGraphicsAdaptor implements GraphicsAdaptor {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipesAdaptor
		];
		readonly name: "graphics";
	};
	shader: Shader;
	init(): void;
	execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
	destroy(): void;
}
export declare function colorToUniform(rgb: number, alpha: number, out: Float32Array, offset: number): void;
export declare function color32BitToUniform(abgr: number, out: Float32Array, offset: number): void;
/**
 * A GraphicsAdaptor that uses the GPU to render graphics.
 * @memberof rendering
 * @ignore
 */
export declare class GpuGraphicsAdaptor implements GraphicsAdaptor {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUPipesAdaptor
		];
		readonly name: "graphics";
	};
	shader: Shader;
	init(): void;
	execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
	destroy(): void;
}
export declare function buildAdaptiveBezier(points: number[], sX: number, sY: number, cp1x: number, cp1y: number, cp2x: number, cp2y: number, eX: number, eY: number, smoothness?: number): number[];
export declare function buildAdaptiveQuadratic(points: number[], sX: number, sY: number, cp1x: number, cp1y: number, eX: number, eY: number, smoothness?: number): number[];
export declare function buildArc(points: number[], x: number, y: number, radius: number, start: number, end: number, clockwise: boolean, steps?: number): void;
/**
 * The arcTo() method creates an arc/curve between two tangents on the canvas.
 *
 * "borrowed" from https://code.google.com/p/fxcanvas/ - thanks google!
 * @param points
 * @param x1
 * @param y1
 * @param x2
 * @param y2
 * @param radius
 */
export declare function buildArcTo(points: number[], x1: number, y1: number, x2: number, y2: number, radius: number): void;
export declare function buildArcToSvg(points: number[], px: number, py: number, cx: number, cy: number, rx: number, ry: number, xAxisRotation?: number, largeArcFlag?: number, sweepFlag?: number): void;
/**
 * The Circle object is used to help draw graphics and can also be used to specify a hit area for containers.
 * @memberof maths
 */
export declare class Circle implements ShapePrimitive {
	/**
	 * The X coordinate of the center of this circle
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coordinate of the center of this circle
	 * @default 0
	 */
	y: number;
	/**
	 * The radius of the circle
	 *  @default 0
	 */
	radius: number;
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'circle'
	 */
	readonly type: SHAPE_PRIMITIVE;
	/**
	 * @param x - The X coordinate of the center of this circle
	 * @param y - The Y coordinate of the center of this circle
	 * @param radius - The radius of the circle
	 */
	constructor(x?: number, y?: number, radius?: number);
	/**
	 * Creates a clone of this Circle instance
	 * @returns A copy of the Circle
	 */
	clone(): Circle;
	/**
	 * Checks whether the x and y coordinates given are contained within this circle
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @returns Whether the x/y coordinates are within this Circle
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this circle including the stroke.
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @param width - The width of the line to check
	 * @param alignment - The alignment of the stroke, 0.5 by default
	 * @returns Whether the x/y coordinates are within this Circle
	 */
	strokeContains(x: number, y: number, width: number, alignment?: number): boolean;
	/**
	 * Returns the framing rectangle of the circle as a Rectangle object
	 * @param out
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	/**
	 * Copies another circle to this one.
	 * @param circle - The circle to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(circle: Circle): this;
	/**
	 * Copies this circle to another one.
	 * @param circle - The circle to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(circle: Circle): Circle;
	toString(): string;
}
/**
 * The Ellipse object is used to help draw graphics and can also be used to specify a hit area for containers.
 * \`\`\`js
 * import { Ellipse } from 'pixi.js';
 *
 * const ellipse = new Ellipse(0, 0, 20, 10); // 40x20 rectangle
 * const isPointInEllipse = ellipse.contains(0, 0); // true
 * \`\`\`
 * @memberof maths
 */
export declare class Ellipse implements ShapePrimitive {
	/**
	 * The X coordinate of the center of this ellipse
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coordinate of the center of this ellipse
	 * @default 0
	 */
	y: number;
	/**
	 * The half width of this ellipse
	 * @default 0
	 */
	halfWidth: number;
	/**
	 * The half height of this ellipse
	 * @default 0
	 */
	halfHeight: number;
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'ellipse'
	 */
	readonly type = "ellipse";
	/**
	 * @param x - The X coordinate of the center of this ellipse
	 * @param y - The Y coordinate of the center of this ellipse
	 * @param halfWidth - The half width of this ellipse
	 * @param halfHeight - The half height of this ellipse
	 */
	constructor(x?: number, y?: number, halfWidth?: number, halfHeight?: number);
	/**
	 * Creates a clone of this Ellipse instance
	 * @returns {Ellipse} A copy of the ellipse
	 */
	clone(): Ellipse;
	/**
	 * Checks whether the x and y coordinates given are contained within this ellipse
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @returns Whether the x/y coords are within this ellipse
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this ellipse including stroke
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param alignment - The alignment of the stroke
	 * @returns Whether the x/y coords are within this ellipse
	 */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/**
	 * Returns the framing rectangle of the ellipse as a Rectangle object
	 * @param out
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	/**
	 * Copies another ellipse to this one.
	 * @param ellipse - The ellipse to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(ellipse: Ellipse): this;
	/**
	 * Copies this ellipse to another one.
	 * @param ellipse - The ellipse to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(ellipse: Ellipse): Ellipse;
	toString(): string;
}
/**
 * The \`RoundedRectangle\` object is an area defined by its position, as indicated by its top-left corner
 * point (\`x\`, \`y\`) and by its \`width\` and its \`height\`, including a \`radius\` property that
 * defines the radius of the rounded corners.
 * @memberof maths
 */
export declare class RoundedRectangle implements ShapePrimitive {
	/**
	 * The X coordinate of the upper-left corner of the rounded rectangle
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coordinate of the upper-left corner of the rounded rectangle
	 * @default 0
	 */
	y: number;
	/**
	 * The overall width of this rounded rectangle
	 * @default 0
	 */
	width: number;
	/**
	 * The overall height of this rounded rectangle
	 * @default 0
	 */
	height: number;
	/**
	 * Controls the radius of the rounded corners
	 * @default 20
	 */
	radius: number;
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'roundedRectangle'
	 */
	readonly type = "roundedRectangle";
	/**
	 * @param x - The X coordinate of the upper-left corner of the rounded rectangle
	 * @param y - The Y coordinate of the upper-left corner of the rounded rectangle
	 * @param width - The overall width of this rounded rectangle
	 * @param height - The overall height of this rounded rectangle
	 * @param radius - Controls the radius of the rounded corners
	 */
	constructor(x?: number, y?: number, width?: number, height?: number, radius?: number);
	/**
	 * Returns the framing rectangle of the rounded rectangle as a Rectangle object
	 * @param out - optional rectangle to store the result
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	/**
	 * Creates a clone of this Rounded Rectangle.
	 * @returns - A copy of the rounded rectangle.
	 */
	clone(): RoundedRectangle;
	/**
	 * Copies another rectangle to this one.
	 * @param rectangle - The rectangle to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(rectangle: RoundedRectangle): this;
	/**
	 * Copies this rectangle to another one.
	 * @param rectangle - The rectangle to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(rectangle: RoundedRectangle): RoundedRectangle;
	/**
	 * Checks whether the x and y coordinates given are contained within this Rounded Rectangle
	 * @param x - The X coordinate of the point to test.
	 * @param y - The Y coordinate of the point to test.
	 * @returns - Whether the x/y coordinates are within this Rounded Rectangle.
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this rectangle including the stroke.
	 * @param pX - The X coordinate of the point to test
	 * @param pY - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param alignment - The alignment of the stroke, 0.5 by default
	 * @returns Whether the x/y coordinates are within this rectangle
	 */
	strokeContains(pX: number, pY: number, strokeWidth: number, alignment?: number): boolean;
	toString(): string;
}
export interface ShapeBuildCommand<T extends ShapePrimitive = ShapePrimitive> {
	extension: ExtensionMetadataDetails;
	build(shape: T, points: number[]): void;
	triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
}
type RoundedShape = Circle | Ellipse | RoundedRectangle;
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildCircle: ShapeBuildCommand<RoundedShape>;
export declare const buildEllipse: {
	extension: {
		name: string;
		type: ExtensionType | ExtensionType[];
		priority?: number;
	};
	build(shape: RoundedShape, points: number[]): void;
	triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
};
export declare const buildRoundedRectangle: {
	extension: {
		name: string;
		type: ExtensionType | ExtensionType[];
		priority?: number;
	};
	build(shape: RoundedShape, points: number[]): void;
	triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
};
/**
 * Builds a line to draw using the polygon method.
 * @param points
 * @param lineStyle
 * @param flipAlignment
 * @param closed
 * @param vertices
 * @param indices
 */
export declare function buildLine(points: number[], lineStyle: StrokeAttributes, flipAlignment: boolean, closed: boolean, vertices: number[], indices: number[]): void;
/**
 * Builds a line to draw using the polygon method.
 * @param points
 * @param closed
 * @param vertices
 * @param indices
 */
export declare function buildPixelLine(points: number[], closed: boolean, vertices: number[], indices: number[]): void;
/**
 * A class to define a shape via user defined coordinates.
 *
 *
 * \`Polygon\` can accept the following different constructor arguments:
 * - An array of \`Point\` objects
 * - An array of coordinate pairs
 *
 *
 * These can be passed as a single array, or as a sequence of arguments.
 * \`\`\`js
 * import { Polygon } from 'pixi.js';
 *
 * // create a polygon object from an array of points, or an array of coordinate pairs
 * const polygon1 = new Polygon([ new Point(0, 0), new Point(0, 100), new Point(100, 100) ]);
 * const polygon2 = new Polygon([ 0, 0, 0, 100, 100, 100 ]);
 *
 * // or create a polygon object from a sequence of points, or coordinate pairs
 * const polygon3 = new Polygon(new Point(0, 0), new Point(0, 100), new Point(100, 100));
 * const polygon4 = new Polygon(0, 0, 0, 100, 100, 100);
 * \`\`\`
 * @memberof maths
 */
export declare class Polygon implements ShapePrimitive {
	/** An array of the points of this polygon. */
	points: number[];
	/** \`false\` after moveTo, \`true\` after \`closePath\`. In all other cases it is \`true\`. */
	closePath: boolean;
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'polygon'
	 */
	readonly type: SHAPE_PRIMITIVE;
	constructor(points: PointData[] | number[]);
	constructor(...points: PointData[] | number[]);
	/**
	 * Determines whether the polygon's points are arranged in a clockwise direction.
	 * This is calculated using the "shoelace formula" (also known as surveyor's formula) to find the signed area.
	 * A positive area indicates clockwise winding, while negative indicates counter-clockwise.
	 *
	 * The formula sums up the cross products of adjacent vertices:
	 * For each pair of adjacent points (x1,y1) and (x2,y2), we calculate (x1*y2 - x2*y1)
	 * The final sum divided by 2 gives the signed area - positive for clockwise.
	 * @returns \`true\` if the polygon's points are arranged clockwise, \`false\` if counter-clockwise
	 */
	isClockwise(): boolean;
	/**
	 * Checks if this polygon completely contains another polygon.
	 *
	 * This is useful for detecting holes in shapes, like when parsing SVG paths.
	 * For example, if you have two polygons:
	 * \`\`\`ts
	 * const outerSquare = new Polygon([0,0, 100,0, 100,100, 0,100]); // A square
	 * const innerSquare = new Polygon([25,25, 75,25, 75,75, 25,75]); // A smaller square inside
	 *
	 * outerSquare.containsPolygon(innerSquare); // Returns true
	 * innerSquare.containsPolygon(outerSquare); // Returns false
	 * \`\`\`
	 * @param polygon - The polygon to test for containment
	 * @returns True if this polygon completely contains the other polygon
	 */
	containsPolygon(polygon: Polygon): boolean;
	/**
	 * Creates a clone of this polygon.
	 * @returns - A copy of the polygon.
	 */
	clone(): Polygon;
	/**
	 * Checks whether the x and y coordinates passed to this function are contained within this polygon.
	 * @param x - The X coordinate of the point to test.
	 * @param y - The Y coordinate of the point to test.
	 * @returns - Whether the x/y coordinates are within this polygon.
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this polygon including the stroke.
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param alignment - The alignment of the stroke, 0.5 by default
	 * @returns Whether the x/y coordinates are within this polygon
	 */
	strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
	/**
	 * Returns the framing rectangle of the polygon as a Rectangle object
	 * @param out - optional rectangle to store the result
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
	/**
	 * Copies another polygon to this one.
	 * @param polygon - The polygon to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(polygon: Polygon): this;
	/**
	 * Copies this polygon to another one.
	 * @param polygon - The polygon to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(polygon: Polygon): Polygon;
	toString(): string;
	/**
	 * Get the last X coordinate of the polygon
	 * @readonly
	 */
	get lastX(): number;
	/**
	 * Get the last Y coordinate of the polygon
	 * @readonly
	 */
	get lastY(): number;
	/**
	 * Get the first X coordinate of the polygon
	 * @readonly
	 */
	get x(): number;
	/**
	 * Get the first Y coordinate of the polygon
	 * @readonly
	 */
	get y(): number;
}
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildPolygon: ShapeBuildCommand<Polygon>;
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildRectangle: ShapeBuildCommand<Rectangle>;
/**
 * A class to define a shape of a triangle via user defined coordinates.
 *
 * Create a \`Triangle\` object with the \`x\`, \`y\`, \`x2\`, \`y2\`, \`x3\`, \`y3\` properties.
 *
 * \`\`\`js
 * import { Triangle } from 'pixi.js';
 *
 * const triangle = new Triangle(0, 0, 100, 0, 50, 50);
 * \`\`\`
 * @memberof maths
 */
export declare class Triangle implements ShapePrimitive {
	/**
	 * The type of the object, mainly used to avoid \`instanceof\` checks
	 * @default 'triangle'
	 */
	readonly type: SHAPE_PRIMITIVE;
	/**
	 * The X coord of the first point.
	 * @default 0
	 */
	x: number;
	/**
	 * The Y coord of the first point.
	 * @default 0
	 */
	y: number;
	/**
	 * The X coord of the second point.
	 * @default 0
	 */
	x2: number;
	/**
	 * The Y coord of the second point.
	 * @default 0
	 */
	y2: number;
	/**
	 * The X coord of the third point.
	 * @default 0
	 */
	x3: number;
	/**
	 * The Y coord of the third point.
	 * @default 0
	 */
	y3: number;
	/**
	 * @param x - The X coord of the first point.
	 * @param y - The Y coord of the first point.
	 * @param x2 - The X coord of the second point.
	 * @param y2 - The Y coord of the second point.
	 * @param x3 - The X coord of the third point.
	 * @param y3 - The Y coord of the third point.
	 */
	constructor(x?: number, y?: number, x2?: number, y2?: number, x3?: number, y3?: number);
	/**
	 * Checks whether the x and y coordinates given are contained within this triangle
	 * @param x - The X coordinate of the point to test
	 * @param y - The Y coordinate of the point to test
	 * @returns Whether the x/y coordinates are within this Triangle
	 */
	contains(x: number, y: number): boolean;
	/**
	 * Checks whether the x and y coordinates given are contained within this triangle including the stroke.
	 * @param pointX - The X coordinate of the point to test
	 * @param pointY - The Y coordinate of the point to test
	 * @param strokeWidth - The width of the line to check
	 * @param _alignment - The alignment of the stroke
	 * @returns Whether the x/y coordinates are within this triangle
	 */
	strokeContains(pointX: number, pointY: number, strokeWidth: number, _alignment?: number): boolean;
	/**
	 * Creates a clone of this Triangle
	 * @returns a copy of the triangle
	 */
	clone(): ShapePrimitive;
	/**
	 * Copies another triangle to this one.
	 * @param triangle - The triangle to copy from.
	 * @returns Returns itself.
	 */
	copyFrom(triangle: Triangle): this;
	/**
	 * Copies this triangle to another one.
	 * @param triangle - The triangle to copy to.
	 * @returns Returns given parameter.
	 */
	copyTo(triangle: Triangle): Triangle;
	/**
	 * Returns the framing rectangle of the triangle as a Rectangle object
	 * @param out - optional rectangle to store the result
	 * @returns The framing rectangle
	 */
	getBounds(out?: Rectangle): Rectangle;
}
/**
 * Builds a triangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildTriangle: ShapeBuildCommand<Triangle>;
/** Represents a session for SVG parsing. Contains the current state and resources needed during parsing. */
export interface Session {
	/** The graphics context to render to */
	context: GraphicsContext;
	/** The current path being constructed */
	path: GraphicsPath;
	/** Map of definitions by id */
	defs: Record<string, FillGradient>;
}
/**
 * Parses an SVG element or string and renders it to a graphics context.
 * Handles both SVG strings and SVG DOM elements as input.
 * @param svg - The SVG content to parse, either as a string or element
 * @param graphicsContext - Optional graphics context to render to
 * @returns The graphics context with the SVG rendered into it
 */
export declare function SVGParser(svg: string | SVGElement | SVGSVGElement, graphicsContext?: GraphicsContext): GraphicsContext;
/**
 * Parses SVG gradient definitions and stores them in the session for later use.
 * Currently supports linear gradients and has placeholder support for radial gradients.
 * @param svg - The root SVG element to parse definitions from
 * @param session - The parsing session to store definitions in
 */
export declare function parseSVGDefinitions(svg: SVGElement, session: Session): void;
/**
 * Parses a float value from an SVG element's attribute.
 * This is commonly used for parsing numeric attributes like coordinates, dimensions,
 * and other measurements from SVG elements.
 * @param svg - The SVG element to get the attribute from
 * @param id - The name of the attribute to parse (e.g. 'x', 'y', 'width', etc)
 * @param defaultValue - The value to return if the attribute doesn't exist or can't be parsed
 * @returns The parsed float value, or the default value if parsing fails
 * @example
 * // For SVG: <rect x="10.5" width="20"/>
 * parseSVGFloatAttribute(rectElement, 'x', 0) // Returns 10.5
 * parseSVGFloatAttribute(rectElement, 'y', 0) // Returns 0 since y is not specified
 */
export declare function parseSVGFloatAttribute(svg: SVGElement, id: string, defaultValue: number): number;
/**
 * Parses an SVG path data string and builds a GraphicsPath object from the commands.
 * This function handles all standard SVG path commands including moves, lines, curves and arcs.
 * It maintains state for the current position and subpaths to properly handle relative commands
 * and path closures.
 *
 * Supported SVG commands:
 * - M/m: Move to absolute/relative
 * - L/l: Line to absolute/relative
 * - H/h: Horizontal line absolute/relative
 * - V/v: Vertical line absolute/relative
 * - C/c: Cubic bezier curve absolute/relative
 * - S/s: Smooth cubic bezier curve absolute/relative
 * - Q/q: Quadratic bezier curve absolute/relative
 * - T/t: Smooth quadratic bezier curve absolute/relative
 * - A/a: Arc absolute/relative
 * - Z/z: Close path
 * @param svgPath - The SVG path data string to parse (e.g. "M0,0 L100,100")
 * @param path - The GraphicsPath object to build the path into
 * @returns The input path object with the SVG commands applied
 */
export declare function parseSVGPath(svgPath: string, path: GraphicsPath): GraphicsPath;
/**
 * A map of SVG style attributes and their default values.
 * Each attribute has a type and default value used for SVG parsing.
 * - 'paint' type can be a color or gradient
 * - 'number' type is a numeric value
 * - 'string' type is a text value
 */
export declare const styleAttributes: {
	fill: {
		type: string;
		default: number;
	};
	"fill-opacity": {
		type: string;
		default: number;
	};
	stroke: {
		type: string;
		default: number;
	};
	"stroke-width": {
		type: string;
		default: number;
	};
	"stroke-opacity": {
		type: string;
		default: number;
	};
	"stroke-linecap": {
		type: string;
		default: string;
	};
	"stroke-linejoin": {
		type: string;
		default: string;
	};
	"stroke-miterlimit": {
		type: string;
		default: number;
	};
	"stroke-dasharray": {
		type: string;
		default: string;
	};
	"stroke-dashoffset": {
		type: string;
		default: number;
	};
	opacity: {
		type: string;
		default: number;
	};
};
/** Represents the result of parsing SVG style attributes */
export type StyleResult = {
	/** The stroke style properties */
	strokeStyle: StrokeStyle;
	/** The fill style properties */
	fillStyle: FillStyle;
	/** Whether fill should be applied */
	useFill: boolean;
	/** Whether stroke should be applied */
	useStroke: boolean;
};
/**
 * Parses SVG style attributes and inline styles to determine fill and stroke properties.
 * Handles both direct attributes and CSS-style declarations in the style attribute.
 * @param svg - The SVG element to parse styles from
 * @param session - The current SVG parsing session containing definitions
 * @returns An object containing the parsed fill and stroke styles
 */
export declare function parseSVGStyle(svg: SVGElement, session: Session): StyleResult;
/**
 * Parses a single SVG style attribute and updates the style result accordingly.
 * Handles color values, gradients, opacities and other style properties.
 * @param session - The current SVG parsing session containing definitions
 * @param result - The style result object to update
 * @param id - The attribute name/id to parse
 * @param value - The attribute value to parse
 */
export declare function parseAttribute(session: Session, result: StyleResult, id: string, value: string): void;
/**
 * Extracts the ID from an SVG url() reference.
 *
 * This function handles all valid SVG url() formats including:
 * - url(#id)
 * - url('#id')
 * - url("#id")
 * - url( #id )
 * - url( '#id' )
 * - url( "#id" )
 *
 * The regex pattern matches:
 * - url followed by optional whitespace
 * - opening parenthesis followed by optional whitespace
 * - optional single or double quotes with optional whitespace
 * - # followed by the ID (any chars except quotes, whitespace, or closing paren)
 * - optional single or double quotes with optional whitespace
 * - closing parenthesis
 * @param url - The SVG url() string to parse
 * @returns The extracted ID string, or empty string if no valid ID found
 */
export declare function extractSvgUrlId(url: string): string;
export declare const shapeBuilders: Record<string, ShapeBuildCommand>;
export declare function buildContextBatches(context: GraphicsContext, gpuContext: GpuGraphicsContext): void;
export interface GeometryPathOptions {
	/** the path to build the geometry from */
	path: GraphicsPath;
	/** a \`Matrix\` that can be used to modify the the texture UVs of the the path being built */
	textureMatrix?: Matrix;
	/** an optional \`MeshGeometry\` to write too instead of creating a new one*/
	out?: MeshGeometry;
}
/**
 * When building a mesh, it helps to leverage the simple API we have in \`GraphicsPath\` as it can often be easier to
 * to define the geometry in a more human readable way. This function takes a \`GraphicsPath\` and returns a \`MeshGeometry\`.
 * @example
 * \`\`\`ts
 *
 * const path = new GraphicsPath()
 *    .drawRect(0, 0, 100, 100)
 *
 * const geometry:MeshGeometry = buildGeometryFromPath(path);
 *
 * const mesh = new Mesh({geometry});
 *
 * \`\`\`
 * You can also pass in a Matrix to transform the uvs as by default you may want to control how they are set up.
 * @param options - either a \`GraphicsPath\` or \`GeometryPathOptions\`
 * @returns a new \`MeshGeometry\` instance build from the path
 */
export declare function buildGeometryFromPath(options: GraphicsPath | GeometryPathOptions): MeshGeometry;
/**
 * Converts a value to a fill style, we do this as PixiJS has a number of ways to define a fill style
 * They can be a direct color, a texture, a gradient, or an object with these values in them
 * This function will take any of these input types and convert them into a single object
 * that PixiJS can understand and use internally.
 * @param value - The value to convert to a fill style
 * @param defaultStyle - The default fill style to use
 * @private
 */
export declare function toFillStyle<T extends FillInput>(value: T, defaultStyle: ConvertedFillStyle): ConvertedFillStyle;
/**
 * Converts a value to a stroke style, similar to \`toFillStyle\` but for strokes
 * @param value - The value to convert to a stroke style
 * @param defaultStyle - The default stroke style to use
 * @private
 */
export declare function toStrokeStyle(value: StrokeInput, defaultStyle: ConvertedStrokeStyle): ConvertedStrokeStyle;
/**
 * Generates a texture matrix for mapping textures onto shapes.
 * This function handles both local and global texture space mapping.
 *
 * In local space, the texture is mapped to fit exactly within the bounds of the shape.
 * In global space, the texture is mapped using its own dimensions and position.
 * @param out - The matrix to store the result in
 * @param style - The fill style containing texture and mapping properties
 * @param shape - The shape to map the texture onto
 * @param matrix - Optional transform matrix to apply
 * @returns The generated texture matrix for UV mapping
 * @example
 * \`\`\`ts
 * const matrix = new Matrix();
 * const textureMatrix = generateTextureMatrix(matrix, fillStyle, shape);
 * // textureMatrix now contains the proper UV mapping for the texture
 * \`\`\`
 */
export declare function generateTextureMatrix(out: Matrix, style: FillStyle, shape: ShapePrimitive, matrix?: Matrix): Matrix;
export declare function getOrientationOfPoints(points: number[]): number;
export declare function triangulateWithHoles(points: number[], holes: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
/**
 * Constructor options used for \`PlaneGeometry\` instances.
 * \`\`\`js
 * const planeGeometry = new PlaneGeometry({
 *    width: 100,
 *    height: 100,
 *    verticesX: 10,
 *    verticesY: 10,
 * });
 * \`\`\`
 * @see {@link scene.PlaneGeometry}
 * @memberof scene
 */
export interface PlaneGeometryOptions {
	/** Width of plane */
	width?: number;
	/** Height of plane */
	height?: number;
	/** Number of vertices on x-axis */
	verticesX?: number;
	/** Number of vertices on y-axis */
	verticesY?: number;
}
/**
 * The PlaneGeometry allows you to draw a 2d plane
 * @memberof scene
 */
export declare class PlaneGeometry extends MeshGeometry {
	static defaultOptions: PlaneGeometryOptions & MeshGeometryOptions;
	/** The number of vertices on x-axis */
	verticesX: number;
	/** The number of vertices on y-axis */
	verticesY: number;
	/** The width of plane */
	width: number;
	/** The height of plane */
	height: number;
	/**
	 * @param {PlaneGeometryOptions} options - Options to be applied to plane geometry
	 */
	constructor(options: PlaneGeometryOptions);
	/** @deprecated since 8.0.0 */
	constructor(width?: number, height?: number, verticesX?: number, verticesY?: number);
	/**
	 * Refreshes plane coordinates
	 * @param options - Options to be applied to plane geometry
	 */
	build(options: PlaneGeometryOptions): void;
}
/**
 * Constructor options used for \`PerspectivePlaneGeometry\` instances.
 * @memberof scene
 */
export interface PerspectivePlaneGeometryOptions extends PlaneGeometryOptions {
	/** The width of the plane */
	width: number;
	/** The height of the plane */
	height: number;
}
/**
 * A PerspectivePlaneGeometry allows you to draw a 2d plane with perspective. Where ever you move the corners
 * the texture will be projected to look like it is in 3d space. Great for mapping a 2D mesh into a 3D scene.
 *
 * IMPORTANT: This is not a full 3D mesh, it is a 2D mesh with a perspective projection applied to it :)
 *
 * \`\`\`js
 * const perspectivePlaneGeometry = new PerspectivePlaneGeometry({
 *  width: 100,
 *  height: 100,
 *  verticesX: 10,
 *  verticesY: 10,
 * });
 * \`\`\`
 * @see {@link scene.PerspectivePlaneGeometry}
 * @memberof scene
 */
export declare class PerspectivePlaneGeometry extends PlaneGeometry {
	/** The corner points of the quad you can modify these directly, if you do make sure to call \`updateProjection\` */
	corners: [
		number,
		number,
		number,
		number,
		number,
		number,
		number,
		number
	];
	private readonly _projectionMatrix;
	/**
	 * @param options - Options to be applied to MeshPlane
	 * @param options.width - The width of the plane
	 * @param options.height - The height of the plane
	 * @param options.verticesX - The amount of vertices on the x axis
	 * @param options.verticesY - The amount of vertices on the y axis
	 */
	constructor(options: PerspectivePlaneGeometryOptions);
	/**
	 * Will set the corners of the quad to the given coordinates
	 * Calculating the perspective so it looks correct!
	 * @param x0 - x coordinate of the first corner
	 * @param y0 - y coordinate of the first corner
	 * @param x1 - x coordinate of the second corner
	 * @param y1 - y coordinate of the second corner
	 * @param x2 - x coordinate of the third corner
	 * @param y2 - y coordinate of the third corner
	 * @param x3 - x coordinate of the fourth corner
	 * @param y3 - y coordinate of the fourth corner
	 */
	setCorners(x0: number, y0: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): void;
	/** Update the projection matrix based on the corners */
	updateProjection(): void;
}
/**
 * Constructor options used for \`MeshPlane\` instances.
 * \`\`\`js
 * const meshPlane = new MeshPlane({
 *    texture: Texture.from('snake.png'),
 *    verticesX: 20,
 *    verticesY: 20,
 * });
 * \`\`\`
 * @see {@link scene.MeshPlane}
 * @memberof scene
 */
export interface MeshPlaneOptions extends Omit<MeshOptions, "geometry"> {
	/** The texture to use on the plane. */
	texture: Texture;
	/** The number of vertices in the x-axis */
	verticesX?: number;
	/** The number of vertices in the y-axis */
	verticesY?: number;
}
/**
 * The MeshPlane allows you to draw a texture across several points and then manipulate these points
 * @example
 * import { Point, MeshPlane, Texture } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * }
 * const MeshPlane = new MeshPlane({ texture: Texture.from('snake.png'), verticesX: points });
 * @memberof scene
 */
export declare class MeshPlane extends Mesh {
	/** The geometry is automatically updated when the texture size changes. */
	autoResize: boolean;
	protected _textureID: number;
	/**
	 * @param options - Options to be applied to MeshPlane
	 */
	constructor(options: MeshPlaneOptions);
	/**
	 * Method used for overrides, to do something in case texture frame was changed.
	 * Meshes based on plane can override it and change more details based on texture.
	 */
	textureUpdated(): void;
	set texture(value: Texture);
	/** The texture of the MeshPlane */
	get texture(): Texture;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
}
/**
 *
 * Constructor options used for \`PerspectiveMesh\` instances.
 * \`\`\`js
 * const meshPlane = new PerspectiveMesh({
 *  texture: Texture.from('snake.png'),
 *  verticesX: 20,
 *  verticesY: 20,
 *  x0: 0,
 *  y0: 0,
 *  x1: 100,
 *  y1: 0,
 *  x2: 100,
 *  y2: 100,
 *  x3: 0,
 *  y3: 100
 * });
 * @see {@link scene.PerspectiveMesh}
 * @memberof scene
 */
export interface PerspectivePlaneOptions extends MeshPlaneOptions {
	/** top left corner x value */
	x0?: number;
	/** top left corner y value */
	y0?: number;
	/** top right corner x value */
	x1?: number;
	/** top right corner y value */
	y1?: number;
	/** bottom right corner x value */
	x2?: number;
	/** bottom right corner y value */
	y2?: number;
	/** bottom left corner x value */
	x3?: number;
	/** bottom left corner y value */
	y3?: number;
}
/**
 * A perspective mesh that allows you to draw a 2d plane with perspective. Where ever you move the corners
 * the texture will be projected to look like it is in 3d space. Great for mapping a 2D mesh into a 3D scene.
 *
 * The calculations is done at the uv level. This means that the more vertices you have the more smooth
 * the perspective will be. If you have a low amount of vertices you may see the texture stretch. Too many vertices
 * could be slower. It is a balance between performance and quality! We leave that to you to decide.
 *
 * IMPORTANT: This is not a full 3D mesh, it is a 2D mesh with a perspective projection applied to it :)
 * @example
 * \`\`\`js
 * const meshPlane = new PerspectiveMesh({
 *  texture: Texture.from('snake.png'),
 *  verticesX: 20,
 *  verticesY: 20,
 *  x0: 0,
 *  y0: 0,
 *  x1: 100,
 *  y1: 0,
 *  x2: 100,
 *  y2: 100,
 *  x3: 0,
 *  y3: 100
 * });
 * @see {@link scene.PerspectiveMesh}
 * @memberof scene
 */
export declare class PerspectiveMesh extends Mesh<PerspectivePlaneGeometry> {
	/** default options for the mesh */
	static defaultOptions: PerspectivePlaneOptions;
	/**
	 * @param options - Options to be applied to PerspectiveMesh
	 */
	constructor(options: PerspectivePlaneOptions);
	/** Update the geometry when the texture is updated */
	protected textureUpdated(): void;
	set texture(value: Texture);
	/** The texture that the mesh uses */
	get texture(): Texture;
	/**
	 * Set the corners of the quad to the given coordinates
	 * The mesh will then calculate the perspective so it looks correct!
	 * @param x0 - x coordinate of the first corner
	 * @param y0 - y coordinate of the first corner
	 * @param x1 - x coordinate of the second corner
	 * @param y1 - y coordinate of the second corner
	 * @param x2 - x coordinate of the third corner
	 * @param y2 - y coordinate of the third corner
	 * @param x3 - x coordinate of the fourth corner
	 * @param y3 - y coordinate of the fourth corner
	 */
	setCorners(x0: number, y0: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): void;
}
/**
 * Apply a projective transformation to a plane geometry
 * @param width - The width of the plane
 * @param height - The height of the plane
 * @param geometry - The plane geometry to apply the transformation to
 * @param transformationMatrix - The transformation matrix to apply
 */
export declare function applyProjectiveTransformationToPlane(width: number, height: number, geometry: PlaneGeometry, transformationMatrix: ArrayFixed<number, 9>): void;
type Matrix3x3 = ArrayFixed<number, 9>;
/**
 * Compute a 2D projection matrix
 * @param out - The matrix to store the result in
 * @param x1s - The x coordinate of the first source point
 * @param y1s - The y coordinate of the first source point
 * @param x1d - The x coordinate of the first destination point
 * @param y1d - The y coordinate of the first destination point
 * @param x2s - The x coordinate of the second source point
 * @param y2s - The y coordinate of the second source point
 * @param x2d - The x coordinate of the second destination point
 * @param y2d - The y coordinate of the second destination point
 * @param x3s - The x coordinate of the third source point
 * @param y3s - The y coordinate of the third source point
 * @param x3d - The x coordinate of the third destination point
 * @param y3d - The y coordinate of the third destination point
 * @param x4s - The x coordinate of the fourth source point
 * @param y4s - The y coordinate of the fourth source point
 * @param x4d - The x coordinate of the fourth destination point
 * @param y4d - The y coordinate of the fourth destination point
 * @returns - The computed 2D projection matrix
 * @private
 */
export declare function compute2DProjection(out: Matrix3x3, x1s: number, y1s: number, x1d: number, y1d: number, x2s: number, y2s: number, x2d: number, y2d: number, x3s: number, y3s: number, x3d: number, y3d: number, x4s: number, y4s: number, x4d: number, y4d: number): Matrix3x3;
/**
 * Constructor options used for \`MeshRope\` instances.
 * \`\`\`js
 * const meshRope = new MeshRope({
 *    texture: Texture.from('snake.png'),
 *    points: [new Point(0, 0), new Point(100, 0)],
 *    textureScale: 0,
 * });
 * \`\`\`
 * @see {@link scene.MeshRope}
 * @memberof scene
 */
export interface MeshRopeOptions extends Omit<MeshOptions, "geometry"> {
	/** The texture to use on the rope. */
	texture: Texture;
	/** An array of points that determine the rope. */
	points: PointData[];
	/**
	 * Rope texture scale, if zero then the rope texture is stretched.
	 * Positive values scale rope texture
	 * keeping its aspect ratio. You can reduce alpha channel artifacts by providing a larger texture
	 * and downsampling here. If set to zero, texture will be stretched instead.
	 */
	textureScale?: number;
}
/**
 * The rope allows you to draw a texture across several points and then manipulate these points
 * @example
 * import { Point, MeshRope, Texture } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * };
 * const rope = new MeshRope(Texture.from('snake.png'), points);
 * @memberof scene
 */
export declare class MeshRope extends Mesh {
	static defaultOptions: Partial<MeshRopeOptions>;
	/** re-calculate vertices by rope points each frame */
	autoUpdate: boolean;
	/**
	 * Note: The wrap mode of the texture is set to REPEAT if \`textureScale\` is positive.
	 * @param options
	 * @param options.texture - The texture to use on the rope.
	 * @param options.points - An array of {@link math.Point} objects to construct this rope.
	 * @param {number} options.textureScale - Optional. Positive values scale rope texture
	 * keeping its aspect ratio. You can reduce alpha channel artifacts by providing a larger texture
	 * and downsampling here. If set to zero, texture will be stretched instead.
	 */
	constructor(options: MeshRopeOptions);
	private _render;
}
/**
 * Options for the simple mesh.
 * @memberof scene
 */
export interface SimpleMeshOptions extends Omit<MeshOptions, "geometry"> {
	/** The texture to use */
	texture: Texture;
	/** if you want to specify the vertices */
	vertices?: Float32Array;
	/** if you want to specify the uvs */
	uvs?: Float32Array;
	/** if you want to specify the indices */
	indices?: Uint32Array;
	/** the topology, can be any of the Topology values */
	topology?: Topology;
}
/**
 * The Simple Mesh class mimics Mesh in PixiJS, providing easy-to-use constructor arguments.
 * For more robust customization, use {@link scene.Mesh}.
 * @memberof scene
 */
export declare class MeshSimple extends Mesh {
	/** Upload vertices buffer each frame. */
	autoUpdate: boolean;
	/**
	 * @param options - Options to be used for construction
	 */
	constructor(options: SimpleMeshOptions);
	/**
	 * Collection of vertices data.
	 * @type {Float32Array}
	 */
	get vertices(): TypedArray;
	set vertices(value: TypedArray);
	private _render;
}
/**
 * Constructor options used for \`RopeGeometry\` instances.
 * \`\`\`js
 * const ropeGeometry = new RopeGeometry({
 *    points: [new Point(0, 0), new Point(100, 0)],
 *    width: 10,
 *    textureScale: 0,
 * });
 * \`\`\`
 * @see {@link scene.RopeGeometry}
 * @memberof scene
 */
export interface RopeGeometryOptions {
	/** The width (i.e., thickness) of the rope. */
	width?: number;
	/** An array of points that determine the rope. */
	points?: PointData[];
	/**
	 * Rope texture scale, if zero then the rope texture is stretched.
	 * By default the rope texture will be stretched to match
	 * rope length. If textureScale is positive this value will be treated as a scaling
	 * factor and the texture will preserve its aspect ratio instead. To create a tiling rope
	 * set baseTexture.wrapMode to 'repeat' and use a power of two texture,
	 * then set textureScale=1 to keep the original texture pixel size.
	 * In order to reduce alpha channel artifacts provide a larger texture and downsample -
	 * i.e. set textureScale=0.5 to scale it down twice.
	 */
	textureScale?: number;
}
/**
 * RopeGeometry allows you to draw a geometry across several points and then manipulate these points.
 * @example
 * import { Point, RopeGeometry } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * };
 * const rope = new RopeGeometry(100, points);
 * @memberof scene
 */
export declare class RopeGeometry extends MeshGeometry {
	/** Default options for RopeGeometry constructor. */
	static defaultOptions: RopeGeometryOptions & MeshGeometryOptions;
	/** An array of points that determine the rope. */
	points: PointData[];
	/** Rope texture scale, if zero then the rope texture is stretched. */
	readonly textureScale: number;
	/**
	 * The width (i.e., thickness) of the rope.
	 * @readonly
	 */
	_width: number;
	/**
	 * @param options - Options to be applied to rope geometry
	 */
	constructor(options: RopeGeometryOptions);
	/**
	 * The width (i.e., thickness) of the rope.
	 * @readonly
	 */
	get width(): number;
	/** Refreshes Rope indices and uvs */
	private _build;
	/** refreshes vertices of Rope mesh */
	updateVertices(): void;
	/** Refreshes Rope indices and uvs */
	update(): void;
}
/**
 * A MeshAdaptor that uses the WebGL to render meshes.
 * @memberof rendering
 * @ignore
 */
export declare class GlMeshAdaptor implements MeshAdaptor {
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipesAdaptor
		];
		readonly name: "mesh";
	};
	private _shader;
	init(): void;
	execute(meshPipe: MeshPipe, mesh: Mesh): void;
	destroy(): void;
}
/**
 * The WebGL adaptor for the mesh system. Allows the Mesh System to be used with the WebGl renderer
 * @memberof rendering
 * @ignore
 */
export declare class GpuMeshAdapter implements MeshAdaptor {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUPipesAdaptor
		];
		readonly name: "mesh";
	};
	private _shader;
	init(): void;
	execute(meshPipe: MeshPipe, mesh: Mesh): void;
	destroy(): void;
}
/**
 * A batchable mesh object.
 * @ignore
 */
export declare class BatchableMesh implements DefaultBatchableMeshElement {
	batcherName: string;
	_topology: Topology;
	readonly packAsQuad = false;
	location: number;
	renderable: ViewContainer;
	indexOffset: number;
	attributeOffset: number;
	texture: Texture;
	geometry: MeshGeometry;
	transform: Matrix;
	roundPixels: 0 | 1;
	_attributeStart: number;
	_batcher: Batcher;
	_batch: Batch;
	_indexStart: number;
	_textureId: number;
	_textureMatrixUpdateId: number;
	private _transformedUvs;
	private _uvUpdateId;
	get blendMode(): BLEND_MODES;
	get topology(): Topology;
	set topology(value: Topology);
	reset(): void;
	/**
	 * Sets the texture for the batchable mesh.
	 * As it does so, it resets the texture matrix update ID.
	 * this is to ensure that the texture matrix is recalculated when the uvs are referenced
	 * @param value - The texture to set.
	 */
	setTexture(value: Texture): void;
	get uvs(): Float32Array;
	get positions(): Float32Array;
	get indices(): Uint32Array;
	get color(): number;
	get groupTransform(): Matrix;
	get attributeSize(): number;
	get indexSize(): number;
}
export declare function getTextureDefaultMatrix(texture: Texture, out: Matrix): Matrix;
/**
 * Represents a particle with properties for position, scale, rotation, color, and texture.
 * @property {number} x - The x-coordinate of the particle.
 * @property {number} y - The y-coordinate of the particle.
 * @property {number} scaleX - The scale factor in the x-axis.
 * @property {number} scaleY - The scale factor in the y-axis.
 * @property {number} anchorX - The x-coordinate of the anchor point.
 * @property {number} anchorY - The y-coordinate of the anchor point.
 * @property {number} rotation - The rotation of the particle in radians.
 * @property {number} color - The color of the particle as a hexadecimal number.
 * @property {Texture} texture - The texture of the particle.
 * @memberof scene
 */
export interface IParticle {
	x: number;
	y: number;
	scaleX: number;
	scaleY: number;
	anchorX: number;
	anchorY: number;
	rotation: number;
	color: number;
	texture: Texture;
}
/**
 * Represents the options for creating a new particle.
 * @property {number} x - The x-coordinate of the particle.
 * @property {number} y - The y-coordinate of the particle.
 * @property {number} scaleX - The scale factor in the x-axis.
 * @property {number} scaleY - The scale factor in the y-axis.
 * @property {number} anchorX - The x-coordinate of the anchor point.
 * @property {number} anchorY - The y-coordinate of the anchor point.
 * @property {number} rotation - The rotation of the particle in radians.
 * @property {Texture} texture - The texture of the particle.
 * @property {ColorSource} tint - The tint color of the particle as a hexadecimal number.
 * @property {number} alpha - The alpha value of the particle.
 * @memberof scene
 */
export type ParticleOptions = Omit<Partial<IParticle>, "color"> & {
	texture: Texture;
	tint?: ColorSource;
	alpha?: number;
};
/**
 * Represents a single particle within a particle container. This class implements the IParticle interface,
 * providing properties and methods to manage the particle's position, scale, rotation, color, and texture.
 *
 * The reason we use a particle over a sprite is that these are much lighter weight and we can create a lot of them
 * without taking on the overhead of a full sprite.
 *
 * Here is an example of how to create a new particle:
 *
 * \`\`\`javascript
 * const particle = new Particle({
 *   texture,
 *   x: 100,
 *   y: 100,
 *   scaleX: 0.5,
 *   scaleY: 0.5,
 *   rotation: Math.PI / 2,
 *   color: 0xff0000,
 * });
 * \`\`\`
 * @implements {IParticle}
 * @memberof scene
 */
export declare class Particle implements IParticle {
	/** Default options for constructing with options */
	static defaultOptions: Partial<ParticleOptions>;
	/** The x-coordinate of the anchor point. */
	anchorX: number;
	/** The y-coordinate of the anchor point. */
	anchorY: number;
	/** The x-coordinate of the particle. */
	x: number;
	/** The y-coordinate of the particle. */
	y: number;
	/** The scale factor in the x-axis. */
	scaleX: number;
	/** The scale factor in the y-axis. */
	scaleY: number;
	/** The rotation of the particle in radians. */
	rotation: number;
	/** The color of the particle as a hexadecimal number. */
	color: number;
	/** The texture of the particle. */
	texture: Texture;
	private _alpha;
	private _tint;
	constructor(options: Texture | ParticleOptions);
	/** Gets or sets the alpha value of the particle. */
	get alpha(): number;
	set alpha(value: number);
	/** Gets or sets the tint color of the particle. */
	get tint(): number;
	set tint(value: ColorSource);
	private _updateColor;
}
export interface ParticleRendererProperty {
	attributeName: string;
	format: VertexFormat;
	code: string;
	dynamic: boolean;
	updateFunction?: (ps: IParticle[], f32v: Float32Array, u32v: Uint32Array, offset: number, stride: number) => void;
}
export declare const particleData: Record<string, ParticleRendererProperty>;
/**
 * Represents the properties of a particle that can be dynamically updated.
 * @property {boolean} [vertices] - Indicates if vertices are dynamic.
 * @property {boolean} [position] - Indicates if position is dynamic.
 * @property {boolean} [rotation] - Indicates if rotation is dynamic.
 * @property {boolean} [uvs] - Indicates if UVs are dynamic.
 * @property {boolean} [color] - Indicates if color is dynamic.
 * @memberof scene
 */
export interface ParticleProperties {
	vertex?: boolean;
	position?: boolean;
	rotation?: boolean;
	uvs?: boolean;
	color?: boolean;
}
/**
 * Options for the ParticleContainer constructor.
 * @extends ContainerOptions
 * @property {Record<string, boolean>} dynamicProperties - Specifies which properties are dynamic.
 * @property {Shader} shader - The shader to use for rendering.
 * @property {boolean} roundPixels - Indicates if pixels should be rounded.
 * @property {Texture} texture - The texture to use for rendering - if not provided the texture of the first child is used.
 * @property {IParticle[]} particles - An array of particles to add to the container.
 * @memberof scene
 */
export interface ParticleContainerOptions extends PixiMixins.ParticleContainerOptions, Omit<ViewContainerOptions, "children"> {
	dynamicProperties?: Record<string, boolean>;
	shader?: Shader;
	roundPixels?: boolean;
	texture?: Texture;
	particles?: IParticle[];
}
export interface ParticleContainer extends PixiMixins.ParticleContainer, ViewContainer {
}
/**
 * The ParticleContainer class is a highly optimized container that can render 1000s or particles at great speed.
 *
 * A ParticleContainer is specialized in that it can only contain and render particles. Particles are
 * lightweight objects that use minimal memory, which helps boost performance.
 *
 * It can render particles EXTREMELY fast!
 *
 * The tradeoff of using a ParticleContainer is that most advanced functionality is unavailable. Particles are simple
 * and cannot have children, filters, masks, etc. They possess only the basic properties: position, scale, rotation,
 * and color.
 *
 * All particles must share the same texture source (using something like a sprite sheet works well here).
 *
 * When creating a ParticleContainer, a developer can specify which of these properties are static and which are dynamic.
 * - Static properties are only updated when you add or remove a child, or when the \`update\` function is called.
 * - Dynamic properties are updated every frame.
 *
 * It is up to the developer to specify which properties are static and which are dynamic. Generally, the more static
 * properties you have (i.e., those that do not change per frame), the faster the rendering.
 *
 * If the developer modifies the children order or any static properties of the particle, they must call the \`update\` method.
 *
 * By default, only the \`position\` property is set to dynamic, which makes rendering very fast!
 *
 * Developers can also provide a custom shader to the particle container, allowing them to render particles in a custom way.
 *
 * To help with performance, the particle containers bounds are not calculated.
 * It's up to the developer to set the boundsArea property.
 *
 * It's extremely easy to use. Below is an example of rendering thousands of sprites at lightning speed.
 *
 * --------- EXPERIMENTAL ---------
 *
 * This is a new API, things may change and it may not work as expected.
 * We want to hear your feedback as we go!
 *
 * --------------------------------
 * @example
 * import { ParticleContainer, Particle } from 'pixi.js';
 *
 * const container = new ParticleContainer();
 *
 * for (let i = 0; i < 100; ++i)
 * {
 *     let particle = new Particle(texture);
 *     container.addParticle(particle);
 * }
 * @memberof scene
 */
export declare class ParticleContainer extends ViewContainer implements Instruction {
	/**
	 * Defines the default options for creating a ParticleContainer.
	 * @property {Record<string, boolean>} dynamicProperties - Specifies which properties are dynamic.
	 * @property {boolean} roundPixels - Indicates if pixels should be  rounded.
	 */
	static defaultOptions: ParticleContainerOptions;
	/** The unique identifier for the render pipe of this ParticleContainer. */
	readonly renderPipeId: string;
	batched: boolean;
	/**
	 * A record of properties and their corresponding ParticleRendererProperty.
	 * @internal
	 */
	_properties: Record<string, ParticleRendererProperty>;
	/** Indicates if the children of this ParticleContainer have changed and need to be updated. */
	_childrenDirty: boolean;
	/**
	 * An array of particles that are children of this ParticleContainer.
	 * it can be modified directly, after which the 'update' method must be called.
	 * to ensure the container is rendered correctly.
	 */
	particleChildren: IParticle[];
	/** The shader used for rendering particles in this ParticleContainer. */
	shader: Shader;
	/**
	 * The texture used for rendering particles in this ParticleContainer.
	 * Defaults to the first childs texture if not set
	 */
	texture: Texture;
	/**
	 * @param options - The options for creating the sprite.
	 */
	constructor(options?: ParticleContainerOptions);
	/**
	 * Adds one or more particles to the container.
	 *
	 * Multiple items can be added like so: \`myContainer.addParticle(thingOne, thingTwo, thingThree)\`
	 * @param {...IParticle} children - The Particle(s) to add to the container
	 * @returns {IParticle} - The first child that was added.
	 */
	addParticle(...children: IParticle[]): IParticle;
	/**
	 * Removes one or more particles from the container.
	 * @param {...IParticle} children - The Particle(s) to remove
	 * @returns {IParticle} The first child that was removed.
	 */
	removeParticle(...children: IParticle[]): IParticle;
	/**
	 * Updates the particle container.
	 * Please call this when you modify the particleChildren array.
	 * or any static properties of the particles.
	 */
	update(): void;
	protected onViewUpdate(): void;
	/**
	 * ParticleContainer does not calculated bounds as it would slow things down,
	 * its up to you to set this via the boundsArea property
	 */
	get bounds(): Bounds;
	/** @private */
	protected updateBounds(): void;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
	/**
	 * Removes all particles from this container that are within the begin and end indexes.
	 * @param beginIndex - The beginning position.
	 * @param endIndex - The ending position. Default value is size of the container.
	 * @returns - List of removed particles
	 */
	removeParticles(beginIndex?: number, endIndex?: number): IParticle[];
	/**
	 * Removes a particle from the specified index position.
	 * @param index - The index to get the particle from
	 * @returns The particle that was removed.
	 */
	removeParticleAt<U extends IParticle>(index: number): U;
	/**
	 * Adds a particle to the container at a specified index. If the index is out of bounds an error will be thrown.
	 * If the particle is already in this container, it will be moved to the specified index.
	 * @param {Container} child - The particle to add.
	 * @param {number} index - The absolute index where the particle will be positioned at the end of the operation.
	 * @returns {Container} The particle that was added.
	 */
	addParticleAt<U extends IParticle>(child: U, index: number): U;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.addParticle()\` instead.
	 * @param {...any} _children
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	addChild<U extends (ContainerChild | IRenderLayer)[]>(..._children: U): U[0];
	/**
	 * This method is not available in ParticleContainer.
	 * Calling this method will throw an error. Please use \`ParticleContainer.removeParticle()\` instead.
	 * @param {...any} _children
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	removeChild<U extends (ContainerChild | IRenderLayer)[]>(..._children: U): U[0];
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.removeParticles()\` instead.
	 * @param {number} [_beginIndex]
	 * @param {number} [_endIndex]
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	removeChildren(_beginIndex?: number, _endIndex?: number): ContainerChild[];
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.removeParticleAt()\` instead.
	 * @param {number} _index
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	removeChildAt<U extends (ContainerChild | IRenderLayer)>(_index: number): U;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.getParticleAt()\` instead.
	 * @param {number} _index
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	getChildAt<U extends (ContainerChild | IRenderLayer)>(_index: number): U;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.setParticleIndex()\` instead.
	 * @param {ContainerChild} _child
	 * @param {number} _index
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	setChildIndex(_child: ContainerChild, _index: number): void;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.getParticleIndex()\` instead.
	 * @param {ContainerChild} _child
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	getChildIndex(_child: ContainerChild): number;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.addParticleAt()\` instead.
	 * @param {ContainerChild} _child
	 * @param {number} _index
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	addChildAt<U extends (ContainerChild | IRenderLayer)>(_child: U, _index: number): U;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error. Please use \`ParticleContainer.swapParticles()\` instead.
	 * @param {ContainerChild} _child
	 * @param {ContainerChild} _child2
	 */
	swapChildren<U extends (ContainerChild | IRenderLayer)>(_child: U, _child2: U): void;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error.
	 * @param _child - The child to reparent
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	reparentChild(..._child: ContainerChild[]): any;
	/**
	 * This method is not available in ParticleContainer.
	 *
	 * Calling this method will throw an error.
	 * @param _child - The child to reparent
	 * @param _index - The index to reparent the child to
	 * @throws {Error} Always throws an error as this method is not available.
	 */
	reparentChildAt(_child: ContainerChild, _index: number): any;
}
export type ParticleUpdateFunction = (ps: IParticle[], f32v: Float32Array, u32v: Uint32Array) => void;
export declare function generateParticleUpdateFunction(properties: Record<string, ParticleRendererProperty>): {
	dynamicUpdate: ParticleUpdateFunction;
	staticUpdate: ParticleUpdateFunction;
};
/**
 * Options for creating a ParticleBuffer.
 * @property {number} size - The size of the particle buffer.
 * @property {Record<string, ParticleRendererProperty>} properties - A record of attributes that the particle container uses.
 */
export interface ParticleBufferOptions {
	size: number;
	properties: Record<string, ParticleRendererProperty>;
}
/**
 * The ParticleBuffer holds the buffers and geometry for a particle container.
 * It also contains the upload functions for the static and dynamic properties.
 * @internal
 */
export declare class ParticleBuffer {
	/** The buffer containing static attribute data for all elements in the batch. */
	staticAttributeBuffer: ViewableBuffer;
	/** The buffer containing dynamic attribute data for all elements in the batch. */
	dynamicAttributeBuffer: ViewableBuffer;
	private readonly _staticBuffer;
	private readonly _dynamicBuffer;
	/** The buffer containing index data for all elements in the batch. */
	indexBuffer: IndexBufferArray;
	private readonly _dynamicStride;
	private readonly _staticStride;
	/** The geometry of the particle buffer. */
	readonly geometry: Geometry;
	private _size;
	private readonly _dynamicUpload;
	private readonly _staticUpload;
	private readonly _generateParticleUpdateCache;
	constructor(options: ParticleBufferOptions);
	getParticleUpdate(properties: Record<string, ParticleRendererProperty>): {
		dynamicUpdate: ParticleUpdateFunction;
		staticUpdate: ParticleUpdateFunction;
	};
	generateParticleUpdate(properties: Record<string, ParticleRendererProperty>): {
		dynamicUpdate: ParticleUpdateFunction;
		staticUpdate: ParticleUpdateFunction;
	};
	update(particles: IParticle[], uploadStatic: boolean): void;
	destroy(): void;
}
export interface ParticleContainerAdaptor {
	execute(particleContainerPop: ParticleContainerPipe, container: ParticleContainer): void;
}
/**
 * Renderer for Particles that is designer for speed over feature set.
 * @memberof scene
 */
export declare class ParticleContainerPipe implements RenderPipe<ParticleContainer> {
	/** The default shader that is used if a sprite doesn't have a more specific one. */
	defaultShader: Shader;
	adaptor: ParticleContainerAdaptor;
	readonly state: State;
	readonly renderer: Renderer;
	private _gpuBufferHash;
	private readonly _destroyRenderableBound;
	readonly localUniforms: UniformGroup<{
		uTranslationMatrix: {
			value: Matrix;
			type: "mat3x3<f32>";
		};
		uColor: {
			value: Float32Array;
			type: "vec4<f32>";
		};
		uRound: {
			value: number;
			type: "f32";
		};
		uResolution: {
			value: number[];
			type: "vec2<f32>";
		};
	}>;
	/**
	 * @param renderer - The renderer this sprite batch works for.
	 * @param adaptor
	 */
	constructor(renderer: Renderer, adaptor: ParticleContainerAdaptor);
	validateRenderable(_renderable: ParticleContainer): boolean;
	addRenderable(renderable: ParticleContainer, instructionSet: InstructionSet): void;
	getBuffers(renderable: ParticleContainer): ParticleBuffer;
	private _initBuffer;
	updateRenderable(_renderable: ParticleContainer): void;
	destroyRenderable(renderable: ParticleContainer): void;
	execute(container: ParticleContainer): void;
	/** Destroys the ParticleRenderer. */
	destroy(): void;
}
export declare class GlParticleContainerAdaptor implements ParticleContainerAdaptor {
	execute(particleContainerPipe: ParticleContainerPipe, container: ParticleContainer): void;
}
export declare class GpuParticleContainerAdaptor implements ParticleContainerAdaptor {
	execute(particleContainerPipe: ParticleContainerPipe, container: ParticleContainer): void;
}
export declare class GlParticleContainerPipe extends ParticleContainerPipe {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes
		];
		readonly name: "particle";
	};
	constructor(renderer: WebGLRenderer);
}
export declare class GpuParticleContainerPipe extends ParticleContainerPipe {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGPUPipes
		];
		readonly name: "particle";
	};
	constructor(renderer: WebGPURenderer);
}
export declare class ParticleShader extends Shader {
	constructor();
}
/**
 * Generic Mask Stack data structure
 * @function createIndicesForQuads
 * @param {number} size - Number of quads
 * @param {Uint16Array|Uint32Array} [outBuffer] - Buffer for output, length has to be \`6 * size\`
 * @returns {Uint16Array|Uint32Array} - Resulting index buffer
 */
export declare function createIndicesForQuads(size: number, outBuffer?: Uint16Array | Uint32Array | null): Uint16Array | Uint32Array;
export type AnimatedSpriteFrames = Texture[] | FrameObject[];
/**
 * Constructor options used for \`AnimatedSprite\` instances.
 * @see {@link scene.AnimatedSprite}
 * @memberof scene
 */
export interface AnimatedSpriteOptions extends PixiMixins.AnimatedSpriteOptions, Omit<SpriteOptions, "texture"> {
	/** The speed that the AnimatedSprite will play at. Higher is faster, lower is slower. */
	animationSpeed?: number;
	/** Whether to start the animation immediately on creation. */
	autoPlay?: boolean;
	/** Whether to use Ticker.shared to auto update animation time. */
	autoUpdate?: boolean;
	/** Whether or not the animate sprite repeats after playing. */
	loop?: boolean;
	/** User-assigned function to call when an AnimatedSprite finishes playing. */
	onComplete?: () => void;
	/** User-assigned function to call when an AnimatedSprite changes which texture is being rendered. */
	onFrameChange?: (currentFrame: number) => void;
	/**
	 * User-assigned function to call when \`loop\` is true, and an AnimatedSprite is played and loops around to start again.
	 */
	onLoop?: () => void;
	/** An array of {@link Texture} or frame objects that make up the animation. */
	textures: AnimatedSpriteFrames;
	/** Update anchor to [Texture's defaultAnchor]{@link Texture#defaultAnchor} when frame changes. */
	updateAnchor?: boolean;
}
export interface AnimatedSprite extends PixiMixins.AnimatedSprite, Sprite {
}
/**
 * An AnimatedSprite is a simple way to display an animation depicted by a list of textures.
 *
 * \`\`\`js
 * import { AnimatedSprite, Texture } from 'pixi.js';
 *
 * const alienImages = [
 *     'image_sequence_01.png',
 *     'image_sequence_02.png',
 *     'image_sequence_03.png',
 *     'image_sequence_04.png',
 * ];
 * const textureArray = [];
 *
 * for (let i = 0; i < 4; i++)
 * {
 *     const texture = Texture.from(alienImages[i]);
 *     textureArray.push(texture);
 * }
 *
 * const animatedSprite = new AnimatedSprite(textureArray);
 * \`\`\`
 *
 * The more efficient and simpler way to create an animated sprite is using a {@link Spritesheet}
 * containing the animation definitions:
 * @example
 * import { AnimatedSprite, Assets } from 'pixi.js';
 *
 * const sheet = await Assets.load('assets/spritesheet.json');
 * animatedSprite = new AnimatedSprite(sheet.animations['image_sequence']);
 * @memberof scene
 */
export declare class AnimatedSprite extends Sprite {
	/**
	 * The speed that the AnimatedSprite will play at. Higher is faster, lower is slower.
	 * @default 1
	 */
	animationSpeed: number;
	/**
	 * Whether or not the animate sprite repeats after playing.
	 * @default true
	 */
	loop: boolean;
	/**
	 * Update anchor to [Texture's defaultAnchor]{@link Texture#defaultAnchor} when frame changes.
	 *
	 * Useful with [sprite sheet animations]{@link Spritesheet#animations} created with tools.
	 * Changing anchor for each frame allows to pin sprite origin to certain moving feature
	 * of the frame (e.g. left foot).
	 *
	 * Note: Enabling this will override any previously set \`anchor\` on each frame change.
	 * @default false
	 */
	updateAnchor: boolean;
	/**
	 * User-assigned function to call when an AnimatedSprite finishes playing.
	 * @example
	 * animation.onComplete = () => {
	 *     // Finished!
	 * };
	 */
	onComplete?: () => void;
	/**
	 * User-assigned function to call when an AnimatedSprite changes which texture is being rendered.
	 * @example
	 * animation.onFrameChange = () => {
	 *     // Updated!
	 * };
	 */
	onFrameChange?: (currentFrame: number) => void;
	/**
	 * User-assigned function to call when \`loop\` is true, and an AnimatedSprite is played and
	 * loops around to start again.
	 * @example
	 * animation.onLoop = () => {
	 *     // Looped!
	 * };
	 */
	onLoop?: () => void;
	private _playing;
	private _textures;
	private _durations;
	/**
	 * \`true\` uses Ticker.shared to auto update animation time.
	 * @default true
	 */
	private _autoUpdate;
	/**
	 * \`true\` if the instance is currently connected to Ticker.shared to auto update animation time.
	 * @default false
	 */
	private _isConnectedToTicker;
	/** Elapsed time since animation has been started, used internally to display current texture. */
	private _currentTime;
	/** The texture index that was displayed last time. */
	private _previousFrame;
	/**
	 * @param frames - Collection of textures or frames to use.
	 * @param autoUpdate - Whether to use Ticker.shared to auto update animation time.
	 */
	constructor(frames: AnimatedSpriteFrames, autoUpdate?: boolean);
	/**
	 * @param options - The options for the AnimatedSprite.
	 */
	constructor(options: AnimatedSpriteOptions);
	/** Stops the AnimatedSprite. */
	stop(): void;
	/** Plays the AnimatedSprite. */
	play(): void;
	/**
	 * Stops the AnimatedSprite and goes to a specific frame.
	 * @param frameNumber - Frame index to stop at.
	 */
	gotoAndStop(frameNumber: number): void;
	/**
	 * Goes to a specific frame and begins playing the AnimatedSprite.
	 * @param frameNumber - Frame index to start at.
	 */
	gotoAndPlay(frameNumber: number): void;
	/**
	 * Updates the object transform for rendering.
	 * @param ticker - the ticker to use to update the object.
	 */
	update(ticker: Ticker): void;
	/** Updates the displayed texture to match the current frame index. */
	private _updateTexture;
	/** Stops the AnimatedSprite and destroys it. */
	destroy(): void;
	/**
	 * A short hand way of creating an AnimatedSprite from an array of frame ids.
	 * @param frames - The array of frames ids the AnimatedSprite will use as its texture frames.
	 * @returns - The new animated sprite with the specified frames.
	 */
	static fromFrames(frames: string[]): AnimatedSprite;
	/**
	 * A short hand way of creating an AnimatedSprite from an array of image ids.
	 * @param images - The array of image urls the AnimatedSprite will use as its texture frames.
	 * @returns The new animate sprite with the specified images as frames.
	 */
	static fromImages(images: string[]): AnimatedSprite;
	/**
	 * The total number of frames in the AnimatedSprite. This is the same as number of textures
	 * assigned to the AnimatedSprite.
	 * @readonly
	 * @default 0
	 */
	get totalFrames(): number;
	/** The array of textures used for this AnimatedSprite. */
	get textures(): AnimatedSpriteFrames;
	set textures(value: AnimatedSpriteFrames);
	/** The AnimatedSprite's current frame index. */
	get currentFrame(): number;
	set currentFrame(value: number);
	/**
	 * Indicates if the AnimatedSprite is currently playing.
	 * @readonly
	 */
	get playing(): boolean;
	/** Whether to use Ticker.shared to auto update animation time. */
	get autoUpdate(): boolean;
	set autoUpdate(value: boolean);
}
/**
 * A reference to a frame in an {@link scene.AnimatedSprite}
 * @memberof scene
 */
export interface FrameObject {
	/** The {@link Texture} of the frame. */
	texture: Texture;
	/** The duration of the frame, in milliseconds. */
	time: number;
}
/**
 * Options for the NineSliceGeometry.
 * @memberof scene
 */
export interface NineSliceGeometryOptions {
	/** The width of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane. */
	width?: number;
	/** The height of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane. */
	height?: number;
	/** The original width of the texture */
	originalWidth?: number;
	/** The original height of the texture */
	originalHeight?: number;
	/** The width of the left column. */
	leftWidth?: number;
	/** The height of the top row. */
	topHeight?: number;
	/** The width of the right column. */
	rightWidth?: number;
	/** The height of the bottom row. */
	bottomHeight?: number;
	/** The anchor point of the NineSliceSprite. */
	anchor?: PointData;
}
/**
 * The NineSliceGeometry class allows you to create a NineSlicePlane object.
 * @memberof scene
 */
export declare class NineSliceGeometry extends PlaneGeometry {
	/** The default options for the NineSliceGeometry. */
	static defaultOptions: NineSliceGeometryOptions;
	_leftWidth: number;
	_rightWidth: number;
	_topHeight: number;
	_bottomHeight: number;
	private _originalWidth;
	private _originalHeight;
	private _anchorX;
	private _anchorY;
	constructor(options?: NineSliceGeometryOptions);
	/**
	 * Updates the NineSliceGeometry with the options.
	 * @param options - The options of the NineSliceGeometry.
	 */
	update(options: NineSliceGeometryOptions): void;
	/** Updates the positions of the vertices. */
	updatePositions(): void;
	/** Updates the UVs of the vertices. */
	updateUvs(): void;
}
/**
 * Constructor options used for \`NineSliceSprite\` instances.
 * \`\`\`js
 * const nineSliceSprite = new NineSliceSprite({
 *    texture: Texture.from('button.png'),
 *    leftWidth: 20,
 *    topHeight: 20,
 *    rightWidth: 20,
 *    bottomHeight: 20,
 * });
 * \`\`\`
 * @see {@link scene.NineSliceSprite}
 * @memberof scene
 */
export interface NineSliceSpriteOptions extends PixiMixins.NineSliceSpriteOptions, ViewContainerOptions {
	/** The texture to use on the NineSliceSprite. */
	texture: Texture;
	/** Width of the left vertical bar (A) */
	leftWidth?: number;
	/** Height of the top horizontal bar (C) */
	topHeight?: number;
	/** Width of the right vertical bar (B) */
	rightWidth?: number;
	/** Height of the bottom horizontal bar (D) */
	bottomHeight?: number;
	/** Width of the NineSliceSprite, setting this will actually modify the vertices and not the UV's of this plane. */
	width?: number;
	/** Height of the NineSliceSprite, setting this will actually modify the vertices and not UV's of this plane. */
	height?: number;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
	/** The anchor point of the NineSliceSprite. */
	anchor?: PointData | number;
}
export interface NineSliceSprite extends PixiMixins.NineSliceSprite, ViewContainer {
}
/**
 * The NineSliceSprite allows you to stretch a texture using 9-slice scaling. The corners will remain unscaled (useful
 * for buttons with rounded corners for example) and the other areas will be scaled horizontally and or vertically
 *
 * <pre>
 *      A                          B
 *    +---+----------------------+---+
 *  C | 1 |          2           | 3 |
 *    +---+----------------------+---+
 *    |   |                      |   |
 *    | 4 |          5           | 6 |
 *    |   |                      |   |
 *    +---+----------------------+---+
 *  D | 7 |          8           | 9 |
 *    +---+----------------------+---+
 *  When changing this objects width and/or height:
 *     areas 1 3 7 and 9 will remain unscaled.
 *     areas 2 and 8 will be stretched horizontally
 *     areas 4 and 6 will be stretched vertically
 *     area 5 will be stretched both horizontally and vertically
 * </pre>
 * @example
 * import { NineSliceSprite, Texture } from 'pixi.js';
 *
 * const plane9 = new NineSliceSprite(Texture.from('BoxWithRoundedCorners.png'), 15, 15, 15, 15);
 * @memberof scene
 */
export declare class NineSliceSprite extends ViewContainer implements View {
	/** The default options, used to override the initial values of any options passed in the constructor. */
	static defaultOptions: NineSliceSpriteOptions;
	readonly renderPipeId: string;
	_texture: Texture;
	batched: boolean;
	_anchor: ObservablePoint;
	private _leftWidth;
	private _topHeight;
	private _rightWidth;
	private _bottomHeight;
	private _width;
	private _height;
	/**
	 * @param {scene.NineSliceSpriteOptions|Texture} options - Options to use
	 * @param options.texture - The texture to use on the NineSliceSprite.
	 * @param options.leftWidth - Width of the left vertical bar (A)
	 * @param options.topHeight - Height of the top horizontal bar (C)
	 * @param options.rightWidth - Width of the right vertical bar (B)
	 * @param options.bottomHeight - Height of the bottom horizontal bar (D)
	 * @param options.width - Width of the NineSliceSprite,
	 * setting this will actually modify the vertices and not the UV's of this plane.
	 * @param options.height - Height of the NineSliceSprite,
	 * setting this will actually modify the vertices and not UV's of this plane.
	 */
	constructor(options: NineSliceSpriteOptions | Texture);
	get anchor(): ObservablePoint;
	set anchor(value: PointData | number);
	/** The width of the NineSliceSprite, setting this will actually modify the vertices and UV's of this plane. */
	get width(): number;
	set width(value: number);
	/** The height of the NineSliceSprite, setting this will actually modify the vertices and UV's of this plane. */
	get height(): number;
	set height(value: number);
	/**
	 * Sets the size of the NiceSliceSprite to the specified width and height.
	 * setting this will actually modify the vertices and UV's of this plane
	 * This is faster than setting the width and height separately.
	 * @param value - This can be either a number or a [Size]{@link Size} object.
	 * @param height - The height to set. Defaults to the value of \`width\` if not provided.
	 */
	setSize(value: number | Optional<Size, "height">, height?: number): void;
	/**
	 * Retrieves the size of the NineSliceSprite as a [Size]{@link Size} object.
	 * This is faster than get the width and height separately.
	 * @param out - Optional object to store the size in.
	 * @returns - The size of the NineSliceSprite.
	 */
	getSize(out?: Size): Size;
	/** The width of the left column (a) of the NineSliceSprite. */
	get leftWidth(): number;
	set leftWidth(value: number);
	/** The width of the right column (b) of the NineSliceSprite. */
	get topHeight(): number;
	set topHeight(value: number);
	/** The width of the right column (b) of the NineSliceSprite. */
	get rightWidth(): number;
	set rightWidth(value: number);
	/** The width of the right column (b) of the NineSliceSprite. */
	get bottomHeight(): number;
	set bottomHeight(value: number);
	/** The texture that the NineSliceSprite is using. */
	get texture(): Texture;
	set texture(value: Texture);
	/** The original width of the texture */
	get originalWidth(): number;
	/** The original height of the texture */
	get originalHeight(): number;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
	/**
	 * @private
	 */
	protected updateBounds(): void;
}
/**
 * Please use the \`NineSliceSprite\` class instead.
 * @deprecated since 8.0.0
 * @memberof scene
 */
export declare class NineSlicePlane extends NineSliceSprite {
	constructor(options: NineSliceSpriteOptions | Texture);
	/** @deprecated since 8.0.0 */
	constructor(texture: Texture, leftWidth: number, topHeight: number, rightWidth: number, bottomHeight: number);
}
export declare class NineSliceSpritePipe implements RenderPipe<NineSliceSprite> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "nineSliceSprite";
	};
	private readonly _renderer;
	private readonly _gpuSpriteHash;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	addRenderable(sprite: NineSliceSprite, instructionSet: InstructionSet): void;
	updateRenderable(sprite: NineSliceSprite): void;
	validateRenderable(sprite: NineSliceSprite): boolean;
	destroyRenderable(sprite: NineSliceSprite): void;
	private _updateBatchableSprite;
	private _getGpuSprite;
	private _initGPUSprite;
	destroy(): void;
}
export declare const tilingBit: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
export declare const tilingBitGl: {
	name: string;
	vertex: {
		header: string;
		main: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
export declare class TilingSpriteShader extends Shader {
	constructor();
	updateUniforms(width: number, height: number, matrix: Matrix, anchorX: number, anchorY: number, texture: Texture): void;
}
/**
 * Options for the {@link utils.Transform} constructor.
 * @memberof utils.Transform
 */
export interface TransformOptions {
	/** The matrix to use. */
	matrix?: Matrix;
	/** The observer to use. */
	observer?: {
		_onUpdate: (transform: Transform) => void;
	};
}
/**
 * The Transform class facilitates the manipulation of a 2D transformation matrix through
 * user-friendly properties: position, scale, rotation, skew, and pivot.
 * @memberof utils
 */
export declare class Transform {
	/**
	 * The local transformation matrix.
	 * @internal
	 * @private
	 */
	_matrix: Matrix;
	/** The coordinate of the object relative to the local coordinates of the parent. */
	position: ObservablePoint;
	/** The scale factor of the object. */
	scale: ObservablePoint;
	/** The pivot point of the container that it rotates around. */
	pivot: ObservablePoint;
	/** The skew amount, on the x and y axis. */
	skew: ObservablePoint;
	/** The rotation amount. */
	protected _rotation: number;
	/**
	 * The X-coordinate value of the normalized local X axis,
	 * the first column of the local transformation matrix without a scale.
	 */
	protected _cx: number;
	/**
	 * The Y-coordinate value of the normalized local X axis,
	 * the first column of the local transformation matrix without a scale.
	 */
	protected _sx: number;
	/**
	 * The X-coordinate value of the normalized local Y axis,
	 * the second column of the local transformation matrix without a scale.
	 */
	protected _cy: number;
	/**
	 * The Y-coordinate value of the normalized local Y axis,
	 * the second column of the local transformation matrix without a scale.
	 */
	protected _sy: number;
	protected dirty: boolean;
	protected observer: Observer<Transform>;
	/**
	 * @param options - Options for the transform.
	 * @param options.matrix - The matrix to use.
	 * @param options.observer - The observer to use.
	 */
	constructor({ matrix, observer }?: TransformOptions);
	/**
	 * This matrix is computed by combining this Transforms position, scale, rotation, skew, and pivot
	 * properties into a single matrix.
	 * @readonly
	 */
	get matrix(): Matrix;
	/**
	 * Called when a value changes.
	 * @param point
	 * @internal
	 * @private
	 */
	_onUpdate(point?: ObservablePoint): void;
	/** Called when the skew or the rotation changes. */
	protected updateSkew(): void;
	toString(): string;
	/**
	 * Decomposes a matrix and sets the transforms properties based on it.
	 * @param matrix - The matrix to decompose
	 */
	setFromMatrix(matrix: Matrix): void;
	/** The rotation of the object in radians. */
	get rotation(): number;
	set rotation(value: number);
}
/**
 * Constructor options used for \`TilingSprite\` instances. Extends {@link scene.TilingSpriteViewOptions}
 * \`\`\`js
 * const tilingSprite = new TilingSprite({
 *    texture: Texture.from('assets/image.png'),
 *    width: 100,
 *    height: 100,
 *    tilePosition: { x: 100, y: 100 },
 *    tileScale: { x: 2, y: 2 },
 * });
 * \`\`\`
 * @see {@link scene.TilingSprite}
 * @see {@link scene.TilingSpriteViewOptions}
 * @memberof scene
 */
export interface TilingSpriteOptions extends PixiMixins.TilingSpriteOptions, ViewContainerOptions {
	/**
	 * The anchor point of the sprite
	 * @default {x: 0, y: 0}
	 */
	anchor?: PointData | number;
	/**
	 * The offset of the image that is being tiled.
	 * @default {x: 0, y: 0}
	 */
	tilePosition?: PointData;
	/**
	 * Scaling of the image that is being tiled.
	 * @default {x: 1, y: 1}
	 */
	tileScale?: PointData;
	/**
	 * The rotation of the image that is being tiled.
	 * @default 0
	 */
	tileRotation?: number;
	/**
	 * The texture to use for the sprite.
	 * @default Texture.WHITE
	 */
	texture?: Texture;
	/**
	 * The width of the tiling sprite. #
	 * @default 256
	 */
	width?: number;
	/**
	 * The height of the tiling sprite.
	 * @default 256
	 */
	height?: number;
	/**
	 * @todo
	 * @default false
	 */
	applyAnchorToTexture?: boolean;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
}
export interface TilingSprite extends PixiMixins.TilingSprite, ViewContainer {
}
/**
 * A tiling sprite is a fast way of rendering a tiling image.
 * @example
 * const tilingSprite = new TilingSprite({
 *    texture: Texture.from('assets/image.png'),
 *    width: 100,
 *    height: 100,
 * });
 *
 * tilingSprite.tilePosition.x = 100;
 * tilingSprite.tilePosition.y = 100;
 *
 * app.stage.addChild(tilingSprite);
 * @memberof scene
 * @extends scene.Container
 */
export declare class TilingSprite extends ViewContainer implements View, Instruction {
	/**
	 * Creates a new tiling sprite.
	 * @param source - The source to create the texture from.
	 * @param options - The options for creating the tiling sprite.
	 * @returns A new tiling sprite.
	 */
	static from(source: Texture | string, options?: TilingSpriteOptions): TilingSprite;
	/** default options for the TilingSprite */
	static defaultOptions: TilingSpriteOptions;
	readonly renderPipeId: string;
	readonly batched = true;
	/**
	 * Flags whether the tiling pattern should originate from the origin instead of the top-left corner in
	 * local space.
	 *
	 * This will make the texture coordinates assigned to each vertex dependent on the value of the anchor. Without
	 * this, the top-left corner always gets the (0, 0) texture coordinate.
	 * @default false
	 */
	applyAnchorToTexture: boolean;
	/**
	 * @see {@link scene.TilingSpriteOptions.applyAnchorToTexture}
	 * @deprecated since 8.0.0
	 */
	get uvRespectAnchor(): boolean;
	set uvRespectAnchor(value: boolean);
	_anchor: ObservablePoint;
	_tileTransform: Transform;
	_texture: Texture;
	private _width;
	private _height;
	/**
	 * @param {rendering.Texture | scene.TilingSpriteOptions} options - The options for creating the tiling sprite.
	 */
	constructor(options?: Texture | TilingSpriteOptions);
	/** @deprecated since 8.0.0 */
	constructor(texture: Texture, width: number, height: number);
	/**
	 * Changes frame clamping in corresponding textureMatrix
	 * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
	 * @default 0.5
	 * @member {number}
	 */
	get clampMargin(): number;
	set clampMargin(value: number);
	/**
	 * The anchor sets the origin point of the sprite. The default value is taken from the {@link Texture}
	 * and passed to the constructor.
	 *
	 * The default is \`(0,0)\`, this means the sprite's origin is the top left.
	 *
	 * Setting the anchor to \`(0.5,0.5)\` means the sprite's origin is centered.
	 *
	 * Setting the anchor to \`(1,1)\` would mean the sprite's origin point will be the bottom right corner.
	 *
	 * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
	 * @example
	 * import { TilingSprite } from 'pixi.js';
	 *
	 * const sprite = new TilingSprite({texture: Texture.WHITE});
	 * sprite.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
	 */
	get anchor(): ObservablePoint;
	set anchor(value: PointData | number);
	/** The offset of the image that is being tiled. */
	get tilePosition(): ObservablePoint;
	set tilePosition(value: PointData);
	/** The scaling of the image that is being tiled. */
	get tileScale(): ObservablePoint;
	set tileScale(value: PointData | number);
	set tileRotation(value: number);
	/** The rotation of the image that is being tiled. */
	get tileRotation(): number;
	/** The transform of the image that is being tiled. */
	get tileTransform(): Transform;
	set texture(value: Texture);
	/** The texture that the sprite is using. */
	get texture(): Texture;
	/** The width of the tiling area. */
	set width(value: number);
	get width(): number;
	set height(value: number);
	/** The height of the tiling area. */
	get height(): number;
	/**
	 * Sets the size of the TilingSprite to the specified width and height.
	 * This is faster than setting the width and height separately.
	 * @param value - This can be either a number or a [Size]{@link Size} object.
	 * @param height - The height to set. Defaults to the value of \`width\` if not provided.
	 */
	setSize(value: number | Optional<Size, "height">, height?: number): void;
	/**
	 * Retrieves the size of the TilingSprite as a [Size]{@link Size} object.
	 * This is faster than get the width and height separately.
	 * @param out - Optional object to store the size in.
	 * @returns - The size of the TilingSprite.
	 */
	getSize(out?: Size): Size;
	/**
	 * @private
	 */
	protected updateBounds(): void;
	/**
	 * Checks if the object contains the given point.
	 * @param point - The point to check
	 */
	containsPoint(point: PointData): boolean;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
}
export declare class TilingSpritePipe implements RenderPipe<TilingSprite> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "tilingSprite";
	};
	private _renderer;
	private readonly _state;
	private readonly _tilingSpriteDataHash;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	validateRenderable(renderable: TilingSprite): boolean;
	addRenderable(tilingSprite: TilingSprite, instructionSet: InstructionSet): void;
	execute(tilingSprite: TilingSprite): void;
	updateRenderable(tilingSprite: TilingSprite): void;
	destroyRenderable(tilingSprite: TilingSprite): void;
	private _getTilingSpriteData;
	private _initTilingSpriteData;
	private _updateBatchableMesh;
	destroy(): void;
	private _updateCanBatch;
}
export declare function applyMatrix(array: TypedArray, stride: number, offset: number, matrix: Matrix): void;
export declare class QuadGeometry extends MeshGeometry {
	constructor();
}
export declare function setPositions(tilingSprite: TilingSprite, positions: Float32Array): void;
export declare function setUvs(tilingSprite: TilingSprite, uvs: Float32Array): void;
/**
 * A number, or a string containing a number.
 * @memberof text
 * @typedef {object} FontMetrics
 * @property {number} ascent - Font ascent
 * @property {number} descent - Font descent
 * @property {number} fontSize - Font size
 */
export interface FontMetrics {
	ascent: number;
	descent: number;
	fontSize: number;
}
/**
 * The TextMetrics object represents the measurement of a block of text with a specified style.
 * @example
 * import { CanvasTextMetrics, TextStyle } from 'pixi.js';
 *
 * const style = new TextStyle({
 *     fontFamily: 'Arial',
 *     fontSize: 24,
 *     fill: 0xff1010,
 *     align: 'center',
 * });
 * const textMetrics = CanvasTextMetrics.measureText('Your text', style);
 * @memberof text
 */
export declare class CanvasTextMetrics {
	/** The text that was measured. */
	text: string;
	/** The style that was measured. */
	style: TextStyle;
	/** The measured width of the text. */
	width: number;
	/** The measured height of the text. */
	height: number;
	/** An array of lines of the text broken by new lines and wrapping is specified in style. */
	lines: string[];
	/** An array of the line widths for each line matched to \`lines\`. */
	lineWidths: number[];
	/** The measured line height for this style. */
	lineHeight: number;
	/** The maximum line width for all measured lines. */
	maxLineWidth: number;
	/** The font properties object from TextMetrics.measureFont. */
	fontProperties: FontMetrics;
	/**
	 * String used for calculate font metrics.
	 * These characters are all tall to help calculate the height required for text.
	 */
	static METRICS_STRING: string;
	/** Baseline symbol for calculate font metrics. */
	static BASELINE_SYMBOL: string;
	/** Baseline multiplier for calculate font metrics. */
	static BASELINE_MULTIPLIER: number;
	/** Height multiplier for setting height of canvas to calculate font metrics. */
	static HEIGHT_MULTIPLIER: number;
	/**
	 * A Unicode "character", or "grapheme cluster", can be composed of multiple Unicode code points,
	 * such as letters with diacritical marks (e.g. \`'\\u0065\\u0301'\`, letter e with acute)
	 * or emojis with modifiers (e.g. \`'\\uD83E\\uDDD1\\u200D\\uD83D\\uDCBB'\`, technologist).
	 * The new \`Intl.Segmenter\` API in ES2022 can split the string into grapheme clusters correctly. If it is not available,
	 * PixiJS will fallback to use the iterator of String, which can only spilt the string into code points.
	 * If you want to get full functionality in environments that don't support \`Intl.Segmenter\` (such as Firefox),
	 * you can use other libraries such as [grapheme-splitter]{@link https://www.npmjs.com/package/grapheme-splitter}
	 * or [graphemer]{@link https://www.npmjs.com/package/graphemer} to create a polyfill. Since these libraries can be
	 * relatively large in size to handle various Unicode grapheme clusters properly, PixiJS won't use them directly.
	 */
	static graphemeSegmenter: (s: string) => string[];
	static _experimentalLetterSpacingSupported?: boolean;
	/**
	 * Checking that we can use modern canvas 2D API.
	 *
	 * Note: This is an unstable API, Chrome < 94 use \`textLetterSpacing\`, later versions use \`letterSpacing\`.
	 * @see TextMetrics.experimentalLetterSpacing
	 * @see https://developer.mozilla.org/en-US/docs/Web/API/ICanvasRenderingContext2D/letterSpacing
	 * @see https://developer.chrome.com/origintrials/#/view_trial/3585991203293757441
	 */
	static get experimentalLetterSpacingSupported(): boolean;
	/**
	 * New rendering behavior for letter-spacing which uses Chrome's new native API. This will
	 * lead to more accurate letter-spacing results because it does not try to manually draw
	 * each character. However, this Chrome API is experimental and may not serve all cases yet.
	 * @see TextMetrics.experimentalLetterSpacingSupported
	 */
	static experimentalLetterSpacing: boolean;
	/** Cache of {@see TextMetrics.FontMetrics} objects. */
	private static _fonts;
	/** Cache of new line chars. */
	private static readonly _newlines;
	/** Cache of breaking spaces. */
	private static readonly _breakingSpaces;
	private static __canvas;
	private static __context;
	private static readonly _measurementCache;
	/**
	 * @param text - the text that was measured
	 * @param style - the style that was measured
	 * @param width - the measured width of the text
	 * @param height - the measured height of the text
	 * @param lines - an array of the lines of text broken by new lines and wrapping if specified in style
	 * @param lineWidths - an array of the line widths for each line matched to \`lines\`
	 * @param lineHeight - the measured line height for this style
	 * @param maxLineWidth - the maximum line width for all measured lines
	 * @param {FontMetrics} fontProperties - the font properties object from TextMetrics.measureFont
	 */
	constructor(text: string, style: TextStyle, width: number, height: number, lines: string[], lineWidths: number[], lineHeight: number, maxLineWidth: number, fontProperties: FontMetrics);
	/**
	 * Measures the supplied string of text and returns a Rectangle.
	 * @param text - The text to measure.
	 * @param style - The text style to use for measuring
	 * @param canvas - optional specification of the canvas to use for measuring.
	 * @param wordWrap
	 * @returns Measured width and height of the text.
	 */
	static measureText(text: string, style: TextStyle, canvas?: ICanvas, wordWrap?: boolean): CanvasTextMetrics;
	private static _measureText;
	/**
	 * Applies newlines to a string to have it optimally fit into the horizontal
	 * bounds set by the Text object's wordWrapWidth property.
	 * @param text - String to apply word wrapping to
	 * @param style - the style to use when wrapping
	 * @param canvas - optional specification of the canvas to use for measuring.
	 * @returns New string with new lines applied where required
	 */
	private static _wordWrap;
	/**
	 * Convenience function for logging each line added during the wordWrap method.
	 * @param line    - The line of text to add
	 * @param newLine - Add new line character to end
	 * @returns A formatted line
	 */
	private static _addLine;
	/**
	 * Gets & sets the widths of calculated characters in a cache object
	 * @param key            - The key
	 * @param letterSpacing  - The letter spacing
	 * @param cache          - The cache
	 * @param context        - The canvas context
	 * @returns The from cache.
	 */
	private static _getFromCache;
	/**
	 * Determines whether we should collapse breaking spaces.
	 * @param whiteSpace - The TextStyle property whiteSpace
	 * @returns Should collapse
	 */
	private static _collapseSpaces;
	/**
	 * Determines whether we should collapse newLine chars.
	 * @param whiteSpace - The white space
	 * @returns should collapse
	 */
	private static _collapseNewlines;
	/**
	 * Trims breaking whitespaces from string.
	 * @param text - The text
	 * @returns Trimmed string
	 */
	private static _trimRight;
	/**
	 * Determines if char is a newline.
	 * @param char - The character
	 * @returns True if newline, False otherwise.
	 */
	private static _isNewline;
	/**
	 * Determines if char is a breaking whitespace.
	 *
	 * It allows one to determine whether char should be a breaking whitespace
	 * For example certain characters in CJK langs or numbers.
	 * It must return a boolean.
	 * @param char - The character
	 * @param [_nextChar] - The next character
	 * @returns True if whitespace, False otherwise.
	 */
	static isBreakingSpace(char: string, _nextChar?: string): boolean;
	/**
	 * Splits a string into words, breaking-spaces and newLine characters
	 * @param text - The text
	 * @returns A tokenized array
	 */
	private static _tokenize;
	/**
	 * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
	 *
	 * It allows one to customise which words should break
	 * Examples are if the token is CJK or numbers.
	 * It must return a boolean.
	 * @param _token - The token
	 * @param breakWords - The style attr break words
	 * @returns Whether to break word or not
	 */
	static canBreakWords(_token: string, breakWords: boolean): boolean;
	/**
	 * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
	 *
	 * It allows one to determine whether a pair of characters
	 * should be broken by newlines
	 * For example certain characters in CJK langs or numbers.
	 * It must return a boolean.
	 * @param _char - The character
	 * @param _nextChar - The next character
	 * @param _token - The token/word the characters are from
	 * @param _index - The index in the token of the char
	 * @param _breakWords - The style attr break words
	 * @returns whether to break word or not
	 */
	static canBreakChars(_char: string, _nextChar: string, _token: string, _index: number, _breakWords: boolean): boolean;
	/**
	 * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
	 *
	 * It is called when a token (usually a word) has to be split into separate pieces
	 * in order to determine the point to break a word.
	 * It must return an array of characters.
	 * @param token - The token to split
	 * @returns The characters of the token
	 * @see CanvasTextMetrics.graphemeSegmenter
	 */
	static wordWrapSplit(token: string): string[];
	/**
	 * Calculates the ascent, descent and fontSize of a given font-style
	 * @param font - String representing the style of the font
	 * @returns Font properties object
	 */
	static measureFont(font: string): FontMetrics;
	/**
	 * Clear font metrics in metrics cache.
	 * @param {string} [font] - font name. If font name not set then clear cache for all fonts.
	 */
	static clearMetrics(font?: string): void;
	/**
	 * Cached canvas element for measuring text
	 * TODO: this should be private, but isn't because of backward compat, will fix later.
	 * @ignore
	 */
	static get _canvas(): ICanvas;
	/**
	 * TODO: this should be private, but isn't because of backward compat, will fix later.
	 * @ignore
	 */
	static get _context(): ICanvasRenderingContext2D;
}
/** @memberof text */
export interface CharData {
	/** Unique id of character */
	id: number;
	/** x-offset to apply when rendering character */
	xOffset: number;
	/** y-offset to apply when rendering character. */
	yOffset: number;
	/** Advancement to apply to next character. */
	xAdvance: number;
	/** The kerning values for this character. */
	kerning: Record<string, number>;
	/** The texture of the character. */
	texture?: Texture;
}
/**
 * The raw data of a character in a bitmap font.
 * @memberof text
 */
export interface RawCharData extends Omit<CharData, "texture"> {
	/** The page of the font texture that the character is on. */
	page: number;
	/** The x position of the character in the page. */
	x: number;
	/** The y position of the character in the page. */
	y: number;
	/** The width of the character in the page. */
	width: number;
	/** The height of the character in the page. */
	height: number;
	/** The letter of the character. */
	letter: string;
}
/**
 * The raw data of a bitmap font.
 * @memberof text
 */
export interface BitmapFontData {
	/** The offset of the font face from the baseline. */
	baseLineOffset: number;
	/** The map of characters by character code. */
	chars: Record<string, RawCharData>;
	/** The map of base page textures (i.e., sheets of glyphs). */
	pages: {
		/** Unique id for bitmap texture */
		id: number;
		/** File name */
		file: string;
	}[];
	/** The line-height of the font face in pixels. */
	lineHeight: number;
	/** The size of the font face in pixels. */
	fontSize: number;
	/** The name of the font face. */
	fontFamily: string;
	/** The range and type of the distance field for this font. */
	distanceField?: {
		/** Type of distance field */
		type: "sdf" | "msdf" | "none";
		/** Range of the distance field in pixels */
		range: number;
	};
}
interface BitmapFontEvents<Type> {
	destroy: [
		Type
	];
}
/**
 * An abstract representation of a bitmap font.
 * @memberof text
 */
export declare abstract class AbstractBitmapFont<FontType> extends EventEmitter<BitmapFontEvents<FontType>> implements Omit<BitmapFontData, "chars" | "pages" | "fontSize"> {
	/** The map of characters by character code. */
	readonly chars: Record<string, CharData>;
	/**
	 * The line-height of the font face in pixels.
	 * @type {number}
	 */
	readonly lineHeight: BitmapFontData["lineHeight"];
	/**
	 * The name of the font face
	 * @type {string}
	 */
	readonly fontFamily: BitmapFontData["fontFamily"];
	/** The metrics of the font face. */
	readonly fontMetrics: FontMetrics;
	/**
	 * The offset of the font face from the baseline.
	 * @type {number}
	 */
	readonly baseLineOffset: BitmapFontData["baseLineOffset"];
	/** The range and type of the distance field for this font. */
	readonly distanceField: BitmapFontData["distanceField"];
	/** The map of base page textures (i.e., sheets of glyphs). */
	readonly pages: {
		texture: Texture;
	}[];
	/** should the fill for this font be applied as a tint to the text. */
	applyFillAsTint: boolean;
	/** The size of the font face in pixels. */
	readonly baseMeasurementFontSize: number;
	protected baseRenderedFontSize: number;
	/**
	 * The name of the font face.
	 * @deprecated since 8.0.0 Use \`fontFamily\` instead.
	 */
	get font(): BitmapFontData["fontFamily"];
	/**
	 * The map of base page textures (i.e., sheets of glyphs).
	 * @deprecated since 8.0.0 Use \`pages\` instead.
	 */
	get pageTextures(): AbstractBitmapFont<FontType>["pages"];
	/**
	 * The size of the font face in pixels.
	 * @deprecated since 8.0.0 Use \`fontMetrics.fontSize\` instead.
	 */
	get size(): BitmapFontData["fontSize"];
	/**
	 * The kind of distance field for this font or "none".
	 * @deprecated since 8.0.0 Use \`distanceField.type\` instead.
	 */
	get distanceFieldRange(): NonNullable<BitmapFontData["distanceField"]>["range"];
	/**
	 * The range of the distance field in pixels.
	 * @deprecated since 8.0.0 Use \`distanceField.range\` instead.
	 */
	get distanceFieldType(): NonNullable<BitmapFontData["distanceField"]>["type"];
	destroy(destroyTextures?: boolean): void;
}
/**
 * Internal data format used to convert to BitmapFontData.
 * @private
 */
export interface BitmapFontRawData {
	info: {
		face: string;
		size: string;
	}[];
	common: {
		lineHeight: string;
		base: string;
	}[];
	page: {
		id: string;
		file: string;
	}[];
	chars: {
		count: number;
	}[];
	char: {
		id: string;
		page: string;
		xoffset: string;
		yoffset: string;
		xadvance: string;
		x: string;
		y: string;
		width: string;
		height: string;
		letter?: string;
		char?: string;
	}[];
	kernings?: {
		count: number;
	}[];
	kerning?: {
		first: string;
		second: string;
		amount: string;
	}[];
	distanceField?: {
		fieldType: "sdf" | "msdf" | "none";
		distanceRange: string;
	}[];
}
export declare const bitmapFontTextParser: {
	test(data: string | XMLDocument | BitmapFontData): boolean;
	parse(txt: string): BitmapFontData;
};
export declare const bitmapFontXMLParser: {
	test(data: string | XMLDocument | BitmapFontData): boolean;
	parse(xml: Document): BitmapFontData;
};
export declare const bitmapFontXMLStringParser: {
	test(data: string | XMLDocument | BitmapFontData): boolean;
	parse(data: string): BitmapFontData;
};
export type ArrayOr<T> = T | T[];
/**
 * Names of the parsers that are built into PixiJS.
 * Can be any of the following defaults:
 * - \`loadJson\`
 * - \`loadSVG\`
 * - \`loadTextures\`
 * - \`loadTxt\`
 * - \`loadVideo\`
 * - \`loadWebFont\`
 * or a custom parser name.
 * @memberof assets
 */
export type LoadParserName = "loadJson" | "loadSVG" | "loadTextures" | "loadTxt" | "loadVideo" | "loadWebFont" | string;
/**
 * A fully resolved asset, with all the information needed to load it.
 * @memberof assets
 */
export interface ResolvedAsset<T = any> {
	/** Aliases associated with asset */
	alias?: string[];
	/** The URL or relative path to the asset */
	src?: string;
	/** Optional data */
	data?: T;
	/** Format, usually the file extension */
	format?: string;
	/** An override that will ensure that the asset is loaded with a specific parser */
	loadParser?: LoadParserName;
}
/**
 * A fully resolved src, Glob patterns will not work here, and the src will be resolved to a single file.
 * @memberof assets
 * @property {string} src - The URL or relative path to the asset
 * @property {string} format - Format, usually the file extension
 * @property {string} loadParser - An override that will ensure that the asset is loaded with a specific parser
 * @property {any} data - Optional data
 */
export type ResolvedSrc = Pick<ResolvedAsset, "src" | "format" | "loadParser" | "data">;
/**
 * A valid asset src. This can be a string, or a [ResolvedSrc]{@link assets.ResolvedSrc},
 * or an array of either.
 * @memberof assets
 */
export type AssetSrc = ArrayOr<string> | (ArrayOr<ResolvedSrc> & {
	[key: string]: any;
});
/**
 * An asset that has not been resolved yet.
 * @memberof assets
 */
export type UnresolvedAsset<T = any> = Pick<ResolvedAsset<T>, "data" | "format" | "loadParser"> & {
	/** Aliases associated with asset */
	alias?: ArrayOr<string>;
	/** The URL or relative path to the asset */
	src?: AssetSrc;
	[key: string]: any;
};
/**
 * Structure of a bundle found in a {@link assets.AssetsManifest Manifest} file
 * @memberof assets
 */
export interface AssetsBundle {
	/** The name of the bundle */
	name: string;
	/** The assets in the bundle */
	assets: UnresolvedAsset[] | Record<string, ArrayOr<string> | UnresolvedAsset>;
}
/**
 * The expected format of a manifest. This could be auto generated or hand made
 * @memberof assets
 */
export interface AssetsManifest {
	/** array of bundles */
	bundles: AssetsBundle[];
}
/**
 * A promise and parser pair
 * @memberof assets
 */
export interface PromiseAndParser {
	/** the promise that is loading the asset */
	promise: Promise<any>;
	/** the parser that is loading the asset */
	parser: LoaderParser;
}
/**
 * The Loader is responsible for loading all assets, such as images, spritesheets, audio files, etc.
 * It does not do anything clever with URLs - it just loads stuff!
 * Behind the scenes all things are cached using promises. This means it's impossible to load an asset more than once.
 * Through the use of LoaderParsers, the loader can understand how to load any kind of file!
 *
 * It is not intended that this class is created by developers - its part of the Asset class
 * This is the second major system of PixiJS' main Assets class
 * @memberof assets
 */
export declare class Loader {
	private readonly _parsers;
	private _parserHash;
	private _parsersValidated;
	/**
	 * All loader parsers registered
	 * @type {assets.LoaderParser[]}
	 */
	parsers: LoaderParser<any, any, Record<string, any>>[];
	/** Cache loading promises that ae currently active */
	promiseCache: Record<string, PromiseAndParser>;
	/** function used for testing */
	reset(): void;
	/**
	 * Used internally to generate a promise for the asset to be loaded.
	 * @param url - The URL to be loaded
	 * @param data - any custom additional information relevant to the asset being loaded
	 * @returns - a promise that will resolve to an Asset for example a Texture of a JSON object
	 */
	private _getLoadPromiseAndParser;
	/**
	 * Loads one or more assets using the parsers added to the Loader.
	 * @example
	 * // Single asset:
	 * const asset = await Loader.load('cool.png');
	 * console.log(asset);
	 *
	 * // Multiple assets:
	 * const assets = await Loader.load(['cool.png', 'cooler.png']);
	 * console.log(assets);
	 * @param assetsToLoadIn - urls that you want to load, or a single one!
	 * @param onProgress - For multiple asset loading only, an optional function that is called
	 * when progress on asset loading is made. The function is passed a single parameter, \`progress\`,
	 * which represents the percentage (0.0 - 1.0) of the assets loaded. Do not use this function
	 * to detect when assets are complete and available, instead use the Promise returned by this function.
	 */
	load<T = any>(assetsToLoadIn: string | ResolvedAsset, onProgress?: (progress: number) => void): Promise<T>;
	load<T = any>(assetsToLoadIn: string[] | ResolvedAsset[], onProgress?: (progress: number) => void): Promise<Record<string, T>>;
	/**
	 * Unloads one or more assets. Any unloaded assets will be destroyed, freeing up memory for your app.
	 * The parser that created the asset, will be the one that unloads it.
	 * @example
	 * // Single asset:
	 * const asset = await Loader.load('cool.png');
	 *
	 * await Loader.unload('cool.png');
	 *
	 * console.log(asset.destroyed); // true
	 * @param assetsToUnloadIn - urls that you want to unload, or a single one!
	 */
	unload(assetsToUnloadIn: string | string[] | ResolvedAsset | ResolvedAsset[]): Promise<void>;
	/** validates our parsers, right now it only checks for name conflicts but we can add more here as required! */
	private _validateParsers;
}
/**
 * The extension priority for loader parsers.
 * Helpful when managing multiple parsers that share the same extension test.
 * The higher priority parsers will be checked first.
 * @enum {number}
 */
export declare enum LoaderParserPriority {
	/** Generic parsers: txt, json, webfonts */
	Low = 0,
	/** PixiJS assets with generic extensions: spritesheets, bitmapfonts  */
	Normal = 1,
	/** Specific texture types: svg, png, ktx, dds, basis */
	High = 2
}
/** A more verbose version of the LoaderParser, allowing you to set the loaded, parsed, and unloaded asset separately */
export interface LoaderParserAdvanced<ASSET = any, PARSED_ASSET = ASSET, UNLOAD_ASSET = ASSET, META_DATA = any, CONFIG = Record<string, any>> {
	/** Should be ExtensionType.LoaderParser */
	extension?: ExtensionMetadata;
	/** A config to adjust the parser */
	config?: CONFIG;
	/** The name of the parser (this can be used when specifying loadParser in a ResolvedAsset) */
	name: string;
	/**
	 * Each URL to load will be tested here,
	 * if the test is passed the assets are loaded using the load function below.
	 * Good place to test for things like file extensions!
	 * @param url - The URL to test
	 * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
	 * @param loader - The loader instance
	 */
	test?: (url: string, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => boolean;
	/**
	 * This is the promise that loads the URL provided
	 * resolves with a loaded asset if returned by the parser.
	 * @param url - The URL to load
	 * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
	 * @param loader - The loader instance
	 */
	load?: <T>(url: string, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<ASSET | T>;
	/**
	 * This function is used to test if the parse function should be run on the asset
	 * If this returns true then parse is called with the asset
	 * @param asset - The loaded asset data
	 * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
	 * @param loader - The loader instance
	 */
	testParse?: (asset: ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<boolean>;
	/**
	 * Gets called on the asset it testParse passes. Useful to convert a raw asset into something more useful
	 * @param asset - The loaded asset data
	 * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
	 * @param loader - The loader instance
	 */
	parse?: <T>(asset: ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<PARSED_ASSET | T>;
	/**
	 * If an asset is parsed using this parser, the unload function will be called when the user requests an asset
	 * to be unloaded. This is useful for things like sounds or textures that can be unloaded from memory
	 * @param asset - The asset to unload/destroy
	 * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
	 * @param loader - The loader instance
	 */
	unload?: (asset: UNLOAD_ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<void> | void;
}
/**
 * The interface to define a loader parser *(all functions are optional)*.
 *
 * When you create a \`parser\` object, the flow for every asset loaded is:
 *
 * 1. \`parser.test()\` - Each URL to load will be tested here, if the test is passed the assets are
 * loaded using the load function below. Good place to test for things like file extensions!
 * 2. \`parser.load()\` - This is the promise that loads the URL provided resolves with a loaded asset
 * if returned by the parser.
 * 3. \`parser.testParse()\` - This function is used to test if the parse function should be run on the
 *  asset If this returns true then parse is called with the asset
 * 4. \`parse.parse()\` - Gets called on the asset it testParse passes. Useful to convert a raw asset
 *  into something more useful
 *
 * <br/>
 * Some loaders may only be used for parsing, some only for loading, and some for both!
 * @memberof assets
 */
export interface LoaderParser<ASSET = any, META_DATA = any, CONFIG = Record<string, any>> extends LoaderParserAdvanced<ASSET, ASSET, ASSET, META_DATA, CONFIG> {
}
export interface BitmapTextLayoutData {
	width: number;
	height: number;
	scale: number;
	offsetY: number;
	lines: {
		width: number;
		charPositions: number[];
		chars: string[];
		spaceWidth: number;
		spacesIndex: number[];
	}[];
}
export declare function getBitmapTextLayout(chars: string[], style: TextStyle, font: AbstractBitmapFont<any>, trimEnd: boolean): BitmapTextLayoutData;
/**
 *
 * The options for installing a new BitmapFont. Once installed the font will be available for use in the BitmapText.
 * It can be accessed by the \`fontFamily\` property of the TextStyle.
 *
 * Install a new BitmapFont will create the characters provided for the font and store them in the cache.
 * But don't worry, if a character is requested that hasn't been generated yet, it will be created on the fly.
 * @memberof text
 */
export interface BitmapFontInstallOptions {
	/** the name of the font, this will be the name you use in the fontFamily of text style to access this font */
	name?: string;
	/**
	 * Characters included in the font set. You can also use ranges.
	 * For example, \`[['a', 'z'], ['A', 'Z'], "!@#$%^&*()~{}[] "]\`.
	 * Don't forget to include spaces ' ' in your character set!
	 * @default BitmapFont.ALPHANUMERIC
	 */
	chars?: string | (string | string[])[];
	/**
	 * Render resolution for glyphs.
	 * @default 1
	 */
	resolution?: number;
	/**
	 * Padding between glyphs on texture atlas. Lower values could mean more visual artifacts
	 * and bleeding from other glyphs, larger values increase the space required on the texture.
	 * @default 4
	 */
	padding?: number;
	/**
	 * Skip generation of kerning information for the BitmapFont.
	 * If true, this could potentially increase the performance, but may impact the rendered text appearance.
	 * @default false
	 */
	skipKerning?: boolean;
	/** Style options to render with BitmapFont. */
	style?: TextStyle | TextStyleOptions;
}
declare class BitmapFontManagerClass {
	/**
	 * This character set includes all the letters in the alphabet (both lower- and upper- case).
	 * @type {string[][]}
	 * @example
	 * BitmapFont.from('ExampleFont', style, { chars: BitmapFont.ALPHA })
	 */
	readonly ALPHA: (string | string[])[];
	/**
	 * This character set includes all decimal digits (from 0 to 9).
	 * @type {string[][]}
	 * @example
	 * BitmapFont.from('ExampleFont', style, { chars: BitmapFont.NUMERIC })
	 */
	readonly NUMERIC: string[][];
	/**
	 * This character set is the union of \`BitmapFont.ALPHA\` and \`BitmapFont.NUMERIC\`.
	 * @type {string[][]}
	 */
	readonly ALPHANUMERIC: (string | string[])[];
	/**
	 * This character set consists of all the ASCII table.
	 * @member {string[][]}
	 * @see http://www.asciitable.com/
	 */
	readonly ASCII: string[][];
	/** Default options for installing a new BitmapFont. */
	defaultOptions: Omit<BitmapFontInstallOptions, "style">;
	/**
	 * Get a font for the specified text and style.
	 * @param text - The text to get the font for
	 * @param style - The style to use
	 */
	getFont(text: string, style: TextStyle): BitmapFont;
	/**
	 * Get the layout of a text for the specified style.
	 * @param text - The text to get the layout for
	 * @param style - The style to use
	 * @param trimEnd - Whether to ignore whitespaces at the end of each line
	 */
	getLayout(text: string, style: TextStyle, trimEnd?: boolean): BitmapTextLayoutData;
	/**
	 * Measure the text using the specified style.
	 * @param text - The text to measure
	 * @param style - The style to use
	 * @param trimEnd - Whether to ignore whitespaces at the end of each line
	 */
	measureText(text: string, style: TextStyle, trimEnd?: boolean): {
		width: number;
		height: number;
		scale: number;
		offsetY: number;
	};
	/**
	 * Generates a bitmap-font for the given style and character set
	 * @param options - Setup options for font generation.
	 * @returns Font generated by style options.
	 * @example
	 * import { BitmapFontManager, BitmapText } from 'pixi.js';
	 *
	 * BitmapFontManager.install('TitleFont', {
	 *     fontFamily: 'Arial',
	 *     fontSize: 12,
	 *     strokeThickness: 2,
	 *     fill: 'purple',
	 * });
	 *
	 * const title = new BitmapText({ text: 'This is the title', fontFamily: 'TitleFont' });
	 */
	install(options: BitmapFontInstallOptions): BitmapFont;
	/** @deprecated since 7.0.0 */
	install(name: string, style?: TextStyle | TextStyleOptions, options?: BitmapFontInstallOptions): BitmapFont;
	/**
	 * Uninstalls a bitmap font from the cache.
	 * @param {string} name - The name of the bitmap font to uninstall.
	 */
	uninstall(name: string): void;
}
export declare const BitmapFontManager: BitmapFontManagerClass;
/**
 * Options for creating a BitmapFont.
 * @memberof text
 */
export interface BitmapFontOptions {
	data: BitmapFontData;
	textures: Texture[];
}
/**
 * A BitmapFont object represents a particular font face, size, and style.
 * @memberof text
 */
export declare class BitmapFont extends AbstractBitmapFont<BitmapFont> {
	/** the url of the font */
	url?: string;
	constructor(options: BitmapFontOptions, url?: string);
	/** Destroys the BitmapFont object. */
	destroy(): void;
	/**
	 * Generates a bitmap-font for the given style and character set
	 * @param options - Setup options for font generation.
	 * @returns Font generated by style options.
	 * @example
	 * import { BitmapFont, BitmapText } from 'pixi.js';
	 *
	 * BitmapFont.install('TitleFont', {
	 *     fontFamily: 'Arial',
	 *     fontSize: 12,
	 *     strokeThickness: 2,
	 *     fill: 'purple',
	 * });
	 *
	 * const title = new BitmapText({ text: 'This is the title', fontFamily: 'TitleFont' });
	 */
	static install(options: BitmapFontInstallOptions): void;
	/**
	 * Uninstalls a bitmap font from the cache.
	 * @param {string} name - The name of the bitmap font to uninstall.
	 */
	static uninstall(name: string): void;
}
/** simple loader plugin for loading in bitmap fonts! */
export declare const bitmapFontCachePlugin: {
	extension: {
		type: ExtensionType.CacheParser;
		name: string;
	};
	test: (asset: BitmapFont) => boolean;
	getCacheableAssets(keys: string[], asset: BitmapFont): Record<string, BitmapFont>;
};
export declare const loadBitmapFont: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
	};
	name: string;
	test(url: string): boolean;
	testParse(data: string): Promise<boolean>;
	parse<T>(asset: string, data: ResolvedAsset, loader: Loader): Promise<BitmapFont>;
	load<T_1>(url: string, _options: ResolvedAsset): Promise<string>;
	unload(bitmapFont: BitmapFont, _resolvedAsset: ResolvedAsset<any>, loader: Loader): Promise<void>;
};
export interface BitmapText extends PixiMixins.BitmapText, AbstractText<TextStyle, TextStyleOptions> {
}
/**
 * A BitmapText Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and give the \`wordWrapWidth\` property a value.
 *
 * The text is created using a bitmap font (a sprite sheet of characters).
 *
 * The primary advantage of this render mode over \`text\` is that all of your textures are pre-generated and loaded,
 * meaning that rendering is fast, and changing text is much faster than Text.
 *
 * The primary disadvantage is that supporting character sets other than latin, such as CJK languages,
 * may be impractical due to the number of characters.
 *
 * <b>Pre-loaded BitmapFonts:</b>
 *
 *
 * PixiJS enables the loading of BitmapFonts through its Asset Manager, supporting both XML and FNT formats.
 * Additionally, PixiJS is compatible with MSDF (Multi-channel Signed Distance Field) and SDF (Signed Distance Field) fonts.
 * These advanced font types allow for scaling without quality degradation and must be created with specific tools,
 * such as the one available at https://msdf-bmfont.donmccurdy.com/.
 *
 * <b>Dynamically Generated BitmapFonts:</b>
 *
 *
 * PixiJS also offers the capability to generate BitmapFonts dynamically. This means that fonts are created in real-time
 * based on specified styles, eliminating the need for pre-loading. This process is initiated simply by assigning a style
 * to a BitmapText object, which then automatically generates the required font.
 *
 * However, dynamically generating a large number of fonts may lead to significant memory use. To prevent this,
 * PixiJS smartly attempts to reuse fonts that closely match the desired style parameters. For instance, if a text style
 * requires a font size of 80 but a similar font of size 100 has already been generated, PixiJS will scale the existing
 * font to fit the new requirement, rather than creating a new font from scratch.
 *
 * For those who prefer to manage BitmapFonts manually, PixiJS provides the BitmapFont.install method. This method
 * allows for the pre-generation and preparation of fonts, making them readily available for use by specifying the
 * fontFamily in your text styling.
 *
 * This approach ensures efficient font management within PixiJS, balancing between dynamic generation for flexibility
 * and manual management for optimized performance.
 * @example
 * import { BitmapText, BitmapFont } from 'pixi.js';
 *
 * // generate a dynamic font behind the scenes:
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 *
 * // pre install
 * BitmapFont.install({
 *    name: 'myFont',
 *    style:{
 *        fontFamily: 'Arial',
 *    }
 * })
 *
 * // new bitmap text with preinstalled font
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *        fontFamily: 'myFont',
 *        fontSize: 24,
 *        fill: 0xff1010,
 *        align: 'center',
 *     }
 * }
 *
 * // load a font from an xml file
 * const font = await Assets.load('path/to/myLoadedFont.fnt');
 *
 * // new bitmap text with loaded font
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *        fontFamily: 'myLoadedFont', // the name of the font in the fnt file
 *        fontSize: 24,
 *        fill: 0xff1010,
 *        align: 'center',
 *     }
 * }
 * @memberof scene
 */
export declare class BitmapText extends AbstractText<TextStyle, TextStyleOptions> implements View {
	readonly renderPipeId: string;
	/**
	 * **Note:** Our docs parser struggles to properly understand the constructor signature.
	 * This is the correct signature.
	 * \`\`\`ts
	 * new BitmapText(options?: TextOptions);
	 * \`\`\`
	 * @param { text.TextOptions } options - The options of the bitmap text.
	 */
	constructor(options?: TextOptions);
	/** @deprecated since 8.0.0 */
	constructor(text?: TextString, options?: Partial<TextStyle>);
	/** @private */
	protected updateBounds(): void;
	/**
	 * The resolution / device pixel ratio of the canvas.
	 * @default 1
	 */
	set resolution(value: number);
	get resolution(): number;
}
export declare class BitmapTextPipe implements RenderPipe<BitmapText> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "bitmapText";
	};
	private _renderer;
	private _gpuBitmapText;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	validateRenderable(bitmapText: BitmapText): boolean;
	addRenderable(bitmapText: BitmapText, instructionSet: InstructionSet): void;
	destroyRenderable(bitmapText: BitmapText): void;
	private _destroyRenderableByUid;
	updateRenderable(bitmapText: BitmapText): void;
	private _updateContext;
	private _getGpuBitmapText;
	initGpuText(bitmapText: BitmapText): Graphics;
	private _updateDistanceField;
	destroy(): void;
}
export interface DynamicBitmapFontOptions {
	style: TextStyle;
	skipKerning?: boolean;
	resolution?: number;
	padding?: number;
	overrideFill?: boolean;
	overrideSize?: boolean;
	textureSize?: number;
	mipmap?: boolean;
}
/**
 * A BitmapFont that generates its glyphs dynamically.
 * @memberof text
 * @ignore
 */
export declare class DynamicBitmapFont extends AbstractBitmapFont<DynamicBitmapFont> {
	static defaultOptions: DynamicBitmapFontOptions;
	/**
	 * this is a resolution modifier for the font size..
	 * texture resolution will also be used to scale texture according to its font size also
	 */
	resolution: number;
	/** The pages of the font. */
	readonly pages: {
		canvasAndContext?: CanvasAndContext;
		texture: Texture;
	}[];
	private readonly _padding;
	private readonly _measureCache;
	private _currentChars;
	private _currentX;
	private _currentY;
	private _currentPageIndex;
	private readonly _style;
	private readonly _skipKerning;
	private readonly _textureSize;
	private readonly _mipmap;
	/**
	 * @param options - The options for the dynamic bitmap font.
	 */
	constructor(options: DynamicBitmapFontOptions);
	ensureCharacters(chars: string): void;
	/**
	 * @deprecated since 8.0.0
	 * The map of base page textures (i.e., sheets of glyphs).
	 */
	get pageTextures(): DynamicBitmapFont["pages"];
	private _applyKerning;
	private _nextPage;
	private _setupContext;
	private _drawGlyph;
	destroy(): void;
}
/**
 * Processes the passed character set data and returns a flattened array of all the characters.
 *
 * Ignored because not directly exposed.
 * @ignore
 * @param {string | string[] | string[][] } chars
 * @returns {string[]} the flattened array of characters
 */
export declare function resolveCharacters(chars: string | (string | string[])[]): string[];
/**
 * Constructor options used for \`HTMLText\` instances.
 * @property {string} [text=''] - The string that you would like the text to display.
 * @property {text.HTMLTextStyle | text.HTMLTextStyleOptions} [style] - The style of the text.
 * @memberof text
 */
export type HTMLTextOptions = TextOptions<HTMLTextStyle, HTMLTextStyleOptions> & PixiMixins.HTMLTextOptions;
export interface HTMLText extends PixiMixins.HTMLText, AbstractText<HTMLTextStyle, HTMLTextStyleOptions> {
}
/**
 * A HTMLText Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and give the \`wordWrapWidth\` property a value.
 *
 * HTMLText uses an svg foreignObject to render HTML text.
 *
 *
 * The primary advantages of this render mode are:
 *
 *  - Supports [HTML tags](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/HTML_text_fundamentals)
 * for styling such as \`<strong>\`, or \`<em>\`, as well as \`<span style="">\`
 *
 *       - Better support for emojis and other HTML layout features, better compatibility with CSS
 *     line-height and letter-spacing.
 *
 *
 * The primary disadvantages are:
 *   - Unlike \`text\`, \`html\` rendering will vary slightly between platforms and browsers.
 * \`html\` uses SVG/DOM to render text and not Context2D's fillText like \`text\`.
 *
 *   - Performance and memory usage is on-par with \`text\` (that is to say, slow and heavy)
 *
 *   - Only works with browsers that support <foreignObject>.
 * @example
 * import { HTMLText } from 'pixi.js';
 *
 * const text = new HTMLText({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 * @memberof scene
 */
export declare class HTMLText extends AbstractText<HTMLTextStyle, HTMLTextStyleOptions> implements View {
	readonly renderPipeId: string;
	/**
	 * @param {text.HTMLTextOptions} options - The options of the html text.
	 */
	constructor(options?: HTMLTextOptions);
	/** @deprecated since 8.0.0 */
	constructor(text?: TextString, options?: Partial<HTMLTextStyle>);
	/** @private */
	protected updateBounds(): void;
}
export declare class HTMLTextPipe implements RenderPipe<HTMLText> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "htmlText";
	};
	private _renderer;
	private _gpuText;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	resolutionChange(): void;
	validateRenderable(htmlText: HTMLText): boolean;
	addRenderable(htmlText: HTMLText, instructionSet: InstructionSet): void;
	updateRenderable(htmlText: HTMLText): void;
	destroyRenderable(htmlText: HTMLText): void;
	private _destroyRenderableById;
	private _updateText;
	private _updateGpuText;
	private _getGpuText;
	initGpuText(htmlText: HTMLText): {
		textureNeedsUploading: boolean;
		generatingTexture: boolean;
		texture: Texture<TextureSource<any>>;
		currentKey: string;
		batchableSprite: BatchableSprite;
	};
	destroy(): void;
}
export declare const nssvg = "http://www.w3.org/2000/svg";
export declare const nsxhtml = "http://www.w3.org/1999/xhtml";
export declare class HTMLTextRenderData {
	svgRoot: SVGSVGElement;
	foreignObject: SVGForeignObjectElement;
	domElement: HTMLElement;
	styleElement: HTMLElement;
	image: HTMLImageElement;
	canvasAndContext?: CanvasAndContext;
	constructor();
}
export interface FontCSSStyleOptions {
	fontFamily: string | string[];
	fontWeight: string;
	fontStyle: string;
}
/**
 * This will take a font url and a style and return a css string that can be injected into a style tag
 * This will contain inlined base64 font and the font family information
 * @param style - the style to generate the css for
 * @param url - The url to load the font from
 * @returns - The css string
 */
export declare function loadFontCSS(style: FontCSSStyleOptions, url: string): Promise<string>;
/**
 * System plugin to the renderer to manage HTMLText
 * @memberof rendering
 */
export declare class HTMLTextSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "htmlText";
	};
	static defaultFontOptions: FontCSSStyleOptions;
	private _activeTextures;
	/**
	 * WebGPU has a cors issue when uploading an image that is an SVGImage
	 * To get around this we need to create a canvas draw the image to it and upload that instead.
	 * Bit of a shame.. but no other work around just yet!
	 */
	private readonly _createCanvas;
	private readonly _renderer;
	constructor(renderer: Renderer);
	getTexture(options: HTMLTextOptions): Promise<Texture>;
	getManagedTexture(text: string, resolution: number, style: HTMLTextStyle, textKey: string): Promise<Texture>;
	private _buildTexturePromise;
	private _increaseReferenceCount;
	decreaseReferenceCount(textKey: string): void;
	private _cleanUp;
	getReferenceCount(textKey: string): number;
	destroy(): void;
}
/**
 * Extracts font families from text. It will extract font families from the style, tagStyles and any font families
 * embedded in the text. It should also strip out duplicates as it goes.
 * @param  text - The text to extract font families from
 * @param style - The style to extract font families from
 * @returns {string[]} - The font families as an array of strings
 */
export declare function extractFontFamilies(text: string, style: HTMLTextStyle): string[];
export declare const FontStylePromiseCache: Map<string, Promise<string>>;
/**
 * takes the font families and returns a css string that can be injected into a style tag
 * It will contain the font families and the font urls encoded as base64
 * @param fontFamilies - The font families to load
 * @param style - The FontCSSStyleOptions to load the font with (used for the first font family)
 * @param defaultOptions - The default options to load the font with (used for the rest of the font families)
 * @param defaultOptions.fontWeight - The default font weight
 * @param defaultOptions.fontStyle - The default font style
 * @returns - The css string
 */
export declare function getFontCss(fontFamilies: string[], style: FontCSSStyleOptions, defaultOptions: {
	fontWeight: string;
	fontStyle: string;
}): Promise<string>;
/**
 * takes all the data and returns a svg url string can be loaded by an image element
 * @param text - The text to measure
 * @param style - The style to use
 * @param resolution - The resolution to use
 * @param fontCSS - The font css to use
 * @param htmlTextData - The HTMLTextRenderData to write the SVG to
 * @returns - The SVG as a url string
 */
export declare function getSVGUrl(text: string, style: HTMLTextStyle, resolution: number, fontCSS: string, htmlTextData: HTMLTextRenderData): string;
/**
 * This function converts an image to a canvas, and returns the canvas.
 * It is used to convert images to canvases to work around a CORS issue where WebGPU cannot
 * upload an SVGImage to a texture.
 *
 * It uses the CanvasPool to get an optimal canvas and context, and then draws the image onto it.
 * Remember to return this canvas is immediately to the CanvasPool for reuse when you are done with it.
 * (eg upload it to the GPU!)
 * @param image - The image to convert to a canvas.
 * @param resolution - The resolution of the canvas.
 */
export declare function getTemporaryCanvasFromImage(image: HTMLImageElement, resolution: number): CanvasAndContext;
/**
 * Resolves a font url to a base64 string
 * @param url - The url to load the font from
 * @returns - The font as a base64 string
 */
export declare function loadFontAsBase64(url: string): Promise<string>;
/**
 * This function loads an SVG image into an HTMLImageElement.
 * The image can then be uploaded as texture to the GPU.
 * iOS has a bug where embedded fonts are not available immediately after the image loads,
 * so we wait an arbitrary amount of time before resolving the promise.
 * @param image - The image to load the SVG into
 * @param url - The url to load the SVG from
 * @param delay - Whether to delay the load
 * @returns - A promise that resolves when the image has loaded
 */
export declare function loadSVGImage(image: HTMLImageElement, url: string, delay: boolean): Promise<void>;
/**
 * Measures the HTML text without actually generating an image.
 * This is used to calculate the size of the text.
 * @param text - The text to measure
 * @param style - The style to use
 * @param fontStyleCSS - The font css to use
 * @param htmlTextRenderData - The HTMLTextRenderData to write the SVG to
 * @returns - The size of the text
 */
export declare function measureHtmlText(text: string, style: HTMLTextStyle, fontStyleCSS?: string, htmlTextRenderData?: HTMLTextRenderData): Size;
/**
 * Internally converts all of the style properties into CSS equivalents.
 * @param style
 * @returns The CSS style string, for setting \`style\` property of root HTMLElement.
 */
export declare function textStyleToCSS(style: HTMLTextStyle): string;
export declare class CanvasTextPipe implements RenderPipe<Text$1> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "text";
	};
	private _renderer;
	private _gpuText;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer);
	resolutionChange(): void;
	validateRenderable(text: Text$1): boolean;
	addRenderable(text: Text$1, instructionSet: InstructionSet): void;
	updateRenderable(text: Text$1): void;
	destroyRenderable(text: Text$1): void;
	private _destroyRenderableById;
	private _updateText;
	private _updateGpuText;
	private _getGpuText;
	initGpuText(text: Text$1): {
		texture: Texture<TextureSource<any>>;
		currentKey: string;
		batchableSprite: BatchableSprite;
	};
	destroy(): void;
}
interface CanvasAndContext$1 {
	canvas: ICanvas;
	context: ICanvasRenderingContext2D;
}
/**
 * System plugin to the renderer to manage canvas text.
 * @memberof rendering
 */
export declare class CanvasTextSystem implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem,
			ExtensionType.CanvasSystem
		];
		readonly name: "canvasText";
	};
	private _activeTextures;
	private readonly _renderer;
	constructor(_renderer: Renderer);
	getTextureSize(text: string, resolution: number, style: TextStyle): {
		width: number;
		height: number;
	};
	/**
	 * This is a function that will create a texture from a text string, style and resolution.
	 * Useful if you want to make a texture of your text and use if for various other pixi things!
	 * @param options - The options of the text that will be used to generate the texture.
	 * @param options.text - the text to render
	 * @param options.style - the style of the text
	 * @param options.resolution - the resolution of the texture
	 * @returns the newly created texture
	 */
	/** @deprecated since 8.0.0 */
	getTexture(text: string, resolution: number, style: TextStyle, textKey: string): Texture;
	getTexture(options: TextOptions): Texture;
	createTextureAndCanvas(options: {
		text: string;
		style: TextStyle;
		resolution?: number;
	}): {
		texture: Texture<TextureSource<any>>;
		canvasAndContext: CanvasAndContext;
	};
	getManagedTexture(text: Text$1): Texture<TextureSource<any>>;
	private _increaseReferenceCount;
	/**
	 * Returns a texture that was created wit the above \`getTexture\` function.
	 * Handy if you are done with a texture and want to return it to the pool.
	 * @param texture - The texture to be returned.
	 */
	returnTexture(texture: Texture): void;
	decreaseReferenceCount(textKey: string): void;
	getReferenceCount(textKey: string): number;
	/**
	 * Renders text to its canvas, and updates its texture.
	 *
	 * By default this is used internally to ensure the texture is correct before rendering,
	 * but it can be used called externally, for example from this class to 'pre-generate' the texture from a piece of text,
	 * and then shared across multiple Sprites.
	 * @param text
	 * @param style
	 * @param resolution
	 * @param canvasAndContext
	 */
	renderTextToCanvas(text: string, style: TextStyle, resolution: number, canvasAndContext: CanvasAndContext$1): void;
	/**
	 * Render the text with letter-spacing.
	 * @param text - The text to draw
	 * @param style
	 * @param canvasAndContext
	 * @param x - Horizontal position to draw the text
	 * @param y - Vertical position to draw the text
	 * @param isStroke - Is this drawing for the outside stroke of the
	 *  text? If not, it's for the inside fill
	 */
	private _drawLetterSpacing;
	destroy(): void;
}
/**
 * Generates a font style string to use for \`TextMetrics.measureFont()\`.
 * @param style
 * @returns Font style string, for passing to \`TextMetrics.measureFont()\`
 */
export declare function fontStringFromTextStyle(style: TextStyle): string;
/**
 * Converts a PixiJS fill style into a Canvas-compatible fill style.
 * Handles solid colors, textures, patterns, and gradients.
 * @param fillStyle - The PixiJS fill style to convert
 * @param context - The canvas rendering context
 * @param textMetrics - Metrics about the text being rendered
 * @param padding - Padding to add to the text metrics (used to ensure that the gradient accommodates the stroke width)
 * @returns Canvas-compatible fill style (string, CanvasGradient, or CanvasPattern)
 */
export declare function getCanvasFillStyle(fillStyle: ConvertedFillStyle, context: ICanvasRenderingContext2D, textMetrics?: CanvasTextMetrics, padding?: number): string | CanvasGradient | CanvasPattern;
export declare class SdfShader extends Shader {
	constructor();
}
export declare const localUniformMSDFBit: {
	name: string;
	vertex: {
		header: string;
		main: string;
		end: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
export declare const localUniformMSDFBitGl: {
	name: string;
	vertex: {
		header: string;
		main: string;
		end: string;
	};
	fragment: {
		header: string;
		main: string;
	};
};
export declare const mSDFBit: {
	name: string;
	fragment: {
		header: string;
	};
};
export declare const mSDFBitGl: {
	name: string;
	fragment: {
		header: string;
	};
};
/**
 * converts the style input into the correct type of TextStyle
 * either HTMLTextStyle or TextStyle based on the renderMode.
 * @param renderMode - The render mode to use
 * @param style - The style to use
 * @returns - The style class
 */
export declare function ensureTextStyle(renderMode: string, style: TextStyle | HTMLTextStyle | TextStyleOptions | HTMLTextStyleOptions): TextStyle;
/**
 * Generates a unique key for the text style.
 * @param style - The style to generate a key for.
 * @returns the key for the style.
 */
export declare function generateTextStyleKey(style: TextStyle): string;
/**
 * Takes an image and creates a texture from it, using a power of 2 texture from the texture pool.
 * Remember to return the texture when you don't need it any more!
 * @param image - The image to create a texture from
 * @param width - the frame width of the texture
 * @param height - the frame height of the texture
 * @param resolution - The resolution of the texture
 * @returns - The texture
 */
export declare function getPo2TextureFromSource(image: HTMLImageElement | HTMLCanvasElement | ICanvas, width: number, height: number, resolution: number): Texture;
/**
 * Updates the bounds of the given batchable sprite based on the provided text object.
 *
 * This function adjusts the bounds of the batchable sprite to match the dimensions
 * and anchor point of the text's texture. Additionally, it compensates for any padding
 * specified in the text's style to ensure the text is rendered correctly on screen.
 * @param {BatchableSprite} batchableSprite - The sprite whose bounds need to be updated.
 * @param {AbstractText} text - The text object containing the texture and style information.
 */
export declare function updateTextBounds(batchableSprite: BatchableSprite, text: AbstractText): void;
export interface TextureShader extends Shader {
	texture: Texture;
}
/**
 * Constructor options used for \`Mesh\` instances. Extends {@link scene.MeshViewOptions}
 * \`\`\`js
 * const mesh = new Mesh({
 *    texture: Texture.from('assets/image.png'),
 *    geometry: new PlaneGeometry(),
 *    shader: Shader.from(VERTEX, FRAGMENT),
 * });
 * \`\`\`
 * @see {@link scene.Mesh}
 * @see {@link scene.MeshViewOptions}
 * @memberof scene
 */
/**
 * @memberof scene
 */
export interface MeshOptions<GEOMETRY extends Geometry = MeshGeometry, SHADER extends Shader = TextureShader> extends PixiMixins.MeshOptions, ContainerOptions {
	/**
	 * Includes vertex positions, face indices, colors, UVs, and
	 * custom attributes within buffers, reducing the cost of passing all
	 * this data to the GPU. Can be shared between multiple Mesh objects.
	 */
	geometry: GEOMETRY;
	/**
	 * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
	 * Can be shared between multiple Mesh objects.
	 */
	shader?: SHADER | null;
	/** The state of WebGL required to render the mesh. */
	state?: State;
	/** The texture that the Mesh uses. Null for non-MeshMaterial shaders */
	texture?: Texture;
	/** Whether or not to round the x/y position. */
	roundPixels?: boolean;
}
export interface Mesh extends PixiMixins.Mesh, ViewContainer {
}
/**
 * Base mesh class.
 *
 * This class empowers you to have maximum flexibility to render any kind of WebGL/WebGPU visuals you can think of.
 * This class assumes a certain level of WebGL/WebGPU knowledge.
 * If you know a bit this should abstract enough away to make your life easier!
 *
 * Pretty much ALL WebGL/WebGPU can be broken down into the following:
 * - Geometry - The structure and data for the mesh. This can include anything from positions, uvs, normals, colors etc..
 * - Shader - This is the shader that PixiJS will render the geometry with (attributes in the shader must match the geometry)
 * - State - This is the state of WebGL required to render the mesh.
 *
 * Through a combination of the above elements you can render anything you want, 2D or 3D!
 * @memberof scene
 */
export declare class Mesh<GEOMETRY extends Geometry = MeshGeometry, SHADER extends Shader = TextureShader> extends ViewContainer implements View, Instruction {
	readonly renderPipeId: string;
	state: State;
	/** @ignore */
	_texture: Texture;
	/** @ignore */
	_geometry: GEOMETRY;
	/** @ignore */
	_shader: SHADER | null;
	/**
	 * @param {scene.MeshOptions} options - options for the mesh instance
	 */
	constructor(options: MeshOptions<GEOMETRY, SHADER>);
	/** @deprecated since 8.0.0 */
	constructor(geometry: GEOMETRY, shader: SHADER, state?: State, drawMode?: Topology);
	/** Alias for {@link scene.Mesh#shader}. */
	get material(): SHADER;
	/**
	 * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
	 * Can be shared between multiple Mesh objects.
	 */
	set shader(value: SHADER | null);
	get shader(): SHADER | null;
	/**
	 * Includes vertex positions, face indices, colors, UVs, and
	 * custom attributes within buffers, reducing the cost of passing all
	 * this data to the GPU. Can be shared between multiple Mesh objects.
	 */
	set geometry(value: GEOMETRY);
	get geometry(): GEOMETRY;
	/** The texture that the Mesh uses. Null for non-MeshMaterial shaders */
	set texture(value: Texture);
	get texture(): Texture;
	get batched(): boolean;
	/**
	 * The local bounds of the mesh.
	 * @type {rendering.Bounds}
	 */
	get bounds(): Bounds;
	/**
	 * Update local bounds of the mesh.
	 * @private
	 */
	protected updateBounds(): void;
	/**
	 * Checks if the object contains the given point.
	 * @param point - The point to check
	 */
	containsPoint(point: PointData): boolean;
	/**
	 * Destroys this sprite renderable and optionally its texture.
	 * @param options - Options parameter. A boolean will act as if all options
	 *  have been set to that value
	 * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
	 * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
	 */
	destroy(options?: DestroyOptions): void;
}
export interface MeshAdaptor {
	init(): void;
	execute(meshPipe: MeshPipe, mesh: Mesh): void;
	destroy(): void;
}
export declare class MeshPipe implements RenderPipe<Mesh>, InstructionPipe<Mesh> {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLPipes,
			ExtensionType.WebGPUPipes,
			ExtensionType.CanvasPipes
		];
		readonly name: "mesh";
	};
	localUniforms: UniformGroup<{
		uTransformMatrix: {
			value: Matrix;
			type: "mat3x3<f32>";
		};
		uColor: {
			value: Float32Array;
			type: "vec4<f32>";
		};
		uRound: {
			value: number;
			type: "f32";
		};
	}>;
	localUniformsBindGroup: BindGroup;
	renderer: Renderer;
	private _meshDataHash;
	private _gpuBatchableMeshHash;
	private _adaptor;
	private readonly _destroyRenderableBound;
	constructor(renderer: Renderer, adaptor: MeshAdaptor);
	validateRenderable(mesh: Mesh): boolean;
	addRenderable(mesh: Mesh, instructionSet: InstructionSet): void;
	updateRenderable(mesh: Mesh): void;
	destroyRenderable(mesh: Mesh): void;
	execute(mesh: Mesh): void;
	private _getMeshData;
	private _initMeshData;
	private _getBatchableMesh;
	private _initBatchableMesh;
	destroy(): void;
}
declare global {
	namespace PixiMixins {
		interface RendererPipes {
			mesh: MeshPipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererPipes {
			particle: ParticleContainerPipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface Container<C extends ContainerChild = ContainerChild> extends ChildrenHelperMixin<C>, ToLocalGlobalMixin, OnRenderMixin, MeasureMixin, EffectsMixin, FindMixin, SortMixin, GetGlobalMixin, CollectRenderablesMixin, GetFastGlobalBoundsMixin, CacheAsTextureMixin {
		}
		interface ContainerOptions extends OnRenderMixinConstructor, MeasureMixinConstructor, EffectsMixinConstructor, FindMixinConstructor, SortMixinConstructor, CacheAsTextureMixinConstructor {
		}
		interface ViewContainer {
		}
		interface ViewContainerOptions {
		}
		interface Graphics {
		}
		interface GraphicsOptions {
		}
		interface Mesh {
		}
		interface MeshOptions {
		}
		interface ParticleContainer {
		}
		interface ParticleContainerOptions {
		}
		interface Sprite {
		}
		interface SpriteOptions {
		}
		interface AnimatedSprite {
		}
		interface AnimatedSpriteOptions {
		}
		interface NineSliceSprite {
		}
		interface NineSliceSpriteOptions {
		}
		interface TilingSprite {
		}
		interface TilingSpriteOptions {
		}
		interface Text {
		}
		interface BitmapText {
		}
		interface TextOptions {
		}
		interface HTMLText {
		}
		interface HTMLTextOptions {
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererPipes {
			nineSliceSprite: NineSliceSpritePipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererPipes {
			tilingSprite: TilingSpritePipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererPipes {
			bitmapText: BitmapTextPipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			htmlText: HTMLTextSystem;
		}
		interface RendererPipes {
			htmlText: HTMLTextPipe;
		}
	}
}
declare global {
	namespace PixiMixins {
		interface RendererSystems {
			canvasText: CanvasTextSystem;
		}
		interface RendererPipes {
			text: CanvasTextPipe;
		}
	}
}
export interface BlendModeFilterOptions {
	source?: string;
	gpu?: {
		functions?: string;
		main?: string;
	};
	gl?: {
		functions?: string;
		main?: string;
	};
}
export declare class BlendModeFilter extends Filter {
	constructor(options: BlendModeFilterOptions);
}
/**
 * Available as \`container.blendMode = 'color'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color'
 * @memberof filters
 */
export declare class ColorBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Looks at the color information in each channel and darkens the base color to
 * reflect the blend color by increasing the contrast between the two.
 *
 * Available as \`container.blendMode = 'color-burn'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color-burn'
 * @memberof filters
 */
export declare class ColorBurnBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Looks at the color information in each channel and brightens the base color to reflect the blend color by decreasing contrast between the two.
 * Available as \`container.blendMode = 'color-dodge'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color-dodge'
 * @memberof filters
 */
export declare class ColorDodgeBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Uses each color channel to select the darker of the following two values; base or blend color
 * Available as \`container.blendMode = 'darken'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'darken'
 * @memberof filters
 */
export declare class DarkenBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'difference'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'difference'
 * @memberof filters
 */
export declare class DifferenceBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Divides the blend from the base color using each color channel
 * Available as \`container.blendMode = 'divide'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'divide'
 * @memberof filters
 */
export declare class DivideBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'exclusion'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'exclusion'
 * @memberof filters
 */
export declare class ExclusionBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'hard-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'hard-light'
 * @memberof filters
 */
export declare class HardLightBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Hard defines each of the color channel values of the blend color to the RGB values of the base color.
 * If the sum of a channel is 255, it receives a value of 255; if less than 255, a value of 0.
 *
 * Available as \`container.blendMode = 'hard-mix'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'hard-mix'
 * @memberof filters
 */
export declare class HardMixBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'lighten'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'lighten'
 * @memberof filters
 */
export declare class LightenBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Looks at the color information in each channel and darkens the base color to
 * reflect the blend color by increasing the contrast between the two.
 *
 * Available as \`container.blendMode = 'linear-burn'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-burn'
 * @memberof filters
 */
export declare class LinearBurnBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Looks at the color information in each channel and brightens the base color to reflect the blend color by decreasing contrast between the two.
 * Available as \`container.blendMode = 'linear-dodge'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-dodge'
 * @memberof filters
 */
export declare class LinearDodgeBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Increase or decrease brightness by burning or dodging color values, based on the blend color
 * Available as \`container.blendMode = 'linear-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-light'
 * @memberof filters
 */
export declare class LinearLightBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'luminosity'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'luminosity'
 * @memberof filters
 */
export declare class LuminosityBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'negation'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'negation'
 */
export declare class NegationBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'overlay'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'overlay'
 */
export declare class OverlayBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Replaces colors based on the blend color.
 * Available as \`container.blendMode = 'pin-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'pin-light'
 * @memberof filters
 */
export declare class PinLightBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'saturation'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'saturation'
 */
export declare class SaturationBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'soft-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'soft-light'
 */
export declare class SoftLightBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Subtracts the blend from the base color using each color channel
 * Available as \`container.blendMode = 'subtract'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'subtract'
 * @memberof filters
 */
export declare class SubtractBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * Available as \`container.blendMode = 'vivid-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'vivid-light'
 */
export declare class VividLightBlend extends BlendModeFilter {
	/** @ignore */
	static extension: ExtensionMetadata;
	constructor();
}
/**
 * For every asset that is cached, it will call the parsers test function
 * the flow is as follows:
 *
 * 1. \`cacheParser.test()\`: Test the asset.
 * 2. \`cacheParser.getCacheableAssets()\`: If the test passes call the getCacheableAssets function with the asset
 *
 * Useful if you want to add more than just a raw asset to the cache
 * (for example a spritesheet will want to make all its sub textures easily accessible in the cache)
 * @memberof assets
 */
export interface CacheParser<T = any> {
	/** The extension type of this cache parser */
	extension?: ExtensionMetadata;
	/** A config to adjust the parser */
	config?: Record<string, any>;
	/**
	 * Gets called by the cache when a dev caches an asset
	 * @param asset - the asset to test
	 */
	test: (asset: T) => boolean;
	/**
	 * If the test passes, this function is called to get the cacheable assets
	 * an example may be that a spritesheet object will return all the sub textures it has so they can
	 * be cached.
	 * @param keys - The keys to cache the assets under
	 * @param asset - The asset to get the cacheable assets from
	 * @returns A key-value pair of cacheable assets
	 */
	getCacheableAssets: (keys: string[], asset: T) => Record<string, any>;
}
/**
 * Format detection is useful for detecting feature support on the current platform.
 * @memberof assets
 */
export interface FormatDetectionParser {
	/** Should be ExtensionType.DetectionParser */
	extension?: ExtensionMetadata;
	/** Browser/platform feature detection supported if return true  */
	test: () => Promise<boolean>;
	/**
	 * Add formats (file extensions) to the existing list of formats.
	 * Return an new array with added formats, do not mutate the formats argument.
	 * @returns {Promise<string[]>} - Promise that resolves to the new formats array.
	 */
	add: (formats: string[]) => Promise<string[]>;
	/**
	 * Remove formats (file extensions) from the list of supported formats.
	 * This is used when uninstalling this DetectionParser.
	 * Return an new array with filtered formats, do not mutate the formats argument.
	 * @returns {Promise<string[]>} - Promise that resolves to the new formats array.
	 */
	remove: (formats: string[]) => Promise<string[]>;
}
/**
 * A prefer order lets the resolver know which assets to prefer depending on the various parameters passed to it.
 * @memberof assets
 */
export interface PreferOrder {
	/** the importance order of the params */
	priority?: string[];
	params: {
		[key: string]: any;
	};
}
/**
 * Format for url parser, will test a string and if it pass will then parse it, turning it into an ResolvedAsset
 * @memberof assets
 */
export interface ResolveURLParser {
	extension?: ExtensionMetadata;
	/** A config to adjust the parser */
	config?: Record<string, any>;
	/** the test to perform on the url to determine if it should be parsed */
	test: (url: string) => boolean;
	/** the function that will convert the url into an object */
	parse: (value: string) => ResolvedAsset & {
		[key: string]: any;
	};
}
/**
 * A more verbose version of the AssetExtension,
 * allowing you to set the cached, loaded, parsed, and unloaded asset separately
 * @memberof assets
 */
export interface AssetExtensionAdvanced<ASSET = any, PARSED_ASSET = ASSET, UNLOAD_ASSET = ASSET, CACHE_ASSET = ASSET, META_DATA = any> {
	/** The type of extension */
	extension: ExtensionType.Asset;
	/** the asset loader */
	loader?: LoaderParserAdvanced<ASSET, PARSED_ASSET, UNLOAD_ASSET, META_DATA>;
	/** the asset resolve parser */
	resolver?: Partial<ResolveURLParser>;
	/** the asset cache parser */
	cache?: Partial<CacheParser<CACHE_ASSET>>;
	/** the asset format detection parser */
	detection?: Partial<FormatDetectionParser>;
}
/**
 * This developer convenience object allows developers to group
 * together the various asset parsers into a single object.
 * @example
 * import { AssetExtension, extensions } from 'pixi.js';
 *
 * // create the CacheParser
 * const cache = {
 *    test(asset: item): boolean {
 *       // Gets called by the cache when a dev caches an asset
 *    },
 *    getCacheableAssets(keys: string[], asset: item): Record<string, any> {
 *       // If the test passes, this function is called to get the cacheable assets
 *       // an example may be that a spritesheet object will return all the sub textures it has so they can
 *       // be cached.
 *    },
 * };
 *
 * // create the ResolveURLParser
 * const resolver = {
 *    test(value: string): boolean {
 *       // the test to perform on the url to determine if it should be parsed
 *    },
 *    parse(value: string): ResolvedAsset {
 *       // the function that will convert the url into an object
 *    },
 * };
 *
 * // create the LoaderParser
 * const loader = {
 *    name: 'itemLoader',
 *    extension: {
 *       type: ExtensionType.LoadParser,
 *    },
 *    async testParse(asset: any, options: ResolvedAsset) {
 *       // This function is used to test if the parse function should be run on the asset
 *    },
 *    async parse(asset: any, options: ResolvedAsset, loader: Loader) {
 *       // Gets called on the asset it testParse passes. Useful to convert a raw asset into something more useful
 *    },
 *    unload(item: any) {
 *       // If an asset is parsed using this parser, the unload function will be called when the user requests an asset
 *       // to be unloaded. This is useful for things like sounds or textures that can be unloaded from memory
 *    },
 * };
 *
 * // put it all together and create the AssetExtension
 * extensions.add({
 *     extension: ExtensionType.Asset,
 *     cache,
 *     resolver,
 *     loader,
 * }
 * @memberof assets
 */
export interface AssetExtension<ASSET = any, META_DATA = any> extends AssetExtensionAdvanced<ASSET, META_DATA> {
}
declare class CacheClass {
	private readonly _parsers;
	private readonly _cache;
	private readonly _cacheMap;
	/** Clear all entries. */
	reset(): void;
	/**
	 * Check if the key exists
	 * @param key - The key to check
	 */
	has(key: any): boolean;
	/**
	 * Fetch entry by key
	 * @param key - The key of the entry to get
	 */
	get<T = any>(key: any): T;
	/**
	 * Set a value by key or keys name
	 * @param key - The key or keys to set
	 * @param value - The value to store in the cache or from which cacheable assets will be derived.
	 */
	set(key: any | any[], value: unknown): void;
	/**
	 * Remove entry by key
	 *
	 * This function will also remove any associated alias from the cache also.
	 * @param key - The key of the entry to remove
	 */
	remove(key: any): void;
	/** All loader parsers registered */
	get parsers(): CacheParser[];
}
declare const Cache$1: CacheClass;
/**
 * Configuration for the [loadTextures]{@link assets.loadTextures} plugin.
 * @see assets.loadTextures
 * @memberof assets
 */
export interface LoadTextureConfig {
	/**
	 * When set to \`true\`, loading and decoding images will happen with Worker thread,
	 * if available on the browser. This is much more performant as network requests
	 * and decoding can be expensive on the CPU. However, not all environments support
	 * Workers, in some cases it can be helpful to disable by setting to \`false\`.
	 * @default true
	 */
	preferWorkers: boolean;
	/**
	 * When set to \`true\`, loading and decoding images will happen with \`createImageBitmap\`,
	 * otherwise it will use \`new Image()\`.
	 * @default true
	 */
	preferCreateImageBitmap: boolean;
	/**
	 * The crossOrigin value to use for images when \`preferCreateImageBitmap\` is \`false\`.
	 * @default 'anonymous'
	 */
	crossOrigin: HTMLImageElement["crossOrigin"];
}
/**
 * Returns a promise that resolves an ImageBitmaps.
 * This function is designed to be used by a worker.
 * Part of WorkerManager!
 * @param url - The image to load an image bitmap for
 * @ignore
 */
export declare function loadImageBitmap(url: string, asset?: ResolvedAsset<TextureSourceOptions<any>>): Promise<ImageBitmap>;
/**
 * A simple plugin to load our textures!
 * This makes use of imageBitmaps where available.
 * We load the \`ImageBitmap\` on a different thread using workers if possible.
 * We can then use the \`ImageBitmap\` as a source for a Pixi texture
 *
 * You can customize the behavior of this loader by setting the \`config\` property.
 * Which can be found [here]{@link assets.LoadTextureConfig}
 * \`\`\`js
 * // Set the config
 * import { loadTextures } from 'pixi.js';
 *
 * loadTextures.config = {
 *    // If true we will use a worker to load the ImageBitmap
 *    preferWorkers: true,
 *    // If false we will use new Image() instead of createImageBitmap,
 *    // we'll also disable the use of workers as it requires createImageBitmap
 *    preferCreateImageBitmap: true,
 *    crossOrigin: 'anonymous',
 * };
 * \`\`\`
 * @memberof assets
 */
export declare const loadTextures: LoaderParser<Texture, TextureSourceOptions, LoadTextureConfig>;
/**
 * Options for how the resolver deals with generating bundle ids
 * @memberof assets
 */
export interface BundleIdentifierOptions {
	/** The character that is used to connect the bundleId and the assetId when generating a bundle asset id key */
	connector?: string;
	/**
	 * A function that generates a bundle asset id key from a bundleId and an assetId
	 * @param bundleId - the bundleId
	 * @param assetId  - the assetId
	 * @returns the bundle asset id key
	 */
	createBundleAssetId?: (bundleId: string, assetId: string) => string;
	/**
	 * A function that generates an assetId from a bundle asset id key. This is the reverse of generateBundleAssetId
	 * @param bundleId - the bundleId
	 * @param assetBundleId - the bundle asset id key
	 * @returns the assetId
	 */
	extractAssetIdFromBundle?: (bundleId: string, assetBundleId: string) => string;
}
/**
 * A class that is responsible for resolving mapping asset URLs to keys.
 * At its most basic it can be used for Aliases:
 *
 * \`\`\`js
 * resolver.add('foo', 'bar');
 * resolver.resolveUrl('foo') // => 'bar'
 * \`\`\`
 *
 * It can also be used to resolve the most appropriate asset for a given URL:
 *
 * \`\`\`js
 * resolver.prefer({
 *     params: {
 *         format: 'webp',
 *         resolution: 2,
 *     }
 * });
 *
 * resolver.add('foo', ['bar@2x.webp', 'bar@2x.png', 'bar.webp', 'bar.png']);
 *
 * resolver.resolveUrl('foo') // => 'bar@2x.webp'
 * \`\`\`
 * Other features include:
 * - Ability to process a manifest file to get the correct understanding of how to resolve all assets
 * - Ability to add custom parsers for specific file types
 * - Ability to add custom prefer rules
 *
 * This class only cares about the URL, not the loading of the asset itself.
 *
 * It is not intended that this class is created by developers - its part of the Asset class
 * This is the third major system of PixiJS' main Assets class
 * @memberof assets
 */
export declare class Resolver {
	/**
	 * The prefix that denotes a URL is for a retina asset.
	 * @static
	 * @name RETINA_PREFIX
	 * @type {RegExp}
	 * @default /@([0-9\\.]+)x/
	 * @example \`@2x\`
	 */
	static RETINA_PREFIX: RegExp;
	private readonly _defaultBundleIdentifierOptions;
	/** The character that is used to connect the bundleId and the assetId when generating a bundle asset id key */
	private _bundleIdConnector;
	/**
	 * A function that generates a bundle asset id key from a bundleId and an assetId
	 * @param bundleId - the bundleId
	 * @param assetId  - the assetId
	 * @returns the bundle asset id key
	 */
	private _createBundleAssetId;
	/**
	 * A function that generates an assetId from a bundle asset id key. This is the reverse of generateBundleAssetId
	 * @param bundleId - the bundleId
	 * @param assetBundleId - the bundle asset id key
	 * @returns the assetId
	 */
	private _extractAssetIdFromBundle;
	private _assetMap;
	private _preferredOrder;
	private readonly _parsers;
	private _resolverHash;
	private _rootPath;
	private _basePath;
	private _manifest;
	private _bundles;
	private _defaultSearchParams;
	/**
	 * Override how the resolver deals with generating bundle ids.
	 * must be called before any bundles are added
	 * @param bundleIdentifier - the bundle identifier options
	 */
	setBundleIdentifier(bundleIdentifier: BundleIdentifierOptions): void;
	/**
	 * Let the resolver know which assets you prefer to use when resolving assets.
	 * Multiple prefer user defined rules can be added.
	 * @example
	 * resolver.prefer({
	 *     // first look for something with the correct format, and then then correct resolution
	 *     priority: ['format', 'resolution'],
	 *     params:{
	 *         format:'webp', // prefer webp images
	 *         resolution: 2, // prefer a resolution of 2
	 *     }
	 * })
	 * resolver.add('foo', ['bar@2x.webp', 'bar@2x.png', 'bar.webp', 'bar.png']);
	 * resolver.resolveUrl('foo') // => 'bar@2x.webp'
	 * @param preferOrders - the prefer options
	 */
	prefer(...preferOrders: PreferOrder[]): void;
	/**
	 * Set the base path to prepend to all urls when resolving
	 * @example
	 * resolver.basePath = 'https://home.com/';
	 * resolver.add('foo', 'bar.ong');
	 * resolver.resolveUrl('foo', 'bar.png'); // => 'https://home.com/bar.png'
	 * @param basePath - the base path to use
	 */
	set basePath(basePath: string);
	get basePath(): string;
	/**
	 * Set the root path for root-relative URLs. By default the \`basePath\`'s root is used. If no \`basePath\` is set, then the
	 * default value for browsers is \`window.location.origin\`
	 * @example
	 * // Application hosted on https://home.com/some-path/index.html
	 * resolver.basePath = 'https://home.com/some-path/';
	 * resolver.rootPath = 'https://home.com/';
	 * resolver.add('foo', '/bar.png');
	 * resolver.resolveUrl('foo', '/bar.png'); // => 'https://home.com/bar.png'
	 * @param rootPath - the root path to use
	 */
	set rootPath(rootPath: string);
	get rootPath(): string;
	/**
	 * All the active URL parsers that help the parser to extract information and create
	 * an asset object-based on parsing the URL itself.
	 *
	 * Can be added using the extensions API
	 * @example
	 * resolver.add('foo', [
	 *     {
	 *         resolution: 2,
	 *         format: 'png',
	 *         src: 'image@2x.png',
	 *     },
	 *     {
	 *         resolution:1,
	 *         format:'png',
	 *         src: 'image.png',
	 *     },
	 * ]);
	 *
	 * // With a url parser the information such as resolution and file format could extracted from the url itself:
	 * extensions.add({
	 *     extension: ExtensionType.ResolveParser,
	 *     test: loadTextures.test, // test if url ends in an image
	 *     parse: (value: string) =>
	 *     ({
	 *         resolution: parseFloat(Resolver.RETINA_PREFIX.exec(value)?.[1] ?? '1'),
	 *         format: value.split('.').pop(),
	 *         src: value,
	 *     }),
	 * });
	 *
	 * // Now resolution and format can be extracted from the url
	 * resolver.add('foo', [
	 *     'image@2x.png',
	 *     'image.png',
	 * ]);
	 */
	get parsers(): ResolveURLParser[];
	/** Used for testing, this resets the resolver to its initial state */
	reset(): void;
	/**
	 * Sets the default URL search parameters for the URL resolver. The urls can be specified as a string or an object.
	 * @param searchParams - the default url parameters to append when resolving urls
	 */
	setDefaultSearchParams(searchParams: string | Record<string, unknown>): void;
	/**
	 * Returns the aliases for a given asset
	 * @param asset - the asset to get the aliases for
	 */
	getAlias(asset: UnresolvedAsset): string[];
	/**
	 * Add a manifest to the asset resolver. This is a nice way to add all the asset information in one go.
	 * generally a manifest would be built using a tool.
	 * @param manifest - the manifest to add to the resolver
	 */
	addManifest(manifest: AssetsManifest): void;
	/**
	 * This adds a bundle of assets in one go so that you can resolve them as a group.
	 * For example you could add a bundle for each screen in you pixi app
	 * @example
	 * resolver.addBundle('animals', [
	 *  { alias: 'bunny', src: 'bunny.png' },
	 *  { alias: 'chicken', src: 'chicken.png' },
	 *  { alias: 'thumper', src: 'thumper.png' },
	 * ]);
	 * // or
	 * resolver.addBundle('animals', {
	 *     bunny: 'bunny.png',
	 *     chicken: 'chicken.png',
	 *     thumper: 'thumper.png',
	 * });
	 *
	 * const resolvedAssets = await resolver.resolveBundle('animals');
	 * @param bundleId - The id of the bundle to add
	 * @param assets - A record of the asset or assets that will be chosen from when loading via the specified key
	 */
	addBundle(bundleId: string, assets: AssetsBundle["assets"]): void;
	/**
	 * Tells the resolver what keys are associated with witch asset.
	 * The most important thing the resolver does
	 * @example
	 * // Single key, single asset:
	 * resolver.add({alias: 'foo', src: 'bar.png');
	 * resolver.resolveUrl('foo') // => 'bar.png'
	 *
	 * // Multiple keys, single asset:
	 * resolver.add({alias: ['foo', 'boo'], src: 'bar.png'});
	 * resolver.resolveUrl('foo') // => 'bar.png'
	 * resolver.resolveUrl('boo') // => 'bar.png'
	 *
	 * // Multiple keys, multiple assets:
	 * resolver.add({alias: ['foo', 'boo'], src: ['bar.png', 'bar.webp']});
	 * resolver.resolveUrl('foo') // => 'bar.png'
	 *
	 * // Add custom data attached to the resolver
	 * Resolver.add({
	 *     alias: 'bunnyBooBooSmooth',
	 *     src: 'bunny{png,webp}',
	 *     data: { scaleMode:SCALE_MODES.NEAREST }, // Base texture options
	 * });
	 *
	 * resolver.resolve('bunnyBooBooSmooth') // => { src: 'bunny.png', data: { scaleMode: SCALE_MODES.NEAREST } }
	 * @param aliases - the UnresolvedAsset or array of UnresolvedAssets to add to the resolver
	 */
	add(aliases: ArrayOr<UnresolvedAsset>): void;
	/**
	 * If the resolver has had a manifest set via setManifest, this will return the assets urls for
	 * a given bundleId or bundleIds.
	 * @example
	 * // Manifest Example
	 * const manifest = {
	 *     bundles: [
	 *         {
	 *             name: 'load-screen',
	 *             assets: [
	 *                 {
	 *                     alias: 'background',
	 *                     src: 'sunset.png',
	 *                 },
	 *                 {
	 *                     alias: 'bar',
	 *                     src: 'load-bar.{png,webp}',
	 *                 },
	 *             ],
	 *         },
	 *         {
	 *             name: 'game-screen',
	 *             assets: [
	 *                 {
	 *                     alias: 'character',
	 *                     src: 'robot.png',
	 *                 },
	 *                 {
	 *                     alias: 'enemy',
	 *                     src: 'bad-guy.png',
	 *                 },
	 *             ],
	 *         },
	 *     ]
	 * };
	 *
	 * resolver.setManifest(manifest);
	 * const resolved = resolver.resolveBundle('load-screen');
	 * @param bundleIds - The bundle ids to resolve
	 * @returns All the bundles assets or a hash of assets for each bundle specified
	 */
	resolveBundle(bundleIds: ArrayOr<string>): Record<string, ResolvedAsset> | Record<string, Record<string, ResolvedAsset>>;
	/**
	 * Does exactly what resolve does, but returns just the URL rather than the whole asset object
	 * @param key - The key or keys to resolve
	 * @returns - The URLs associated with the key(s)
	 */
	resolveUrl(key: ArrayOr<string>): string | Record<string, string>;
	/**
	 * Resolves each key in the list to an asset object.
	 * Another key function of the resolver! After adding all the various key/asset pairs. this will run the logic
	 * of finding which asset to return based on any preferences set using the \`prefer\` function
	 * by default the same key passed in will be returned if nothing is matched by the resolver.
	 * @example
	 * resolver.add('boo', 'bunny.png');
	 *
	 * resolver.resolve('boo') // => { src: 'bunny.png' }
	 *
	 * // Will return the same string as no key was added for this value..
	 * resolver.resolve('another-thing.png') // => { src: 'another-thing.png' }
	 * @param keys - key or keys to resolve
	 * @returns - the resolve asset or a hash of resolve assets for each key specified
	 */
	resolve(keys: string): ResolvedAsset;
	resolve(keys: string[]): Record<string, ResolvedAsset>;
	/**
	 * Checks if an asset with a given key exists in the resolver
	 * @param key - The key of the asset
	 */
	hasKey(key: string): boolean;
	/**
	 * Checks if a bundle with the given key exists in the resolver
	 * @param key - The key of the bundle
	 */
	hasBundle(key: string): boolean;
	/**
	 * Internal function for figuring out what prefer criteria an asset should use.
	 * @param assets
	 */
	private _getPreferredOrder;
	/**
	 * Appends the default url parameters to the url
	 * @param url - The url to append the default parameters to
	 * @returns - The url with the default parameters appended
	 */
	private _appendDefaultSearchParams;
	private _buildResolvedAsset;
}
export declare function getUrlExtension(url: string): string;
/**
 * Configuration for the [loadSVG]{@link assets.loadSVG} plugin.
 * @see assets.loadSVG
 * @memberof assets
 */
export interface LoadSVGConfig {
	/**
	 * The crossOrigin value to use for loading the SVG as an image.
	 * @default 'anonymous'
	 */
	crossOrigin: HTMLImageElement["crossOrigin"];
	/**
	 * When set to \`true\`, loading and decoding images will happen with \`new Image()\`,
	 * @default false
	 */
	parseAsGraphicsContext: boolean;
}
/**
 * A simple loader plugin for loading json data
 * @memberof assets
 */
export declare const loadSvg: LoaderParser<Texture | GraphicsContext, TextureSourceOptions & LoadSVGConfig, LoadSVGConfig>;
/**
 * Callback for when progress on asset loading is made.
 * The function is passed a single parameter, \`progress\`, which represents the percentage (0.0 - 1.0)
 * of the assets loaded.
 * @memberof assets
 * @callback ProgressCallback
 * @param {number} progress - The percentage (0.0 - 1.0) of the assets loaded.
 * @returns {void}
 * @example
 * (progress) => console.log(progress * 100 + '%')
 */
export type ProgressCallback = (progress: number) => void;
/**
 * Extensible preferences that can be used, for instance, when configuring loaders.
 * @since 7.2.0
 * @memberof assets
 */
export interface AssetsPreferences extends LoadTextureConfig, LoadSVGConfig, PixiMixins.AssetsPreferences {
}
/**
 * Initialization options object for the Assets Class.
 * @memberof assets
 */
export interface AssetInitOptions {
	/** a base path for any assets loaded */
	basePath?: string;
	/** a default URL parameter string to append to all assets loaded */
	defaultSearchParams?: string | Record<string, any>;
	/**
	 * a manifest to tell the asset loader upfront what all your assets are
	 * this can be the manifest object itself, or a URL to the manifest.
	 */
	manifest?: string | AssetsManifest;
	/**
	 * optional preferences for which textures preferences you have when resolving assets
	 * for example you might set the resolution to 0.5 if the user is on a rubbish old phone
	 * or you might set the resolution to 2 if the user is on a retina display
	 */
	texturePreference?: {
		/** the resolution order you prefer, can be an array (priority order - first is preferred) or a single resolutions  */
		resolution?: number | number[];
		/**
		 * the formats you prefer, by default this will be:
		 * ['avif', 'webp', 'png', 'jpg', 'jpeg', 'webm', 'mp4', 'm4v', 'ogv']
		 */
		format?: ArrayOr<string>;
	};
	/**
	 * If true, don't attempt to detect whether browser has preferred formats available.
	 * May result in increased performance as it skips detection step.
	 */
	skipDetections?: boolean;
	/** advanced - override how bundlesIds are generated */
	bundleIdentifier?: BundleIdentifierOptions;
	/** Optional loader preferences */
	preferences?: Partial<AssetsPreferences>;
}
/**
 * A one stop shop for all Pixi resource management!
 * Super modern and easy to use, with enough flexibility to customize and do what you need!
 * @namespace assets
 *
 * Use the singleton class [Assets]{@link assets.Assets} to easily load and manage all your assets.
 *
 * \`\`\`typescript
 * import { Assets, Texture } from 'pixi.js';
 *
 * const bunnyTexture = await Assets.load<Texture>('bunny.png');
 * const sprite = new Sprite(bunnyTexture);
 * \`\`\`
 *
 * Check out the sections below for more information on how to deal with assets.
 *
 * <details id="assets-loading">
 *
 * <summary>Asset Loading</summary>
 *
 * Do not be afraid to load things multiple times - under the hood, it will **NEVER** load anything more than once.
 *
 * *For example:*
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * promise1 = Assets.load('bunny.png')
 * promise2 = Assets.load('bunny.png')
 *
 * // promise1 === promise2
 * \`\`\`
 *
 * Here both promises will be the same. Once resolved... Forever resolved! It makes for really easy resource management!
 *
 * Out of the box Pixi supports the following files:
 * - Textures (**_avif_**, **_webp_**, **_png_**, **_jpg_**, **_gif_**, **_svg_**) via {@link assets.loadTextures}, {@link assets.loadSvg}
 * - Video Textures (**_mp4_**, **_m4v_**, **_webm_**, **_ogg_**, **_ogv_**, **_h264_**, **_avi_**, **_mov_**) via {@link assets.loadVideoTextures}
 * - Sprite sheets (**_json_**) via {@link assets.spritesheetAsset}
 * - Bitmap fonts (**_xml_**, **_fnt_**, **_txt_**) via {@link assets.loadBitmapFont}
 * - Web fonts (**_ttf_**, **_woff_**, **_woff2_**) via {@link assets.loadWebFont}
 * - JSON files (**_json_**) via {@link assets.loadJson}
 * - Text Files (**_txt_**) via {@link assets.loadTxt}
 * <br/>
 * More types can be added fairly easily by creating additional {@link assets.LoaderParser LoaderParsers}.
 * </details>
 *
 * <details id="textures">
 *
 * <summary>Textures</summary>
 *
 * - Textures are loaded as ImageBitmap on a worker thread where possible. Leading to much less janky load + parse times.
 * - By default, we will prefer to load AVIF and WebP image files if you specify them.
 * But if the browser doesn't support AVIF or WebP we will fall back to png and jpg.
 * - Textures can also be accessed via \`Texture.from()\` (see {@link core.from|Texture.from})
 * and now use this asset manager under the hood!
 * - Don't worry if you set preferences for textures that don't exist
 * (for example you prefer 2x resolutions images but only 1x is available for that texture,
 * the Assets manager will pick that up as a fallback automatically)
 *
 * #### Sprite sheets
 * - It's hard to know what resolution a sprite sheet is without loading it first, to address this
 * there is a naming convention we have added that will let Pixi understand the image format and resolution
 * of the spritesheet via its file name: \`my-spritesheet{resolution}.{imageFormat}.json\`
 * <br><br>For example:
 *   - \`my-spritesheet@2x.webp.json\`* // 2x resolution, WebP sprite sheet*
 *   - \`my-spritesheet@0.5x.png.json\`* // 0.5x resolution, png sprite sheet*
 * - This is optional! You can just load a sprite sheet as normal.
 * This is only useful if you have a bunch of different res / formatted spritesheets.
 * </details>
 *
 * <details id="fonts">
 *
 * <summary>Fonts</summary>
 *
 * Web fonts will be loaded with all weights.
 * It is possible to load only specific weights by doing the following:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * // Load specific weights..
 * await Assets.load({
 *     data: {
 *         weights: ['normal'], // Only loads the weight
 *     },
 *     src: \`outfit.woff2\`,
 * });
 *
 * // Load everything...
 * await Assets.load(\`outfit.woff2\`);
 * \`\`\`
 * </details>
 *
 * <details id="background-loading">
 *
 * <summary>Background Loading</summary>
 *
 * Background loading will load stuff for you passively behind the scenes. To minimize jank,
 * it will only load one asset at a time. As soon as a developer calls \`Assets.load(...)\` the
 * background loader is paused and requested assets are loaded as a priority.
 * Don't worry if something is in there that's already loaded, it will just get skipped!
 *
 * You still need to call \`Assets.load(...)\` to get an asset that has been loaded in the background.
 * It's just that this promise will resolve instantly if the asset
 * has already been loaded.
 * </details>
 *
 * <details id="manifests-and-bundles">
 *
 * <summary>Manifest and Bundles</summary>
 *
 * - {@link assets.AssetsManifest Manifest} is a descriptor that contains a list of all assets and their properties.
 * - {@link assets.AssetsBundle Bundles} are a way to group assets together.
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * // Manifest Example
 * const manifest = {
 *     bundles: [
 *         {
 *             name: 'load-screen',
 *             assets: [
 *                 {
 *                     alias: 'background',
 *                     src: 'sunset.png',
 *                 },
 *                 {
 *                     alias: 'bar',
 *                     src: 'load-bar.{png,webp}',
 *                 },
 *             ],
 *         },
 *         {
 *             name: 'game-screen',
 *             assets: [
 *                 {
 *                     alias: 'character',
 *                     src: 'robot.png',
 *                 },
 *                 {
 *                     alias: 'enemy',
 *                     src: 'bad-guy.png',
 *                 },
 *             ],
 *         },
 *     ]
 * };
 *
 * await Assets.init({ manifest });
 *
 * // Load a bundle...
 * loadScreenAssets = await Assets.loadBundle('load-screen');
 * // Load another bundle...
 * gameScreenAssets = await Assets.loadBundle('game-screen');
 * \`\`\`
 * </details>
 */
/**
 * The global Assets class, it's a singleton so you don't need to instantiate it.
 *
 * **The \`Assets\` class has four main responsibilities:**
 * 1. Allows users to map URLs to keys and resolve them according to the user's browser capabilities
 * 2. Loads the resources and transforms them into assets that developers understand.
 * 3. Caches the assets and provides a way to access them.
 * 4. Allow developers to unload assets and clear the cache.
 *
 *
 * **It also has a few advanced features:**
 * 1. Allows developers to provide a {@link assets.Manifest} upfront of all assets and help manage
 * them via {@link assets.AssetsBundles Bundles}.
 * 2. Allows users to background load assets. Shortening (or eliminating) load times and improving UX. With this feature,
 * in-game loading bars can be a thing of the past!
 * @example
 * import { Assets } from 'pixi.js';
 *
 * const bunny = await Assets.load('bunny.png');
 * @memberof assets
 * @class Assets
 */
export declare class AssetsClass {
	/** the resolver to map various urls */
	resolver: Resolver;
	/** The loader, loads stuff! */
	loader: Loader;
	/**
	 * The global cache of all assets within PixiJS
	 * @type {assets.Cache}
	 */
	cache: typeof Cache$1;
	/** takes care of loading assets in the background */
	private readonly _backgroundLoader;
	private readonly _detections;
	private _initialized;
	constructor();
	/**
	 * Best practice is to call this function before any loading commences
	 * Initiating is the best time to add any customization to the way things are loaded.
	 *
	 * you do not need to call this for the Assets class to work, only if you want to set any initial properties
	 * @param options - options to initialize the Assets manager with
	 */
	init(options?: AssetInitOptions): Promise<void>;
	/**
	 * Allows you to specify how to resolve any assets load requests.
	 * There are a few ways to add things here as shown below:
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * // Simple
	 * Assets.add({alias: 'bunnyBooBoo', src: 'bunny.png'});
	 * const bunny = await Assets.load('bunnyBooBoo');
	 *
	 * // Multiple keys:
	 * Assets.add({alias: ['burger', 'chicken'], src: 'bunny.png'});
	 *
	 * const bunny = await Assets.load('burger');
	 * const bunny2 = await Assets.load('chicken');
	 *
	 * // passing options to to the object
	 * Assets.add({
	 *     alias: 'bunnyBooBooSmooth',
	 *     src: 'bunny.{png,webp}',
	 *     data: { scaleMode: SCALE_MODES.NEAREST }, // Base texture options
	 * });
	 *
	 * // Multiple assets
	 *
	 * // The following all do the same thing:
	 *
	 * Assets.add({alias: 'bunnyBooBoo', src: 'bunny.{png,webp}'});
	 *
	 * Assets.add({
	 *     alias: 'bunnyBooBoo',
	 *     src: [
	 *         'bunny.png',
	 *         'bunny.webp',
	 *    ],
	 * });
	 *
	 * const bunny = await Assets.load('bunnyBooBoo'); // Will try to load WebP if available
	 * @param assets - the unresolved assets to add to the resolver
	 */
	add(assets: (ArrayOr<UnresolvedAsset>)): void;
	/**
	 * Loads your assets! You pass in a key or URL and it will return a promise that
	 * resolves to the loaded asset. If multiple assets a requested, it will return a hash of assets.
	 *
	 * Don't worry about loading things multiple times, behind the scenes assets are only ever loaded
	 * once and the same promise reused behind the scenes so you can safely call this function multiple
	 * times with the same key and it will always return the same asset.
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * // Load a URL:
	 * const myImageTexture = await Assets.load('http://some.url.com/image.png'); // => returns a texture
	 *
	 * Assets.add('thumper', 'bunny.png');
	 * Assets.add('chicko', 'chicken.png');
	 *
	 * // Load multiple assets:
	 * const textures = await Assets.load(['thumper', 'chicko']); // => {thumper: Texture, chicko: Texture}
	 * @param urls - the urls to load
	 * @param onProgress - optional function that is called when progress on asset loading is made.
	 * The function is passed a single parameter, \`progress\`, which represents the percentage
	 * (0.0 - 1.0) of the assets loaded.
	 * @returns - the assets that were loaded, either a single asset or a hash of assets
	 */
	load<T = any>(urls: string | UnresolvedAsset, onProgress?: ProgressCallback): Promise<T>;
	load<T = any>(urls: string[] | UnresolvedAsset[], onProgress?: ProgressCallback): Promise<Record<string, T>>;
	/**
	 * This adds a bundle of assets in one go so that you can load them as a group.
	 * For example you could add a bundle for each screen in you pixi app
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * Assets.addBundle('animals', [
	 *  { alias: 'bunny', src: 'bunny.png' },
	 *  { alias: 'chicken', src: 'chicken.png' },
	 *  { alias: 'thumper', src: 'thumper.png' },
	 * ]);
	 * // or
	 * Assets.addBundle('animals', {
	 *     bunny: 'bunny.png',
	 *     chicken: 'chicken.png',
	 *     thumper: 'thumper.png',
	 * });
	 *
	 * const assets = await Assets.loadBundle('animals');
	 * @param bundleId - the id of the bundle to add
	 * @param assets - a record of the asset or assets that will be chosen from when loading via the specified key
	 */
	addBundle(bundleId: string, assets: AssetsBundle["assets"]): void;
	/**
	 * Bundles are a way to load multiple assets at once.
	 * If a manifest has been provided to the init function then you can load a bundle, or bundles.
	 * you can also add bundles via \`addBundle\`
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * // Manifest Example
	 * const manifest = {
	 *     bundles: [
	 *         {
	 *             name: 'load-screen',
	 *             assets: [
	 *                 {
	 *                     alias: 'background',
	 *                     src: 'sunset.png',
	 *                 },
	 *                 {
	 *                     alias: 'bar',
	 *                     src: 'load-bar.{png,webp}',
	 *                 },
	 *             ],
	 *         },
	 *         {
	 *             name: 'game-screen',
	 *             assets: [
	 *                 {
	 *                     alias: 'character',
	 *                     src: 'robot.png',
	 *                 },
	 *                 {
	 *                     alias: 'enemy',
	 *                     src: 'bad-guy.png',
	 *                 },
	 *             ],
	 *         },
	 *     ]
	 * };
	 *
	 * await Assets.init({ manifest });
	 *
	 * // Load a bundle...
	 * loadScreenAssets = await Assets.loadBundle('load-screen');
	 * // Load another bundle...
	 * gameScreenAssets = await Assets.loadBundle('game-screen');
	 * @param bundleIds - the bundle id or ids to load
	 * @param onProgress - Optional function that is called when progress on asset loading is made.
	 * The function is passed a single parameter, \`progress\`, which represents the percentage (0.0 - 1.0)
	 * of the assets loaded. Do not use this function to detect when assets are complete and available,
	 * instead use the Promise returned by this function.
	 * @returns all the bundles assets or a hash of assets for each bundle specified
	 */
	loadBundle(bundleIds: ArrayOr<string>, onProgress?: ProgressCallback): Promise<any>;
	/**
	 * Initiate a background load of some assets. It will passively begin to load these assets in the background.
	 * So when you actually come to loading them you will get a promise that resolves to the loaded assets immediately
	 *
	 * An example of this might be that you would background load game assets after your initial load.
	 * then when you got to actually load your game screen assets when a player goes to the game - the loading
	 * would already have stared or may even be complete, saving you having to show an interim load bar.
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * Assets.backgroundLoad('bunny.png');
	 *
	 * // later on in your app...
	 * await Assets.loadBundle('bunny.png'); // Will resolve quicker as loading may have completed!
	 * @param urls - the url / urls you want to background load
	 */
	backgroundLoad(urls: ArrayOr<string>): Promise<void>;
	/**
	 * Initiate a background of a bundle, works exactly like backgroundLoad but for bundles.
	 * this can only be used if the loader has been initiated with a manifest
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * await Assets.init({
	 *     manifest: {
	 *         bundles: [
	 *             {
	 *                 name: 'load-screen',
	 *                 assets: [...],
	 *             },
	 *             ...
	 *         ],
	 *     },
	 * });
	 *
	 * Assets.backgroundLoadBundle('load-screen');
	 *
	 * // Later on in your app...
	 * await Assets.loadBundle('load-screen'); // Will resolve quicker as loading may have completed!
	 * @param bundleIds - the bundleId / bundleIds you want to background load
	 */
	backgroundLoadBundle(bundleIds: ArrayOr<string>): Promise<void>;
	/**
	 * Only intended for development purposes.
	 * This will wipe the resolver and caches.
	 * You will need to reinitialize the Asset
	 */
	reset(): void;
	/**
	 * Instantly gets an asset already loaded from the cache. If the asset has not yet been loaded,
	 * it will return undefined. So it's on you! When in doubt just use \`Assets.load\` instead.
	 * (Remember, the loader will never load things more than once!)
	 * @param keys - The key or keys for the assets that you want to access
	 * @returns - The assets or hash of assets requested
	 */
	get<T = any>(keys: string): T;
	get<T = any>(keys: string[]): Record<string, T>;
	/**
	 * helper function to map resolved assets back to loaded assets
	 * @param resolveResults - the resolve results from the resolver
	 * @param onProgress - the progress callback
	 */
	private _mapLoadToResolve;
	/**
	 * Unload an asset or assets. As the Assets class is responsible for creating the assets via the \`load\` function
	 * this will make sure to destroy any assets and release them from memory.
	 * Once unloaded, you will need to load the asset again.
	 *
	 * Use this to help manage assets if you find that you have a large app and you want to free up memory.
	 *
	 * - it's up to you as the developer to make sure that textures are not actively being used when you unload them,
	 * Pixi won't break but you will end up with missing assets. Not a good look for the user!
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * // Load a URL:
	 * const myImageTexture = await Assets.load('http://some.url.com/image.png'); // => returns a texture
	 *
	 * await Assets.unload('http://some.url.com/image.png')
	 *
	 * // myImageTexture will be destroyed now.
	 *
	 * // Unload multiple assets:
	 * const textures = await Assets.unload(['thumper', 'chicko']);
	 * @param urls - the urls to unload
	 */
	unload(urls: ArrayOr<string> | ResolvedAsset | ResolvedAsset[]): Promise<void>;
	/**
	 * Bundles are a way to manage multiple assets at once.
	 * this will unload all files in a bundle.
	 *
	 * once a bundle has been unloaded, you need to load it again to have access to the assets.
	 * @example
	 * import { Assets } from 'pixi.js';
	 *
	 * Assets.addBundle({
	 *     'thumper': 'http://some.url.com/thumper.png',
	 * })
	 *
	 * const assets = await Assets.loadBundle('thumper');
	 *
	 * // Now to unload...
	 *
	 * await Assets.unloadBundle('thumper');
	 *
	 * // All assets in the assets object will now have been destroyed and purged from the cache
	 * @param bundleIds - the bundle id or ids to unload
	 */
	unloadBundle(bundleIds: ArrayOr<string>): Promise<void>;
	private _unloadFromResolved;
	/**
	 * Detects the supported formats for the browser, and returns an array of supported formats, respecting
	 * the users preferred formats order.
	 * @param options - the options to use when detecting formats
	 * @param options.preferredFormats - the preferred formats to use
	 * @param options.skipDetections - if we should skip the detections altogether
	 * @param options.detections - the detections to use
	 * @returns - the detected formats
	 */
	private _detectFormats;
	/** All the detection parsers currently added to the Assets class. */
	get detections(): FormatDetectionParser[];
	/**
	 * General setter for preferences. This is a helper function to set preferences on all parsers.
	 * @param preferences - the preferences to set
	 */
	setPreferences(preferences: Partial<AssetsPreferences>): void;
}
export declare const Assets: AssetsClass;
/**
 * Quietly Loads assets in the background.
 * @memberof assets
 */
export declare class BackgroundLoader {
	/** Whether or not the loader should continue loading. */
	private _isActive;
	/** Assets to load. */
	private readonly _assetList;
	/** Whether or not the loader is loading. */
	private _isLoading;
	/** Number of assets to load at a time. */
	private readonly _maxConcurrent;
	/** Should the loader log to the console. */
	verbose: boolean;
	private readonly _loader;
	/**
	 * @param loader
	 * @param verbose - should the loader log to the console
	 */
	constructor(loader: Loader, verbose?: boolean);
	/**
	 * Adds an array of assets to load.
	 * @param assetUrls - assets to load
	 */
	add(assetUrls: ResolvedAsset[]): void;
	/**
	 * Loads the next set of assets. Will try to load as many assets as it can at the same time.
	 *
	 * The max assets it will try to load at one time will be 4.
	 */
	private _next;
	/**
	 * Activate/Deactivate the loading. If set to true then it will immediately continue to load the next asset.
	 * @returns whether the class is active
	 */
	get active(): boolean;
	set active(value: boolean);
}
/**
 * Returns an object of textures from an array of textures to be cached
 * @memberof assets
 */
export declare const cacheTextureArray: CacheParser<Texture[]>;
/**
 * Detects if the browser supports the AVIF image format.
 * @memberof assets
 */
export declare const detectAvif: FormatDetectionParser;
/**
 * Adds some default image formats to the detection parser
 * @memberof assets
 */
export declare const detectDefaults: FormatDetectionParser;
/**
 * Detects if the browser supports the MP4 video format.
 * @memberof assets
 */
export declare const detectMp4: FormatDetectionParser;
/**
 * Detects if the browser supports the OGV video format.
 * @memberof assets
 */
export declare const detectOgv: FormatDetectionParser;
/**
 * Detects if the browser supports the WebM video format.
 * @memberof assets
 */
export declare const detectWebm: FormatDetectionParser;
/**
 * Detects if the browser supports the WebP image format.
 * @memberof assets
 */
export declare const detectWebp: FormatDetectionParser;
export declare function testImageFormat(imageData: string): Promise<boolean>;
export declare function testVideoFormat(mimeType: string): boolean;
/**
 * A simple loader plugin for loading json data
 * @memberof assets
 */
export declare const loadJson: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string): Promise<T>;
};
/**
 * A simple loader plugin for loading text data
 * @memberof assets
 */
export declare const loadTxt: {
	name: string;
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
		name: string;
	};
	test(url: string): boolean;
	load<T>(url: string): Promise<string>;
};
/**
 * Data for loading a font
 * @memberof assets
 */
export type LoadFontData = {
	/** Font family name */
	family: string;
	/** A set of optional descriptors passed as an object. It can contain any of the descriptors available for @font-face: */
	display: string;
	/**
	 * The featureSettings property of the FontFace interface retrieves or sets infrequently used
	 * font features that are not available from a font's variant properties.
	 */
	featureSettings: string;
	/** The stretch property of the FontFace interface retrieves or sets how the font stretches. */
	stretch: string;
	/** The style property of the FontFace interface retrieves or sets the font's style. */
	style: string;
	/**
	 * The unicodeRange property of the FontFace interface retrieves or sets the range of
	 * unicode code points encompassing the font.
	 */
	unicodeRange: string;
	/** The variant property of the FontFace interface programmatically retrieves or sets font variant values. */
	variant: string;
	/** The weight property of the FontFace interface retrieves or sets the weight of the font. */
	weights: string[];
};
/**
 * Return font face name from a file name
 * Ex.: 'fonts/titan-one.woff' turns into 'Titan One'
 * @param url - File url
 * @memberof assets
 */
export declare function getFontFamilyName(url: string): string;
/**
 * A loader plugin for handling web fonts
 * @example
 * import { Assets } from 'pixi.js';
 *
 * Assets.load({
 *   alias: 'font',
 *   src: 'fonts/titan-one.woff',
 *   data: {
 *     family: 'Titan One',
 *     weights: ['normal', 'bold'],
 *   }
 * })
 * @memberof assets
 */
export declare const loadWebFont: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string, options?: ResolvedAsset<LoadFontData>): Promise<FontFace | FontFace[]>;
	unload(font: FontFace | FontFace[]): void;
};
/**
 * Set cross origin based detecting the url and the crossorigin
 * @param element - Element to apply crossOrigin
 * @param url - URL to check
 * @param crossorigin - Cross origin value to use
 * @memberof assets
 */
export declare function crossOrigin(element: HTMLImageElement | HTMLVideoElement, url: string, crossorigin?: boolean | string): void;
/**
 * Preload a video element
 * @param element - Video element to preload
 */
export declare function preloadVideo(element: HTMLVideoElement): Promise<void>;
/**
 * Sets the \`crossOrigin\` property for this resource based on if the url
 * for this resource is cross-origin. If crossOrigin was manually set, this
 * function does nothing.
 * Nipped from the resource loader!
 * @ignore
 * @param url - The url to test.
 * @param {object} [loc=window.location] - The location object to test against.
 * @returns The crossOrigin value to use (or empty string for none).
 * @memberof assets
 */
export declare function determineCrossOrigin(url: string, loc?: Location): string;
/**
 * A simple plugin to load video textures.
 *
 * You can pass VideoSource options to the loader via the .data property of the asset descriptor
 * when using Asset.load().
 * \`\`\`js
 * // Set the data
 * const texture = await Assets.load({
 *     src: './assets/city.mp4',
 *     data: {
 *         preload: true,
 *         autoPlay: true,
 *     },
 * });
 * \`\`\`
 * @memberof assets
 */
export declare const loadVideoTextures: {
	name: string;
	extension: {
		type: ExtensionType.LoadParser;
		name: string;
	};
	test(url: string): boolean;
	load<T>(url: string, asset: ResolvedAsset<VideoSourceOptions>, loader: Loader): Promise<Texture>;
	unload(texture: Texture): void;
};
/**
 * Creates a texture from a source and adds it to the cache.
 * @param source - source of the texture
 * @param loader - loader
 * @param url - url of the texture
 * @ignore
 */
export declare function createTexture(source: TextureSource, loader: Loader, url: string): Texture<TextureSource<any>>;
declare class WorkerManagerClass {
	worker: Worker;
	private _resolveHash;
	private readonly _workerPool;
	private readonly _queue;
	private _initialized;
	private _createdWorkers;
	private _isImageBitmapSupported?;
	constructor();
	isImageBitmapSupported(): Promise<boolean>;
	loadImageBitmap(src: string, asset?: ResolvedAsset<TextureSourceOptions<any>>): Promise<ImageBitmap>;
	private _initWorkers;
	private _getWorker;
	private _returnWorker;
	private _complete;
	private _run;
	private _next;
}
export declare const WorkerManager: WorkerManagerClass;
/**
 * A parser that will resolve a json urls resolution for spritesheets
 * e.g. \`assets/spritesheet@1x.json\`
 * @memberof assets
 */
export declare const resolveJsonUrl: {
	extension: {
		type: ExtensionType.ResolveParser;
		priority: number;
		name: string;
	};
	test: (value: string) => boolean;
	parse: (value: string) => {
		resolution: number;
		format: string;
		src: string;
	};
};
/**
 * A parser that will resolve a texture url
 * @memberof assets
 */
export declare const resolveTextureUrl: {
	extension: {
		type: ExtensionType.ResolveParser;
		name: string;
	};
	test: (url: string, resolvedAsset?: ResolvedAsset<TextureSourceOptions<any>>, loader?: Loader) => boolean;
	parse: (value: string) => {
		resolution: number;
		format: string;
		src: string;
	};
};
export declare function checkDataUrl(url: string, mimes: string | string[]): boolean;
export declare function checkExtension(url: string, extension: string | string[]): boolean;
export declare const convertToList: <T>(input: string | T | (string | T)[], transform?: (input: string) => T, forceTransform?: boolean) => T[];
/**
 * Copies the search params from one url to another
 * @param targetUrl - the url to copy the search params to
 * @param sourceUrl - the url container the search params we want to copy
 * @returns the url with the search params copied
 */
export declare const copySearchParams: (targetUrl: string, sourceUrl: string) => string;
/**
 * Creates a list of all possible combinations of the given strings.
 * @example
 * const out2 = createStringVariations('name is {chicken,wolf,sheep}');
 * console.log(out2); // [ 'name is chicken', 'name is wolf', 'name is sheep' ]
 * @param string - The string to process
 */
export declare function createStringVariations(string: string): string[];
/**
 * Checks if the given value is an array.
 * @param item - The item to test
 */
export declare const isSingleItem: (item: unknown) => boolean;
export declare const detectBasis: FormatDetectionParser;
/** Loads KTX textures! */
export declare const loadBasis: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
		name: string;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
	unload(texture: Texture | Texture[]): void;
};
export type BASISModuleCreator = (config: {
	locateFile: (file: string) => string;
}) => {
	then: (result: (libktx: BASISModule) => void) => void;
};
export type BasisTextureConstructor = new (data: Uint8Array) => BasisTexture;
export interface BASISModule {
	initializeBasis(): void;
	BasisFile: BasisTextureConstructor;
}
export interface BasisTexture {
	getNumImages(): number;
	getNumLevels(imageIndex: number): number;
	startTranscoding(): boolean;
	getImageWidth(imageIndex: number, levelIndex: number): number;
	getImageHeight(imageIndex: number, levelIndex: number): number;
	getImageTranscodedSizeInBytes(imageIndex: number, levelIndex: number, format: number): number;
	transcodeImage(buffer: Uint8Array, imageIndex: number, levelIndex: number, format: number, unused: number, getAlphaForOpaqueFormats: number): boolean;
}
export declare function createLevelBuffers(basisTexture: BasisTexture, basisTranscoderFormat: number): Uint8Array[];
export declare function gpuFormatToBasisTranscoderFormat(transcoderFormat: string): number;
export declare const basisTranscoderUrls: {
	jsUrl: string;
	wasmUrl: string;
};
export declare function setBasisTranscoderPath(config: Partial<typeof basisTranscoderUrls>): void;
export declare function loadBasisOnWorker(url: string, supportedTextures: TEXTURE_FORMATS[]): Promise<TextureSourceOptions>;
/**
 * @see https://docs.microsoft.com/en-us/windows/win32/api/dxgiformat/ne-dxgiformat-dxgi_format
 * This is way over-blown for us! Lend us a hand, and remove the ones that aren't used (but set the remaining
 * ones to their correct value)
 * @ignore
 */
export declare enum DXGI_FORMAT {
	DXGI_FORMAT_UNKNOWN = 0,
	DXGI_FORMAT_R32G32B32A32_TYPELESS = 1,
	DXGI_FORMAT_R32G32B32A32_FLOAT = 2,
	DXGI_FORMAT_R32G32B32A32_UINT = 3,
	DXGI_FORMAT_R32G32B32A32_SINT = 4,
	DXGI_FORMAT_R32G32B32_TYPELESS = 5,
	DXGI_FORMAT_R32G32B32_FLOAT = 6,
	DXGI_FORMAT_R32G32B32_UINT = 7,
	DXGI_FORMAT_R32G32B32_SINT = 8,
	DXGI_FORMAT_R16G16B16A16_TYPELESS = 9,
	DXGI_FORMAT_R16G16B16A16_FLOAT = 10,
	DXGI_FORMAT_R16G16B16A16_UNORM = 11,
	DXGI_FORMAT_R16G16B16A16_UINT = 12,
	DXGI_FORMAT_R16G16B16A16_SNORM = 13,
	DXGI_FORMAT_R16G16B16A16_SINT = 14,
	DXGI_FORMAT_R32G32_TYPELESS = 15,
	DXGI_FORMAT_R32G32_FLOAT = 16,
	DXGI_FORMAT_R32G32_UINT = 17,
	DXGI_FORMAT_R32G32_SINT = 18,
	DXGI_FORMAT_R32G8X24_TYPELESS = 19,
	DXGI_FORMAT_D32_FLOAT_S8X24_UINT = 20,
	DXGI_FORMAT_R32_FLOAT_X8X24_TYPELESS = 21,
	DXGI_FORMAT_X32_TYPELESS_G8X24_UINT = 22,
	DXGI_FORMAT_R10G10B10A2_TYPELESS = 23,
	DXGI_FORMAT_R10G10B10A2_UNORM = 24,
	DXGI_FORMAT_R10G10B10A2_UINT = 25,
	DXGI_FORMAT_R11G11B10_FLOAT = 26,
	DXGI_FORMAT_R8G8B8A8_TYPELESS = 27,
	DXGI_FORMAT_R8G8B8A8_UNORM = 28,
	DXGI_FORMAT_R8G8B8A8_UNORM_SRGB = 29,
	DXGI_FORMAT_R8G8B8A8_UINT = 30,
	DXGI_FORMAT_R8G8B8A8_SNORM = 31,
	DXGI_FORMAT_R8G8B8A8_SINT = 32,
	DXGI_FORMAT_R16G16_TYPELESS = 33,
	DXGI_FORMAT_R16G16_FLOAT = 34,
	DXGI_FORMAT_R16G16_UNORM = 35,
	DXGI_FORMAT_R16G16_UINT = 36,
	DXGI_FORMAT_R16G16_SNORM = 37,
	DXGI_FORMAT_R16G16_SINT = 38,
	DXGI_FORMAT_R32_TYPELESS = 39,
	DXGI_FORMAT_D32_FLOAT = 40,
	DXGI_FORMAT_R32_FLOAT = 41,
	DXGI_FORMAT_R32_UINT = 42,
	DXGI_FORMAT_R32_SINT = 43,
	DXGI_FORMAT_R24G8_TYPELESS = 44,
	DXGI_FORMAT_D24_UNORM_S8_UINT = 45,
	DXGI_FORMAT_R24_UNORM_X8_TYPELESS = 46,
	DXGI_FORMAT_X24_TYPELESS_G8_UINT = 47,
	DXGI_FORMAT_R8G8_TYPELESS = 48,
	DXGI_FORMAT_R8G8_UNORM = 49,
	DXGI_FORMAT_R8G8_UINT = 50,
	DXGI_FORMAT_R8G8_SNORM = 51,
	DXGI_FORMAT_R8G8_SINT = 52,
	DXGI_FORMAT_R16_TYPELESS = 53,
	DXGI_FORMAT_R16_FLOAT = 54,
	DXGI_FORMAT_D16_UNORM = 55,
	DXGI_FORMAT_R16_UNORM = 56,
	DXGI_FORMAT_R16_UINT = 57,
	DXGI_FORMAT_R16_SNORM = 58,
	DXGI_FORMAT_R16_SINT = 59,
	DXGI_FORMAT_R8_TYPELESS = 60,
	DXGI_FORMAT_R8_UNORM = 61,
	DXGI_FORMAT_R8_UINT = 62,
	DXGI_FORMAT_R8_SNORM = 63,
	DXGI_FORMAT_R8_SINT = 64,
	DXGI_FORMAT_A8_UNORM = 65,
	DXGI_FORMAT_R1_UNORM = 66,
	DXGI_FORMAT_R9G9B9E5_SHAREDEXP = 67,
	DXGI_FORMAT_R8G8_B8G8_UNORM = 68,
	DXGI_FORMAT_G8R8_G8B8_UNORM = 69,
	DXGI_FORMAT_BC1_TYPELESS = 70,
	DXGI_FORMAT_BC1_UNORM = 71,
	DXGI_FORMAT_BC1_UNORM_SRGB = 72,
	DXGI_FORMAT_BC2_TYPELESS = 73,
	DXGI_FORMAT_BC2_UNORM = 74,
	DXGI_FORMAT_BC2_UNORM_SRGB = 75,
	DXGI_FORMAT_BC3_TYPELESS = 76,
	DXGI_FORMAT_BC3_UNORM = 77,
	DXGI_FORMAT_BC3_UNORM_SRGB = 78,
	DXGI_FORMAT_BC4_TYPELESS = 79,
	DXGI_FORMAT_BC4_UNORM = 80,
	DXGI_FORMAT_BC4_SNORM = 81,
	DXGI_FORMAT_BC5_TYPELESS = 82,
	DXGI_FORMAT_BC5_UNORM = 83,
	DXGI_FORMAT_BC5_SNORM = 84,
	DXGI_FORMAT_B5G6R5_UNORM = 85,
	DXGI_FORMAT_B5G5R5A1_UNORM = 86,
	DXGI_FORMAT_B8G8R8A8_UNORM = 87,
	DXGI_FORMAT_B8G8R8X8_UNORM = 88,
	DXGI_FORMAT_R10G10B10_XR_BIAS_A2_UNORM = 89,
	DXGI_FORMAT_B8G8R8A8_TYPELESS = 90,
	DXGI_FORMAT_B8G8R8A8_UNORM_SRGB = 91,
	DXGI_FORMAT_B8G8R8X8_TYPELESS = 92,
	DXGI_FORMAT_B8G8R8X8_UNORM_SRGB = 93,
	DXGI_FORMAT_BC6H_TYPELESS = 94,
	DXGI_FORMAT_BC6H_UF16 = 95,
	DXGI_FORMAT_BC6H_SF16 = 96,
	DXGI_FORMAT_BC7_TYPELESS = 97,
	DXGI_FORMAT_BC7_UNORM = 98,
	DXGI_FORMAT_BC7_UNORM_SRGB = 99,
	DXGI_FORMAT_AYUV = 100,
	DXGI_FORMAT_Y410 = 101,
	DXGI_FORMAT_Y416 = 102,
	DXGI_FORMAT_NV12 = 103,
	DXGI_FORMAT_P010 = 104,
	DXGI_FORMAT_P016 = 105,
	DXGI_FORMAT_420_OPAQUE = 106,
	DXGI_FORMAT_YUY2 = 107,
	DXGI_FORMAT_Y210 = 108,
	DXGI_FORMAT_Y216 = 109,
	DXGI_FORMAT_NV11 = 110,
	DXGI_FORMAT_AI44 = 111,
	DXGI_FORMAT_IA44 = 112,
	DXGI_FORMAT_P8 = 113,
	DXGI_FORMAT_A8P8 = 114,
	DXGI_FORMAT_B4G4R4A4_UNORM = 115,
	DXGI_FORMAT_P208 = 116,
	DXGI_FORMAT_V208 = 117,
	DXGI_FORMAT_V408 = 118,
	DXGI_FORMAT_SAMPLER_FEEDBACK_MIN_MIP_OPAQUE = 119,
	DXGI_FORMAT_SAMPLER_FEEDBACK_MIP_REGION_USED_OPAQUE = 120,
	DXGI_FORMAT_FORCE_UINT = 121
}
/**
 * Possible values of the field {@link DDS_DX10_FIELDS.RESOURCE_DIMENSION}
 * @ignore
 */
export declare enum D3D10_RESOURCE_DIMENSION {
	DDS_DIMENSION_TEXTURE1D = 2,
	DDS_DIMENSION_TEXTURE2D = 3,
	DDS_DIMENSION_TEXTURE3D = 6
}
export declare enum D3DFMT {
	UNKNOWN = 0,
	R8G8B8 = 20,
	A8R8G8B8 = 21,
	X8R8G8B8 = 22,
	R5G6B5 = 23,
	X1R5G5B5 = 24,
	A1R5G5B5 = 25,
	A4R4G4B4 = 26,
	R3G3B2 = 27,
	A8 = 28,
	A8R3G3B2 = 29,
	X4R4G4B4 = 30,
	A2B10G10R10 = 31,
	A8B8G8R8 = 32,
	X8B8G8R8 = 33,
	G16R16 = 34,
	A2R10G10B10 = 35,
	A16B16G16R16 = 36,
	A8P8 = 40,
	P8 = 41,
	L8 = 50,
	A8L8 = 51,
	A4L4 = 52,
	V8U8 = 60,
	L6V5U5 = 61,
	X8L8V8U8 = 62,
	Q8W8V8U8 = 63,
	V16U16 = 64,
	A2W10V10U10 = 67,
	Q16W16V16U16 = 110,
	R16F = 111,
	G16R16F = 112,
	A16B16G16R16F = 113,
	R32F = 114,
	G32R32F = 115,
	A32B32G32R32F = 116,
	UYVY,
	R8G8_B8G8,
	YUY2,
	D3DFMT_G8R8_G8B8,
	DXT1,
	DXT2,
	DXT3,
	DXT4,
	DXT5,
	ATI1,
	AT1N,
	ATI2,
	AT2N,
	BC4U,
	BC4S,
	BC5U,
	BC5S,
	DX10
}
/**
 * Maps \`FOURCC_*\` formats to {@link TEXTURE_FORMATS}.
 * https://en.wikipedia.org/wiki/S3_Texture_Compression#S3TC_format_comparison
 * https://github.com/microsoft/DirectXTex/blob/main/DDSTextureLoader/DDSTextureLoader11.cpp
 * @ignore
 */
export declare const FOURCC_TO_TEXTURE_FORMAT: {
	[id: number]: TEXTURE_FORMATS;
};
/**
 * Maps {@link DXGI_FORMAT} to {@link TEXTURE_FORMATS}
 * @ignore
 */
export declare const DXGI_TO_TEXTURE_FORMAT: {
	[id: number]: TEXTURE_FORMATS;
};
export declare const DDS: {
	MAGIC_VALUE: number;
	MAGIC_SIZE: number;
	HEADER_SIZE: number;
	HEADER_DX10_SIZE: number;
	PIXEL_FORMAT_FLAGS: {
		ALPHAPIXELS: number;
		ALPHA: number;
		FOURCC: number;
		RGB: number;
		RGBA: number;
		YUV: number;
		LUMINANCE: number;
		LUMINANCEA: number;
	};
	RESOURCE_MISC_TEXTURECUBE: number;
	HEADER_FIELDS: {
		MAGIC: number;
		SIZE: number;
		FLAGS: number;
		HEIGHT: number;
		WIDTH: number;
		MIPMAP_COUNT: number;
		PIXEL_FORMAT: number;
		PF_FLAGS: number;
		FOURCC: number;
		RGB_BITCOUNT: number;
		R_BIT_MASK: number;
		G_BIT_MASK: number;
		B_BIT_MASK: number;
		A_BIT_MASK: number;
	};
	HEADER_DX10_FIELDS: {
		DXGI_FORMAT: number;
		RESOURCE_DIMENSION: number;
		MISC_FLAG: number;
		ARRAY_SIZE: number;
		MISC_FLAGS2: number;
	};
	DXGI_FORMAT: typeof DXGI_FORMAT;
	D3D10_RESOURCE_DIMENSION: typeof D3D10_RESOURCE_DIMENSION;
	D3DFMT: typeof D3DFMT;
};
export declare const TEXTURE_FORMAT_BLOCK_SIZE: Record<string, number>;
/** Loads KTX textures! */
export declare const loadDDS: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
		name: string;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
	unload(texture: Texture | Texture[]): void;
};
export declare function parseDDS(arrayBuffer: ArrayBuffer, supportedFormats: TEXTURE_FORMATS[]): TextureSourceOptions<Uint8Array[]>;
/** Loads KTX textures! */
export declare const loadKTX: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
		name: string;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
	unload(texture: Texture | Texture[]): void;
};
export declare function parseKTX(arrayBuffer: ArrayBuffer, supportedFormats: TEXTURE_FORMATS[]): TextureSourceOptions<Uint8Array[]>;
export declare enum GL_INTERNAL_FORMAT {
	RGBA8_SNORM = 36759,
	RGBA = 6408,
	RGBA8UI = 36220,
	SRGB8_ALPHA8 = 35907,
	RGBA8I = 36238,
	RGBA8 = 32856,
	COMPRESSED_RGB_S3TC_DXT1_EXT = 33776,
	COMPRESSED_RGBA_S3TC_DXT1_EXT = 33777,
	COMPRESSED_RGBA_S3TC_DXT3_EXT = 33778,
	COMPRESSED_RGBA_S3TC_DXT5_EXT = 33779,
	COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT = 35917,
	COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT = 35918,
	COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT = 35919,
	COMPRESSED_SRGB_S3TC_DXT1_EXT = 35916,
	COMPRESSED_RED_RGTC1_EXT = 36283,
	COMPRESSED_SIGNED_RED_RGTC1_EXT = 36284,
	COMPRESSED_RED_GREEN_RGTC2_EXT = 36285,
	COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT = 36286,
	COMPRESSED_R11_EAC = 37488,
	COMPRESSED_SIGNED_R11_EAC = 37489,
	COMPRESSED_RG11_EAC = 37490,
	COMPRESSED_SIGNED_RG11_EAC = 37491,
	COMPRESSED_RGB8_ETC2 = 37492,
	COMPRESSED_RGBA8_ETC2_EAC = 37496,
	COMPRESSED_SRGB8_ETC2 = 37493,
	COMPRESSED_SRGB8_ALPHA8_ETC2_EAC = 37497,
	COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2 = 37494,
	COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2 = 37495,
	COMPRESSED_RGBA_ASTC_4x4_KHR = 37808,
	COMPRESSED_RGBA_ASTC_5x4_KHR = 37809,
	COMPRESSED_RGBA_ASTC_5x5_KHR = 37810,
	COMPRESSED_RGBA_ASTC_6x5_KHR = 37811,
	COMPRESSED_RGBA_ASTC_6x6_KHR = 37812,
	COMPRESSED_RGBA_ASTC_8x5_KHR = 37813,
	COMPRESSED_RGBA_ASTC_8x6_KHR = 37814,
	COMPRESSED_RGBA_ASTC_8x8_KHR = 37815,
	COMPRESSED_RGBA_ASTC_10x5_KHR = 37816,
	COMPRESSED_RGBA_ASTC_10x6_KHR = 37817,
	COMPRESSED_RGBA_ASTC_10x8_KHR = 37818,
	COMPRESSED_RGBA_ASTC_10x10_KHR = 37819,
	COMPRESSED_RGBA_ASTC_12x10_KHR = 37820,
	COMPRESSED_RGBA_ASTC_12x12_KHR = 37821,
	COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR = 37840,
	COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR = 37841,
	COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR = 37842,
	COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR = 37843,
	COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR = 37844,
	COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR = 37845,
	COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR = 37846,
	COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR = 37847,
	COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR = 37848,
	COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR = 37849,
	COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR = 37850,
	COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR = 37851,
	COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR = 37852,
	COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR = 37853,
	COMPRESSED_RGBA_BPTC_UNORM_EXT = 36492,
	COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT = 36493,
	COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT = 36494,
	COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT = 36495
}
export declare const KTX: {
	FILE_HEADER_SIZE: number;
	FILE_IDENTIFIER: number[];
	FORMATS_TO_COMPONENTS: {
		[id: number]: number;
	};
	INTERNAL_FORMAT_TO_BYTES_PER_PIXEL: {
		[id: number]: number;
	};
	INTERNAL_FORMAT_TO_TEXTURE_FORMATS: {
		[id: number]: TEXTURE_FORMATS;
	};
	FIELDS: {
		FILE_IDENTIFIER: number;
		ENDIANNESS: number;
		GL_TYPE: number;
		GL_TYPE_SIZE: number;
		GL_FORMAT: number;
		GL_INTERNAL_FORMAT: number;
		GL_BASE_INTERNAL_FORMAT: number;
		PIXEL_WIDTH: number;
		PIXEL_HEIGHT: number;
		PIXEL_DEPTH: number;
		NUMBER_OF_ARRAY_ELEMENTS: number;
		NUMBER_OF_FACES: number;
		NUMBER_OF_MIPMAP_LEVELS: number;
		BYTES_OF_KEY_VALUE_DATA: number;
	};
	TYPES_TO_BYTES_PER_COMPONENT: {
		[id: number]: number;
	};
	TYPES_TO_BYTES_PER_PIXEL: {
		[id: number]: number;
	};
	ENDIANNESS: number;
};
/** Loads KTX2 textures! */
export declare const loadKTX2: {
	extension: {
		type: ExtensionType.LoadParser;
		priority: LoaderParserPriority;
		name: string;
	};
	name: string;
	test(url: string): boolean;
	load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
	unload(texture: Texture | Texture[]): Promise<void>;
};
export type LIBKTXModuleCreator = (config: {
	locateFile: (file: string) => string;
}) => {
	then: (result: (libktx: LIBKTXModule) => void) => void;
};
export interface KTXTexture {
	getImageData(level: number, layer: number, face: number): Uint8Array;
	glInternalformat: number;
	vkFormat: number;
	classId: number;
	numLevels: number;
	baseHeight: number;
	baseWidth: number;
	transcodeBasis(transcodeFormat: any, arg1: number): unknown;
	needsTranscoding: boolean;
}
export interface LIBKTXModule {
	ErrorCode: any;
	TranscodeTarget: any;
	ktxTexture: new (data: Uint8Array) => KTXTexture;
}
export type COMPRESSED_TEXTURE_FORMATS = TEXTURE_FORMATS | "rgb8unorm" | "rgb8unorm-srgb";
export declare function convertFormatIfRequired(textureOptions: TextureSourceOptions): void;
export declare function createLevelBuffersFromKTX(ktxTexture: KTXTexture): Uint8Array[];
export declare function getTextureFormatFromKTXTexture(ktxTexture: KTXTexture): COMPRESSED_TEXTURE_FORMATS;
export declare function glFormatToGPUFormat(glInternalFormat: number): COMPRESSED_TEXTURE_FORMATS;
export declare function gpuFormatToKTXBasisTranscoderFormat(transcoderFormat: string): string;
export declare const ktxTranscoderUrls: {
	jsUrl: string;
	wasmUrl: string;
};
export declare function setKTXTranscoderPath(config: Partial<typeof ktxTranscoderUrls>): void;
export declare function vkFormatToGPUFormat(vkFormat: number): COMPRESSED_TEXTURE_FORMATS;
export declare function loadKTX2onWorker(url: string, supportedTextures: TEXTURE_FORMATS[]): Promise<TextureSourceOptions>;
export declare const detectCompressed: FormatDetectionParser;
export declare const validFormats: string[];
export declare const resolveCompressedTextureUrl: {
	extension: ExtensionType.ResolveParser;
	test: (value: string) => boolean;
	parse: (value: string) => {
		resolution: number;
		format: string;
		src: string;
	};
};
type RectangleLike = {
	x: number;
	y: number;
	width: number;
	height: number;
};
/**
 * The Culler class is responsible for managing and culling containers.
 *
 *
 * Culled containers will not be rendered, and their children will not be processed. This can be useful for
 * performance optimization when dealing with large scenes.
 * @example
 * import { Culler, Container } from 'pixi.js';
 *
 * const culler = new Culler();
 * const stage = new Container();
 *
 * ... set up stage ...
 *
 * culler.cull(stage, { x: 0, y: 0, width: 800, height: 600 });
 * renderer.render(stage);
 * @memberof scene
 */
export declare class Culler {
	/**
	 * Culls the children of a specific container based on the given view. This will also cull items that are not
	 * being explicitly managed by the culler.
	 * @param container - The container to cull.
	 * @param view - The view rectangle.
	 * @param skipUpdateTransform - Whether to skip updating the transform.
	 */
	cull(container: Container, view: RectangleLike, skipUpdateTransform?: boolean): void;
	private _cullRecursive;
	/** A shared instance of the Culler class. */
	static shared: Culler;
}
/**
 * An {@link app.Application} plugin that will automatically cull your stage using the renderers screen size.
 * @example
 * import { extensions, CullerPlugin } from 'pixi.js';
 *
 * extensions.add(CullerPlugin);
 * @memberof app
 * @see {@link scene.Culler}
 */
export declare class CullerPlugin {
	/** @ignore */
	static extension: ExtensionMetadata;
	static renderer: Renderer;
	static stage: Container;
	static render: () => void;
	private static _renderRef;
	static init(): void;
	static destroy(): void;
}
/**
 * PixiJS supports multiple environments including browsers, Web Workers, and Node.js.
 * The environment is auto-detected by default using the {@link environment.autoDetectEnvironment} function.
 *
 * The {@link environment.Adapter} interface provides a way to abstract away the differences between
 * these environments. PixiJS uses the {@link environment.BrowserAdapter} by default.
 *
 * However you can manually set the environment using the {@link environment.DOMAdapter} singleton, for example to
 * use Pixi within a WebWorker.
 * \`\`\`js
 * import { DOMAdapter, WebWorkerAdapter } from 'pixi.js';
 *
 * // WebWorkerAdapter is an implementation of the Adapter interface
 * DOMAdapter.set(WebWorkerAdapter);
 *
 * // use the adapter to create a canvas (in this case an OffscreenCanvas)
 * DOMAdapter.get().createCanvas(800, 600);
 * \`\`\`
 * @namespace environment
 */
/**
 * This interface describes all the DOM dependent calls that Pixi makes throughout its codebase.
 * Implementations of this interface can be used to make sure Pixi will work in any environment,
 * such as browser, Web Workers, and Node.js.
 * @memberof environment
 */
export interface Adapter {
	/** Returns a canvas object that can be used to create a webgl context. */
	createCanvas: (width?: number, height?: number) => ICanvas;
	/** Returns a 2D rendering context. */
	getCanvasRenderingContext2D: () => {
		prototype: ICanvasRenderingContext2D;
	};
	/** Returns a WebGL rendering context. */
	getWebGLRenderingContext: () => typeof WebGLRenderingContext;
	/** Returns a partial implementation of the browsers window.navigator */
	getNavigator: () => {
		userAgent: string;
		gpu: GPU | null;
	};
	/** Returns the current base URL For browser environments this is either the document.baseURI or window.location.href */
	getBaseUrl: () => string;
	/** Return the font face set if available */
	getFontFaceSet: () => FontFaceSet | null;
	/** Returns a Response object that has been fetched from the given URL. */
	fetch: (url: RequestInfo, options?: RequestInit) => Promise<Response>;
	/** Returns Document object that has been parsed from the given XML string. */
	parseXML: (xml: string) => Document;
}
/**
 * The DOMAdapter is a singleton that allows PixiJS to perform DOM operations, such as creating a canvas.
 * This allows PixiJS to be used in any environment, such as a web browser, Web Worker, or Node.js.
 * It uses the {@link environment.Adapter} interface to abstract away the differences between these environments
 * and uses the {@link environment.BrowserAdapter} by default.
 *
 * It has two methods: \`get():Adapter\` and \`set(adapter: Adapter)\`.
 *
 * Defaults to the {@link environment.BrowserAdapter}.
 * @example
 * import { DOMAdapter, WebWorkerAdapter } from 'pixi.js';
 *
 * // WebWorkerAdapter is an implementation of the Adapter interface
 * DOMAdapter.set(WebWorkerAdapter);
 *
 * // use the adapter to create a canvas (in this case an OffscreenCanvas)
 * DOMAdapter.get().createCanvas(800, 600);
 * @memberof environment
 */
export declare const DOMAdapter: {
	/**
	 * Returns the current adapter.
	 * @returns {environment.Adapter} The current adapter.
	 */
	get(): Adapter;
	/**
	 * Sets the current adapter.
	 * @param adapter - The new adapter.
	 */
	set(adapter: Adapter): void;
};
/**
 * Automatically detects the environment and loads the appropriate extensions.
 * @param skip - whether to skip loading the default extensions
 */
export declare function loadEnvironmentExtensions(skip: boolean): Promise<void>;
/**
 * @param add - whether to add the default imports to the bundle
 * @deprecated since 8.1.6. Use \`loadEnvironmentExtensions\` instead
 */
export declare function autoDetectEnvironment(add: boolean): Promise<void>;
/**
 * This is an implementation of the {@link environment.Adapter} interface.
 * It can be used to make Pixi work in the browser.
 * @memberof environment
 * @property {Function} createCanvas - Creates a canvas element of the given size.
 * This canvas is created using the browser's native canvas element.
 * @property {Function} getCanvasRenderingContext2D - Returns a 2D rendering context.
 * @property {Function} getWebGLRenderingContext - Returns a WebGL rendering context.
 * @property {Function} getNavigator - Returns browsers window.navigator
 * @property {Function} getBaseUrl - Returns the current base URL for browser environments this is either
 * the document.baseURI or window.location.href
 * @property {Function} getFontFaceSet - Return the font face set if available
 * @property {Function} fetch - Returns a Response object that has been fetched from the given URL.
 * @property {Function} parseXML - Returns Document object that has been parsed from the given XML string.
 */
export declare const BrowserAdapter: Adapter;
/**
 * Extension for the browser environment.
 * @memberof environment
 */
export declare const browserExt: {
	extension: {
		type: ExtensionType;
		name: string;
		priority: number;
	};
	test: () => boolean;
	load: () => Promise<void>;
};
/**
 * This is an implementation of the {@link environment.Adapter} interface.
 * It can be used to make Pixi work in a Web Worker.
 * @memberof environment
 * @property {Function} createCanvas - Creates a canvas element of the given size using the browser's native OffscreenCanvas.
 * @property {Function} getCanvasRenderingContext2D - Returns a 2D rendering context.
 * @property {Function} getWebGLRenderingContext - Returns a WebGL rendering context.
 * @property {Function} getNavigator - Returns browsers window.navigator
 * @property {Function} getBaseUrl - Returns the current base URL of the worker, which is globalThis.location.href
 * @property {Function} getFontFaceSet - Return the font face set if available
 * @property {Function} fetch - Returns a Response object that has been fetched from the given URL.
 * @property {Function} parseXML - Returns Document object that has been parsed from the given XML string.
 * @memberof environment
 */
export declare const WebWorkerAdapter: Adapter;
/**
 * Extension for the webworker environment.
 * @memberof environment
 */
export declare const webworkerExt: {
	extension: {
		type: ExtensionType;
		name: string;
		priority: number;
	};
	test: () => boolean;
	load: () => Promise<void>;
};
/**
 * A simplified shape of an interactive object for the \`eventTarget\` property of a {@link FederatedEvent}
 * @memberof events
 * @deprecated since 8.1.4
 */
export interface FederatedEventTarget extends EventEmitter, EventTarget, Required<FederatedOptions> {
	/** The parent of this event target. */
	readonly parent?: FederatedEventTarget;
	/** The children of this event target. */
	readonly children?: ReadonlyArray<FederatedEventTarget>;
	_internalEventMode: EventMode;
	/** Returns true if the Container has interactive 'static' or 'dynamic' */
	isInteractive: () => boolean;
	/** Remove all listeners, or those of the specified event. */
	removeAllListeners(event?: string | symbol): this;
}
declare class EventsTickerClass {
	/** The event system. */
	events: EventSystem;
	/** The DOM element to listen to events on. */
	domElement: HTMLElement;
	/** The frequency that fake events will be fired. */
	interactionFrequency: number;
	private _deltaTime;
	private _didMove;
	private _tickerAdded;
	private _pauseUpdate;
	/**
	 * Initializes the event ticker.
	 * @param events - The event system.
	 */
	init(events: EventSystem): void;
	/** Whether to pause the update checks or not. */
	get pauseUpdate(): boolean;
	set pauseUpdate(paused: boolean);
	/** Adds the ticker listener. */
	addTickerListener(): void;
	/** Removes the ticker listener. */
	removeTickerListener(): void;
	/** Sets flag to not fire extra events when the user has already moved there mouse */
	pointerMoved(): void;
	/** Updates the state of interactive objects. */
	private _update;
	/**
	 * Updates the state of interactive objects if at least {@link interactionFrequency}
	 * milliseconds have passed since the last invocation.
	 *
	 * Invoked by a throttled ticker update from {@link Ticker.system}.
	 * @param ticker - The throttled ticker.
	 */
	private _tickerUpdate;
}
export declare const EventsTicker: EventsTickerClass;
/** A helper object containing the hsl shader code for both glsl */
export declare const hslgl = "\\n\\tfloat getLuminosity(vec3 c) {\\n\\t\\treturn 0.3 * c.r + 0.59 * c.g + 0.11 * c.b;\\n\\t}\\n\\n\\tvec3 setLuminosity(vec3 c, float lum) {\\n\\t\\tfloat modLum = lum - getLuminosity(c);\\n\\t\\tvec3 color = c.rgb + vec3(modLum);\\n\\n\\t\\t// clip back into legal range\\n\\t\\tmodLum = getLuminosity(color);\\n\\t\\tvec3 modLumVec = vec3(modLum);\\n\\n\\t\\tfloat cMin = min(color.r, min(color.g, color.b));\\n\\t\\tfloat cMax = max(color.r, max(color.g, color.b));\\n\\n\\t\\tif(cMin < 0.0) {\\n\\t\\t\\tcolor = mix(modLumVec, color, modLum / (modLum - cMin));\\n\\t\\t}\\n\\n\\t\\tif(cMax > 1.0) {\\n\\t\\t\\tcolor = mix(modLumVec, color, (1.0 - modLum) / (cMax - modLum));\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\n\\tfloat getSaturation(vec3 c) {\\n\\t\\treturn max(c.r, max(c.g, c.b)) - min(c.r, min(c.g, c.b));\\n\\t}\\n\\n\\tvec3 setSaturationMinMidMax(vec3 cSorted, float s) {\\n\\t\\tvec3 colorSorted = cSorted;\\n\\n\\t\\tif(colorSorted.z > colorSorted.x) {\\n\\t\\t\\tcolorSorted.y = (((colorSorted.y - colorSorted.x) * s) / (colorSorted.z - colorSorted.x));\\n\\t\\t\\tcolorSorted.z = s;\\n\\t\\t}\\n\\t\\telse {\\n\\t\\t\\tcolorSorted.y = 0.0;\\n\\t\\t\\tcolorSorted.z = 0.0;\\n\\t\\t}\\n\\n\\t\\tcolorSorted.x = 0.0;\\n\\n\\t\\treturn colorSorted;\\n\\t}\\n\\n\\tvec3 setSaturation(vec3 c, float s) {\\n\\t\\tvec3 color = c;\\n\\n\\t\\tif(color.r <= color.g && color.r <= color.b) {\\n\\t\\t\\tif(color.g <= color.b) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.rgb, s).rgb;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.rbg, s).rbg;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse if(color.g <= color.r && color.g <= color.b) {\\n\\t\\t\\tif(color.r <= color.b) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.grb, s).grb;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.gbr, s).gbr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse {\\n\\t\\t\\t// Using bgr for both fixes part of hue\\n\\t\\t\\tif(color.r <= color.g) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.brg, s).brg;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.bgr, s).bgr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n    ";
/** A helper object containing the hsl shader code for wgsl */
export declare const hslgpu = "\\n\\tfn getLuminosity(c: vec3<f32>) -> f32\\n\\t{\\n\\t\\treturn 0.3*c.r + 0.59*c.g + 0.11*c.b;\\n\\t}\\n\\n\\tfn setLuminosity(c: vec3<f32>, lum: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar modLum: f32 = lum - getLuminosity(c);\\n\\t\\tvar color: vec3<f32> = c.rgb + modLum;\\n\\n\\t\\t// clip back into legal range\\n\\t\\tmodLum = getLuminosity(color);\\n\\t\\tlet modLumVec = vec3<f32>(modLum);\\n\\n\\t\\tlet cMin: f32 = min(color.r, min(color.g, color.b));\\n\\t\\tlet cMax: f32 = max(color.r, max(color.g, color.b));\\n\\n\\t\\tif(cMin < 0.0)\\n\\t\\t{\\n\\t\\t\\tcolor = mix(modLumVec, color, modLum / (modLum - cMin));\\n\\t\\t}\\n\\n\\t\\tif(cMax > 1.0)\\n\\t\\t{\\n\\t\\t\\tcolor = mix(modLumVec, color, (1 - modLum) / (cMax - modLum));\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\n\\tfn getSaturation(c: vec3<f32>) -> f32\\n\\t{\\n\\t\\treturn max(c.r, max(c.g, c.b)) - min(c.r, min(c.g, c.b));\\n\\t}\\n\\n\\tfn setSaturationMinMidMax(cSorted: vec3<f32>, s: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar colorSorted = cSorted;\\n\\n\\t\\tif(colorSorted.z > colorSorted.x)\\n\\t\\t{\\n\\t\\t\\tcolorSorted.y = (((colorSorted.y - colorSorted.x) * s) / (colorSorted.z - colorSorted.x));\\n\\t\\t\\tcolorSorted.z = s;\\n\\t\\t}\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\tcolorSorted.y = 0;\\n\\t\\t\\tcolorSorted.z = 0;\\n\\t\\t}\\n\\n\\t\\tcolorSorted.x = 0;\\n\\n\\t\\treturn colorSorted;\\n\\t}\\n\\n\\tfn setSaturation(c: vec3<f32>, s: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar color = c;\\n\\n\\t\\tif (color.r <= color.g && color.r <= color.b)\\n\\t\\t{\\n\\t\\t\\tif (color.g <= color.b)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.rgb, s)).rgb;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.rbg, s)).rbg;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse if (color.g <= color.r && color.g <= color.b)\\n\\t\\t{\\n\\t\\t\\tif (color.r <= color.b)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.grb, s)).grb;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.gbr, s)).gbr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\t// Using bgr for both fixes part of hue\\n\\t\\t\\tif (color.r <= color.g)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.brg, s)).brg;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor  = vec3<f32>(setSaturationMinMidMax(color.bgr, s)).bgr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\t";
/**
 * Options for AlphaFilter
 * @memberof filters
 */
export interface AlphaFilterOptions extends FilterOptions {
	/**
	 * Amount of alpha from 0 to 1, where 0 is transparent
	 * @default 1
	 */
	alpha: number;
}
/**
 * Simplest filter - applies alpha.
 *
 * Use this instead of Container's alpha property to avoid visual layering of individual elements.
 * AlphaFilter applies alpha evenly across the entire display object and any opaque elements it contains.
 * If elements are not opaque, they will blend with each other anyway.
 *
 * Very handy if you want to use common features of all filters:
 *
 * 1. Assign a blendMode to this filter, blend all elements inside display object with background.
 *
 * 2. To use clipping in display coordinates, assign a filterArea to the same container that has this filter.
 * @memberof filters
 */
export declare class AlphaFilter extends Filter {
	/** Default filter options */
	static readonly defaultOptions: AlphaFilterOptions;
	constructor(options?: AlphaFilterOptions);
	/**
	 * Coefficient for alpha multiplication
	 * @default 1
	 */
	get alpha(): number;
	set alpha(value: number);
}
/**
 * Options for BlurFilterPass
 * @memberof filters
 */
export interface BlurFilterPassOptions extends BlurFilterOptions {
	/** Do pass along the x-axis (\`true\`) or y-axis (\`false\`). */
	horizontal: boolean;
}
/**
 * The BlurFilterPass applies a horizontal or vertical Gaussian blur to an object.
 * @memberof filters
 */
export declare class BlurFilterPass extends Filter {
	/** Default blur filter pass options */
	static defaultOptions: Partial<BlurFilterPassOptions>;
	/** Do pass along the x-axis (\`true\`) or y-axis (\`false\`). */
	horizontal: boolean;
	/** The number of passes to run the filter. */
	passes: number;
	/** The strength of the blur filter. */
	strength: number;
	private _quality;
	private readonly _uniforms;
	/**
	 * @param options
	 * @param options.horizontal - Do pass along the x-axis (\`true\`) or y-axis (\`false\`).
	 * @param options.strength - The strength of the blur filter.
	 * @param options.quality - The quality of the blur filter.
	 * @param options.kernelSize - The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
	 */
	constructor(options: BlurFilterPassOptions);
	/**
	 * Applies the filter.
	 * @param filterManager - The manager.
	 * @param input - The input target.
	 * @param output - The output target.
	 * @param clearMode - How to clear
	 */
	apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
	/**
	 * Sets the strength of both the blur.
	 * @default 16
	 */
	get blur(): number;
	set blur(value: number);
	/**
	 * Sets the quality of the blur by modifying the number of passes. More passes means higher
	 * quality blurring but the lower the performance.
	 * @default 4
	 */
	get quality(): number;
	set quality(value: number);
}
/**
 * Options for BlurFilter
 * @memberof filters
 */
export interface BlurFilterOptions extends FilterOptions {
	/**
	 * The strength of the blur filter.
	 * @default 8
	 */
	strength?: number;
	/**
	 * The horizontal strength of the blur.
	 * @default 8
	 */
	strengthX?: number;
	/**
	 * The vertical strength of the blur.
	 * @default 8
	 */
	strengthY?: number;
	/**
	 * The quality of the blur filter.
	 * @default 4
	 */
	quality?: number;
	/**
	 * The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
	 * @default 5
	 */
	kernelSize?: number;
}
/**
 * The BlurFilter applies a Gaussian blur to an object.
 *
 * The strength of the blur can be set for the x-axis and y-axis separately.
 * @memberof filters
 */
export declare class BlurFilter extends Filter {
	/** Default blur filter options */
	static defaultOptions: Partial<BlurFilterOptions>;
	/** The horizontal blur filter */
	blurXFilter: BlurFilterPass;
	/** The vertical blur filter */
	blurYFilter: BlurFilterPass;
	private _repeatEdgePixels;
	/**
	 * @param {filters.BlurFilterOptions} options - The options of the blur filter.
	 */
	constructor(options?: BlurFilterOptions);
	/** @deprecated since 8.0.0 */
	constructor(strength?: number, quality?: number, resolution?: number | null, kernelSize?: number);
	/**
	 * Applies the filter.
	 * @param filterManager - The manager.
	 * @param input - The input target.
	 * @param output - The output target.
	 * @param clearMode - How to clear
	 */
	apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
	protected updatePadding(): void;
	/**
	 * Sets the strength of both the blurX and blurY properties simultaneously
	 * @default 8
	 */
	get strength(): number;
	set strength(value: number);
	/**
	 * Sets the number of passes for blur. More passes means higher quality bluring.
	 * @default 1
	 */
	get quality(): number;
	set quality(value: number);
	/**
	 * Sets the strength of horizontal blur
	 * @default 8
	 */
	get strengthX(): number;
	set strengthX(value: number);
	/**
	 * Sets the strength of the vertical blur
	 * @default 8
	 */
	get strengthY(): number;
	set strengthY(value: number);
	/**
	 * Sets the strength of both the blurX and blurY properties simultaneously
	 * @default 2
	 * @deprecated since 8.3.0
	 * @see BlurFilter.strength
	 */
	get blur(): number;
	set blur(value: number);
	/**
	 * Sets the strength of the blurX property
	 * @default 2
	 * @deprecated since 8.3.0
	 * @see BlurFilter.strengthX
	 */
	get blurX(): number;
	set blurX(value: number);
	/**
	 * Sets the strength of the blurY property
	 * @default 2
	 * @deprecated since 8.3.0
	 * @see BlurFilter.strengthY
	 */
	get blurY(): number;
	set blurY(value: number);
	/**
	 * If set to true the edge of the target will be clamped
	 * @default false
	 */
	get repeatEdgePixels(): boolean;
	set repeatEdgePixels(value: boolean);
}
export interface IGAUSSIAN_VALUES {
	[x: number]: number[];
}
export declare const GAUSSIAN_VALUES: IGAUSSIAN_VALUES;
export declare function generateBlurFragSource(kernelSize: number): string;
export declare function generateBlurGlProgram(horizontal: boolean, kernelSize: number): GlProgram;
export declare function generateBlurVertSource(kernelSize: number, x: boolean): string;
export declare function generateBlurProgram(horizontal: boolean, kernelSize: number): GpuProgram;
/**
 * 5x4 matrix for transforming RGBA color and alpha
 * @memberof filters
 */
export type ColorMatrix = ArrayFixed<number, 20>;
/**
 * The ColorMatrixFilter class lets you apply a 5x4 matrix transformation on the RGBA
 * color and alpha values of every pixel on your container to produce a result
 * with a new set of RGBA color and alpha values. It's pretty powerful!
 *
 * \`\`\`js
 *  let colorMatrix = new filters.ColorMatrixFilter();
 *  container.filters = [colorMatrix];
 *  colorMatrix.contrast(2);
 * \`\`\`
 * @author Clément Chenebault <clement@goodboydigital.com>
 * @memberof filters
 */
export declare class ColorMatrixFilter extends Filter {
	constructor(options?: FilterOptions);
	/**
	 * Transforms current matrix and set the new one
	 * @param {number[]} matrix - 5x4 matrix
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	private _loadMatrix;
	/**
	 * Multiplies two mat5's
	 * @private
	 * @param out - 5x4 matrix the receiving matrix
	 * @param a - 5x4 matrix the first operand
	 * @param b - 5x4 matrix the second operand
	 * @returns {number[]} 5x4 matrix
	 */
	private _multiply;
	/**
	 * Create a Float32 Array and normalize the offset component to 0-1
	 * @param {number[]} matrix - 5x4 matrix
	 * @returns {number[]} 5x4 matrix with all values between 0-1
	 */
	private _colorMatrix;
	/**
	 * Adjusts brightness
	 * @param b - value of the brightness (0-1, where 0 is black)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	brightness(b: number, multiply: boolean): void;
	/**
	 * Sets each channel on the diagonal of the color matrix.
	 * This can be used to achieve a tinting effect on Containers similar to the tint field of some
	 * display objects like Sprite, Text, Graphics, and Mesh.
	 * @param color - Color of the tint. This is a hex value.
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	tint(color: ColorSource, multiply?: boolean): void;
	/**
	 * Set the matrices in grey scales
	 * @param scale - value of the grey (0-1, where 0 is black)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	greyscale(scale: number, multiply: boolean): void;
	/**
	 * for our american friends!
	 * @param scale
	 * @param multiply
	 */
	grayscale(scale: number, multiply: boolean): void;
	/**
	 * Set the black and white matrice.
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	blackAndWhite(multiply: boolean): void;
	/**
	 * Set the hue property of the color
	 * @param rotation - in degrees
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	hue(rotation: number, multiply: boolean): void;
	/**
	 * Set the contrast matrix, increase the separation between dark and bright
	 * Increase contrast : shadows darker and highlights brighter
	 * Decrease contrast : bring the shadows up and the highlights down
	 * @param amount - value of the contrast (0-1)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	contrast(amount: number, multiply: boolean): void;
	/**
	 * Set the saturation matrix, increase the separation between colors
	 * Increase saturation : increase contrast, brightness, and sharpness
	 * @param amount - The saturation amount (0-1)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	saturate(amount?: number, multiply?: boolean): void;
	/** Desaturate image (remove color) Call the saturate function */
	desaturate(): void;
	/**
	 * Negative image (inverse of classic rgb matrix)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	negative(multiply: boolean): void;
	/**
	 * Sepia image
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	sepia(multiply: boolean): void;
	/**
	 * Color motion picture process invented in 1916 (thanks Dominic Szablewski)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	technicolor(multiply: boolean): void;
	/**
	 * Polaroid filter
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	polaroid(multiply: boolean): void;
	/**
	 * Filter who transforms : Red -> Blue and Blue -> Red
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	toBGR(multiply: boolean): void;
	/**
	 * Color reversal film introduced by Eastman Kodak in 1935. (thanks Dominic Szablewski)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	kodachrome(multiply: boolean): void;
	/**
	 * Brown delicious browni filter (thanks Dominic Szablewski)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	browni(multiply: boolean): void;
	/**
	 * Vintage filter (thanks Dominic Szablewski)
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	vintage(multiply: boolean): void;
	/**
	 * We don't know exactly what it does, kind of gradient map, but funny to play with!
	 * @param desaturation - Tone values.
	 * @param toned - Tone values.
	 * @param lightColor - Tone values, example: \`0xFFE580\`
	 * @param darkColor - Tone values, example: \`0xFFE580\`
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	colorTone(desaturation: number, toned: number, lightColor: ColorSource, darkColor: ColorSource, multiply: boolean): void;
	/**
	 * Night effect
	 * @param intensity - The intensity of the night effect.
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	night(intensity: number, multiply: boolean): void;
	/**
	 * Predator effect
	 *
	 * Erase the current matrix by setting a new independent one
	 * @param amount - how much the predator feels his future victim
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	predator(amount: number, multiply: boolean): void;
	/**
	 * LSD effect
	 *
	 * Multiply the current matrix
	 * @param multiply - if true, current matrix and matrix are multiplied. If false,
	 *  just set the current matrix with @param matrix
	 */
	lsd(multiply: boolean): void;
	/** Erase the current matrix by setting the default one. */
	reset(): void;
	/**
	 * The matrix of the color matrix filter
	 * @member {number[]}
	 * @default [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]
	 */
	get matrix(): ColorMatrix;
	set matrix(value: ColorMatrix);
	/**
	 * The opacity value to use when mixing the original and resultant colors.
	 *
	 * When the value is 0, the original color is used without modification.
	 * When the value is 1, the result color is used.
	 * When in the range (0, 1) the color is interpolated between the original and result by this amount.
	 * @default 1
	 */
	get alpha(): number;
	set alpha(value: number);
}
/**
 * Options for DisplacementFilter
 * @memberof filters
 */
export interface DisplacementFilterOptions extends FilterOptions {
	/** The texture used for the displacement map. */
	sprite: Sprite;
	/** The scale of the displacement. */
	scale?: number | PointData;
}
/**
 * A Noise effect filter.
 *
 * original filter: https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/noise.js
 * @memberof filters
 * @author Vico @vicocotea
 */
export declare class DisplacementFilter extends Filter {
	private readonly _sprite;
	/**
	 * **Note:** Our docs parser struggles to properly understand the constructor signature.
	 * This is the correct signature.
	 * \`\`\`ts
	 * new DisplacementFilter(options?: DisplacementFilterOptions);
	 * \`\`\`
	 * @param options - The options for the filter.
	 * @param options.sprite - The texture used for the displacement map.
	 * @param options.scale - The scale of the displacement.
	 */
	constructor(options: Sprite | DisplacementFilterOptions);
	constructor(sprite: Sprite, scale?: number | PointData);
	/**
	 * Applies the filter.
	 * @param filterManager - The manager.
	 * @param input - The input target.
	 * @param output - The output target.
	 * @param clearMode - clearMode.
	 */
	apply(filterManager: FilterSystem, input: Texture, output: Texture, clearMode: boolean): void;
	/** scaleX, scaleY for displacements */
	get scale(): Point;
}
/**
 * Options for NoiseFilter
 * @memberof filters
 */
export interface NoiseFilterOptions extends FilterOptions {
	/** The amount of noise to apply, this value should be in the range (0, 1]. */
	noise?: number;
	/** A seed value to apply to the random noise generation. \`Math.random()\` is a good value to use. */
	seed?: number;
}
/**
 * A Noise effect filter.
 *
 * original filter: https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/noise.js
 * @memberof filters
 * @author Vico @vicocotea
 */
export declare class NoiseFilter extends Filter {
	static readonly defaultOptions: NoiseFilterOptions;
	/**
	 * @param options - The options of the noise filter.
	 */
	constructor(options?: NoiseFilterOptions);
	/**
	 * The amount of noise to apply, this value should be in the range (0, 1].
	 * @default 0.5
	 */
	get noise(): number;
	set noise(value: number);
	/** A seed value to apply to the random noise generation. \`Math.random()\` is a good value to use. */
	get seed(): number;
	set seed(value: number);
}
export interface MaskFilterOptions extends FilterOptions {
	sprite: Sprite;
	inverse?: boolean;
	scale?: number | {
		x: number;
		y: number;
	};
}
export declare class MaskFilter extends Filter {
	sprite: Sprite;
	private readonly _textureMatrix;
	constructor(options: MaskFilterOptions);
	set inverse(value: boolean);
	get inverse(): boolean;
	apply(filterManager: FilterSystem, input: Texture, output: Texture, clearMode: boolean): void;
}
type GD8Symmetry = number;
/**
 * @typedef {number} GD8Symmetry
 * @see groupD8
 */
/**
 * Implements the dihedral group D8, which is similar to
 * [group D4]{@link http://mathworld.wolfram.com/DihedralGroupD4.html};
 * D8 is the same but with diagonals, and it is used for texture
 * rotations.
 *
 * The directions the U- and V- axes after rotation
 * of an angle of \`a: GD8Constant\` are the vectors \`(uX(a), uY(a))\`
 * and \`(vX(a), vY(a))\`. These aren't necessarily unit vectors.
 *
 * **Origin:**<br>
 *  This is the small part of gameofbombs.com portal system. It works.
 * @see maths.groupD8.E
 * @see maths.groupD8.SE
 * @see maths.groupD8.S
 * @see maths.groupD8.SW
 * @see maths.groupD8.W
 * @see maths.groupD8.NW
 * @see maths.groupD8.N
 * @see maths.groupD8.NE
 * @author Ivan @ivanpopelyshev
 * @namespace maths.groupD8
 */
export declare const groupD8: {
	/**
	 * | Rotation | Direction |
	 * |----------|-----------|
	 * | 0°       | East      |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	E: number;
	/**
	 * | Rotation | Direction |
	 * |----------|-----------|
	 * | 45°↻     | Southeast |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	SE: number;
	/**
	 * | Rotation | Direction |
	 * |----------|-----------|
	 * | 90°↻     | South     |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	S: number;
	/**
	 * | Rotation | Direction |
	 * |----------|-----------|
	 * | 135°↻    | Southwest |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	SW: number;
	/**
	 * | Rotation | Direction |
	 * |----------|-----------|
	 * | 180°     | West      |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	W: number;
	/**
	 * | Rotation    | Direction    |
	 * |-------------|--------------|
	 * | -135°/225°↻ | Northwest    |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	NW: number;
	/**
	 * | Rotation    | Direction    |
	 * |-------------|--------------|
	 * | -90°/270°↻  | North        |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	N: number;
	/**
	 * | Rotation    | Direction    |
	 * |-------------|--------------|
	 * | -45°/315°↻  | Northeast    |
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	NE: number;
	/**
	 * Reflection about Y-axis.
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	MIRROR_VERTICAL: number;
	/**
	 * Reflection about the main diagonal.
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	MAIN_DIAGONAL: number;
	/**
	 * Reflection about X-axis.
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	MIRROR_HORIZONTAL: number;
	/**
	 * Reflection about reverse diagonal.
	 * @memberof maths.groupD8
	 * @constant {GD8Symmetry}
	 */
	REVERSE_DIAGONAL: number;
	/**
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} ind - sprite rotation angle.
	 * @returns {GD8Symmetry} The X-component of the U-axis
	 *    after rotating the axes.
	 */
	uX: (ind: GD8Symmetry) => GD8Symmetry;
	/**
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} ind - sprite rotation angle.
	 * @returns {GD8Symmetry} The Y-component of the U-axis
	 *    after rotating the axes.
	 */
	uY: (ind: GD8Symmetry) => GD8Symmetry;
	/**
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} ind - sprite rotation angle.
	 * @returns {GD8Symmetry} The X-component of the V-axis
	 *    after rotating the axes.
	 */
	vX: (ind: GD8Symmetry) => GD8Symmetry;
	/**
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} ind - sprite rotation angle.
	 * @returns {GD8Symmetry} The Y-component of the V-axis
	 *    after rotating the axes.
	 */
	vY: (ind: GD8Symmetry) => GD8Symmetry;
	/**
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} rotation - symmetry whose opposite
	 *   is needed. Only rotations have opposite symmetries while
	 *   reflections don't.
	 * @returns {GD8Symmetry} The opposite symmetry of \`rotation\`
	 */
	inv: (rotation: GD8Symmetry) => GD8Symmetry;
	/**
	 * Composes the two D8 operations.
	 *
	 * Taking \`^\` as reflection:
	 *
	 * |       | E=0 | S=2 | W=4 | N=6 | E^=8 | S^=10 | W^=12 | N^=14 |
	 * |-------|-----|-----|-----|-----|------|-------|-------|-------|
	 * | E=0   | E   | S   | W   | N   | E^   | S^    | W^    | N^    |
	 * | S=2   | S   | W   | N   | E   | S^   | W^    | N^    | E^    |
	 * | W=4   | W   | N   | E   | S   | W^   | N^    | E^    | S^    |
	 * | N=6   | N   | E   | S   | W   | N^   | E^    | S^    | W^    |
	 * | E^=8  | E^  | N^  | W^  | S^  | E    | N     | W     | S     |
	 * | S^=10 | S^  | E^  | N^  | W^  | S    | E     | N     | W     |
	 * | W^=12 | W^  | S^  | E^  | N^  | W    | S     | E     | N     |
	 * | N^=14 | N^  | W^  | S^  | E^  | N    | W     | S     | E     |
	 *
	 * [This is a Cayley table]{@link https://en.wikipedia.org/wiki/Cayley_table}
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} rotationSecond - Second operation, which
	 *   is the row in the above cayley table.
	 * @param {GD8Symmetry} rotationFirst - First operation, which
	 *   is the column in the above cayley table.
	 * @returns {GD8Symmetry} Composed operation
	 */
	add: (rotationSecond: GD8Symmetry, rotationFirst: GD8Symmetry) => GD8Symmetry;
	/**
	 * Reverse of \`add\`.
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} rotationSecond - Second operation
	 * @param {GD8Symmetry} rotationFirst - First operation
	 * @returns {GD8Symmetry} Result
	 */
	sub: (rotationSecond: GD8Symmetry, rotationFirst: GD8Symmetry) => GD8Symmetry;
	/**
	 * Adds 180 degrees to rotation, which is a commutative
	 * operation.
	 * @memberof maths.groupD8
	 * @param {number} rotation - The number to rotate.
	 * @returns {number} Rotated number
	 */
	rotate180: (rotation: number) => number;
	/**
	 * Checks if the rotation angle is vertical, i.e. south
	 * or north. It doesn't work for reflections.
	 * @memberof maths.groupD8
	 * @param {GD8Symmetry} rotation - The number to check.
	 * @returns {boolean} Whether or not the direction is vertical
	 */
	isVertical: (rotation: GD8Symmetry) => boolean;
	/**
	 * Approximates the vector \`V(dx,dy)\` into one of the
	 * eight directions provided by \`groupD8\`.
	 * @memberof maths.groupD8
	 * @param {number} dx - X-component of the vector
	 * @param {number} dy - Y-component of the vector
	 * @returns {GD8Symmetry} Approximation of the vector into
	 *  one of the eight symmetries.
	 */
	byDirection: (dx: number, dy: number) => GD8Symmetry;
	/**
	 * Helps sprite to compensate texture packer rotation.
	 * @memberof maths.groupD8
	 * @param {Matrix} matrix - sprite world matrix
	 * @param {GD8Symmetry} rotation - The rotation factor to use.
	 * @param {number} tx - sprite anchoring
	 * @param {number} ty - sprite anchoring
	 */
	matrixAppendRotationInv: (matrix: Matrix, rotation: GD8Symmetry, tx?: number, ty?: number) => void;
};
/**
 * Rounds to next power of two.
 * @function nextPow2
 * @param {number} v - input value
 * @returns {number} - next rounded power of two
 * @memberof maths
 */
export declare function nextPow2(v: number): number;
/**
 * Checks if a number is a power of two.
 * @function isPow2
 * @param {number} v - input value
 * @returns {boolean} \`true\` if value is power of two
 * @memberof maths
 */
export declare function isPow2(v: number): boolean;
/**
 * Computes ceil of log base 2
 * @function log2
 * @param {number} v - input value
 * @returns {number} logarithm base 2
 * @memberof maths
 */
export declare function log2(v: number): number;
export declare function squaredDistanceToLineSegment(x: number, y: number, x1: number, y1: number, x2: number, y2: number): number;
/**
 * Check if a point is inside a triangle.
 * @param px - x coordinate of the point
 * @param py - y coordinate of the point
 * @param x1 - x coordinate of the first vertex of the triangle
 * @param y1 - y coordinate of the first vertex of the triangle
 * @param x2 - x coordinate of the second vertex of the triangle
 * @param y2 - y coordinate of the second vertex of the triangle
 * @param x3 - x coordinate of the third vertex of the triangle
 * @param y3 - y coordinate of the third vertex of the triangle
 * @returns \`true\` if the point is inside the triangle, \`false\` otherwise
 */
export declare function pointInTriangle(px: number, py: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): boolean;
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class extends the base functionality and resolves given resource items ready for the queue.
 * @memberof rendering
 */
export declare abstract class PrepareQueue extends PrepareBase {
	/**
	 * Resolve the given resource type and return an item for the queue
	 * @param source
	 * @param queue
	 */
	protected resolveQueueItem(source: PrepareSourceItem, queue: PrepareQueueItem[]): void;
	/**
	 * Resolve the given container and return an item for the queue
	 * @param container
	 * @param queue
	 */
	protected resolveContainerQueueItem(container: Container, queue: PrepareQueueItem[]): void;
	/**
	 * Resolve the given graphics context and return an item for the queue
	 * @param graphicsContext
	 */
	protected resolveGraphicsContextQueueItem(graphicsContext: GraphicsContext): PrepareQueueItem | null;
}
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class extends the resolver functionality and uploads the given queue items.
 * @memberof rendering
 */
export declare abstract class PrepareUpload extends PrepareQueue {
	/**
	 * Upload the given queue item
	 * @param item
	 */
	protected uploadQueueItem(item: PrepareQueueItem): void;
	protected uploadTextureSource(textureSource: TextureSource): void;
	protected uploadText(_text: Text$1): void;
	protected uploadBitmapText(_text: BitmapText): void;
	protected uploadHTMLText(_text: HTMLText): void;
	/**
	 * Resolve the given graphics context and return an item for the queue
	 * @param graphicsContext
	 */
	protected uploadGraphicsContext(graphicsContext: GraphicsContext): void;
}
/**
 * The prepare system provides renderer-specific plugins for pre-rendering DisplayObjects. This is useful for
 * asynchronously preparing and uploading to the GPU assets, textures, graphics waiting to be displayed.
 *
 * Do not instantiate this plugin directly. It is available from the \`renderer.prepare\` property.
 * @example
 * import 'pixi.js/prepare';
 * import { Application, Graphics } from 'pixi.js';
 *
 * // Create a new application (prepare will be auto-added to renderer)
 * const app = new Application();
 * await app.init();
 * document.body.appendChild(app.view);
 *
 * // Don't start rendering right away
 * app.stop();
 *
 * // Create a display object
 * const rect = new Graphics()
 *     .beginFill(0x00ff00)
 *     .drawRect(40, 40, 200, 200);
 *
 * // Add to the stage
 * app.stage.addChild(rect);
 *
 * // Don't start rendering until the graphic is uploaded to the GPU
 * app.renderer.prepare.upload(app.stage, () => {
 *     app.start();
 * });
 * @memberof rendering
 */
export declare class PrepareSystem extends PrepareUpload implements System {
	/** @ignore */
	static extension: {
		readonly type: readonly [
			ExtensionType.WebGLSystem,
			ExtensionType.WebGPUSystem
		];
		readonly name: "prepare";
	};
	/** Destroys the plugin, don't use after this. */
	destroy(): void;
}
/**
 * Represents the JSON data for a spritesheet atlas.
 * @memberof assets
 */
export interface SpritesheetFrameData {
	/** The frame rectangle of the texture. */
	frame: {
		x: number;
		y: number;
		w: number;
		h: number;
	};
	/** Whether the texture is trimmed. */
	trimmed?: boolean;
	/** Whether the texture is rotated. */
	rotated?: boolean;
	/** The source size of the texture. */
	sourceSize?: {
		w: number;
		h: number;
	};
	/** The sprite source size. */
	spriteSourceSize?: {
		h?: number;
		w?: number;
		x: number;
		y: number;
	};
	/** The anchor point of the texture. */
	anchor?: PointData;
	/** The 9-slice borders of the texture. */
	borders?: TextureBorders;
}
/**
 * Atlas format.
 * @memberof assets
 */
export interface SpritesheetData {
	/** The frames of the atlas. */
	frames: Dict<SpritesheetFrameData>;
	/** The animations of the atlas. */
	animations?: Dict<string[]>;
	/** The meta data of the atlas. */
	meta: {
		app?: string;
		format?: string;
		frameTags?: {
			from: number;
			name: string;
			to: number;
			direction: string;
		}[];
		image?: string;
		layers?: {
			blendMode: string;
			name: string;
			opacity: number;
		}[];
		scale: number | string;
		size?: {
			h: number;
			w: number;
		};
		slices?: {
			color: string;
			name: string;
			keys: {
				frame: number;
				bounds: {
					x: number;
					y: number;
					w: number;
					h: number;
				};
			}[];
		}[];
		related_multi_packs?: string[];
		version?: string;
	};
}
/**
 * Utility class for maintaining reference to a collection
 * of Textures on a single Spritesheet.
 *
 * To access a sprite sheet from your code you may pass its JSON data file to Pixi's loader:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * const sheet = await Assets.load('images/spritesheet.json');
 * \`\`\`
 *
 * Alternately, you may circumvent the loader by instantiating the Spritesheet directly:
 *
 * \`\`\`js
 * import { Spritesheet } from 'pixi.js';
 *
 * const sheet = new Spritesheet(texture, spritesheetData);
 * await sheet.parse();
 * console.log('Spritesheet ready to use!');
 * \`\`\`
 *
 * With the \`sheet.textures\` you can create Sprite objects, and \`sheet.animations\` can be used to create an AnimatedSprite.
 *
 * Here's an example of a sprite sheet JSON data file:
 * \`\`\`json
 * {
 *     "frames": {
 *         "enemy1.png":
 *         {
 *             "frame": {"x":103,"y":1,"w":32,"h":32},
 *             "spriteSourceSize": {"x":0,"y":0,"w":32,"h":32},
 *             "sourceSize": {"w":32,"h":32},
 *             "anchor": {"x":16,"y":16}
 *         },
 *         "enemy2.png":
 *         {
 *             "frame": {"x":103,"y":35,"w":32,"h":32},
 *             "spriteSourceSize": {"x":0,"y":0,"w":32,"h":32},
 *             "sourceSize": {"w":32,"h":32},
 *             "anchor": {"x":16,"y":16}
 *         },
 *         "button.png":
 *         {
 *             "frame": {"x":1,"y":1,"w":100,"h":100},
 *             "spriteSourceSize": {"x":0,"y":0,"w":100,"h":100},
 *             "sourceSize": {"w":100,"h":100},
 *             "anchor": {"x":0,"y":0},
 *             "borders": {"left":35,"top":35,"right":35,"bottom":35}
 *         }
 *     },
 *
 *     "animations": {
 *         "enemy": ["enemy1.png","enemy2.png"]
 *     },
 *
 *     "meta": {
 *         "image": "sheet.png",
 *         "format": "RGBA8888",
 *         "size": {"w":136,"h":102},
 *         "scale": "1"
 *     }
 * }
 * \`\`\`
 * Sprite sheets can be packed using tools like {@link https://codeandweb.com/texturepacker|TexturePacker},
 * {@link https://renderhjs.net/shoebox/|Shoebox} or {@link https://github.com/krzysztof-o/spritesheet.js|Spritesheet.js}.
 * Default anchor points (see {@link Texture#defaultAnchor}), default 9-slice borders
 * (see {@link Texture#defaultBorders}) and grouping of animation sprites are currently only
 * supported by TexturePacker.
 *
 * Alternative ways for loading spritesheet image if you need more control:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * const sheetTexture = await Assets.load('images/spritesheet.png');
 * Assets.add({
 *     alias: 'atlas',
 *     src: 'images/spritesheet.json',
 *     data: {texture: sheetTexture} // using of preloaded texture
 * });
 * const sheet = await Assets.load('atlas')
 * \`\`\`
 *
 * or:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * Assets.add({
 *     alias: 'atlas',
 *     src: 'images/spritesheet.json',
 *     data: {imageFilename: 'my-spritesheet.2x.avif'} // using of custom filename located in "images/my-spritesheet.2x.avif"
 * });
 * const sheet = await Assets.load('atlas')
 * \`\`\`
 * @memberof assets
 */
export declare class Spritesheet<S extends SpritesheetData = SpritesheetData> {
	/** The maximum number of Textures to build per process. */
	static readonly BATCH_SIZE = 1000;
	/** For multi-packed spritesheets, this contains a reference to all the other spritesheets it depends on. */
	linkedSheets: Spritesheet<S>[];
	/** Reference to the source texture. */
	textureSource: TextureSource;
	/**
	 * A map containing all textures of the sprite sheet.
	 * Can be used to create a {@link Sprite|Sprite}:
	 * @example
	 * import { Sprite } from 'pixi.js';
	 *
	 * new Sprite(sheet.textures['image.png']);
	 */
	textures: Record<keyof S["frames"], Texture>;
	/**
	 * A map containing the textures for each animation.
	 * Can be used to create an {@link AnimatedSprite|AnimatedSprite}:
	 * @example
	 * import { AnimatedSprite } from 'pixi.js';
	 *
	 * new AnimatedSprite(sheet.animations['anim_name']);
	 */
	animations: Record<keyof NonNullable<S["animations"]>, Texture[]>;
	/**
	 * Reference to the original JSON data.
	 * @type {object}
	 */
	data: S;
	/** The resolution of the spritesheet. */
	resolution: number;
	/**
	 * Reference to original source image from the Loader. This reference is retained so we
	 * can destroy the Texture later on. It is never used internally.
	 */
	private _texture;
	/**
	 * Map of spritesheet frames.
	 * @type {object}
	 */
	private _frames;
	/** Collection of frame names. */
	private _frameKeys;
	/** Current batch index being processed. */
	private _batchIndex;
	/**
	 * Callback when parse is completed.
	 * @type {Function}
	 */
	private _callback;
	/**
	 * @param texture - Reference to the source BaseTexture object.
	 * @param {object} data - Spritesheet image data.
	 */
	constructor(texture: BindableTexture, data: S);
	/**
	 * Parser spritesheet from loaded data. This is done asynchronously
	 * to prevent creating too many Texture within a single process.
	 */
	parse(): Promise<Record<string, Texture>>;
	/**
	 * Process a batch of frames
	 * @param initialFrameIndex - The index of frame to start.
	 */
	private _processFrames;
	/** Parse animations config. */
	private _processAnimations;
	/** The parse has completed. */
	private _parseComplete;
	/** Begin the next batch of textures. */
	private _nextBatch;
	/**
	 * Destroy Spritesheet and don't use after this.
	 * @param {boolean} [destroyBase=false] - Whether to destroy the base texture as well
	 */
	destroy(destroyBase?: boolean): void;
}
export interface SpriteSheetJson extends SpritesheetData {
	meta: {
		image: string;
		scale: string;
		related_multi_packs?: string[];
	};
}
/**
 * Asset extension for loading spritesheets
 * @example
 * import { Assets } from 'pixi.js';
 *
 * Assets.load({
 *     alias: 'spritesheet',
 *     src: 'path/to/spritesheet.json',
 *     data: {
 *         ignoreMultiPack: true,
 *         textureOptions: {
 *             scaleMode: "nearest"
 *         }
 *     }
 * })
 * @type {AssetExtension}
 * @memberof assets
 */
export declare const spritesheetAsset: {
	extension: ExtensionType.Asset;
	/** Handle the caching of the related Spritesheet Textures */
	cache: {
		test: (asset: Spritesheet) => boolean;
		getCacheableAssets: (keys: string[], asset: Spritesheet) => Record<string, any>;
	};
	/** Resolve the resolution of the asset. */
	resolver: {
		extension: {
			type: ExtensionType.ResolveParser;
			name: string;
		};
		test: (value: string) => boolean;
		parse: (value: string) => {
			resolution: number;
			format: string;
			src: string;
		};
	};
	/**
	 * Loader plugin that parses sprite sheets!
	 * once the JSON has been loaded this checks to see if the JSON is spritesheet data.
	 * If it is, we load the spritesheets image and parse the data into Spritesheet
	 * All textures in the sprite sheet are then added to the cache
	 */
	loader: {
		name: string;
		extension: {
			type: ExtensionType.LoadParser;
			priority: LoaderParserPriority;
			name: string;
		};
		testParse(asset: SpriteSheetJson, options: ResolvedAsset): Promise<boolean>;
		parse<T>(asset: SpriteSheetJson, options: ResolvedAsset<{
			texture?: Texture;
			imageFilename?: string;
			ignoreMultiPack?: boolean;
			textureOptions?: TextureSourceOptions;
		}>, loader?: Loader): Promise<Spritesheet>;
		unload(spritesheet: Spritesheet, _resolvedAsset: ResolvedAsset<any>, loader: Loader): Promise<void>;
	};
};
/**
 * Represents the update priorities used by internal Pixi classes when registered with
 * the {@link ticker.Ticker} object. Higher priority items are updated first and lower
 * priority items, such as render, should go later.
 * @static
 * @enum {number}
 * @memberof ticker
 */
export declare enum UPDATE_PRIORITY {
	/**
	 * Highest priority used for interaction events in {@link EventSystem}
	 * @default 50
	 */
	INTERACTION = 50,
	/**
	 * High priority updating, used by {@link AnimatedSprite}
	 * @default 25
	 */
	HIGH = 25,
	/**
	 * Default priority for ticker events, see {@link Ticker#add}.
	 * @default 0
	 */
	NORMAL = 0,
	/**
	 * Low priority used for {@link Application} rendering.
	 * @default -25
	 */
	LOW = -25,
	/**
	 * Lowest priority used for {@link BasePrepare} utility.
	 * @default -50
	 */
	UTILITY = -50
}
/**
 * Internal class for handling the priority sorting of ticker handlers.
 * @private
 * @class
 */
export declare class TickerListener<T = any> {
	/** The current priority. */
	priority: number;
	/** The next item in chain. */
	next: TickerListener;
	/** The previous item in chain. */
	previous: TickerListener;
	/** The handler function to execute. */
	private _fn;
	/** The calling to execute. */
	private _context;
	/** If this should only execute once. */
	private readonly _once;
	/** \`true\` if this listener has been destroyed already. */
	private _destroyed;
	/**
	 * Constructor
	 * @private
	 * @param fn - The listener function to be added for one update
	 * @param context - The listener context
	 * @param priority - The priority for emitting
	 * @param once - If the handler should fire once
	 */
	constructor(fn: TickerCallback<T>, context?: T, priority?: number, once?: boolean);
	/**
	 * Simple compare function to figure out if a function and context match.
	 * @param fn - The listener function to be added for one update
	 * @param context - The listener context
	 * @returns \`true\` if the listener match the arguments
	 */
	match(fn: TickerCallback<T>, context?: any): boolean;
	/**
	 * Emit by calling the current function.
	 * @param ticker - The ticker emitting.
	 * @returns Next ticker
	 */
	emit(ticker: Ticker): TickerListener;
	/**
	 * Connect to the list.
	 * @param previous - Input node, previous listener
	 */
	connect(previous: TickerListener): void;
	/**
	 * Destroy and don't use after this.
	 * @param hard - \`true\` to remove the \`next\` reference, this
	 *        is considered a hard destroy. Soft destroy maintains the next reference.
	 * @returns The listener to redirect while emitting or removing.
	 */
	destroy(hard?: boolean): TickerListener;
}
/**
 * Helper for detecting the correct alpha mode for video textures.
 * For some reason, some browsers/devices/WebGL implementations premultiply the alpha
 * of a video before and then a second time if \`UNPACK_PREMULTIPLY_ALPHA_WEBGL\`
 * is true. So the video is premultiplied twice if the alpha mode is \`UNPACK\`.
 * In this case we need the alpha mode to be \`PMA\`. This function detects
 * the upload behavior by uploading a white 2x2 webm with 50% alpha
 * without \`UNPACK_PREMULTIPLY_ALPHA_WEBGL\` and then checking whether
 * the uploaded pixels are premultiplied.
 * @memberof utils
 * @function detectVideoAlphaMode
 * @returns {Promise<ALPHA_MODES>} The correct alpha mode for video textures.
 */
export declare function detectVideoAlphaMode(): Promise<ALPHA_MODES>;
export declare function isSafari(): boolean;
/**
 * Helper for checking for WebGL support.
 * @param failIfMajorPerformanceCaveat - whether to fail if there is a major performance caveat, defaults to false
 * @memberof utils
 * @function isWebGLSupported
 * @returns {boolean} Is WebGL supported.
 */
export declare function isWebGLSupported(failIfMajorPerformanceCaveat?: boolean): boolean;
/**
 * Helper for checking for WebGPU support.
 * @param options - The options for requesting a GPU adapter.
 * @memberof utils
 * @function isWebGPUSupported
 * @returns Is WebGPU supported.
 */
export declare function isWebGPUSupported(options?: GPURequestAdapterOptions): Promise<boolean>;
/**
 * Not all platforms allow to generate function code (e.g., \`new Function\`).
 * this provides the platform-level detection.
 * @private
 * @returns {boolean} \`true\` if \`new Function\` is supported.
 */
export declare function unsafeEvalSupported(): boolean;
/**
 * Measuring the bounds of a canvas' visible (non-transparent) pixels.
 * @param canvas - The canvas to measure.
 * @param resolution - The resolution of the canvas.
 * @returns The bounding box of the canvas' visible pixels.
 * @since 7.1.0
 * @memberof utils
 */
export declare function getCanvasBoundingBox(canvas: ICanvas, resolution?: number): Rectangle;
/**
 * Regexp for data URI.
 * Based on: {@link https://github.com/ragingwind/data-uri-regex}
 * @static
 * @type {RegExp}
 * @default /(?:^data:image\\/([\\w+]+);(?:[\\w=]+|charset=[\\w-]+)?(?:;base64)?,)/i
 * @example
 * import { DATA_URI } from 'pixi.js';
 *
 * DATA_URI.test('data:image/png;base64,foobar'); // => true
 * @memberof utils
 */
export declare const DATA_URI: RegExp;
/** The current version of PixiJS. This is automatically replaced by the build process. */
export declare const VERSION = "$_VERSION";
/**
 * Takes a hash and removes all the \`undefined\`/\`null\` values from it.
 * In PixiJS, we tend to null properties instead of using 'delete' for performance reasons.
 * However, in some cases, this could be a problem if the hash grows too large over time,
 * this function can be used to clean a hash.
 * @param hash - The hash to clean.
 * @returns A new hash with all the \`undefined\`/\`null\` values removed.
 * @memberof utils
 */
export declare function cleanHash<T>(hash: Record<string, T>): Record<string, T>;
/**
 * Removes all \`undefined\`/\`null\` elements from the given array and compacts the array.
 *
 * This function iterates through the array, shifting non-undefined elements to the left
 * to fill gaps created by \`undefined\` elements. The length of the array is then adjusted
 * to remove the trailing \`undefined\` elements.
 * @param arr - The array to be cleaned.
 * @returns The cleaned array with all \`undefined\` elements removed.
 * @example
 * // Example usage:
 * const arr = [1, undefined, 2, undefined, 3];
 * const cleanedArr = cleanArray(arr);
 * console.log(cleanedArr); // Output: [1, 2, 3]
 * @memberof utils
 */
export declare function cleanArray<T>(arr: T[]): T[];
/**
 * Remove items from a javascript array without generating garbage
 * @function removeItems
 * @memberof utils
 * @param {Array<any>} arr - Array to remove elements from
 * @param {number} startIdx - starting index
 * @param {number} removeCount - how many to remove
 */
export declare function removeItems(arr: any[], startIdx: number, removeCount: number): void;
type UIDNames = "default" | "resource" | "texture" | "textureSource" | "textureResource" | "batcher" | "graphicsContext" | "graphicsView" | "graphicsPath" | "fillGradient" | "fillPattern" | "meshView" | "renderable" | "buffer" | "bufferResource" | "geometry" | "instructionSet" | "renderTarget" | "uniform" | "spriteView" | "textView" | "tilingSpriteView" | "shader";
/**
 * Gets the next unique identifier
 * @param name - The name of the identifier.
 * @function uid
 * @returns {number} The next unique identifier to use.
 * @memberof utils
 */
export declare function uid(name?: UIDNames): number;
/** Resets the next unique identifier to 0. This is used for some tests, dont touch or things WILL explode :) */
export declare function resetUids(): void;
/**
 * Updates the bounds of a quad (a rectangular area) based on the provided texture and anchor point.
 *
 * This function calculates the minimum and maximum x and y coordinates of the bounds, taking into
 * account the texture's original dimensions and any trimming that may have been applied to it.
 * @param {BoundsData} bounds - The bounds object to be updated. It contains minX, maxX, minY, and maxY properties.
 * @param {ObservablePoint} anchor - The anchor point of the texture, which affects the positioning of the bounds.
 * @param {Texture} texture - The texture whose dimensions and trimming information are used to update the bounds.
 */
export declare function updateQuadBounds(bounds: BoundsData, anchor: ObservablePoint, texture: Texture): void;
/**
 * deprecation name for version 8.0.0
 * @ignore
 */
export declare const v8_0_0 = "8.0.0";
export declare const v8_3_4 = "8.3.4";
/**
 * Helper for warning developers about deprecated features & settings.
 * A stack track for warnings is given; useful for tracking-down where
 * deprecated methods/properties/classes are being used within the code.
 * @memberof utils
 * @ignore
 * @function deprecation
 * @param {string} version - The version where the feature became deprecated
 * @param {string} message - Message should include what is deprecated, where, and the new solution
 * @param {number} [ignoreDepth=3] - The number of steps to ignore at the top of the error stack
 *        this is mostly to ignore internal deprecation calls.
 */
export declare function deprecation(version: string, message: string, ignoreDepth?: number): void;
/**
 * Logs a texture to the console as a base64 image.
 * This can be very useful for debugging issues with rendering.
 * @param texture - The texture to log
 * @param renderer - The renderer to use
 * @param size - The size of the texture to log in the console
 * @ignore
 */
export declare function logDebugTexture(texture: Texture, renderer: Renderer, size?: number): Promise<void>;
export declare function logScene(container: Container, depth?: number, data?: {
	color?: string;
}): void;
export declare function logRenderGroupScene(renderGroup: RenderGroup, depth?: number, data?: {
	index: number;
	color?: string;
}): void;
/**
 * Logs a PixiJS warning message to the console. Stops logging after 500 warnings have been logged.
 * @param args - The warning message(s) to log
 * @returns {void}
 * @memberof utils
 * @ignore
 */
export declare function warn(...args: any[]): void;
export declare const NOOP: () => void;
/**
 * get the resolution / device pixel ratio of an asset by looking for the prefix
 * used by spritesheets and image urls
 * @memberof utils
 * @function getResolutionOfUrl
 * @param {string} url - the image path
 * @param {number} [defaultValue=1] - the defaultValue if no filename prefix is set.
 * @returns {number} resolution / device pixel ratio of an asset
 */
export declare function getResolutionOfUrl(url: string, defaultValue?: number): number;
/**
 * Path utilities for working with URLs and file paths in a cross-platform way.
 * All paths that are passed in will become normalized to have posix separators.
 * \`\`\`js
 * import { path } from 'pixi.js';
 *
 * path.normalize('http://www.example.com/foo/bar/../baz'); // http://www.example.com/foo/baz
 * \`\`\`
 * @memberof utils
 */
export interface Path {
	/**
	 * Converts a path to posix format.
	 * @param path - The path to convert to posix
	 */
	toPosix: (path: string) => string;
	/**
	 * Checks if the path is a URL e.g. http://, https://
	 * @param path - The path to check
	 */
	isUrl: (path: string) => boolean;
	/**
	 * Checks if the path is a data URL
	 * @param path - The path to check
	 */
	isDataUrl: (path: string) => boolean;
	/**
	 * Checks if the path is a blob URL
	 * @param path - The path to check
	 */
	isBlobUrl: (path: string) => boolean;
	/**
	 * Checks if the path has a protocol e.g. http://, https://, file:///, data:, blob:, C:/
	 * This will return true for windows file paths
	 * @param path - The path to check
	 */
	hasProtocol: (path: string) => boolean;
	/**
	 * Returns the protocol of the path e.g. http://, https://, file:///, data:, blob:, C:/
	 * @param path - The path to get the protocol from
	 */
	getProtocol: (path: string) => string;
	/**
	 * Converts URL to an absolute path.
	 * When loading from a Web Worker, we must use absolute paths.
	 * If the URL is already absolute we return it as is
	 * If it's not, we convert it
	 * @param url - The URL to test
	 * @param customBaseUrl - The base URL to use
	 * @param customRootUrl - The root URL to use
	 */
	toAbsolute: (url: string, baseUrl?: string, rootUrl?: string) => string;
	/**
	 * Normalizes the given path, resolving '..' and '.' segments
	 * @param path - The path to normalize
	 */
	normalize: (path: string) => string;
	/**
	 * Determines if path is an absolute path.
	 * Absolute paths can be urls, data urls, or paths on disk
	 * @param path - The path to test
	 */
	isAbsolute: (path: string) => boolean;
	/**
	 * Joins all given path segments together using the platform-specific separator as a delimiter,
	 * then normalizes the resulting path
	 * @param segments - The segments of the path to join
	 */
	join: (...paths: string[]) => string;
	/**
	 * Returns the directory name of a path
	 * @param path - The path to parse
	 */
	dirname: (path: string) => string;
	/**
	 * Returns the root of the path e.g. /, C:/, file:///, http://domain.com/
	 * @param path - The path to parse
	 */
	rootname: (path: string) => string;
	/**
	 * Returns the last portion of a path
	 * @param path - The path to test
	 * @param ext - Optional extension to remove
	 */
	basename: (path: string, ext?: string) => string;
	/**
	 * Returns the extension of the path, from the last occurrence of the . (period) character to end of string in the last
	 * portion of the path. If there is no . in the last portion of the path, or if there are no . characters other than
	 * the first character of the basename of path, an empty string is returned.
	 * @param path - The path to parse
	 */
	extname: (path: string) => string;
	/**
	 * Parses a path into an object containing the 'root', \`dir\`, \`base\`, \`ext\`, and \`name\` properties.
	 * @param path - The path to parse
	 */
	parse: (path: string) => {
		root?: string;
		dir?: string;
		base?: string;
		ext?: string;
		name?: string;
	};
	sep: string;
	delimiter: string;
	joinExtensions: string[];
}
/**
 * Path utilities for working with URLs and file paths in a cross-platform way.
 * All paths that are passed in will become normalized to have posix separators.
 * \`\`\`js
 * import { path } from 'pixi.js';
 *
 * path.normalize('http://www.example.com/foo/bar/../baz'); // http://www.example.com/foo/baz
 * \`\`\`
 * @see {@link utils.Path}
 * @memberof utils
 */
export declare const path: Path;
/**
 * A type alias for a constructor of a Pool.
 * @template T The type of items in the pool. Must extend PoolItem.
 * @memberof utils
 */
export type PoolConstructor<T extends PoolItem> = new () => Pool<T>;
/**
 * A group of pools that can be used to store objects of different types.
 * @memberof utils
 */
export declare class PoolGroupClass {
	/**
	 * A map to store the pools by their class type.
	 * @private
	 */
	private readonly _poolsByClass;
	/**
	 * Prepopulates a specific pool with a given number of items.
	 * @template T The type of items in the pool. Must extend PoolItem.
	 * @param {PoolItemConstructor<T>} Class - The constructor of the items in the pool.
	 * @param {number} total - The number of items to add to the pool.
	 */
	prepopulate<T extends PoolItem>(Class: PoolItemConstructor<T>, total: number): void;
	/**
	 * Gets an item from a specific pool.
	 * @template T The type of items in the pool. Must extend PoolItem.
	 * @param {PoolItemConstructor<T>} Class - The constructor of the items in the pool.
	 * @param {unknown} [data] - Optional data to pass to the item's constructor.
	 * @returns {T} The item from the pool.
	 */
	get<T extends PoolItem>(Class: PoolItemConstructor<T>, data?: unknown): T;
	/**
	 * Returns an item to its respective pool.
	 * @param {PoolItem} item - The item to return to the pool.
	 */
	return(item: PoolItem): void;
	/**
	 * Gets a specific pool based on the class type.
	 * @template T The type of items in the pool. Must extend PoolItem.
	 * @param {PoolItemConstructor<T>} ClassType - The constructor of the items in the pool.
	 * @returns {Pool<T>} The pool of the given class type.
	 */
	getPool<T extends PoolItem>(ClassType: PoolItemConstructor<T>): Pool<T>;
	/** gets the usage stats of each pool in the system */
	stats(): Record<string, {
		free: number;
		used: number;
		size: number;
	}>;
}
export declare const BigPool: PoolGroupClass;
/**
 * Prints out the version and renderer information for this running instance of PixiJS.
 * @param type - The name of the renderer this instance is using.
 * @returns {void}
 */
export declare function sayHello(type: string): void;

export {
	Buffer$1 as Buffer,
	Cache$1 as Cache,
	EXT_texture_compression_bptc$1 as EXT_texture_compression_bptc,
	EXT_texture_compression_rgtc$1 as EXT_texture_compression_rgtc,
	ExtensionFormat as ExtensionFormatLoose,
	GPU$1 as GPU,
	PredefinedColorSpace$1 as PredefinedColorSpace,
	RenderingContext$1 as RenderingContext,
	StrictExtensionFormat as ExtensionFormat,
	Text$1 as Text,
	WEBGL_compressed_texture_etc$1 as WEBGL_compressed_texture_etc,
	WEBGL_compressed_texture_etc1$1 as WEBGL_compressed_texture_etc1,
	WEBGL_compressed_texture_pvrtc$1 as WEBGL_compressed_texture_pvrtc,
	exports$1 as earcut,
};

export as namespace PIXI;

export {};
`,Cn=`/// <reference types="@webgpu/types" />

declare module '*.wgsl'
{
    const shader: 'string';

    export default shader;
}

declare module '*.vert'
{
    const shader: 'string';

    export default shader;
}

declare module '*.frag'
{
    const shader: 'string';

    export default shader;
}
`,Rn=`declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface Container extends Partial<import('./accessibilityTarget').AccessibleTarget> {}

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ContainerOptions extends Partial<import('./accessibilityTarget').AccessibleOptions> {}

        interface RendererSystems
        {
            accessibility: import('./AccessibilitySystem').AccessibilitySystem;
        }
    }
}

export {};
`,Gn=`import { ExtensionType } from '../extensions/Extensions';
import type { System } from '../rendering/renderers/shared/system/System';
import type { Renderer } from '../rendering/renderers/types';
import type { isMobileResult } from '../utils/browser/isMobile';
/** @ignore */
export interface AccessibilitySystemOptions {
    accessibilityOptions?: AccessibilityOptions;
}
/** @ignore */
export interface AccessibilityOptions {
    /** Whether to enable accessibility features on initialization instead of waiting for tab key */
    enabledByDefault?: boolean;
    /** Whether to visually show the accessibility divs for debugging */
    debug?: boolean;
    /** Whether to allow tab key press to activate accessibility features */
    activateOnTab?: boolean;
    /** Whether to deactivate accessibility when mouse moves */
    deactivateOnMouseMove?: boolean;
}
/**
 * The Accessibility system provides screen reader and keyboard navigation support for PixiJS content.
 * It creates an accessible DOM layer over the canvas that can be controlled programmatically or through user interaction.
 *
 * By default, the system activates when users press the tab key. This behavior can be customized through options:
 * \`\`\`js
 * const app = new Application({
 *     accessibilityOptions: {
 *         enabledByDefault: true,    // Enable immediately instead of waiting for tab
 *         activateOnTab: false,      // Disable tab key activation
 *         debug: false,               // Show/hide accessibility divs
 *         deactivateOnMouseMove: false, // Prevent accessibility from being deactivated when mouse moves
 *     }
 * });
 * \`\`\`
 *
 * The system can also be controlled programmatically:
 * \`\`\`js
 * app.renderer.accessibility.setAccessibilityEnabled(true);
 * \`\`\`
 *
 * To make individual containers accessible:
 * \`\`\`js
 * container.accessible = true;
 * \`\`\`
 *
 * An instance of this class is automatically created at \`renderer.accessibility\`
 * @memberof accessibility
 */
export declare class AccessibilitySystem implements System<AccessibilitySystemOptions> {
    private readonly _mobileInfo;
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "accessibility";
    };
    /** default options used by the system */
    static defaultOptions: AccessibilityOptions;
    /** Whether accessibility divs are visible for debugging */
    debug: boolean;
    /** Whether to activate on tab key press */
    private _activateOnTab;
    /** Whether to deactivate accessibility when mouse moves */
    private _deactivateOnMouseMove;
    /**
     * The renderer this accessibility manager works for.
     * @type {WebGLRenderer|WebGPURenderer}
     */
    private _renderer;
    /** Internal variable, see isActive getter. */
    private _isActive;
    /** Internal variable, see isMobileAccessibility getter. */
    private _isMobileAccessibility;
    /** Button element for handling touch hooks. */
    private _hookDiv;
    /** This is the dom element that will sit over the PixiJS element. This is where the div overlays will go. */
    private _div;
    /** A simple pool for storing divs. */
    private _pool;
    /** This is a tick used to check if an object is no longer being rendered. */
    private _renderId;
    /** The array of currently active accessible items. */
    private _children;
    /** Count to throttle div updates on android devices. */
    private _androidUpdateCount;
    /**  The frequency to update the div elements. */
    private readonly _androidUpdateFrequency;
    /**
     * @param {WebGLRenderer|WebGPURenderer} renderer - A reference to the current renderer
     */
    constructor(renderer: Renderer, _mobileInfo?: isMobileResult);
    /**
     * Value of \`true\` if accessibility is currently active and accessibility layers are showing.
     * @member {boolean}
     * @readonly
     */
    get isActive(): boolean;
    /**
     * Value of \`true\` if accessibility is enabled for touch devices.
     * @member {boolean}
     * @readonly
     */
    get isMobileAccessibility(): boolean;
    get hookDiv(): HTMLElement;
    /**
     * Creates the touch hooks.
     * @private
     */
    private _createTouchHook;
    /**
     * Destroys the touch hooks.
     * @private
     */
    private _destroyTouchHook;
    /**
     * Activating will cause the Accessibility layer to be shown.
     * This is called when a user presses the tab key.
     * @private
     */
    private _activate;
    private _initAccessibilitySetup;
    /**
     * Deactivates the accessibility system. Removes listeners and accessibility elements.
     * @private
     */
    private _deactivate;
    /**
     * This recursive function will run through the scene graph and add any new accessible objects to the DOM layer.
     * @private
     * @param {Container} container - The Container to check.
     */
    private _updateAccessibleObjects;
    /**
     * Runner init called, view is available at this point.
     * @ignore
     */
    init(options?: AccessibilitySystemOptions): void;
    /**
     * Updates the accessibility layer during rendering.
     * - Removes divs for containers no longer in the scene
     * - Updates the position and dimensions of the root div
     * - Updates positions of active accessibility divs
     * Only fires while the accessibility system is active.
     * @ignore
     */
    postrender(): void;
    /**
     * private function that will visually add the information to the
     * accessibility div
     * @param {HTMLElement} div -
     */
    private _updateDebugHTML;
    /**
     * Adjust the hit area based on the bounds of a display object
     * @param {Rectangle} hitArea - Bounds of the child
     */
    private _capHitArea;
    /**
     * Creates or reuses a div element for a Container and adds it to the accessibility layer.
     * Sets up ARIA attributes, event listeners, and positioning based on the container's properties.
     * @private
     * @param {Container} container - The child to make accessible.
     */
    private _addChild;
    /**
     * Dispatch events with the EventSystem.
     * @param e
     * @param type
     * @private
     */
    private _dispatchEvent;
    /**
     * Maps the div button press to pixi's EventSystem (click)
     * @private
     * @param {MouseEvent} e - The click event.
     */
    private _onClick;
    /**
     * Maps the div focus events to pixi's EventSystem (mouseover)
     * @private
     * @param {FocusEvent} e - The focus event.
     */
    private _onFocus;
    /**
     * Maps the div focus events to pixi's EventSystem (mouseout)
     * @private
     * @param {FocusEvent} e - The focusout event.
     */
    private _onFocusOut;
    /**
     * Is called when a key is pressed
     * @private
     * @param {KeyboardEvent} e - The keydown event.
     */
    private _onKeyDown;
    /**
     * Is called when the mouse moves across the renderer element
     * @private
     * @param {MouseEvent} e - The mouse event.
     */
    private _onMouseMove;
    /** Destroys the accessibility system. Removes all elements and listeners. */
    destroy(): void;
    /**
     * Enables or disables the accessibility system.
     * @param enabled - Whether to enable or disable accessibility.
     */
    setAccessibilityEnabled(enabled: boolean): void;
}
`,Mn=`import type { Container } from '../scene/container/Container';
/**
 * The type of the pointer event to listen for.
 * Can be any of the following:
 * - \`auto\`
 * - \`none\`
 * - \`visiblePainted\`
 * - \`visibleFill\`
 * - \`visibleStroke\`
 * - \`visible\`
 * - \`painted\`
 * - \`fill\`
 * - \`stroke\`
 * - \`all\`
 * - \`inherit\`
 * @memberof accessibility
 * @see https://developer.mozilla.org/en-US/docs/Web/CSS/pointer-events
 */
export type PointerEvents = 'auto' | 'none' | 'visiblePainted' | 'visibleFill' | 'visibleStroke' | 'visible' | 'painted' | 'fill' | 'stroke' | 'all' | 'inherit';
/**
 * When \`accessible\` is enabled on any display object, these properties will affect its accessibility.
 * @memberof accessibility
 */
export interface AccessibleOptions {
    /**
     * Flag for if the object is accessible. If true AccessibilityManager will overlay a
     * shadow div with attributes set
     * @default false
     */
    accessible: boolean;
    /**
     * Sets the title attribute of the shadow div
     * If accessibleTitle AND accessibleHint has not been this will default to 'container [tabIndex]'
     * @member {string}
     */
    accessibleTitle: string | null;
    /** Sets the aria-label attribute of the shadow div */
    accessibleHint: string | null;
    /**
     * @default 0
     */
    tabIndex: number;
    /**
     * Specify the type of div the accessible layer is. Screen readers treat the element differently
     * depending on this type. Defaults to button.
     * @default 'button'
     */
    accessibleType: keyof HTMLElementTagNameMap;
    /**
     * Specify the pointer-events the accessible div will use
     * Defaults to auto.
     * @default 'auto'
     * @type {accessibility.PointerEvents}
     */
    /** Sets the text content of the shadow div */
    accessibleText: string | null;
    accessiblePointerEvents: PointerEvents;
    /**
     * Setting to false will prevent any children inside this container to
     * be accessible. Defaults to true.
     * @default true
     */
    accessibleChildren: boolean;
}
/**
 * The Accessibility object is attached to the {@link Container}.
 * @private
 */
export interface AccessibleTarget extends AccessibleOptions {
    _accessibleActive: boolean;
    _accessibleDiv: AccessibleHTMLElement | null;
    _renderId: number;
}
export interface AccessibleHTMLElement extends HTMLElement {
    type?: string;
    container?: Container;
}
/**
 * Default property values of accessible objects
 * used by {@link AccessibilitySystem}.
 * @private
 * @example
 * import { accessibleTarget } from 'pixi.js';
 *
 * function MyObject() {}
 * Object.assign(MyObject.prototype, accessibleTarget);
 */
export declare const accessibilityTarget: AccessibleTarget;
`,kn=`export * from './AccessibilitySystem';
export * from './accessibilityTarget';
`,Fn=`export {};
`,On=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'color'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color'
 * @memberof filters
 */
export declare class ColorBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,In=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Looks at the color information in each channel and darkens the base color to
 * reflect the blend color by increasing the contrast between the two.
 *
 * Available as \`container.blendMode = 'color-burn'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color-burn'
 * @memberof filters
 */
export declare class ColorBurnBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Ln=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Looks at the color information in each channel and brightens the base color to reflect the blend color by decreasing contrast between the two.
 * Available as \`container.blendMode = 'color-dodge'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'color-dodge'
 * @memberof filters
 */
export declare class ColorDodgeBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Bn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Uses each color channel to select the darker of the following two values; base or blend color
 * Available as \`container.blendMode = 'darken'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'darken'
 * @memberof filters
 */
export declare class DarkenBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Dn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'difference'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'difference'
 * @memberof filters
 */
export declare class DifferenceBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Un=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Divides the blend from the base color using each color channel
 * Available as \`container.blendMode = 'divide'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'divide'
 * @memberof filters
 */
export declare class DivideBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,jn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'exclusion'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'exclusion'
 * @memberof filters
 */
export declare class ExclusionBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Wn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'hard-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'hard-light'
 * @memberof filters
 */
export declare class HardLightBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Hn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Hard defines each of the color channel values of the blend color to the RGB values of the base color.
 * If the sum of a channel is 255, it receives a value of 255; if less than 255, a value of 0.
 *
 * Available as \`container.blendMode = 'hard-mix'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'hard-mix'
 * @memberof filters
 */
export declare class HardMixBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Vn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'lighten'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'lighten'
 * @memberof filters
 */
export declare class LightenBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Nn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Looks at the color information in each channel and darkens the base color to
 * reflect the blend color by increasing the contrast between the two.
 *
 * Available as \`container.blendMode = 'linear-burn'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-burn'
 * @memberof filters
 */
export declare class LinearBurnBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,zn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Looks at the color information in each channel and brightens the base color to reflect the blend color by decreasing contrast between the two.
 * Available as \`container.blendMode = 'linear-dodge'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-dodge'
 * @memberof filters
 */
export declare class LinearDodgeBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Xn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Increase or decrease brightness by burning or dodging color values, based on the blend color
 * Available as \`container.blendMode = 'linear-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'linear-light'
 * @memberof filters
 */
export declare class LinearLightBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Kn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'luminosity'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'luminosity'
 * @memberof filters
 */
export declare class LuminosityBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,qn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'negation'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'negation'
 */
export declare class NegationBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Yn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'overlay'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'overlay'
 */
export declare class OverlayBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Jn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Replaces colors based on the blend color.
 * Available as \`container.blendMode = 'pin-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'pin-light'
 * @memberof filters
 */
export declare class PinLightBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,$n=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'saturation'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'saturation'
 */
export declare class SaturationBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Qn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'soft-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'soft-light'
 */
export declare class SoftLightBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,Zn=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Subtracts the blend from the base color using each color channel
 * Available as \`container.blendMode = 'subtract'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'subtract'
 * @memberof filters
 */
export declare class SubtractBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,et=`import { BlendModeFilter } from '../filters/blend-modes/BlendModeFilter';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Available as \`container.blendMode = 'vivid-light'\` after importing \`pixi.js/advanced-blend-modes\`.
 * @example
 * import 'pixi.js/advanced-blend-modes';
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('something.png');
 * sprite.blendMode = 'vivid-light'
 */
export declare class VividLightBlend extends BlendModeFilter {
    /** @ignore */
    static extension: ExtensionMetadata;
    constructor();
}
`,nt=`export * from './ColorBlend';
export * from './ColorBurnBlend';
export * from './ColorDodgeBlend';
export * from './DarkenBlend';
export * from './DifferenceBlend';
export * from './DivideBlend';
export * from './ExclusionBlend';
export * from './HardLightBlend';
export * from './HardMixBlend';
export * from './LightenBlend';
export * from './LinearBurnBlend';
export * from './LinearDodgeBlend';
export * from './LinearLightBlend';
export * from './LuminosityBlend';
export * from './NegationBlend';
export * from './OverlayBlend';
export * from './PinLightBlend';
export * from './SaturationBlend';
export * from './SoftLightBlend';
export * from './SubtractBlend';
export * from './VividLightBlend';
`,tt=`export {};
`,rt=`import { Container } from '../scene/container/Container';
import type { Rectangle } from '../maths/shapes/Rectangle';
import type { AutoDetectOptions } from '../rendering/renderers/autoDetectRenderer';
import type { RendererDestroyOptions } from '../rendering/renderers/shared/system/AbstractRenderer';
import type { Renderer } from '../rendering/renderers/types';
import type { DestroyOptions } from '../scene/container/destroyTypes';
/**
 * The app module provides a set of classes to use as a starting point when building applications.
 *
 * <aside>This module has a mixin for <code>TickerPlugin</code> and <code>ResizePlugin</code>.
 * These will need to be imported if you are managing your own renderer.</aside>
 *
 * \`\`\`js
 * import { Application } from 'pixi.js';
 *
 * const app = new Application();
 *
 * await app.init();
 *
 * // don't forget to add the canvas to the DOM
 * document.body.appendChild(app.canvas);
 * \`\`\`
 * @namespace app
 */
/**
 * Any plugin that's usable for Application should contain these methods.
 * @example
 * import { ApplicationPlugin } from 'pixi.js';
 *
 * const plugin: ApplicationPlugin = {
 *    init: (options: Partial<ApplicationOptions>) =>
 *    {
 *       // handle init here, use app options if needed
 *    },
 *    destroy: () =>
 *    {
 *       // handle destruction code here
 *    }
 * }
 * @memberof app
 * @see {@link app.ApplicationOptions}
 * @ignore
 */
export interface ApplicationPlugin {
    /**
     * Called when Application is constructed, scoped to Application instance.
     * Passes in \`options\` as the only argument, which are Application \`init()\` options.
     * @param {object} options - Application options.
     */
    init(options: Partial<ApplicationOptions>): void;
    /** Called when destroying Application, scoped to Application instance. */
    destroy(): void;
}
/**
 * Application options supplied to the {@link app.Application#init} method.
 * @memberof app
 * @example
 * import { Application } from 'pixi.js';
 *
 * const app = new Application();
 *
 * await app.init({
 *    autoStart: false,
 *    resizeTo: window,
 *    sharedTicker: true,
 * });
 */
export interface ApplicationOptions extends AutoDetectOptions, PixiMixins.ApplicationOptions {
}
export interface Application extends PixiMixins.Application {
}
/**
 * Convenience class to create a new PixiJS application.
 *
 * This class automatically creates the renderer, ticker and root container.
 * @example
 * import { Application, Sprite } from 'pixi.js';
 *
 * // Create the application
 * const app = new Application();
 *
 * await app.init({ width: 800, height: 600 });
 *
 * // Add the view to the DOM
 * document.body.appendChild(app.canvas);
 *
 * // ex, add display objects
 * app.stage.addChild(Sprite.from('something.png'));
 * @memberof app
 */
export declare class Application<R extends Renderer = Renderer> {
    /**
     * Collection of installed plugins.
     * @alias _plugins
     */
    static _plugins: ApplicationPlugin[];
    /** The root display container that's rendered. */
    stage: Container;
    /**
     * WebGL renderer if available, otherwise CanvasRenderer.
     * @member {rendering.Renderer}
     */
    renderer: R;
    /** Create new Application instance */
    constructor();
    /** @deprecated since 8.0.0 */
    constructor(options?: Partial<ApplicationOptions>);
    /**
     * @param options - The optional application and renderer parameters.
     */
    init(options?: Partial<ApplicationOptions>): Promise<void>;
    /** Render the current stage. */
    render(): void;
    /**
     * Reference to the renderer's canvas element.
     * @readonly
     * @member {HTMLCanvasElement}
     */
    get canvas(): R['canvas'];
    /**
     * Reference to the renderer's canvas element.
     * @member {HTMLCanvasElement}
     * @deprecated since 8.0.0
     */
    get view(): R['canvas'];
    /**
     * Reference to the renderer's screen rectangle. Its safe to use as \`filterArea\` or \`hitArea\` for the whole screen.
     * @readonly
     */
    get screen(): Rectangle;
    /**
     * Destroys the application and all of its resources.
     * @param {object|boolean}[rendererDestroyOptions=false] - The options for destroying the renderer.
     * @param {boolean}[rendererDestroyOptions.removeView=false] - Removes the Canvas element from the DOM.
     * @param {object|boolean} [options=false] - The options for destroying the stage.
     * @param {boolean} [options.children=false] - If set to true, all the children will have their destroy method
     * called as well. \`options\` will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Only used for children with textures e.g. Sprites.
     * If options.children is set to true,
     * it should destroy the texture of the child sprite.
     * @param {boolean} [options.textureSource=false] - Only used for children with textures e.g. Sprites.
     *  If options.children is set to true,
     * it should destroy the texture source of the child sprite.
     * @param {boolean} [options.context=false] - Only used for children with graphicsContexts e.g. Graphics.
     * If options.children is set to true,
     * it should destroy the context of the child graphics.
     */
    destroy(rendererDestroyOptions?: RendererDestroyOptions, options?: DestroyOptions): void;
}
`,ot=`import type { Ticker } from '../ticker/Ticker';
import type { ResizePluginOptions } from './ResizePlugin';
import type { TickerPluginOptions } from './TickerPlugin';

declare global
{
    namespace PixiMixins
    {
        // Extend the Application interface with resize and ticker functionalities
        interface Application
        {
            resizeTo: Window | HTMLElement;
            resize(): void;
            queueResize(): void;
            cancelResize(): void;

            ticker: Ticker;
            stop(): void;
            start(): void;
        }

        // Combine ResizePluginOptions and TickerPluginOptions into ApplicationOptions
        interface ApplicationOptions extends ResizePluginOptions, TickerPluginOptions {}
    }
}

export {};
`,at=`import type { ExtensionMetadata } from '../extensions/Extensions';
import type { Renderer } from '../rendering/renderers/types';
type ResizeableRenderer = Pick<Renderer, 'resize'>;
/**
 * Application options for the {@link app.ResizePlugin}.
 * @memberof app
 * @property {Window|HTMLElement} [resizeTo=window] - Element to automatically resize the renderer to.
 */
export interface ResizePluginOptions {
    /**
     * Element to automatically resize the renderer to.
     * @memberof app.ApplicationOptions
     */
    resizeTo?: Window | HTMLElement;
}
/**
 * Middleware for Application's resize functionality.
 *
 * Adds the following methods to {@link app.Application}:
 * * {@link app.Application#resizeTo}
 * * {@link app.Application#resize}
 * * {@link app.Application#queueResize}
 * * {@link app.Application#cancelResize}
 * @example
 * import { extensions, ResizePlugin } from 'pixi.js';
 *
 * extensions.add(ResizePlugin);
 * @memberof app
 */
export declare class ResizePlugin {
    /** @ignore */
    static extension: ExtensionMetadata;
    static resizeTo: Window | HTMLElement;
    static resize: () => void;
    static renderer: ResizeableRenderer;
    static queueResize: () => void;
    static render: () => void;
    private static _resizeId;
    private static _resizeTo;
    private static _cancelResize;
    /**
     * Initialize the plugin with scope of application instance
     * @static
     * @private
     * @param {object} [options] - See application options
     */
    static init(options: ResizePluginOptions): void;
    /**
     * Clean up the ticker, scoped to application
     * @static
     * @private
     */
    static destroy(): void;
}
export {};
`,it=`import { Ticker } from '../ticker/Ticker';
import type { ExtensionMetadata } from '../extensions/Extensions';
/**
 * Application options for the {@link app.TickerPlugin}.
 * @memberof app
 * @property {boolean} [autoStart=true] - Automatically starts the rendering after the construction.
 * **Note**: Setting this parameter to \`false\` does NOT stop the shared ticker even if you set
 * \`options.sharedTicker\` to \`true\` in case that it is already started. Stop it by your own.
 * @property {boolean} [sharedTicker=false] - Set\`true\` to use \`Ticker.shared\`, \`false\` to create new ticker.
 * If set to \`false\`, you cannot register a handler to occur before anything that runs on the shared ticker.
 * The system ticker will always run before both the shared ticker and the app ticker.
 */
export interface TickerPluginOptions {
    /**
     * Automatically starts the rendering after the construction.
     *  **Note**: Setting this parameter to \`false\` does NOT stop the shared ticker even if you set
     *  \`options.sharedTicker\` to \`true\` in case that it is already started. Stop it by your own.
     * @memberof app.ApplicationOptions
     * @default true
     */
    autoStart?: boolean;
    /**
     * Set\`true\` to use \`Ticker.shared\`, \`false\` to create new ticker.
     *  If set to \`false\`, you cannot register a handler to occur before anything that runs on the shared ticker.
     *  The system ticker will always run before both the shared ticker and the app ticker.
     * @memberof app.ApplicationOptions
     * @default false
     */
    sharedTicker?: boolean;
}
/**
 * Middleware for Application's {@link ticker.Ticker} functionality.
 *
 * Adds the following methods to {@link app.Application}:
 * * {@link app.Application#start}
 * * {@link app.Application#stop}
 * * {@link app.Application#ticker}
 * @example
 * import { extensions, TickerPlugin } from 'pixi.js';
 *
 * extensions.add(TickerPlugin);
 * @memberof app
 */
export declare class TickerPlugin {
    /** @ignore */
    static extension: ExtensionMetadata;
    static start: () => void;
    static stop: () => void;
    private static _ticker;
    static ticker: Ticker;
    /**
     * Initialize the plugin with scope of application instance
     * @static
     * @private
     * @param {object} [options] - See application options
     */
    static init(options?: PixiMixins.ApplicationOptions): void;
    /**
     * Clean up the ticker, scoped to application.
     * @static
     * @private
     */
    static destroy(): void;
}
`,st=`export * from './Application';
export * from './ResizePlugin';
export * from './TickerPlugin';
`,lt=`export {};
`,dt=`import type { ExtensionType } from '../extensions/Extensions';
import type { CacheParser } from './cache/CacheParser';
import type { FormatDetectionParser } from './detections/types';
import type { LoaderParserAdvanced } from './loader/parsers/LoaderParser';
import type { ResolveURLParser } from './resolver/types';
/**
 * A more verbose version of the AssetExtension,
 * allowing you to set the cached, loaded, parsed, and unloaded asset separately
 * @memberof assets
 */
interface AssetExtensionAdvanced<ASSET = any, PARSED_ASSET = ASSET, UNLOAD_ASSET = ASSET, CACHE_ASSET = ASSET, META_DATA = any> {
    /** The type of extension */
    extension: ExtensionType.Asset;
    /** the asset loader */
    loader?: LoaderParserAdvanced<ASSET, PARSED_ASSET, UNLOAD_ASSET, META_DATA>;
    /** the asset resolve parser */
    resolver?: Partial<ResolveURLParser>;
    /** the asset cache parser */
    cache?: Partial<CacheParser<CACHE_ASSET>>;
    /** the asset format detection parser */
    detection?: Partial<FormatDetectionParser>;
}
/**
 * This developer convenience object allows developers to group
 * together the various asset parsers into a single object.
 * @example
 * import { AssetExtension, extensions } from 'pixi.js';
 *
 * // create the CacheParser
 * const cache = {
 *    test(asset: item): boolean {
 *       // Gets called by the cache when a dev caches an asset
 *    },
 *    getCacheableAssets(keys: string[], asset: item): Record<string, any> {
 *       // If the test passes, this function is called to get the cacheable assets
 *       // an example may be that a spritesheet object will return all the sub textures it has so they can
 *       // be cached.
 *    },
 * };
 *
 * // create the ResolveURLParser
 * const resolver = {
 *    test(value: string): boolean {
 *       // the test to perform on the url to determine if it should be parsed
 *    },
 *    parse(value: string): ResolvedAsset {
 *       // the function that will convert the url into an object
 *    },
 * };
 *
 * // create the LoaderParser
 * const loader = {
 *    name: 'itemLoader',
 *    extension: {
 *       type: ExtensionType.LoadParser,
 *    },
 *    async testParse(asset: any, options: ResolvedAsset) {
 *       // This function is used to test if the parse function should be run on the asset
 *    },
 *    async parse(asset: any, options: ResolvedAsset, loader: Loader) {
 *       // Gets called on the asset it testParse passes. Useful to convert a raw asset into something more useful
 *    },
 *    unload(item: any) {
 *       // If an asset is parsed using this parser, the unload function will be called when the user requests an asset
 *       // to be unloaded. This is useful for things like sounds or textures that can be unloaded from memory
 *    },
 * };
 *
 * // put it all together and create the AssetExtension
 * extensions.add({
 *     extension: ExtensionType.Asset,
 *     cache,
 *     resolver,
 *     loader,
 * }
 * @memberof assets
 */
interface AssetExtension<ASSET = any, META_DATA = any> extends AssetExtensionAdvanced<ASSET, META_DATA> {
}
export type { AssetExtension, AssetExtensionAdvanced };
`,pt=`import { Cache } from './cache/Cache';
import { Loader } from './loader/Loader';
import { type LoadTextureConfig } from './loader/parsers/textures/loadTextures';
import { Resolver } from './resolver/Resolver';
import type { FormatDetectionParser } from './detections/types';
import type { LoadSVGConfig } from './loader/parsers/textures/loadSVG';
import type { BundleIdentifierOptions } from './resolver/Resolver';
import type { ArrayOr, AssetsBundle, AssetsManifest, ResolvedAsset, UnresolvedAsset } from './types';
/**
 * Callback for when progress on asset loading is made.
 * The function is passed a single parameter, \`progress\`, which represents the percentage (0.0 - 1.0)
 * of the assets loaded.
 * @memberof assets
 * @callback ProgressCallback
 * @param {number} progress - The percentage (0.0 - 1.0) of the assets loaded.
 * @returns {void}
 * @example
 * (progress) => console.log(progress * 100 + '%')
 */
export type ProgressCallback = (progress: number) => void;
/**
 * Extensible preferences that can be used, for instance, when configuring loaders.
 * @since 7.2.0
 * @memberof assets
 */
export interface AssetsPreferences extends LoadTextureConfig, LoadSVGConfig, PixiMixins.AssetsPreferences {
}
/**
 * Initialization options object for the Assets Class.
 * @memberof assets
 */
export interface AssetInitOptions {
    /** a base path for any assets loaded */
    basePath?: string;
    /** a default URL parameter string to append to all assets loaded */
    defaultSearchParams?: string | Record<string, any>;
    /**
     * a manifest to tell the asset loader upfront what all your assets are
     * this can be the manifest object itself, or a URL to the manifest.
     */
    manifest?: string | AssetsManifest;
    /**
     * optional preferences for which textures preferences you have when resolving assets
     * for example you might set the resolution to 0.5 if the user is on a rubbish old phone
     * or you might set the resolution to 2 if the user is on a retina display
     */
    texturePreference?: {
        /** the resolution order you prefer, can be an array (priority order - first is preferred) or a single resolutions  */
        resolution?: number | number[];
        /**
         * the formats you prefer, by default this will be:
         * ['avif', 'webp', 'png', 'jpg', 'jpeg', 'webm', 'mp4', 'm4v', 'ogv']
         */
        format?: ArrayOr<string>;
    };
    /**
     * If true, don't attempt to detect whether browser has preferred formats available.
     * May result in increased performance as it skips detection step.
     */
    skipDetections?: boolean;
    /** advanced - override how bundlesIds are generated */
    bundleIdentifier?: BundleIdentifierOptions;
    /** Optional loader preferences */
    preferences?: Partial<AssetsPreferences>;
}
/**
 * A one stop shop for all Pixi resource management!
 * Super modern and easy to use, with enough flexibility to customize and do what you need!
 * @namespace assets
 *
 * Use the singleton class [Assets]{@link assets.Assets} to easily load and manage all your assets.
 *
 * \`\`\`typescript
 * import { Assets, Texture } from 'pixi.js';
 *
 * const bunnyTexture = await Assets.load<Texture>('bunny.png');
 * const sprite = new Sprite(bunnyTexture);
 * \`\`\`
 *
 * Check out the sections below for more information on how to deal with assets.
 *
 * <details id="assets-loading">
 *
 * <summary>Asset Loading</summary>
 *
 * Do not be afraid to load things multiple times - under the hood, it will **NEVER** load anything more than once.
 *
 * *For example:*
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * promise1 = Assets.load('bunny.png')
 * promise2 = Assets.load('bunny.png')
 *
 * // promise1 === promise2
 * \`\`\`
 *
 * Here both promises will be the same. Once resolved... Forever resolved! It makes for really easy resource management!
 *
 * Out of the box Pixi supports the following files:
 * - Textures (**_avif_**, **_webp_**, **_png_**, **_jpg_**, **_gif_**, **_svg_**) via {@link assets.loadTextures}, {@link assets.loadSvg}
 * - Video Textures (**_mp4_**, **_m4v_**, **_webm_**, **_ogg_**, **_ogv_**, **_h264_**, **_avi_**, **_mov_**) via {@link assets.loadVideoTextures}
 * - Sprite sheets (**_json_**) via {@link assets.spritesheetAsset}
 * - Bitmap fonts (**_xml_**, **_fnt_**, **_txt_**) via {@link assets.loadBitmapFont}
 * - Web fonts (**_ttf_**, **_woff_**, **_woff2_**) via {@link assets.loadWebFont}
 * - JSON files (**_json_**) via {@link assets.loadJson}
 * - Text Files (**_txt_**) via {@link assets.loadTxt}
 * <br/>
 * More types can be added fairly easily by creating additional {@link assets.LoaderParser LoaderParsers}.
 * </details>
 *
 * <details id="textures">
 *
 * <summary>Textures</summary>
 *
 * - Textures are loaded as ImageBitmap on a worker thread where possible. Leading to much less janky load + parse times.
 * - By default, we will prefer to load AVIF and WebP image files if you specify them.
 * But if the browser doesn't support AVIF or WebP we will fall back to png and jpg.
 * - Textures can also be accessed via \`Texture.from()\` (see {@link core.from|Texture.from})
 * and now use this asset manager under the hood!
 * - Don't worry if you set preferences for textures that don't exist
 * (for example you prefer 2x resolutions images but only 1x is available for that texture,
 * the Assets manager will pick that up as a fallback automatically)
 *
 * #### Sprite sheets
 * - It's hard to know what resolution a sprite sheet is without loading it first, to address this
 * there is a naming convention we have added that will let Pixi understand the image format and resolution
 * of the spritesheet via its file name: \`my-spritesheet{resolution}.{imageFormat}.json\`
 * <br><br>For example:
 *   - \`my-spritesheet@2x.webp.json\`* // 2x resolution, WebP sprite sheet*
 *   - \`my-spritesheet@0.5x.png.json\`* // 0.5x resolution, png sprite sheet*
 * - This is optional! You can just load a sprite sheet as normal.
 * This is only useful if you have a bunch of different res / formatted spritesheets.
 * </details>
 *
 * <details id="fonts">
 *
 * <summary>Fonts</summary>
 *
 * Web fonts will be loaded with all weights.
 * It is possible to load only specific weights by doing the following:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * // Load specific weights..
 * await Assets.load({
 *     data: {
 *         weights: ['normal'], // Only loads the weight
 *     },
 *     src: \`outfit.woff2\`,
 * });
 *
 * // Load everything...
 * await Assets.load(\`outfit.woff2\`);
 * \`\`\`
 * </details>
 *
 * <details id="background-loading">
 *
 * <summary>Background Loading</summary>
 *
 * Background loading will load stuff for you passively behind the scenes. To minimize jank,
 * it will only load one asset at a time. As soon as a developer calls \`Assets.load(...)\` the
 * background loader is paused and requested assets are loaded as a priority.
 * Don't worry if something is in there that's already loaded, it will just get skipped!
 *
 * You still need to call \`Assets.load(...)\` to get an asset that has been loaded in the background.
 * It's just that this promise will resolve instantly if the asset
 * has already been loaded.
 * </details>
 *
 * <details id="manifests-and-bundles">
 *
 * <summary>Manifest and Bundles</summary>
 *
 * - {@link assets.AssetsManifest Manifest} is a descriptor that contains a list of all assets and their properties.
 * - {@link assets.AssetsBundle Bundles} are a way to group assets together.
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * // Manifest Example
 * const manifest = {
 *     bundles: [
 *         {
 *             name: 'load-screen',
 *             assets: [
 *                 {
 *                     alias: 'background',
 *                     src: 'sunset.png',
 *                 },
 *                 {
 *                     alias: 'bar',
 *                     src: 'load-bar.{png,webp}',
 *                 },
 *             ],
 *         },
 *         {
 *             name: 'game-screen',
 *             assets: [
 *                 {
 *                     alias: 'character',
 *                     src: 'robot.png',
 *                 },
 *                 {
 *                     alias: 'enemy',
 *                     src: 'bad-guy.png',
 *                 },
 *             ],
 *         },
 *     ]
 * };
 *
 * await Assets.init({ manifest });
 *
 * // Load a bundle...
 * loadScreenAssets = await Assets.loadBundle('load-screen');
 * // Load another bundle...
 * gameScreenAssets = await Assets.loadBundle('game-screen');
 * \`\`\`
 * </details>
 */
/**
 * The global Assets class, it's a singleton so you don't need to instantiate it.
 *
 * **The \`Assets\` class has four main responsibilities:**
 * 1. Allows users to map URLs to keys and resolve them according to the user's browser capabilities
 * 2. Loads the resources and transforms them into assets that developers understand.
 * 3. Caches the assets and provides a way to access them.
 * 4. Allow developers to unload assets and clear the cache.
 *
 *
 * **It also has a few advanced features:**
 * 1. Allows developers to provide a {@link assets.Manifest} upfront of all assets and help manage
 * them via {@link assets.AssetsBundles Bundles}.
 * 2. Allows users to background load assets. Shortening (or eliminating) load times and improving UX. With this feature,
 * in-game loading bars can be a thing of the past!
 * @example
 * import { Assets } from 'pixi.js';
 *
 * const bunny = await Assets.load('bunny.png');
 * @memberof assets
 * @class Assets
 */
export declare class AssetsClass {
    /** the resolver to map various urls */
    resolver: Resolver;
    /** The loader, loads stuff! */
    loader: Loader;
    /**
     * The global cache of all assets within PixiJS
     * @type {assets.Cache}
     */
    cache: typeof Cache;
    /** takes care of loading assets in the background */
    private readonly _backgroundLoader;
    private readonly _detections;
    private _initialized;
    constructor();
    /**
     * Best practice is to call this function before any loading commences
     * Initiating is the best time to add any customization to the way things are loaded.
     *
     * you do not need to call this for the Assets class to work, only if you want to set any initial properties
     * @param options - options to initialize the Assets manager with
     */
    init(options?: AssetInitOptions): Promise<void>;
    /**
     * Allows you to specify how to resolve any assets load requests.
     * There are a few ways to add things here as shown below:
     * @example
     * import { Assets } from 'pixi.js';
     *
     * // Simple
     * Assets.add({alias: 'bunnyBooBoo', src: 'bunny.png'});
     * const bunny = await Assets.load('bunnyBooBoo');
     *
     * // Multiple keys:
     * Assets.add({alias: ['burger', 'chicken'], src: 'bunny.png'});
     *
     * const bunny = await Assets.load('burger');
     * const bunny2 = await Assets.load('chicken');
     *
     * // passing options to to the object
     * Assets.add({
     *     alias: 'bunnyBooBooSmooth',
     *     src: 'bunny.{png,webp}',
     *     data: { scaleMode: SCALE_MODES.NEAREST }, // Base texture options
     * });
     *
     * // Multiple assets
     *
     * // The following all do the same thing:
     *
     * Assets.add({alias: 'bunnyBooBoo', src: 'bunny.{png,webp}'});
     *
     * Assets.add({
     *     alias: 'bunnyBooBoo',
     *     src: [
     *         'bunny.png',
     *         'bunny.webp',
     *    ],
     * });
     *
     * const bunny = await Assets.load('bunnyBooBoo'); // Will try to load WebP if available
     * @param assets - the unresolved assets to add to the resolver
     */
    add(assets: (ArrayOr<UnresolvedAsset>)): void;
    /**
     * Loads your assets! You pass in a key or URL and it will return a promise that
     * resolves to the loaded asset. If multiple assets a requested, it will return a hash of assets.
     *
     * Don't worry about loading things multiple times, behind the scenes assets are only ever loaded
     * once and the same promise reused behind the scenes so you can safely call this function multiple
     * times with the same key and it will always return the same asset.
     * @example
     * import { Assets } from 'pixi.js';
     *
     * // Load a URL:
     * const myImageTexture = await Assets.load('http://some.url.com/image.png'); // => returns a texture
     *
     * Assets.add('thumper', 'bunny.png');
     * Assets.add('chicko', 'chicken.png');
     *
     * // Load multiple assets:
     * const textures = await Assets.load(['thumper', 'chicko']); // => {thumper: Texture, chicko: Texture}
     * @param urls - the urls to load
     * @param onProgress - optional function that is called when progress on asset loading is made.
     * The function is passed a single parameter, \`progress\`, which represents the percentage
     * (0.0 - 1.0) of the assets loaded.
     * @returns - the assets that were loaded, either a single asset or a hash of assets
     */
    load<T = any>(urls: string | UnresolvedAsset, onProgress?: ProgressCallback): Promise<T>;
    load<T = any>(urls: string[] | UnresolvedAsset[], onProgress?: ProgressCallback): Promise<Record<string, T>>;
    /**
     * This adds a bundle of assets in one go so that you can load them as a group.
     * For example you could add a bundle for each screen in you pixi app
     * @example
     * import { Assets } from 'pixi.js';
     *
     * Assets.addBundle('animals', [
     *  { alias: 'bunny', src: 'bunny.png' },
     *  { alias: 'chicken', src: 'chicken.png' },
     *  { alias: 'thumper', src: 'thumper.png' },
     * ]);
     * // or
     * Assets.addBundle('animals', {
     *     bunny: 'bunny.png',
     *     chicken: 'chicken.png',
     *     thumper: 'thumper.png',
     * });
     *
     * const assets = await Assets.loadBundle('animals');
     * @param bundleId - the id of the bundle to add
     * @param assets - a record of the asset or assets that will be chosen from when loading via the specified key
     */
    addBundle(bundleId: string, assets: AssetsBundle['assets']): void;
    /**
     * Bundles are a way to load multiple assets at once.
     * If a manifest has been provided to the init function then you can load a bundle, or bundles.
     * you can also add bundles via \`addBundle\`
     * @example
     * import { Assets } from 'pixi.js';
     *
     * // Manifest Example
     * const manifest = {
     *     bundles: [
     *         {
     *             name: 'load-screen',
     *             assets: [
     *                 {
     *                     alias: 'background',
     *                     src: 'sunset.png',
     *                 },
     *                 {
     *                     alias: 'bar',
     *                     src: 'load-bar.{png,webp}',
     *                 },
     *             ],
     *         },
     *         {
     *             name: 'game-screen',
     *             assets: [
     *                 {
     *                     alias: 'character',
     *                     src: 'robot.png',
     *                 },
     *                 {
     *                     alias: 'enemy',
     *                     src: 'bad-guy.png',
     *                 },
     *             ],
     *         },
     *     ]
     * };
     *
     * await Assets.init({ manifest });
     *
     * // Load a bundle...
     * loadScreenAssets = await Assets.loadBundle('load-screen');
     * // Load another bundle...
     * gameScreenAssets = await Assets.loadBundle('game-screen');
     * @param bundleIds - the bundle id or ids to load
     * @param onProgress - Optional function that is called when progress on asset loading is made.
     * The function is passed a single parameter, \`progress\`, which represents the percentage (0.0 - 1.0)
     * of the assets loaded. Do not use this function to detect when assets are complete and available,
     * instead use the Promise returned by this function.
     * @returns all the bundles assets or a hash of assets for each bundle specified
     */
    loadBundle(bundleIds: ArrayOr<string>, onProgress?: ProgressCallback): Promise<any>;
    /**
     * Initiate a background load of some assets. It will passively begin to load these assets in the background.
     * So when you actually come to loading them you will get a promise that resolves to the loaded assets immediately
     *
     * An example of this might be that you would background load game assets after your initial load.
     * then when you got to actually load your game screen assets when a player goes to the game - the loading
     * would already have stared or may even be complete, saving you having to show an interim load bar.
     * @example
     * import { Assets } from 'pixi.js';
     *
     * Assets.backgroundLoad('bunny.png');
     *
     * // later on in your app...
     * await Assets.loadBundle('bunny.png'); // Will resolve quicker as loading may have completed!
     * @param urls - the url / urls you want to background load
     */
    backgroundLoad(urls: ArrayOr<string>): Promise<void>;
    /**
     * Initiate a background of a bundle, works exactly like backgroundLoad but for bundles.
     * this can only be used if the loader has been initiated with a manifest
     * @example
     * import { Assets } from 'pixi.js';
     *
     * await Assets.init({
     *     manifest: {
     *         bundles: [
     *             {
     *                 name: 'load-screen',
     *                 assets: [...],
     *             },
     *             ...
     *         ],
     *     },
     * });
     *
     * Assets.backgroundLoadBundle('load-screen');
     *
     * // Later on in your app...
     * await Assets.loadBundle('load-screen'); // Will resolve quicker as loading may have completed!
     * @param bundleIds - the bundleId / bundleIds you want to background load
     */
    backgroundLoadBundle(bundleIds: ArrayOr<string>): Promise<void>;
    /**
     * Only intended for development purposes.
     * This will wipe the resolver and caches.
     * You will need to reinitialize the Asset
     */
    reset(): void;
    /**
     * Instantly gets an asset already loaded from the cache. If the asset has not yet been loaded,
     * it will return undefined. So it's on you! When in doubt just use \`Assets.load\` instead.
     * (Remember, the loader will never load things more than once!)
     * @param keys - The key or keys for the assets that you want to access
     * @returns - The assets or hash of assets requested
     */
    get<T = any>(keys: string): T;
    get<T = any>(keys: string[]): Record<string, T>;
    /**
     * helper function to map resolved assets back to loaded assets
     * @param resolveResults - the resolve results from the resolver
     * @param onProgress - the progress callback
     */
    private _mapLoadToResolve;
    /**
     * Unload an asset or assets. As the Assets class is responsible for creating the assets via the \`load\` function
     * this will make sure to destroy any assets and release them from memory.
     * Once unloaded, you will need to load the asset again.
     *
     * Use this to help manage assets if you find that you have a large app and you want to free up memory.
     *
     * - it's up to you as the developer to make sure that textures are not actively being used when you unload them,
     * Pixi won't break but you will end up with missing assets. Not a good look for the user!
     * @example
     * import { Assets } from 'pixi.js';
     *
     * // Load a URL:
     * const myImageTexture = await Assets.load('http://some.url.com/image.png'); // => returns a texture
     *
     * await Assets.unload('http://some.url.com/image.png')
     *
     * // myImageTexture will be destroyed now.
     *
     * // Unload multiple assets:
     * const textures = await Assets.unload(['thumper', 'chicko']);
     * @param urls - the urls to unload
     */
    unload(urls: ArrayOr<string> | ResolvedAsset | ResolvedAsset[]): Promise<void>;
    /**
     * Bundles are a way to manage multiple assets at once.
     * this will unload all files in a bundle.
     *
     * once a bundle has been unloaded, you need to load it again to have access to the assets.
     * @example
     * import { Assets } from 'pixi.js';
     *
     * Assets.addBundle({
     *     'thumper': 'http://some.url.com/thumper.png',
     * })
     *
     * const assets = await Assets.loadBundle('thumper');
     *
     * // Now to unload...
     *
     * await Assets.unloadBundle('thumper');
     *
     * // All assets in the assets object will now have been destroyed and purged from the cache
     * @param bundleIds - the bundle id or ids to unload
     */
    unloadBundle(bundleIds: ArrayOr<string>): Promise<void>;
    private _unloadFromResolved;
    /**
     * Detects the supported formats for the browser, and returns an array of supported formats, respecting
     * the users preferred formats order.
     * @param options - the options to use when detecting formats
     * @param options.preferredFormats - the preferred formats to use
     * @param options.skipDetections - if we should skip the detections altogether
     * @param options.detections - the detections to use
     * @returns - the detected formats
     */
    private _detectFormats;
    /** All the detection parsers currently added to the Assets class. */
    get detections(): FormatDetectionParser[];
    /**
     * General setter for preferences. This is a helper function to set preferences on all parsers.
     * @param preferences - the preferences to set
     */
    setPreferences(preferences: Partial<AssetsPreferences>): void;
}
export declare const Assets: AssetsClass;
`,ct=`declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface AssetsPreferences
        {
        }
    }

}

export {};
`,ut=`import type { Loader } from './loader/Loader';
import type { ResolvedAsset } from './types';
/**
 * Quietly Loads assets in the background.
 * @memberof assets
 */
export declare class BackgroundLoader {
    /** Whether or not the loader should continue loading. */
    private _isActive;
    /** Assets to load. */
    private readonly _assetList;
    /** Whether or not the loader is loading. */
    private _isLoading;
    /** Number of assets to load at a time. */
    private readonly _maxConcurrent;
    /** Should the loader log to the console. */
    verbose: boolean;
    private readonly _loader;
    /**
     * @param loader
     * @param verbose - should the loader log to the console
     */
    constructor(loader: Loader, verbose?: boolean);
    /**
     * Adds an array of assets to load.
     * @param assetUrls - assets to load
     */
    add(assetUrls: ResolvedAsset[]): void;
    /**
     * Loads the next set of assets. Will try to load as many assets as it can at the same time.
     *
     * The max assets it will try to load at one time will be 4.
     */
    private _next;
    /**
     * Activate/Deactivate the loading. If set to true then it will immediately continue to load the next asset.
     * @returns whether the class is active
     */
    get active(): boolean;
    set active(value: boolean);
}
`,mt=`import type { CacheParser } from './CacheParser';
/**
 * A single Cache for all assets.
 *
 * When assets are added to the cache via set they normally are added to the cache as key-value pairs.
 *
 * With this cache, you can add parsers that will take the object and convert it to a list of assets that can be cached.
 * for example a cacheSpritesheet parser will add all of the textures found within its sprite sheet directly to the cache.
 *
 * This gives devs the flexibility to cache any type of object however we want.
 *
 * It is not intended that this class is created by developers - it is part of the Asset package.
 * This is the first major system of PixiJS' main Assets class.
 * @example
 * import { Cache } from 'pixi.js';
 *
 * Cache.set('bunny', bunnyTexture);
 * @class Cache
 * @memberof assets
 */
declare class CacheClass {
    private readonly _parsers;
    private readonly _cache;
    private readonly _cacheMap;
    /** Clear all entries. */
    reset(): void;
    /**
     * Check if the key exists
     * @param key - The key to check
     */
    has(key: any): boolean;
    /**
     * Fetch entry by key
     * @param key - The key of the entry to get
     */
    get<T = any>(key: any): T;
    /**
     * Set a value by key or keys name
     * @param key - The key or keys to set
     * @param value - The value to store in the cache or from which cacheable assets will be derived.
     */
    set(key: any | any[], value: unknown): void;
    /**
     * Remove entry by key
     *
     * This function will also remove any associated alias from the cache also.
     * @param key - The key of the entry to remove
     */
    remove(key: any): void;
    /** All loader parsers registered */
    get parsers(): CacheParser[];
}
export declare const Cache: CacheClass;
export {};
`,ht=`import type { ExtensionMetadata } from '../../extensions/Extensions';
/**
 * For every asset that is cached, it will call the parsers test function
 * the flow is as follows:
 *
 * 1. \`cacheParser.test()\`: Test the asset.
 * 2. \`cacheParser.getCacheableAssets()\`: If the test passes call the getCacheableAssets function with the asset
 *
 * Useful if you want to add more than just a raw asset to the cache
 * (for example a spritesheet will want to make all its sub textures easily accessible in the cache)
 * @memberof assets
 */
export interface CacheParser<T = any> {
    /** The extension type of this cache parser */
    extension?: ExtensionMetadata;
    /** A config to adjust the parser */
    config?: Record<string, any>;
    /**
     * Gets called by the cache when a dev caches an asset
     * @param asset - the asset to test
     */
    test: (asset: T) => boolean;
    /**
     * If the test passes, this function is called to get the cacheable assets
     * an example may be that a spritesheet object will return all the sub textures it has so they can
     * be cached.
     * @param keys - The keys to cache the assets under
     * @param asset - The asset to get the cacheable assets from
     * @returns A key-value pair of cacheable assets
     */
    getCacheableAssets: (keys: string[], asset: T) => Record<string, any>;
}
`,ft=`import { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { CacheParser } from '../CacheParser';
/**
 * Returns an object of textures from an array of textures to be cached
 * @memberof assets
 */
export declare const cacheTextureArray: CacheParser<Texture[]>;
`,bt=`import type { FormatDetectionParser } from '../types';
/**
 * Detects if the browser supports the AVIF image format.
 * @memberof assets
 */
export declare const detectAvif: FormatDetectionParser;
`,gt=`import type { FormatDetectionParser } from '../types';
/**
 * Adds some default image formats to the detection parser
 * @memberof assets
 */
export declare const detectDefaults: FormatDetectionParser;
`,yt=`import type { FormatDetectionParser } from '../types';
/**
 * Detects if the browser supports the MP4 video format.
 * @memberof assets
 */
export declare const detectMp4: FormatDetectionParser;
`,xt=`import type { FormatDetectionParser } from '../types';
/**
 * Detects if the browser supports the OGV video format.
 * @memberof assets
 */
export declare const detectOgv: FormatDetectionParser;
`,vt=`import type { FormatDetectionParser } from '../types';
/**
 * Detects if the browser supports the WebM video format.
 * @memberof assets
 */
export declare const detectWebm: FormatDetectionParser;
`,Tt=`import type { FormatDetectionParser } from '../types';
/**
 * Detects if the browser supports the WebP image format.
 * @memberof assets
 */
export declare const detectWebp: FormatDetectionParser;
`,St=`import type { ExtensionMetadata } from '../../extensions/Extensions';
/**
 * Format detection is useful for detecting feature support on the current platform.
 * @memberof assets
 */
export interface FormatDetectionParser {
    /** Should be ExtensionType.DetectionParser */
    extension?: ExtensionMetadata;
    /** Browser/platform feature detection supported if return true  */
    test: () => Promise<boolean>;
    /**
     * Add formats (file extensions) to the existing list of formats.
     * Return an new array with added formats, do not mutate the formats argument.
     * @returns {Promise<string[]>} - Promise that resolves to the new formats array.
     */
    add: (formats: string[]) => Promise<string[]>;
    /**
     * Remove formats (file extensions) from the list of supported formats.
     * This is used when uninstalling this DetectionParser.
     * Return an new array with filtered formats, do not mutate the formats argument.
     * @returns {Promise<string[]>} - Promise that resolves to the new formats array.
     */
    remove: (formats: string[]) => Promise<string[]>;
}
`,wt=`export declare function testImageFormat(imageData: string): Promise<boolean>;
`,_t=`export declare function testVideoFormat(mimeType: string): boolean;
`,Et=`export * from './AssetExtension';
export * from './Assets';
export * from './BackgroundLoader';
export * from './cache/Cache';
export * from './cache/CacheParser';
export * from './cache/parsers/cacheTextureArray';
export * from './detections/parsers/detectAvif';
export * from './detections/parsers/detectDefaults';
export * from './detections/parsers/detectMp4';
export * from './detections/parsers/detectOgv';
export * from './detections/parsers/detectWebm';
export * from './detections/parsers/detectWebp';
export * from './detections/types';
export * from './detections/utils/testImageFormat';
export * from './detections/utils/testVideoFormat';
export * from './loader/Loader';
export * from './loader/parsers/LoaderParser';
export * from './loader/parsers/loadJson';
export * from './loader/parsers/loadTxt';
export * from './loader/parsers/loadWebFont';
export * from './loader/parsers/textures/loadSVG';
export * from './loader/parsers/textures/loadTextures';
export * from './loader/parsers/textures/loadVideoTextures';
export * from './loader/parsers/textures/utils/createTexture';
export * from './loader/types';
export * from './loader/workers/WorkerManager';
export * from './resolver/parsers/resolveJsonUrl';
export * from './resolver/parsers/resolveTextureUrl';
export * from './resolver/Resolver';
export * from './resolver/types';
export * from './types';
export * from './utils/checkDataUrl';
export * from './utils/checkExtension';
export * from './utils/convertToList';
export * from './utils/copySearchParams';
export * from './utils/createStringVariations';
export * from './utils/isSingleItem';
`,Pt=`import type { ResolvedAsset } from '../types';
import type { LoaderParser } from './parsers/LoaderParser';
import type { PromiseAndParser } from './types';
/**
 * The Loader is responsible for loading all assets, such as images, spritesheets, audio files, etc.
 * It does not do anything clever with URLs - it just loads stuff!
 * Behind the scenes all things are cached using promises. This means it's impossible to load an asset more than once.
 * Through the use of LoaderParsers, the loader can understand how to load any kind of file!
 *
 * It is not intended that this class is created by developers - its part of the Asset class
 * This is the second major system of PixiJS' main Assets class
 * @memberof assets
 */
export declare class Loader {
    private readonly _parsers;
    private _parserHash;
    private _parsersValidated;
    /**
     * All loader parsers registered
     * @type {assets.LoaderParser[]}
     */
    parsers: LoaderParser<any, any, Record<string, any>>[];
    /** Cache loading promises that ae currently active */
    promiseCache: Record<string, PromiseAndParser>;
    /** function used for testing */
    reset(): void;
    /**
     * Used internally to generate a promise for the asset to be loaded.
     * @param url - The URL to be loaded
     * @param data - any custom additional information relevant to the asset being loaded
     * @returns - a promise that will resolve to an Asset for example a Texture of a JSON object
     */
    private _getLoadPromiseAndParser;
    /**
     * Loads one or more assets using the parsers added to the Loader.
     * @example
     * // Single asset:
     * const asset = await Loader.load('cool.png');
     * console.log(asset);
     *
     * // Multiple assets:
     * const assets = await Loader.load(['cool.png', 'cooler.png']);
     * console.log(assets);
     * @param assetsToLoadIn - urls that you want to load, or a single one!
     * @param onProgress - For multiple asset loading only, an optional function that is called
     * when progress on asset loading is made. The function is passed a single parameter, \`progress\`,
     * which represents the percentage (0.0 - 1.0) of the assets loaded. Do not use this function
     * to detect when assets are complete and available, instead use the Promise returned by this function.
     */
    load<T = any>(assetsToLoadIn: string | ResolvedAsset, onProgress?: (progress: number) => void): Promise<T>;
    load<T = any>(assetsToLoadIn: string[] | ResolvedAsset[], onProgress?: (progress: number) => void): Promise<Record<string, T>>;
    /**
     * Unloads one or more assets. Any unloaded assets will be destroyed, freeing up memory for your app.
     * The parser that created the asset, will be the one that unloads it.
     * @example
     * // Single asset:
     * const asset = await Loader.load('cool.png');
     *
     * await Loader.unload('cool.png');
     *
     * console.log(asset.destroyed); // true
     * @param assetsToUnloadIn - urls that you want to unload, or a single one!
     */
    unload(assetsToUnloadIn: string | string[] | ResolvedAsset | ResolvedAsset[]): Promise<void>;
    /** validates our parsers, right now it only checks for name conflicts but we can add more here as required! */
    private _validateParsers;
}
`,At=`import type { ExtensionMetadata } from '../../../extensions/Extensions';
import type { ResolvedAsset } from '../../types';
import type { Loader } from '../Loader';
/**
 * The extension priority for loader parsers.
 * Helpful when managing multiple parsers that share the same extension test.
 * The higher priority parsers will be checked first.
 * @enum {number}
 */
export declare enum LoaderParserPriority {
    /** Generic parsers: txt, json, webfonts */
    Low = 0,
    /** PixiJS assets with generic extensions: spritesheets, bitmapfonts  */
    Normal = 1,
    /** Specific texture types: svg, png, ktx, dds, basis */
    High = 2
}
/** A more verbose version of the LoaderParser, allowing you to set the loaded, parsed, and unloaded asset separately */
export interface LoaderParserAdvanced<ASSET = any, PARSED_ASSET = ASSET, UNLOAD_ASSET = ASSET, META_DATA = any, CONFIG = Record<string, any>> {
    /** Should be ExtensionType.LoaderParser */
    extension?: ExtensionMetadata;
    /** A config to adjust the parser */
    config?: CONFIG;
    /** The name of the parser (this can be used when specifying loadParser in a ResolvedAsset) */
    name: string;
    /**
     * Each URL to load will be tested here,
     * if the test is passed the assets are loaded using the load function below.
     * Good place to test for things like file extensions!
     * @param url - The URL to test
     * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
     * @param loader - The loader instance
     */
    test?: (url: string, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => boolean;
    /**
     * This is the promise that loads the URL provided
     * resolves with a loaded asset if returned by the parser.
     * @param url - The URL to load
     * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
     * @param loader - The loader instance
     */
    load?: <T>(url: string, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<ASSET | T>;
    /**
     * This function is used to test if the parse function should be run on the asset
     * If this returns true then parse is called with the asset
     * @param asset - The loaded asset data
     * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
     * @param loader - The loader instance
     */
    testParse?: (asset: ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<boolean>;
    /**
     * Gets called on the asset it testParse passes. Useful to convert a raw asset into something more useful
     * @param asset - The loaded asset data
     * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
     * @param loader - The loader instance
     */
    parse?: <T>(asset: ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<PARSED_ASSET | T>;
    /**
     * If an asset is parsed using this parser, the unload function will be called when the user requests an asset
     * to be unloaded. This is useful for things like sounds or textures that can be unloaded from memory
     * @param asset - The asset to unload/destroy
     * @param resolvedAsset - Any custom additional information relevant to the asset being loaded
     * @param loader - The loader instance
     */
    unload?: (asset: UNLOAD_ASSET, resolvedAsset?: ResolvedAsset<META_DATA>, loader?: Loader) => Promise<void> | void;
}
/**
 * The interface to define a loader parser *(all functions are optional)*.
 *
 * When you create a \`parser\` object, the flow for every asset loaded is:
 *
 * 1. \`parser.test()\` - Each URL to load will be tested here, if the test is passed the assets are
 * loaded using the load function below. Good place to test for things like file extensions!
 * 2. \`parser.load()\` - This is the promise that loads the URL provided resolves with a loaded asset
 * if returned by the parser.
 * 3. \`parser.testParse()\` - This function is used to test if the parse function should be run on the
 *  asset If this returns true then parse is called with the asset
 * 4. \`parse.parse()\` - Gets called on the asset it testParse passes. Useful to convert a raw asset
 *  into something more useful
 *
 * <br/>
 * Some loaders may only be used for parsing, some only for loading, and some for both!
 * @memberof assets
 */
export interface LoaderParser<ASSET = any, META_DATA = any, CONFIG = Record<string, any>> extends LoaderParserAdvanced<ASSET, ASSET, ASSET, META_DATA, CONFIG> {
}
`,Ct=`import { ExtensionType } from '../../../extensions/Extensions';
import { LoaderParserPriority } from './LoaderParser';
/**
 * A simple loader plugin for loading json data
 * @memberof assets
 */
export declare const loadJson: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string): Promise<T>;
};
`,Rt=`import { ExtensionType } from '../../../extensions/Extensions';
import { LoaderParserPriority } from './LoaderParser';
/**
 * A simple loader plugin for loading text data
 * @memberof assets
 */
export declare const loadTxt: {
    name: string;
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
        name: string;
    };
    test(url: string): boolean;
    load<T>(url: string): Promise<string>;
};
`,Gt=`import { ExtensionType } from '../../../extensions/Extensions';
import { LoaderParserPriority } from './LoaderParser';
import type { ResolvedAsset } from '../../types';
/**
 * Data for loading a font
 * @memberof assets
 */
export type LoadFontData = {
    /** Font family name */
    family: string;
    /** A set of optional descriptors passed as an object. It can contain any of the descriptors available for @font-face: */
    display: string;
    /**
     * The featureSettings property of the FontFace interface retrieves or sets infrequently used
     * font features that are not available from a font's variant properties.
     */
    featureSettings: string;
    /** The stretch property of the FontFace interface retrieves or sets how the font stretches. */
    stretch: string;
    /** The style property of the FontFace interface retrieves or sets the font's style. */
    style: string;
    /**
     * The unicodeRange property of the FontFace interface retrieves or sets the range of
     * unicode code points encompassing the font.
     */
    unicodeRange: string;
    /** The variant property of the FontFace interface programmatically retrieves or sets font variant values. */
    variant: string;
    /** The weight property of the FontFace interface retrieves or sets the weight of the font. */
    weights: string[];
};
/**
 * Return font face name from a file name
 * Ex.: 'fonts/titan-one.woff' turns into 'Titan One'
 * @param url - File url
 * @memberof assets
 */
export declare function getFontFamilyName(url: string): string;
/**
 * A loader plugin for handling web fonts
 * @example
 * import { Assets } from 'pixi.js';
 *
 * Assets.load({
 *   alias: 'font',
 *   src: 'fonts/titan-one.woff',
 *   data: {
 *     family: 'Titan One',
 *     weights: ['normal', 'bold'],
 *   }
 * })
 * @memberof assets
 */
export declare const loadWebFont: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string, options?: ResolvedAsset<LoadFontData>): Promise<FontFace | FontFace[]>;
    unload(font: FontFace | FontFace[]): void;
};
`,Mt=`import { GraphicsContext } from '../../../../scene/graphics/shared/GraphicsContext';
import { type LoaderParser } from '../LoaderParser';
import type { TextureSourceOptions } from '../../../../rendering/renderers/shared/texture/sources/TextureSource';
import type { Texture } from '../../../../rendering/renderers/shared/texture/Texture';
/**
 * Configuration for the [loadSVG]{@link assets.loadSVG} plugin.
 * @see assets.loadSVG
 * @memberof assets
 */
export interface LoadSVGConfig {
    /**
     * The crossOrigin value to use for loading the SVG as an image.
     * @default 'anonymous'
     */
    crossOrigin: HTMLImageElement['crossOrigin'];
    /**
     * When set to \`true\`, loading and decoding images will happen with \`new Image()\`,
     * @default false
     */
    parseAsGraphicsContext: boolean;
}
/**
 * A simple loader plugin for loading json data
 * @memberof assets
 */
export declare const loadSvg: LoaderParser<Texture | GraphicsContext, TextureSourceOptions & LoadSVGConfig, LoadSVGConfig>;
`,kt=`import type { TextureSourceOptions } from '../../../../rendering/renderers/shared/texture/sources/TextureSource';
import type { Texture } from '../../../../rendering/renderers/shared/texture/Texture';
import type { ResolvedAsset } from '../../../types';
import type { LoaderParser } from '../LoaderParser';
/**
 * Configuration for the [loadTextures]{@link assets.loadTextures} plugin.
 * @see assets.loadTextures
 * @memberof assets
 */
export interface LoadTextureConfig {
    /**
     * When set to \`true\`, loading and decoding images will happen with Worker thread,
     * if available on the browser. This is much more performant as network requests
     * and decoding can be expensive on the CPU. However, not all environments support
     * Workers, in some cases it can be helpful to disable by setting to \`false\`.
     * @default true
     */
    preferWorkers: boolean;
    /**
     * When set to \`true\`, loading and decoding images will happen with \`createImageBitmap\`,
     * otherwise it will use \`new Image()\`.
     * @default true
     */
    preferCreateImageBitmap: boolean;
    /**
     * The crossOrigin value to use for images when \`preferCreateImageBitmap\` is \`false\`.
     * @default 'anonymous'
     */
    crossOrigin: HTMLImageElement['crossOrigin'];
}
/**
 * Returns a promise that resolves an ImageBitmaps.
 * This function is designed to be used by a worker.
 * Part of WorkerManager!
 * @param url - The image to load an image bitmap for
 * @ignore
 */
export declare function loadImageBitmap(url: string, asset?: ResolvedAsset<TextureSourceOptions<any>>): Promise<ImageBitmap>;
/**
 * A simple plugin to load our textures!
 * This makes use of imageBitmaps where available.
 * We load the \`ImageBitmap\` on a different thread using workers if possible.
 * We can then use the \`ImageBitmap\` as a source for a Pixi texture
 *
 * You can customize the behavior of this loader by setting the \`config\` property.
 * Which can be found [here]{@link assets.LoadTextureConfig}
 * \`\`\`js
 * // Set the config
 * import { loadTextures } from 'pixi.js';
 *
 * loadTextures.config = {
 *    // If true we will use a worker to load the ImageBitmap
 *    preferWorkers: true,
 *    // If false we will use new Image() instead of createImageBitmap,
 *    // we'll also disable the use of workers as it requires createImageBitmap
 *    preferCreateImageBitmap: true,
 *    crossOrigin: 'anonymous',
 * };
 * \`\`\`
 * @memberof assets
 */
export declare const loadTextures: LoaderParser<Texture, TextureSourceOptions, LoadTextureConfig>;
`,Ft=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { VideoSourceOptions } from '../../../../rendering/renderers/shared/texture/sources/VideoSource';
import type { Texture } from '../../../../rendering/renderers/shared/texture/Texture';
import type { ResolvedAsset } from '../../../types';
import type { Loader } from '../../Loader';
/**
 * Set cross origin based detecting the url and the crossorigin
 * @param element - Element to apply crossOrigin
 * @param url - URL to check
 * @param crossorigin - Cross origin value to use
 * @memberof assets
 */
export declare function crossOrigin(element: HTMLImageElement | HTMLVideoElement, url: string, crossorigin?: boolean | string): void;
/**
 * Preload a video element
 * @param element - Video element to preload
 */
export declare function preloadVideo(element: HTMLVideoElement): Promise<void>;
/**
 * Sets the \`crossOrigin\` property for this resource based on if the url
 * for this resource is cross-origin. If crossOrigin was manually set, this
 * function does nothing.
 * Nipped from the resource loader!
 * @ignore
 * @param url - The url to test.
 * @param {object} [loc=window.location] - The location object to test against.
 * @returns The crossOrigin value to use (or empty string for none).
 * @memberof assets
 */
export declare function determineCrossOrigin(url: string, loc?: Location): string;
/**
 * A simple plugin to load video textures.
 *
 * You can pass VideoSource options to the loader via the .data property of the asset descriptor
 * when using Asset.load().
 * \`\`\`js
 * // Set the data
 * const texture = await Assets.load({
 *     src: './assets/city.mp4',
 *     data: {
 *         preload: true,
 *         autoPlay: true,
 *     },
 * });
 * \`\`\`
 * @memberof assets
 */
export declare const loadVideoTextures: {
    name: string;
    extension: {
        type: ExtensionType.LoadParser;
        name: string;
    };
    test(url: string): boolean;
    load<T>(url: string, asset: ResolvedAsset<VideoSourceOptions>, loader: Loader): Promise<Texture>;
    unload(texture: Texture): void;
};
`,Ot=`import { Texture } from '../../../../../rendering/renderers/shared/texture/Texture';
import type { TextureSource } from '../../../../../rendering/renderers/shared/texture/sources/TextureSource';
import type { Loader } from '../../../Loader';
/**
 * Creates a texture from a source and adds it to the cache.
 * @param source - source of the texture
 * @param loader - loader
 * @param url - url of the texture
 * @ignore
 */
export declare function createTexture(source: TextureSource, loader: Loader, url: string): Texture<TextureSource<any>>;
`,It=`import type { LoaderParser } from './parsers/LoaderParser';
/**
 * A promise and parser pair
 * @memberof assets
 */
export interface PromiseAndParser {
    /** the promise that is loading the asset */
    promise: Promise<any>;
    /** the parser that is loading the asset */
    parser: LoaderParser;
}
`,Lt=`import type { TextureSourceOptions } from '../../../rendering/renderers/shared/texture/sources/TextureSource';
import type { ResolvedAsset } from '../../types';
declare class WorkerManagerClass {
    worker: Worker;
    private _resolveHash;
    private readonly _workerPool;
    private readonly _queue;
    private _initialized;
    private _createdWorkers;
    private _isImageBitmapSupported?;
    constructor();
    isImageBitmapSupported(): Promise<boolean>;
    loadImageBitmap(src: string, asset?: ResolvedAsset<TextureSourceOptions<any>>): Promise<ImageBitmap>;
    private _initWorkers;
    private _getWorker;
    private _returnWorker;
    private _complete;
    private _run;
    private _next;
}
declare const WorkerManager: WorkerManagerClass;
export { WorkerManager, };
`,Bt=`declare const WHITE_PNG = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAwMCAO+ip1sAAAAASUVORK5CYII=";
declare function checkImageBitmap(): Promise<boolean>;
`,Dt=`interface MessageData {
    data: any[];
    uuid: number;
    id: string;
}
declare function loadImageBitmap(url: string, alphaMode?: string): Promise<ImageBitmap>;
`,Ut=`import type { ArrayOr, AssetsBundle, AssetsManifest, ResolvedAsset, UnresolvedAsset } from '../types';
import type { PreferOrder, ResolveURLParser } from './types';
/**
 * Options for how the resolver deals with generating bundle ids
 * @memberof assets
 */
export interface BundleIdentifierOptions {
    /** The character that is used to connect the bundleId and the assetId when generating a bundle asset id key */
    connector?: string;
    /**
     * A function that generates a bundle asset id key from a bundleId and an assetId
     * @param bundleId - the bundleId
     * @param assetId  - the assetId
     * @returns the bundle asset id key
     */
    createBundleAssetId?: (bundleId: string, assetId: string) => string;
    /**
     * A function that generates an assetId from a bundle asset id key. This is the reverse of generateBundleAssetId
     * @param bundleId - the bundleId
     * @param assetBundleId - the bundle asset id key
     * @returns the assetId
     */
    extractAssetIdFromBundle?: (bundleId: string, assetBundleId: string) => string;
}
/**
 * A class that is responsible for resolving mapping asset URLs to keys.
 * At its most basic it can be used for Aliases:
 *
 * \`\`\`js
 * resolver.add('foo', 'bar');
 * resolver.resolveUrl('foo') // => 'bar'
 * \`\`\`
 *
 * It can also be used to resolve the most appropriate asset for a given URL:
 *
 * \`\`\`js
 * resolver.prefer({
 *     params: {
 *         format: 'webp',
 *         resolution: 2,
 *     }
 * });
 *
 * resolver.add('foo', ['bar@2x.webp', 'bar@2x.png', 'bar.webp', 'bar.png']);
 *
 * resolver.resolveUrl('foo') // => 'bar@2x.webp'
 * \`\`\`
 * Other features include:
 * - Ability to process a manifest file to get the correct understanding of how to resolve all assets
 * - Ability to add custom parsers for specific file types
 * - Ability to add custom prefer rules
 *
 * This class only cares about the URL, not the loading of the asset itself.
 *
 * It is not intended that this class is created by developers - its part of the Asset class
 * This is the third major system of PixiJS' main Assets class
 * @memberof assets
 */
export declare class Resolver {
    /**
     * The prefix that denotes a URL is for a retina asset.
     * @static
     * @name RETINA_PREFIX
     * @type {RegExp}
     * @default /@([0-9\\.]+)x/
     * @example \`@2x\`
     */
    static RETINA_PREFIX: RegExp;
    private readonly _defaultBundleIdentifierOptions;
    /** The character that is used to connect the bundleId and the assetId when generating a bundle asset id key */
    private _bundleIdConnector;
    /**
     * A function that generates a bundle asset id key from a bundleId and an assetId
     * @param bundleId - the bundleId
     * @param assetId  - the assetId
     * @returns the bundle asset id key
     */
    private _createBundleAssetId;
    /**
     * A function that generates an assetId from a bundle asset id key. This is the reverse of generateBundleAssetId
     * @param bundleId - the bundleId
     * @param assetBundleId - the bundle asset id key
     * @returns the assetId
     */
    private _extractAssetIdFromBundle;
    private _assetMap;
    private _preferredOrder;
    private readonly _parsers;
    private _resolverHash;
    private _rootPath;
    private _basePath;
    private _manifest;
    private _bundles;
    private _defaultSearchParams;
    /**
     * Override how the resolver deals with generating bundle ids.
     * must be called before any bundles are added
     * @param bundleIdentifier - the bundle identifier options
     */
    setBundleIdentifier(bundleIdentifier: BundleIdentifierOptions): void;
    /**
     * Let the resolver know which assets you prefer to use when resolving assets.
     * Multiple prefer user defined rules can be added.
     * @example
     * resolver.prefer({
     *     // first look for something with the correct format, and then then correct resolution
     *     priority: ['format', 'resolution'],
     *     params:{
     *         format:'webp', // prefer webp images
     *         resolution: 2, // prefer a resolution of 2
     *     }
     * })
     * resolver.add('foo', ['bar@2x.webp', 'bar@2x.png', 'bar.webp', 'bar.png']);
     * resolver.resolveUrl('foo') // => 'bar@2x.webp'
     * @param preferOrders - the prefer options
     */
    prefer(...preferOrders: PreferOrder[]): void;
    /**
     * Set the base path to prepend to all urls when resolving
     * @example
     * resolver.basePath = 'https://home.com/';
     * resolver.add('foo', 'bar.ong');
     * resolver.resolveUrl('foo', 'bar.png'); // => 'https://home.com/bar.png'
     * @param basePath - the base path to use
     */
    set basePath(basePath: string);
    get basePath(): string;
    /**
     * Set the root path for root-relative URLs. By default the \`basePath\`'s root is used. If no \`basePath\` is set, then the
     * default value for browsers is \`window.location.origin\`
     * @example
     * // Application hosted on https://home.com/some-path/index.html
     * resolver.basePath = 'https://home.com/some-path/';
     * resolver.rootPath = 'https://home.com/';
     * resolver.add('foo', '/bar.png');
     * resolver.resolveUrl('foo', '/bar.png'); // => 'https://home.com/bar.png'
     * @param rootPath - the root path to use
     */
    set rootPath(rootPath: string);
    get rootPath(): string;
    /**
     * All the active URL parsers that help the parser to extract information and create
     * an asset object-based on parsing the URL itself.
     *
     * Can be added using the extensions API
     * @example
     * resolver.add('foo', [
     *     {
     *         resolution: 2,
     *         format: 'png',
     *         src: 'image@2x.png',
     *     },
     *     {
     *         resolution:1,
     *         format:'png',
     *         src: 'image.png',
     *     },
     * ]);
     *
     * // With a url parser the information such as resolution and file format could extracted from the url itself:
     * extensions.add({
     *     extension: ExtensionType.ResolveParser,
     *     test: loadTextures.test, // test if url ends in an image
     *     parse: (value: string) =>
     *     ({
     *         resolution: parseFloat(Resolver.RETINA_PREFIX.exec(value)?.[1] ?? '1'),
     *         format: value.split('.').pop(),
     *         src: value,
     *     }),
     * });
     *
     * // Now resolution and format can be extracted from the url
     * resolver.add('foo', [
     *     'image@2x.png',
     *     'image.png',
     * ]);
     */
    get parsers(): ResolveURLParser[];
    /** Used for testing, this resets the resolver to its initial state */
    reset(): void;
    /**
     * Sets the default URL search parameters for the URL resolver. The urls can be specified as a string or an object.
     * @param searchParams - the default url parameters to append when resolving urls
     */
    setDefaultSearchParams(searchParams: string | Record<string, unknown>): void;
    /**
     * Returns the aliases for a given asset
     * @param asset - the asset to get the aliases for
     */
    getAlias(asset: UnresolvedAsset): string[];
    /**
     * Add a manifest to the asset resolver. This is a nice way to add all the asset information in one go.
     * generally a manifest would be built using a tool.
     * @param manifest - the manifest to add to the resolver
     */
    addManifest(manifest: AssetsManifest): void;
    /**
     * This adds a bundle of assets in one go so that you can resolve them as a group.
     * For example you could add a bundle for each screen in you pixi app
     * @example
     * resolver.addBundle('animals', [
     *  { alias: 'bunny', src: 'bunny.png' },
     *  { alias: 'chicken', src: 'chicken.png' },
     *  { alias: 'thumper', src: 'thumper.png' },
     * ]);
     * // or
     * resolver.addBundle('animals', {
     *     bunny: 'bunny.png',
     *     chicken: 'chicken.png',
     *     thumper: 'thumper.png',
     * });
     *
     * const resolvedAssets = await resolver.resolveBundle('animals');
     * @param bundleId - The id of the bundle to add
     * @param assets - A record of the asset or assets that will be chosen from when loading via the specified key
     */
    addBundle(bundleId: string, assets: AssetsBundle['assets']): void;
    /**
     * Tells the resolver what keys are associated with witch asset.
     * The most important thing the resolver does
     * @example
     * // Single key, single asset:
     * resolver.add({alias: 'foo', src: 'bar.png');
     * resolver.resolveUrl('foo') // => 'bar.png'
     *
     * // Multiple keys, single asset:
     * resolver.add({alias: ['foo', 'boo'], src: 'bar.png'});
     * resolver.resolveUrl('foo') // => 'bar.png'
     * resolver.resolveUrl('boo') // => 'bar.png'
     *
     * // Multiple keys, multiple assets:
     * resolver.add({alias: ['foo', 'boo'], src: ['bar.png', 'bar.webp']});
     * resolver.resolveUrl('foo') // => 'bar.png'
     *
     * // Add custom data attached to the resolver
     * Resolver.add({
     *     alias: 'bunnyBooBooSmooth',
     *     src: 'bunny{png,webp}',
     *     data: { scaleMode:SCALE_MODES.NEAREST }, // Base texture options
     * });
     *
     * resolver.resolve('bunnyBooBooSmooth') // => { src: 'bunny.png', data: { scaleMode: SCALE_MODES.NEAREST } }
     * @param aliases - the UnresolvedAsset or array of UnresolvedAssets to add to the resolver
     */
    add(aliases: ArrayOr<UnresolvedAsset>): void;
    /**
     * If the resolver has had a manifest set via setManifest, this will return the assets urls for
     * a given bundleId or bundleIds.
     * @example
     * // Manifest Example
     * const manifest = {
     *     bundles: [
     *         {
     *             name: 'load-screen',
     *             assets: [
     *                 {
     *                     alias: 'background',
     *                     src: 'sunset.png',
     *                 },
     *                 {
     *                     alias: 'bar',
     *                     src: 'load-bar.{png,webp}',
     *                 },
     *             ],
     *         },
     *         {
     *             name: 'game-screen',
     *             assets: [
     *                 {
     *                     alias: 'character',
     *                     src: 'robot.png',
     *                 },
     *                 {
     *                     alias: 'enemy',
     *                     src: 'bad-guy.png',
     *                 },
     *             ],
     *         },
     *     ]
     * };
     *
     * resolver.setManifest(manifest);
     * const resolved = resolver.resolveBundle('load-screen');
     * @param bundleIds - The bundle ids to resolve
     * @returns All the bundles assets or a hash of assets for each bundle specified
     */
    resolveBundle(bundleIds: ArrayOr<string>): Record<string, ResolvedAsset> | Record<string, Record<string, ResolvedAsset>>;
    /**
     * Does exactly what resolve does, but returns just the URL rather than the whole asset object
     * @param key - The key or keys to resolve
     * @returns - The URLs associated with the key(s)
     */
    resolveUrl(key: ArrayOr<string>): string | Record<string, string>;
    /**
     * Resolves each key in the list to an asset object.
     * Another key function of the resolver! After adding all the various key/asset pairs. this will run the logic
     * of finding which asset to return based on any preferences set using the \`prefer\` function
     * by default the same key passed in will be returned if nothing is matched by the resolver.
     * @example
     * resolver.add('boo', 'bunny.png');
     *
     * resolver.resolve('boo') // => { src: 'bunny.png' }
     *
     * // Will return the same string as no key was added for this value..
     * resolver.resolve('another-thing.png') // => { src: 'another-thing.png' }
     * @param keys - key or keys to resolve
     * @returns - the resolve asset or a hash of resolve assets for each key specified
     */
    resolve(keys: string): ResolvedAsset;
    resolve(keys: string[]): Record<string, ResolvedAsset>;
    /**
     * Checks if an asset with a given key exists in the resolver
     * @param key - The key of the asset
     */
    hasKey(key: string): boolean;
    /**
     * Checks if a bundle with the given key exists in the resolver
     * @param key - The key of the bundle
     */
    hasBundle(key: string): boolean;
    /**
     * Internal function for figuring out what prefer criteria an asset should use.
     * @param assets
     */
    private _getPreferredOrder;
    /**
     * Appends the default url parameters to the url
     * @param url - The url to append the default parameters to
     * @returns - The url with the default parameters appended
     */
    private _appendDefaultSearchParams;
    private _buildResolvedAsset;
}
export declare function getUrlExtension(url: string): string;
`,jt=`import { ExtensionType } from '../../../extensions/Extensions';
/**
 * A parser that will resolve a json urls resolution for spritesheets
 * e.g. \`assets/spritesheet@1x.json\`
 * @memberof assets
 */
export declare const resolveJsonUrl: {
    extension: {
        type: ExtensionType.ResolveParser;
        priority: number;
        name: string;
    };
    test: (value: string) => boolean;
    parse: (value: string) => {
        resolution: number;
        format: string;
        src: string;
    };
};
`,Wt=`import { ExtensionType } from '../../../extensions/Extensions';
/**
 * A parser that will resolve a texture url
 * @memberof assets
 */
export declare const resolveTextureUrl: {
    extension: {
        type: ExtensionType.ResolveParser;
        name: string;
    };
    test: (url: string, resolvedAsset?: import("../..").ResolvedAsset<import("../../..").TextureSourceOptions<any>>, loader?: import("../..").Loader) => boolean;
    parse: (value: string) => {
        resolution: number;
        format: string;
        src: string;
    };
};
`,Ht=`import type { ExtensionMetadata } from '../../extensions/Extensions';
import type { ResolvedAsset } from '../types';
/**
 * A prefer order lets the resolver know which assets to prefer depending on the various parameters passed to it.
 * @memberof assets
 */
export interface PreferOrder {
    /** the importance order of the params */
    priority?: string[];
    params: {
        [key: string]: any;
    };
}
/**
 * Format for url parser, will test a string and if it pass will then parse it, turning it into an ResolvedAsset
 * @memberof assets
 */
export interface ResolveURLParser {
    extension?: ExtensionMetadata;
    /** A config to adjust the parser */
    config?: Record<string, any>;
    /** the test to perform on the url to determine if it should be parsed */
    test: (url: string) => boolean;
    /** the function that will convert the url into an object */
    parse: (value: string) => ResolvedAsset & {
        [key: string]: any;
    };
}
`,Vt=`export type ArrayOr<T> = T | T[];
/**
 * Names of the parsers that are built into PixiJS.
 * Can be any of the following defaults:
 * - \`loadJson\`
 * - \`loadSVG\`
 * - \`loadTextures\`
 * - \`loadTxt\`
 * - \`loadVideo\`
 * - \`loadWebFont\`
 * or a custom parser name.
 * @memberof assets
 */
export type LoadParserName = 'loadJson' | 'loadSVG' | 'loadTextures' | 'loadTxt' | 'loadVideo' | 'loadWebFont' | string;
/**
 * A fully resolved asset, with all the information needed to load it.
 * @memberof assets
 */
export interface ResolvedAsset<T = any> {
    /** Aliases associated with asset */
    alias?: string[];
    /** The URL or relative path to the asset */
    src?: string;
    /** Optional data */
    data?: T;
    /** Format, usually the file extension */
    format?: string;
    /** An override that will ensure that the asset is loaded with a specific parser */
    loadParser?: LoadParserName;
}
/**
 * A fully resolved src, Glob patterns will not work here, and the src will be resolved to a single file.
 * @memberof assets
 * @property {string} src - The URL or relative path to the asset
 * @property {string} format - Format, usually the file extension
 * @property {string} loadParser - An override that will ensure that the asset is loaded with a specific parser
 * @property {any} data - Optional data
 */
export type ResolvedSrc = Pick<ResolvedAsset, 'src' | 'format' | 'loadParser' | 'data'>;
/**
 * A valid asset src. This can be a string, or a [ResolvedSrc]{@link assets.ResolvedSrc},
 * or an array of either.
 * @memberof assets
 */
export type AssetSrc = ArrayOr<string> | (ArrayOr<ResolvedSrc> & {
    [key: string]: any;
});
/**
 * An asset that has not been resolved yet.
 * @memberof assets
 */
export type UnresolvedAsset<T = any> = Pick<ResolvedAsset<T>, 'data' | 'format' | 'loadParser'> & {
    /** Aliases associated with asset */
    alias?: ArrayOr<string>;
    /** The URL or relative path to the asset */
    src?: AssetSrc;
    [key: string]: any;
};
/**
 * Structure of a bundle found in a {@link assets.AssetsManifest Manifest} file
 * @memberof assets
 */
export interface AssetsBundle {
    /** The name of the bundle */
    name: string;
    /** The assets in the bundle */
    assets: UnresolvedAsset[] | Record<string, ArrayOr<string> | UnresolvedAsset>;
}
/**
 * The expected format of a manifest. This could be auto generated or hand made
 * @memberof assets
 */
export interface AssetsManifest {
    /** array of bundles */
    bundles: AssetsBundle[];
}
`,Nt=`export declare function checkDataUrl(url: string, mimes: string | string[]): boolean;
`,zt=`export declare function checkExtension(url: string, extension: string | string[]): boolean;
`,Xt=`export declare const convertToList: <T>(input: string | T | (string | T)[], transform?: (input: string) => T, forceTransform?: boolean) => T[];
`,Kt=`/**
 * Copies the search params from one url to another
 * @param targetUrl - the url to copy the search params to
 * @param sourceUrl - the url container the search params we want to copy
 * @returns the url with the search params copied
 */
export declare const copySearchParams: (targetUrl: string, sourceUrl: string) => string;
`,qt=`/**
 * Creates a list of all possible combinations of the given strings.
 * @example
 * const out2 = createStringVariations('name is {chicken,wolf,sheep}');
 * console.log(out2); // [ 'name is chicken', 'name is wolf', 'name is sheep' ]
 * @param string - The string to process
 */
export declare function createStringVariations(string: string): string[];
`,Yt=`/**
 * Checks if the given value is an array.
 * @param item - The item to test
 */
export declare const isSingleItem: (item: unknown) => boolean;
`,Jt=`import type { HslaColor, HslColor, HsvaColor, HsvColor, RgbaColor, RgbColor } from '@pixi/colord';
/**
 * Pixi supports multiple color formats, including CSS color strings, hex, numbers, and arrays.
 *
 * When providing values for any of the color properties, you can use any of the {@link color.ColorSource} formats.
 * \`\`\`typescript
 * import { Color } from 'pixi.js';
 *
 * // All of these are valid:
 * sprite.tint = 'red';
 * sprite.tint = 0xff0000;
 * sprite.tint = '#ff0000';
 * sprite.tint = new Color('red');
 *
 * // Same for graphics fill/stroke colors and other  color values:
 * graphics.fill({ color: 'red' });
 * graphics.fill({ color: 0xff0000 });
 * graphics.stroke({ color: '#ff0000' });
 * graphics.stroke({ color: new Color('red')};
 * \`\`\`
 * @namespace color
 */
/**
 * RGBA color array.
 *
 * \`[number, number, number, number]\`
 * @memberof color
 */
export type RgbaArray = [number, number, number, number];
/**
 * Valid formats to use when defining any color properties, also valid for the {@link color.Color} constructor.
 *
 * These types are extended from [colord](https://www.npmjs.com/package/colord) with some PixiJS-specific extensions.
 *
 * Possible value types are:
 * - [Color names](https://www.w3.org/TR/css-color-4/#named-colors):
 *   \`'red'\`, \`'green'\`, \`'blue'\`, \`'white'\`, etc.
 * - RGB hex integers (\`0xRRGGBB\`):
 *   \`0xff0000\`, \`0x00ff00\`, \`0x0000ff\`, etc.
 * - [RGB(A) hex strings](https://www.w3.org/TR/css-color-4/#hex-notation):
 *   - 6 digits (\`RRGGBB\`): \`'ff0000'\`, \`'#00ff00'\`, \`'0x0000ff'\`, etc.
 *   - 3 digits (\`RGB\`): \`'f00'\`, \`'#0f0'\`, \`'0x00f'\`, etc.
 *   - 8 digits (\`RRGGBBAA\`): \`'ff000080'\`, \`'#00ff0080'\`, \`'0x0000ff80'\`, etc.
 *   - 4 digits (\`RGBA\`): \`'f008'\`, \`'#0f08'\`, \`'0x00f8'\`, etc.
 * - RGB(A) objects:
 *   \`{ r: 255, g: 0, b: 0 }\`, \`{ r: 255, g: 0, b: 0, a: 0.5 }\`, etc.
 * - [RGB(A) strings](https://www.w3.org/TR/css-color-4/#rgb-functions):
 *   \`'rgb(255, 0, 0)'\`, \`'rgb(100% 0% 0%)'\`, \`'rgba(255, 0, 0, 0.5)'\`, \`'rgba(100% 0% 0% / 50%)'\`, etc.
 * - RGB(A) arrays:
 *   \`[1, 0, 0]\`, \`[1, 0, 0, 0.5]\`, etc.
 * - RGB(A) Float32Array:
 *   \`new Float32Array([1, 0, 0])\`, \`new Float32Array([1, 0, 0, 0.5])\`, etc.
 * - RGB(A) Uint8Array:
 *   \`new Uint8Array([255, 0, 0])\`, \`new Uint8Array([255, 0, 0, 128])\`, etc.
 * - RGB(A) Uint8ClampedArray:
 *   \`new Uint8ClampedArray([255, 0, 0])\`, \`new Uint8ClampedArray([255, 0, 0, 128])\`, etc.
 * - HSL(A) objects:
 *   \`{ h: 0, s: 100, l: 50 }\`, \`{ h: 0, s: 100, l: 50, a: 0.5 }\`, etc.
 * - [HSL(A) strings](https://www.w3.org/TR/css-color-4/#the-hsl-notation):
 *   \`'hsl(0, 100%, 50%)'\`, \`'hsl(0deg 100% 50%)'\`, \`'hsla(0, 100%, 50%, 0.5)'\`, \`'hsla(0deg 100% 50% / 50%)'\`, etc.
 * - HSV(A) objects:
 *   \`{ h: 0, s: 100, v: 100 }\`, \`{ h: 0, s: 100, v: 100, a: 0.5 }\`, etc.
 * - {@link color.Color} objects.
 * @since 7.2.0
 * @memberof color
 */
export type ColorSource = string | number | number[] | Float32Array | Uint8Array | Uint8ClampedArray | HslColor | HslaColor | HsvColor | HsvaColor | RgbColor | RgbaColor | Color | number;
/**
 * Color utility class. Can accept any {@link color.ColorSource} format in its constructor.
 * \`\`\`js
 * import { Color } from 'pixi.js';
 *
 * new Color('red').toArray(); // [1, 0, 0, 1]
 * new Color(0xff0000).toArray(); // [1, 0, 0, 1]
 * new Color('ff0000').toArray(); // [1, 0, 0, 1]
 * new Color('#f00').toArray(); // [1, 0, 0, 1]
 * new Color('0xff0000ff').toArray(); // [1, 0, 0, 1]
 * new Color('#f00f').toArray(); // [1, 0, 0, 1]
 * new Color({ r: 255, g: 0, b: 0, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('rgb(255, 0, 0, 0.5)').toArray(); // [1, 0, 0, 0.5]
 * new Color([1, 1, 1]).toArray(); // [1, 1, 1, 1]
 * new Color([1, 0, 0, 0.5]).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Float32Array([1, 0, 0, 0.5])).toArray(); // [1, 0, 0, 0.5]
 * new Color(new Uint8Array([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color(new Uint8ClampedArray([255, 0, 0, 255])).toArray(); // [1, 0, 0, 1]
 * new Color({ h: 0, s: 100, l: 50, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * new Color('hsl(0, 100%, 50%, 50%)').toArray(); // [1, 0, 0, 0.5]
 * new Color({ h: 0, s: 100, v: 100, a: 0.5 }).toArray(); // [1, 0, 0, 0.5]
 * \`\`\`
 * @since 7.2.0
 * @memberof color
 */
export declare class Color {
    /**
     * Default Color object for static uses
     * @example
     * import { Color } from 'pixi.js';
     * Color.shared.setValue(0xffffff).toHex(); // '#ffffff'
     */
    static readonly shared: Color;
    /**
     * Temporary Color object for static uses internally.
     * As to not conflict with Color.shared.
     * @ignore
     */
    private static readonly _temp;
    /** Pattern for hex strings */
    private static readonly HEX_PATTERN;
    /** Internal color source, from constructor or set value */
    private _value;
    /** Normalized rgba component, floats from 0-1 */
    private _components;
    /** Cache color as number */
    private _int;
    /** An array of the current Color. Only populated when \`toArray\` functions are called */
    private _arrayRgba;
    private _arrayRgb;
    /**
     * @param {ColorSource} value - Optional value to use, if not provided, white is used.
     */
    constructor(value?: ColorSource);
    /** Get red component (0 - 1) */
    get red(): number;
    /** Get green component (0 - 1) */
    get green(): number;
    /** Get blue component (0 - 1) */
    get blue(): number;
    /** Get alpha component (0 - 1) */
    get alpha(): number;
    /**
     * Set the value, suitable for chaining
     * @param value
     * @see Color.value
     */
    setValue(value: ColorSource): this;
    /**
     * The current color source.
     *
     * When setting:
     * - Setting to an instance of \`Color\` will copy its color source and components.
     * - Otherwise, \`Color\` will try to normalize the color source and set the components.
     *   If the color source is invalid, an \`Error\` will be thrown and the \`Color\` will left unchanged.
     *
     * Note: The \`null\` in the setter's parameter type is added to match the TypeScript rule: return type of getter
     * must be assignable to its setter's parameter type. Setting \`value\` to \`null\` will throw an \`Error\`.
     *
     * When getting:
     * - A return value of \`null\` means the previous value was overridden (e.g., {@link Color.multiply multiply},
     *   {@link Color.premultiply premultiply} or {@link Color.round round}).
     * - Otherwise, the color source used when setting is returned.
     */
    set value(value: ColorSource | null);
    get value(): Exclude<ColorSource, Color> | null;
    /**
     * Copy a color source internally.
     * @param value - Color source
     */
    private _cloneSource;
    /**
     * Equality check for color sources.
     * @param value1 - First color source
     * @param value2 - Second color source
     * @returns \`true\` if the color sources are equal, \`false\` otherwise.
     */
    private _isSourceEqual;
    /**
     * Convert to a RGBA color object.
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1, a: 1 }
     */
    toRgba(): RgbaColor;
    /**
     * Convert to a RGB color object.
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toRgb(); // returns { r: 1, g: 1, b: 1 }
     */
    toRgb(): RgbColor;
    /** Convert to a CSS-style rgba string: \`rgba(255,255,255,1.0)\`. */
    toRgbaString(): string;
    /**
     * Convert to an [R, G, B] array of clamped uint8 values (0 to 255).
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toUint8RgbArray(); // returns [255, 255, 255]
     * @param {number[]|Uint8Array|Uint8ClampedArray} [out] - Output array
     */
    toUint8RgbArray(): number[];
    toUint8RgbArray<T extends number[] | Uint8Array | Uint8ClampedArray>(out: T): T;
    /**
     * Convert to an [R, G, B, A] array of normalized floats (numbers from 0.0 to 1.0).
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toArray(); // returns [1, 1, 1, 1]
     * @param {number[]|Float32Array} [out] - Output array
     */
    toArray(): number[];
    toArray<T extends number[] | Float32Array>(out: T): T;
    /**
     * Convert to an [R, G, B] array of normalized floats (numbers from 0.0 to 1.0).
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toRgbArray(); // returns [1, 1, 1]
     * @param {number[]|Float32Array} [out] - Output array
     */
    toRgbArray(): number[];
    toRgbArray<T extends number[] | Float32Array>(out: T): T;
    /**
     * Convert to a hexadecimal number.
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toNumber(); // returns 16777215
     */
    toNumber(): number;
    /**
     * Convert to a BGR number
     * @example
     * import { Color } from 'pixi.js';
     * new Color(0xffcc99).toBgrNumber(); // returns 0x99ccff
     */
    toBgrNumber(): number;
    /**
     * Convert to a hexadecimal number in little endian format (e.g., BBGGRR).
     * @example
     * import { Color } from 'pixi.js';
     * new Color(0xffcc99).toLittleEndianNumber(); // returns 0x99ccff
     * @returns {number} - The color as a number in little endian format.
     */
    toLittleEndianNumber(): number;
    /**
     * Multiply with another color. This action is destructive, and will
     * override the previous \`value\` property to be \`null\`.
     * @param {ColorSource} value - The color to multiply by.
     */
    multiply(value: ColorSource): this;
    /**
     * Converts color to a premultiplied alpha format. This action is destructive, and will
     * override the previous \`value\` property to be \`null\`.
     * @param alpha - The alpha to multiply by.
     * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
     * @returns {Color} - Itself.
     */
    premultiply(alpha: number, applyToRGB?: boolean): this;
    /**
     * Premultiplies alpha with current color.
     * @param {number} alpha - The alpha to multiply by.
     * @param {boolean} [applyToRGB=true] - Whether to premultiply RGB channels.
     * @returns {number} tint multiplied by alpha
     */
    toPremultiplied(alpha: number, applyToRGB?: boolean): number;
    /**
     * Convert to a hexadecimal string.
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toHex(); // returns "#ffffff"
     */
    toHex(): string;
    /**
     * Convert to a hexadecimal string with alpha.
     * @example
     * import { Color } from 'pixi.js';
     * new Color('white').toHexa(); // returns "#ffffffff"
     */
    toHexa(): string;
    /**
     * Set alpha, suitable for chaining.
     * @param alpha
     */
    setAlpha(alpha: number): this;
    /**
     * Normalize the input value into rgba
     * @param value - Input value
     */
    private _normalize;
    /** Refresh the internal color rgb number */
    private _refreshInt;
    /**
     * Clamps values to a range. Will override original values
     * @param value - Value(s) to clamp
     * @param min - Minimum value
     * @param max - Maximum value
     */
    private _clamp;
    /**
     * Check if the value is a color-like object
     * @param value - Value to check
     * @returns True if the value is a color-like object
     * @static
     * @example
     * import { Color } from 'pixi.js';
     * Color.isColorLike('white'); // returns true
     * Color.isColorLike(0xffffff); // returns true
     * Color.isColorLike([1, 1, 1]); // returns true
     */
    static isColorLike(value: unknown): value is ColorSource;
}
`,$t=`export * from './Color';
`,Qt=`import type { FormatDetectionParser } from '../../assets/detections/types';
export declare const detectBasis: FormatDetectionParser;
`,Zt=`export {};
`,er=`import { LoaderParserPriority } from '../../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../../extensions/Extensions';
import type { Loader } from '../../assets/loader/Loader';
import type { ResolvedAsset } from '../../assets/types';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
/** Loads KTX textures! */
export declare const loadBasis: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
        name: string;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
    unload(texture: Texture | Texture[]): void;
};
`,nr=`export type BASISModuleCreator = (config: {
    locateFile: (file: string) => string;
}) => {
    then: (result: (libktx: BASISModule) => void) => void;
};
export type BasisTextureConstructor = new (data: Uint8Array) => BasisTexture;
export interface BASISModule {
    initializeBasis(): void;
    BasisFile: BasisTextureConstructor;
}
export interface BasisTexture {
    getNumImages(): number;
    getNumLevels(imageIndex: number): number;
    startTranscoding(): boolean;
    getImageWidth(imageIndex: number, levelIndex: number): number;
    getImageHeight(imageIndex: number, levelIndex: number): number;
    getImageTranscodedSizeInBytes(imageIndex: number, levelIndex: number, format: number): number;
    transcodeImage(buffer: Uint8Array, imageIndex: number, levelIndex: number, format: number, unused: number, getAlphaForOpaqueFormats: number): boolean;
}
`,tr=`import type { BasisTexture } from '../types';
export declare function createLevelBuffers(basisTexture: BasisTexture, basisTranscoderFormat: number): Uint8Array[];
`,rr=`export declare function gpuFormatToBasisTranscoderFormat(transcoderFormat: string): number;
`,or=`export declare const basisTranscoderUrls: {
    jsUrl: string;
    wasmUrl: string;
};
export declare function setBasisTranscoderPath(config: Partial<typeof basisTranscoderUrls>): void;
`,ar=`export {};
`,ir=`import type { TEXTURE_FORMATS } from '../../../rendering/renderers/shared/texture/const';
import type { TextureSourceOptions } from '../../../rendering/renderers/shared/texture/sources/TextureSource';
export declare function loadBasisOnWorker(url: string, supportedTextures: TEXTURE_FORMATS[]): Promise<TextureSourceOptions>;
`,sr=`import type { TEXTURE_FORMATS } from '../../rendering/renderers/shared/texture/const';
/**
 * @see https://docs.microsoft.com/en-us/windows/win32/api/dxgiformat/ne-dxgiformat-dxgi_format
 * This is way over-blown for us! Lend us a hand, and remove the ones that aren't used (but set the remaining
 * ones to their correct value)
 * @ignore
 */
export declare enum DXGI_FORMAT {
    DXGI_FORMAT_UNKNOWN = 0,
    DXGI_FORMAT_R32G32B32A32_TYPELESS = 1,
    DXGI_FORMAT_R32G32B32A32_FLOAT = 2,
    DXGI_FORMAT_R32G32B32A32_UINT = 3,
    DXGI_FORMAT_R32G32B32A32_SINT = 4,
    DXGI_FORMAT_R32G32B32_TYPELESS = 5,
    DXGI_FORMAT_R32G32B32_FLOAT = 6,
    DXGI_FORMAT_R32G32B32_UINT = 7,
    DXGI_FORMAT_R32G32B32_SINT = 8,
    DXGI_FORMAT_R16G16B16A16_TYPELESS = 9,
    DXGI_FORMAT_R16G16B16A16_FLOAT = 10,
    DXGI_FORMAT_R16G16B16A16_UNORM = 11,
    DXGI_FORMAT_R16G16B16A16_UINT = 12,
    DXGI_FORMAT_R16G16B16A16_SNORM = 13,
    DXGI_FORMAT_R16G16B16A16_SINT = 14,
    DXGI_FORMAT_R32G32_TYPELESS = 15,
    DXGI_FORMAT_R32G32_FLOAT = 16,
    DXGI_FORMAT_R32G32_UINT = 17,
    DXGI_FORMAT_R32G32_SINT = 18,
    DXGI_FORMAT_R32G8X24_TYPELESS = 19,
    DXGI_FORMAT_D32_FLOAT_S8X24_UINT = 20,
    DXGI_FORMAT_R32_FLOAT_X8X24_TYPELESS = 21,
    DXGI_FORMAT_X32_TYPELESS_G8X24_UINT = 22,
    DXGI_FORMAT_R10G10B10A2_TYPELESS = 23,
    DXGI_FORMAT_R10G10B10A2_UNORM = 24,
    DXGI_FORMAT_R10G10B10A2_UINT = 25,
    DXGI_FORMAT_R11G11B10_FLOAT = 26,
    DXGI_FORMAT_R8G8B8A8_TYPELESS = 27,
    DXGI_FORMAT_R8G8B8A8_UNORM = 28,
    DXGI_FORMAT_R8G8B8A8_UNORM_SRGB = 29,
    DXGI_FORMAT_R8G8B8A8_UINT = 30,
    DXGI_FORMAT_R8G8B8A8_SNORM = 31,
    DXGI_FORMAT_R8G8B8A8_SINT = 32,
    DXGI_FORMAT_R16G16_TYPELESS = 33,
    DXGI_FORMAT_R16G16_FLOAT = 34,
    DXGI_FORMAT_R16G16_UNORM = 35,
    DXGI_FORMAT_R16G16_UINT = 36,
    DXGI_FORMAT_R16G16_SNORM = 37,
    DXGI_FORMAT_R16G16_SINT = 38,
    DXGI_FORMAT_R32_TYPELESS = 39,
    DXGI_FORMAT_D32_FLOAT = 40,
    DXGI_FORMAT_R32_FLOAT = 41,
    DXGI_FORMAT_R32_UINT = 42,
    DXGI_FORMAT_R32_SINT = 43,
    DXGI_FORMAT_R24G8_TYPELESS = 44,
    DXGI_FORMAT_D24_UNORM_S8_UINT = 45,
    DXGI_FORMAT_R24_UNORM_X8_TYPELESS = 46,
    DXGI_FORMAT_X24_TYPELESS_G8_UINT = 47,
    DXGI_FORMAT_R8G8_TYPELESS = 48,
    DXGI_FORMAT_R8G8_UNORM = 49,
    DXGI_FORMAT_R8G8_UINT = 50,
    DXGI_FORMAT_R8G8_SNORM = 51,
    DXGI_FORMAT_R8G8_SINT = 52,
    DXGI_FORMAT_R16_TYPELESS = 53,
    DXGI_FORMAT_R16_FLOAT = 54,
    DXGI_FORMAT_D16_UNORM = 55,
    DXGI_FORMAT_R16_UNORM = 56,
    DXGI_FORMAT_R16_UINT = 57,
    DXGI_FORMAT_R16_SNORM = 58,
    DXGI_FORMAT_R16_SINT = 59,
    DXGI_FORMAT_R8_TYPELESS = 60,
    DXGI_FORMAT_R8_UNORM = 61,
    DXGI_FORMAT_R8_UINT = 62,
    DXGI_FORMAT_R8_SNORM = 63,
    DXGI_FORMAT_R8_SINT = 64,
    DXGI_FORMAT_A8_UNORM = 65,
    DXGI_FORMAT_R1_UNORM = 66,
    DXGI_FORMAT_R9G9B9E5_SHAREDEXP = 67,
    DXGI_FORMAT_R8G8_B8G8_UNORM = 68,
    DXGI_FORMAT_G8R8_G8B8_UNORM = 69,
    DXGI_FORMAT_BC1_TYPELESS = 70,
    DXGI_FORMAT_BC1_UNORM = 71,
    DXGI_FORMAT_BC1_UNORM_SRGB = 72,
    DXGI_FORMAT_BC2_TYPELESS = 73,
    DXGI_FORMAT_BC2_UNORM = 74,
    DXGI_FORMAT_BC2_UNORM_SRGB = 75,
    DXGI_FORMAT_BC3_TYPELESS = 76,
    DXGI_FORMAT_BC3_UNORM = 77,
    DXGI_FORMAT_BC3_UNORM_SRGB = 78,
    DXGI_FORMAT_BC4_TYPELESS = 79,
    DXGI_FORMAT_BC4_UNORM = 80,
    DXGI_FORMAT_BC4_SNORM = 81,
    DXGI_FORMAT_BC5_TYPELESS = 82,
    DXGI_FORMAT_BC5_UNORM = 83,
    DXGI_FORMAT_BC5_SNORM = 84,
    DXGI_FORMAT_B5G6R5_UNORM = 85,
    DXGI_FORMAT_B5G5R5A1_UNORM = 86,
    DXGI_FORMAT_B8G8R8A8_UNORM = 87,
    DXGI_FORMAT_B8G8R8X8_UNORM = 88,
    DXGI_FORMAT_R10G10B10_XR_BIAS_A2_UNORM = 89,
    DXGI_FORMAT_B8G8R8A8_TYPELESS = 90,
    DXGI_FORMAT_B8G8R8A8_UNORM_SRGB = 91,
    DXGI_FORMAT_B8G8R8X8_TYPELESS = 92,
    DXGI_FORMAT_B8G8R8X8_UNORM_SRGB = 93,
    DXGI_FORMAT_BC6H_TYPELESS = 94,
    DXGI_FORMAT_BC6H_UF16 = 95,
    DXGI_FORMAT_BC6H_SF16 = 96,
    DXGI_FORMAT_BC7_TYPELESS = 97,
    DXGI_FORMAT_BC7_UNORM = 98,
    DXGI_FORMAT_BC7_UNORM_SRGB = 99,
    DXGI_FORMAT_AYUV = 100,
    DXGI_FORMAT_Y410 = 101,
    DXGI_FORMAT_Y416 = 102,
    DXGI_FORMAT_NV12 = 103,
    DXGI_FORMAT_P010 = 104,
    DXGI_FORMAT_P016 = 105,
    DXGI_FORMAT_420_OPAQUE = 106,
    DXGI_FORMAT_YUY2 = 107,
    DXGI_FORMAT_Y210 = 108,
    DXGI_FORMAT_Y216 = 109,
    DXGI_FORMAT_NV11 = 110,
    DXGI_FORMAT_AI44 = 111,
    DXGI_FORMAT_IA44 = 112,
    DXGI_FORMAT_P8 = 113,
    DXGI_FORMAT_A8P8 = 114,
    DXGI_FORMAT_B4G4R4A4_UNORM = 115,
    DXGI_FORMAT_P208 = 116,
    DXGI_FORMAT_V208 = 117,
    DXGI_FORMAT_V408 = 118,
    DXGI_FORMAT_SAMPLER_FEEDBACK_MIN_MIP_OPAQUE = 119,
    DXGI_FORMAT_SAMPLER_FEEDBACK_MIP_REGION_USED_OPAQUE = 120,
    DXGI_FORMAT_FORCE_UINT = 121
}
/**
 * Possible values of the field {@link DDS_DX10_FIELDS.RESOURCE_DIMENSION}
 * @ignore
 */
export declare enum D3D10_RESOURCE_DIMENSION {
    DDS_DIMENSION_TEXTURE1D = 2,
    DDS_DIMENSION_TEXTURE2D = 3,
    DDS_DIMENSION_TEXTURE3D = 6
}
export declare enum D3DFMT {
    UNKNOWN = 0,
    R8G8B8 = 20,
    A8R8G8B8 = 21,
    X8R8G8B8 = 22,
    R5G6B5 = 23,
    X1R5G5B5 = 24,
    A1R5G5B5 = 25,
    A4R4G4B4 = 26,
    R3G3B2 = 27,
    A8 = 28,
    A8R3G3B2 = 29,
    X4R4G4B4 = 30,
    A2B10G10R10 = 31,
    A8B8G8R8 = 32,
    X8B8G8R8 = 33,
    G16R16 = 34,
    A2R10G10B10 = 35,
    A16B16G16R16 = 36,
    A8P8 = 40,
    P8 = 41,
    L8 = 50,
    A8L8 = 51,
    A4L4 = 52,
    V8U8 = 60,
    L6V5U5 = 61,
    X8L8V8U8 = 62,
    Q8W8V8U8 = 63,
    V16U16 = 64,
    A2W10V10U10 = 67,
    Q16W16V16U16 = 110,
    R16F = 111,
    G16R16F = 112,
    A16B16G16R16F = 113,
    R32F = 114,
    G32R32F = 115,
    A32B32G32R32F = 116,
    UYVY,
    R8G8_B8G8,
    YUY2,
    D3DFMT_G8R8_G8B8,
    DXT1,
    DXT2,
    DXT3,
    DXT4,
    DXT5,
    ATI1,
    AT1N,
    ATI2,
    AT2N,
    BC4U,
    BC4S,
    BC5U,
    BC5S,
    DX10
}
/**
 * Maps \`FOURCC_*\` formats to {@link TEXTURE_FORMATS}.
 * https://en.wikipedia.org/wiki/S3_Texture_Compression#S3TC_format_comparison
 * https://github.com/microsoft/DirectXTex/blob/main/DDSTextureLoader/DDSTextureLoader11.cpp
 * @ignore
 */
export declare const FOURCC_TO_TEXTURE_FORMAT: {
    [id: number]: TEXTURE_FORMATS;
};
/**
 * Maps {@link DXGI_FORMAT} to {@link TEXTURE_FORMATS}
 * @ignore
 */
export declare const DXGI_TO_TEXTURE_FORMAT: {
    [id: number]: TEXTURE_FORMATS;
};
export declare const DDS: {
    MAGIC_VALUE: number;
    MAGIC_SIZE: number;
    HEADER_SIZE: number;
    HEADER_DX10_SIZE: number;
    PIXEL_FORMAT_FLAGS: {
        ALPHAPIXELS: number;
        ALPHA: number;
        FOURCC: number;
        RGB: number;
        RGBA: number;
        YUV: number;
        LUMINANCE: number;
        LUMINANCEA: number;
    };
    RESOURCE_MISC_TEXTURECUBE: number;
    HEADER_FIELDS: {
        MAGIC: number;
        SIZE: number;
        FLAGS: number;
        HEIGHT: number;
        WIDTH: number;
        MIPMAP_COUNT: number;
        PIXEL_FORMAT: number;
        PF_FLAGS: number;
        FOURCC: number;
        RGB_BITCOUNT: number;
        R_BIT_MASK: number;
        G_BIT_MASK: number;
        B_BIT_MASK: number;
        A_BIT_MASK: number;
    };
    HEADER_DX10_FIELDS: {
        DXGI_FORMAT: number;
        RESOURCE_DIMENSION: number;
        MISC_FLAG: number;
        ARRAY_SIZE: number;
        MISC_FLAGS2: number;
    };
    DXGI_FORMAT: typeof DXGI_FORMAT;
    D3D10_RESOURCE_DIMENSION: typeof D3D10_RESOURCE_DIMENSION;
    D3DFMT: typeof D3DFMT;
};
export declare const TEXTURE_FORMAT_BLOCK_SIZE: Record<string, number>;
`,lr=`export {};
`,dr=`import { LoaderParserPriority } from '../../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../../extensions/Extensions';
import type { Loader } from '../../assets/loader/Loader';
import type { ResolvedAsset } from '../../assets/types';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
/** Loads KTX textures! */
export declare const loadDDS: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
        name: string;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
    unload(texture: Texture | Texture[]): void;
};
`,pr=`import type { TEXTURE_FORMATS } from '../../rendering/renderers/shared/texture/const';
import type { TextureSourceOptions } from '../../rendering/renderers/shared/texture/sources/TextureSource';
export declare function parseDDS(arrayBuffer: ArrayBuffer, supportedFormats: TEXTURE_FORMATS[]): TextureSourceOptions<Uint8Array[]>;
`,cr=`export * from './basis/detectBasis';
export * from './basis/loadBasis';
export * from './basis/types';
export * from './basis/utils/createLevelBuffers';
export * from './basis/utils/gpuFormatToBasisTranscoderFormat';
export * from './basis/utils/setBasisTranscoderPath';
export * from './basis/worker/loadBasisOnWorker';
export * from './dds/const';
export * from './dds/loadDDS';
export * from './dds/parseDDS';
export * from './ktx/loadKTX';
export * from './ktx/parseKTX';
export * from './ktx2/const';
export * from './ktx2/loadKTX2';
export * from './ktx2/types';
export * from './ktx2/utils/convertFormatIfRequired';
export * from './ktx2/utils/createLevelBuffersFromKTX';
export * from './ktx2/utils/getTextureFormatFromKTXTexture';
export * from './ktx2/utils/glFormatToGPUFormat';
export * from './ktx2/utils/gpuFormatToKTXBasisTranscoderFormat';
export * from './ktx2/utils/setKTXTranscoderPath';
export * from './ktx2/utils/vkFormatToGPUFormat';
export * from './ktx2/worker/loadKTX2onWorker';
export * from './shared/detectCompressed';
export * from './shared/resolveCompressedTextureUrl';
`,ur=`export {};
`,mr=`import { LoaderParserPriority } from '../../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../../extensions/Extensions';
import type { Loader } from '../../assets/loader/Loader';
import type { ResolvedAsset } from '../../assets/types';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
/** Loads KTX textures! */
export declare const loadKTX: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
        name: string;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
    unload(texture: Texture | Texture[]): void;
};
`,hr=`import type { TEXTURE_FORMATS } from '../../rendering/renderers/shared/texture/const';
import type { TextureSourceOptions } from '../../rendering/renderers/shared/texture/sources/TextureSource';
export declare function parseKTX(arrayBuffer: ArrayBuffer, supportedFormats: TEXTURE_FORMATS[]): TextureSourceOptions<Uint8Array[]>;
`,fr=`import type { TEXTURE_FORMATS } from '../../rendering/renderers/shared/texture/const';
export declare enum GL_INTERNAL_FORMAT {
    RGBA8_SNORM = 36759,
    RGBA = 6408,
    RGBA8UI = 36220,
    SRGB8_ALPHA8 = 35907,
    RGBA8I = 36238,
    RGBA8 = 32856,
    COMPRESSED_RGB_S3TC_DXT1_EXT = 33776,
    COMPRESSED_RGBA_S3TC_DXT1_EXT = 33777,
    COMPRESSED_RGBA_S3TC_DXT3_EXT = 33778,
    COMPRESSED_RGBA_S3TC_DXT5_EXT = 33779,
    COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT = 35917,
    COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT = 35918,
    COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT = 35919,
    COMPRESSED_SRGB_S3TC_DXT1_EXT = 35916,
    COMPRESSED_RED_RGTC1_EXT = 36283,
    COMPRESSED_SIGNED_RED_RGTC1_EXT = 36284,
    COMPRESSED_RED_GREEN_RGTC2_EXT = 36285,
    COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT = 36286,
    COMPRESSED_R11_EAC = 37488,
    COMPRESSED_SIGNED_R11_EAC = 37489,
    COMPRESSED_RG11_EAC = 37490,
    COMPRESSED_SIGNED_RG11_EAC = 37491,
    COMPRESSED_RGB8_ETC2 = 37492,
    COMPRESSED_RGBA8_ETC2_EAC = 37496,
    COMPRESSED_SRGB8_ETC2 = 37493,
    COMPRESSED_SRGB8_ALPHA8_ETC2_EAC = 37497,
    COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2 = 37494,
    COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2 = 37495,
    COMPRESSED_RGBA_ASTC_4x4_KHR = 37808,
    COMPRESSED_RGBA_ASTC_5x4_KHR = 37809,
    COMPRESSED_RGBA_ASTC_5x5_KHR = 37810,
    COMPRESSED_RGBA_ASTC_6x5_KHR = 37811,
    COMPRESSED_RGBA_ASTC_6x6_KHR = 37812,
    COMPRESSED_RGBA_ASTC_8x5_KHR = 37813,
    COMPRESSED_RGBA_ASTC_8x6_KHR = 37814,
    COMPRESSED_RGBA_ASTC_8x8_KHR = 37815,
    COMPRESSED_RGBA_ASTC_10x5_KHR = 37816,
    COMPRESSED_RGBA_ASTC_10x6_KHR = 37817,
    COMPRESSED_RGBA_ASTC_10x8_KHR = 37818,
    COMPRESSED_RGBA_ASTC_10x10_KHR = 37819,
    COMPRESSED_RGBA_ASTC_12x10_KHR = 37820,
    COMPRESSED_RGBA_ASTC_12x12_KHR = 37821,
    COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR = 37840,
    COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR = 37841,
    COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR = 37842,
    COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR = 37843,
    COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR = 37844,
    COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR = 37845,
    COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR = 37846,
    COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR = 37847,
    COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR = 37848,
    COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR = 37849,
    COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR = 37850,
    COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR = 37851,
    COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR = 37852,
    COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR = 37853,
    COMPRESSED_RGBA_BPTC_UNORM_EXT = 36492,
    COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT = 36493,
    COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT = 36494,
    COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT = 36495
}
export declare const KTX: {
    FILE_HEADER_SIZE: number;
    FILE_IDENTIFIER: number[];
    FORMATS_TO_COMPONENTS: {
        [id: number]: number;
    };
    INTERNAL_FORMAT_TO_BYTES_PER_PIXEL: {
        [id: number]: number;
    };
    INTERNAL_FORMAT_TO_TEXTURE_FORMATS: {
        [id: number]: TEXTURE_FORMATS;
    };
    FIELDS: {
        FILE_IDENTIFIER: number;
        ENDIANNESS: number;
        GL_TYPE: number;
        GL_TYPE_SIZE: number;
        GL_FORMAT: number;
        GL_INTERNAL_FORMAT: number;
        GL_BASE_INTERNAL_FORMAT: number;
        PIXEL_WIDTH: number;
        PIXEL_HEIGHT: number;
        PIXEL_DEPTH: number;
        NUMBER_OF_ARRAY_ELEMENTS: number;
        NUMBER_OF_FACES: number;
        NUMBER_OF_MIPMAP_LEVELS: number;
        BYTES_OF_KEY_VALUE_DATA: number;
    };
    TYPES_TO_BYTES_PER_COMPONENT: {
        [id: number]: number;
    };
    TYPES_TO_BYTES_PER_PIXEL: {
        [id: number]: number;
    };
    ENDIANNESS: number;
};
`,br=`export {};
`,gr=`import { LoaderParserPriority } from '../../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../../extensions/Extensions';
import type { Loader } from '../../assets/loader/Loader';
import type { ResolvedAsset } from '../../assets/types';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
/** Loads KTX2 textures! */
export declare const loadKTX2: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
        name: string;
    };
    name: string;
    test(url: string): boolean;
    load<T>(url: string, _asset: ResolvedAsset, loader: Loader): Promise<Texture | Texture[]>;
    unload(texture: Texture | Texture[]): Promise<void>;
};
`,yr=`import type { TEXTURE_FORMATS } from '../../rendering/renderers/shared/texture/const';
export type LIBKTXModuleCreator = (config: {
    locateFile: (file: string) => string;
}) => {
    then: (result: (libktx: LIBKTXModule) => void) => void;
};
export interface KTXTexture {
    getImageData(level: number, layer: number, face: number): Uint8Array;
    glInternalformat: number;
    vkFormat: number;
    classId: number;
    numLevels: number;
    baseHeight: number;
    baseWidth: number;
    transcodeBasis(transcodeFormat: any, arg1: number): unknown;
    needsTranscoding: boolean;
}
export interface LIBKTXModule {
    ErrorCode: any;
    TranscodeTarget: any;
    ktxTexture: new (data: Uint8Array) => KTXTexture;
}
export type COMPRESSED_TEXTURE_FORMATS = TEXTURE_FORMATS | 'rgb8unorm' | 'rgb8unorm-srgb';
`,xr=`import type { TextureSourceOptions } from '../../../rendering/renderers/shared/texture/sources/TextureSource';
export declare function convertFormatIfRequired(textureOptions: TextureSourceOptions): void;
`,vr=`import type { KTXTexture } from '../types';
export declare function createLevelBuffersFromKTX(ktxTexture: KTXTexture): Uint8Array[];
`,Tr=`import type { COMPRESSED_TEXTURE_FORMATS, KTXTexture } from '../types';
export declare function getTextureFormatFromKTXTexture(ktxTexture: KTXTexture): COMPRESSED_TEXTURE_FORMATS;
`,Sr=`import type { COMPRESSED_TEXTURE_FORMATS } from '../types';
export declare function glFormatToGPUFormat(glInternalFormat: number): COMPRESSED_TEXTURE_FORMATS;
`,wr=`export declare function gpuFormatToKTXBasisTranscoderFormat(transcoderFormat: string): string;
`,_r=`export declare const ktxTranscoderUrls: {
    jsUrl: string;
    wasmUrl: string;
};
export declare function setKTXTranscoderPath(config: Partial<typeof ktxTranscoderUrls>): void;
`,Er=`import type { COMPRESSED_TEXTURE_FORMATS } from '../types';
export declare function vkFormatToGPUFormat(vkFormat: number): COMPRESSED_TEXTURE_FORMATS;
`,Pr=`export {};
`,Ar=`import type { TEXTURE_FORMATS } from '../../../rendering/renderers/shared/texture/const';
import type { TextureSourceOptions } from '../../../rendering/renderers/shared/texture/sources/TextureSource';
export declare function loadKTX2onWorker(url: string, supportedTextures: TEXTURE_FORMATS[]): Promise<TextureSourceOptions>;
`,Cr=`import type { FormatDetectionParser } from '../../assets/detections/types';
export declare const detectCompressed: FormatDetectionParser;
`,Rr=`import { ExtensionType } from '../../extensions/Extensions';
export declare const validFormats: string[];
export declare const resolveCompressedTextureUrl: {
    extension: ExtensionType.ResolveParser;
    test: (value: string) => boolean;
    parse: (value: string) => {
        resolution: number;
        format: string;
        src: string;
    };
};
`,Gr=`import type { Container } from '../scene/container/Container';
type RectangleLike = {
    x: number;
    y: number;
    width: number;
    height: number;
};
/**
 * The Culler class is responsible for managing and culling containers.
 *
 *
 * Culled containers will not be rendered, and their children will not be processed. This can be useful for
 * performance optimization when dealing with large scenes.
 * @example
 * import { Culler, Container } from 'pixi.js';
 *
 * const culler = new Culler();
 * const stage = new Container();
 *
 * ... set up stage ...
 *
 * culler.cull(stage, { x: 0, y: 0, width: 800, height: 600 });
 * renderer.render(stage);
 * @memberof scene
 */
export declare class Culler {
    /**
     * Culls the children of a specific container based on the given view. This will also cull items that are not
     * being explicitly managed by the culler.
     * @param container - The container to cull.
     * @param view - The view rectangle.
     * @param skipUpdateTransform - Whether to skip updating the transform.
     */
    cull(container: Container, view: RectangleLike, skipUpdateTransform?: boolean): void;
    private _cullRecursive;
    /** A shared instance of the Culler class. */
    static shared: Culler;
}
export {};
`,Mr=`import type { ExtensionMetadata } from '../extensions/Extensions';
import type { Renderer } from '../rendering/renderers/types';
import type { Container } from '../scene/container/Container';
/**
 * An {@link app.Application} plugin that will automatically cull your stage using the renderers screen size.
 * @example
 * import { extensions, CullerPlugin } from 'pixi.js';
 *
 * extensions.add(CullerPlugin);
 * @memberof app
 * @see {@link scene.Culler}
 */
export declare class CullerPlugin {
    /** @ignore */
    static extension: ExtensionMetadata;
    static renderer: Renderer;
    static stage: Container;
    static render: () => void;
    private static _renderRef;
    static init(): void;
    static destroy(): void;
}
`,kr=`declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface Container extends Partial<import('./cullingMixin').CullingMixinConstructor> {}

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ContainerOptions extends Partial<import('./cullingMixin').CullingMixinConstructor> {}
    }
}

export {};
`,Fr=`import type { Rectangle } from '../maths/shapes/Rectangle';
export interface CullingMixinConstructor {
    /**
     * If set, this shape is used for culling instead of the bounds of this object.
     * It can improve the culling performance of objects with many children.
     * The culling area is defined in local space.
     * @memberof scene.Container#
     */
    cullArea: Rectangle;
    /**
     * Should this object be rendered if the bounds of this object are out of frame?
     *
     * Culling has no effect on whether updateTransform is called.
     * @default false
     * @memberof scene.Container#
     */
    cullable: boolean;
    /**
     * Determines if the children to the container can be culled
     * Setting this to false allows PixiJS to bypass a recursive culling function
     * Which can help to optimize very complex scenes
     * @default true
     * @memberof scene.Container#
     */
    cullableChildren: boolean;
}
export declare const cullingMixin: CullingMixinConstructor;
`,Or=`export * from './Culler';
export * from './CullerPlugin';
export * from './cullingMixin';
`,Ir=`import { Point } from '../maths/point/Point';
import { ViewContainer, type ViewContainerOptions } from '../scene/view/ViewContainer';
import type { PointData } from '../maths/point/PointData';
/**
 * Options for the {@link scene.DOMContainer} constructor.
 * @memberof scene
 */
export interface DOMContainerOptions extends ViewContainerOptions {
    /** The DOM element to use for the container. */
    element?: HTMLElement;
    /** The anchor point of the container. */
    anchor?: PointData | number;
}
/**
 * The DOMContainer object is used to render DOM elements within the PixiJS scene graph.
 * It allows you to integrate HTML elements into your PixiJS application.
 *
 * DOMContainer is especially useful for rendering standard DOM elements
 * that handle user input, such as \`<input>\` or \`<textarea>\`.
 * This is often simpler and more flexible than trying to implement text input
 * directly in PixiJS. For instance, if you need text fields or text areas,
 * you can embed them through this container for native browser text handling.
 *
 * --------- EXPERIMENTAL ---------
 *
 * This is a new API, things may change and it may not work as expected.
 * We want to hear your feedback as we go!
 *
 * --------------------------------
 * @example
 * \`\`\`js
 * import { DOMContainer } from 'pixi.js';
 *
 * const element = document.createElement('div');
 * element.innerHTML = 'Hello World!';
 *
 * const domContainer = new DOMContainer({ element });
 * \`\`\`
 * @memberof scene
 * @extends scene.ViewContainer
 */
export declare class DOMContainer extends ViewContainer {
    /** @private */
    readonly renderPipeId: string;
    /** @private */
    batched: boolean;
    /**
     * The anchor point of the container.
     * @private
     */
    readonly _anchor: Point;
    /** The DOM element that this container is using. */
    private _element;
    /**
     * @param options - The options for creating the DOM container.
     */
    constructor(options?: DOMContainerOptions);
    /**
     * The anchor sets the origin point of the container.
     * The default is \`(0,0)\`, this means the container's origin is the top left.
     *
     * Setting the anchor to \`(0.5,0.5)\` means the container's origin is centered.
     * Setting the anchor to \`(1,1)\` would mean the container's origin point will be the bottom right corner.
     *
     * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
     */
    get anchor(): Point;
    set anchor(value: PointData | number);
    set element(value: HTMLElement);
    /** The DOM element that this container is using. */
    get element(): HTMLElement;
    /** @private */
    protected updateBounds(): void;
    /**
     * Destroys this DOM container.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     */
    destroy(options?: boolean): void;
}
`,Lr=`declare global
{
    namespace PixiMixins
    {

        interface RendererSystems
        {
            dom: import('./DOMPipe').DOMPipe;
        }
    }
}

export {};
`,Br=`import { ExtensionType } from '../extensions/Extensions';
import { type DOMContainer } from './DOMContainer';
import type { InstructionSet } from '../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../rendering/renderers/types';
/**
 * The DOMPipe class is responsible for managing and rendering DOM elements within a PixiJS scene.
 * It maps dom elements to the canvas and ensures they are correctly positioned and visible.
 */
export declare class DOMPipe implements RenderPipe<DOMContainer> {
    /**
     * Static property defining the extension type and name for the DOMPipe.
     * This is used to register the DOMPipe with different rendering pipelines.
     */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "dom";
    };
    private _renderer;
    private readonly _destroyRenderableBound;
    /** Array to keep track of attached DOM elements */
    private readonly _attachedDomElements;
    /** The main DOM element that acts as a container for other DOM elements */
    private readonly _domElement;
    /**
     * Constructor for the DOMPipe class.
     * @param renderer - The renderer instance that this DOMPipe will be associated with.
     */
    constructor(renderer: Renderer);
    /**
     * Adds a renderable DOM container to the list of attached elements.
     * @param domContainer - The DOM container to be added.
     * @param _instructionSet - The instruction set (unused).
     */
    addRenderable(domContainer: DOMContainer, _instructionSet: InstructionSet): void;
    /**
     * Updates a renderable DOM container.
     * @param _domContainer - The DOM container to be updated (unused).
     */
    updateRenderable(_domContainer: DOMContainer): void;
    /**
     * Validates a renderable DOM container.
     * @param _domContainer - The DOM container to be validated (unused).
     * @returns Always returns true as validation is not required.
     */
    validateRenderable(_domContainer: DOMContainer): boolean;
    /**
     * Destroys a renderable DOM container, removing it from the list of attached elements.
     * @param domContainer - The DOM container to be destroyed.
     */
    destroyRenderable(domContainer: DOMContainer): void;
    /** Handles the post-rendering process, ensuring DOM elements are correctly positioned and visible. */
    postrender(): void;
    /** Destroys the DOMPipe, removing all attached DOM elements and cleaning up resources. */
    destroy(): void;
}
`,Dr=`export * from './DOMContainer';
export * from './DOMPipe';
`,Ur=`export * from './index';
`,jr=`import { type Adapter } from '../environment/adapter';
/**
 * This is an implementation of the {@link environment.Adapter} interface.
 * It can be used to make Pixi work in the browser.
 * @memberof environment
 * @property {Function} createCanvas - Creates a canvas element of the given size.
 * This canvas is created using the browser's native canvas element.
 * @property {Function} getCanvasRenderingContext2D - Returns a 2D rendering context.
 * @property {Function} getWebGLRenderingContext - Returns a WebGL rendering context.
 * @property {Function} getNavigator - Returns browsers window.navigator
 * @property {Function} getBaseUrl - Returns the current base URL for browser environments this is either
 * the document.baseURI or window.location.href
 * @property {Function} getFontFaceSet - Return the font face set if available
 * @property {Function} fetch - Returns a Response object that has been fetched from the given URL.
 * @property {Function} parseXML - Returns Document object that has been parsed from the given XML string.
 */
export declare const BrowserAdapter: Adapter;
`,Wr=`import '../accessibility/init';
import '../app/init';
import '../events/init';
import '../dom/init';
import '../spritesheet/init';
import '../rendering/init';
import '../scene/graphics/init';
import '../scene/mesh/init';
import '../scene/particle-container/init';
import '../scene/text/init';
import '../scene/text-bitmap/init';
import '../scene/text-html/init';
import '../scene/sprite-tiling/init';
import '../scene/sprite-nine-slice/init';
import '../filters/init';
`,Hr=`import { ExtensionType } from '../extensions/Extensions';
/**
 * Extension for the browser environment.
 * @memberof environment
 */
export declare const browserExt: {
    extension: {
        type: ExtensionType;
        name: string;
        priority: number;
    };
    test: () => boolean;
    load: () => Promise<void>;
};
`,Vr=`export * from './BrowserAdapter';
export * from './browserExt';
`,Nr=`import { type Adapter } from '../environment/adapter';
/**
 * This is an implementation of the {@link environment.Adapter} interface.
 * It can be used to make Pixi work in a Web Worker.
 * @memberof environment
 * @property {Function} createCanvas - Creates a canvas element of the given size using the browser's native OffscreenCanvas.
 * @property {Function} getCanvasRenderingContext2D - Returns a 2D rendering context.
 * @property {Function} getWebGLRenderingContext - Returns a WebGL rendering context.
 * @property {Function} getNavigator - Returns browsers window.navigator
 * @property {Function} getBaseUrl - Returns the current base URL of the worker, which is globalThis.location.href
 * @property {Function} getFontFaceSet - Return the font face set if available
 * @property {Function} fetch - Returns a Response object that has been fetched from the given URL.
 * @property {Function} parseXML - Returns Document object that has been parsed from the given XML string.
 * @memberof environment
 */
export declare const WebWorkerAdapter: Adapter;
`,zr=`export * from './WebWorkerAdapter';
export * from './webworkerExt';
`,Xr=`import '../app/init';
import '../spritesheet/init';
import '../rendering/init';
import '../scene/graphics/init';
import '../scene/mesh/init';
import '../scene/particle-container/init';
import '../scene/text/init';
import '../scene/text-bitmap/init';
import '../scene/text-html/init';
import '../scene/sprite-tiling/init';
import '../scene/sprite-nine-slice/init';
import '../filters/init';
`,Kr=`import { ExtensionType } from '../extensions/Extensions';
/**
 * Extension for the webworker environment.
 * @memberof environment
 */
export declare const webworkerExt: {
    extension: {
        type: ExtensionType;
        name: string;
        priority: number;
    };
    test: () => boolean;
    load: () => Promise<void>;
};
`,qr=`/// <reference types="@webgpu/types" />
import type { ICanvas } from './canvas/ICanvas';
import type { ICanvasRenderingContext2D } from './canvas/ICanvasRenderingContext2D';
/**
 * PixiJS supports multiple environments including browsers, Web Workers, and Node.js.
 * The environment is auto-detected by default using the {@link environment.autoDetectEnvironment} function.
 *
 * The {@link environment.Adapter} interface provides a way to abstract away the differences between
 * these environments. PixiJS uses the {@link environment.BrowserAdapter} by default.
 *
 * However you can manually set the environment using the {@link environment.DOMAdapter} singleton, for example to
 * use Pixi within a WebWorker.
 * \`\`\`js
 * import { DOMAdapter, WebWorkerAdapter } from 'pixi.js';
 *
 * // WebWorkerAdapter is an implementation of the Adapter interface
 * DOMAdapter.set(WebWorkerAdapter);
 *
 * // use the adapter to create a canvas (in this case an OffscreenCanvas)
 * DOMAdapter.get().createCanvas(800, 600);
 * \`\`\`
 * @namespace environment
 */
/**
 * This interface describes all the DOM dependent calls that Pixi makes throughout its codebase.
 * Implementations of this interface can be used to make sure Pixi will work in any environment,
 * such as browser, Web Workers, and Node.js.
 * @memberof environment
 */
export interface Adapter {
    /** Returns a canvas object that can be used to create a webgl context. */
    createCanvas: (width?: number, height?: number) => ICanvas;
    /** Returns a 2D rendering context. */
    getCanvasRenderingContext2D: () => {
        prototype: ICanvasRenderingContext2D;
    };
    /** Returns a WebGL rendering context. */
    getWebGLRenderingContext: () => typeof WebGLRenderingContext;
    /** Returns a partial implementation of the browsers window.navigator */
    getNavigator: () => {
        userAgent: string;
        gpu: GPU | null;
    };
    /** Returns the current base URL For browser environments this is either the document.baseURI or window.location.href */
    getBaseUrl: () => string;
    /** Return the font face set if available */
    getFontFaceSet: () => FontFaceSet | null;
    /** Returns a Response object that has been fetched from the given URL. */
    fetch: (url: RequestInfo, options?: RequestInit) => Promise<Response>;
    /** Returns Document object that has been parsed from the given XML string. */
    parseXML: (xml: string) => Document;
}
/**
 * The DOMAdapter is a singleton that allows PixiJS to perform DOM operations, such as creating a canvas.
 * This allows PixiJS to be used in any environment, such as a web browser, Web Worker, or Node.js.
 * It uses the {@link environment.Adapter} interface to abstract away the differences between these environments
 * and uses the {@link environment.BrowserAdapter} by default.
 *
 * It has two methods: \`get():Adapter\` and \`set(adapter: Adapter)\`.
 *
 * Defaults to the {@link environment.BrowserAdapter}.
 * @example
 * import { DOMAdapter, WebWorkerAdapter } from 'pixi.js';
 *
 * // WebWorkerAdapter is an implementation of the Adapter interface
 * DOMAdapter.set(WebWorkerAdapter);
 *
 * // use the adapter to create a canvas (in this case an OffscreenCanvas)
 * DOMAdapter.get().createCanvas(800, 600);
 * @memberof environment
 */
export declare const DOMAdapter: {
    /**
     * Returns the current adapter.
     * @returns {environment.Adapter} The current adapter.
     */
    get(): Adapter;
    /**
     * Sets the current adapter.
     * @param adapter - The new adapter.
     */
    set(adapter: Adapter): void;
};
`,Yr=`/**
 * Automatically detects the environment and loads the appropriate extensions.
 * @param skip - whether to skip loading the default extensions
 */
export declare function loadEnvironmentExtensions(skip: boolean): Promise<void>;
/**
 * @param add - whether to add the default imports to the bundle
 * @deprecated since 8.1.6. Use \`loadEnvironmentExtensions\` instead
 */
export declare function autoDetectEnvironment(add: boolean): Promise<void>;
`,Jr=`/// <reference types="@webgpu/types" />
import type { ICanvasRenderingContext2D } from './ICanvasRenderingContext2D';
export type ContextIds = '2d' | 'bitmaprenderer' | 'webgl' | 'experimental-webgl' | 'webgl2' | 'experimental-webgl2' | 'webgpu';
export type PredefinedColorSpace = 'srgb' | 'display-p3';
export type RenderingContext = ICanvasRenderingContext2D | ImageBitmapRenderingContext | WebGLRenderingContext | WebGL2RenderingContext;
export interface ICanvasRenderingContext2DSettings {
    alpha?: boolean;
    colorSpace?: PredefinedColorSpace;
    desynchronized?: boolean;
    willReadFrequently?: boolean;
}
export type ContextSettings = ICanvasRenderingContext2DSettings | ImageBitmapRenderingContextSettings | WebGLContextAttributes;
export interface ICanvasParentNode {
    /** Adds a node to the end of the list of children of the parent node. */
    appendChild(element: HTMLElement): void;
    /** Removes a child node from the parent node. */
    removeChild(element: HTMLElement): void;
    removeChild(element: ICanvas): void;
}
export interface ICanvasStyle {
    width?: string;
    height?: string;
    cursor?: string;
    touchAction?: string;
    msTouchAction?: string;
    msContentZooming?: string;
}
export interface ICanvasRect {
    x: number;
    y: number;
    width: number;
    height: number;
}
export interface WebGLContextEventMap {
    'webglcontextlost': WebGLContextEvent;
    'webglcontextrestore': WebGLContextEvent;
}
/**
 * Common interface for HTMLCanvasElement, OffscreenCanvas, and other custom canvas classes.
 * @extends PixiMixins.ICanvas
 * @extends Partial<EventTarget>
 * @memberof environment
 */
export interface ICanvas extends PixiMixins.ICanvas, Partial<EventTarget> {
    /** Width of the canvas. */
    width: number;
    /** Height of the canvas. */
    height: number;
    /**
     * Get rendering context of the canvas.
     * @param {ContextIds} contextId - The identifier of the type of context to create.
     * @param {ContextSettings} options - The options for creating context.
     * @returns {RenderingContext | null} The created context, or null if contextId is not supported.
     */
    getContext(contextId: '2d', options?: ICanvasRenderingContext2DSettings): ICanvasRenderingContext2D | null;
    getContext(contextId: 'bitmaprenderer', options?: ImageBitmapRenderingContextSettings): ImageBitmapRenderingContext | null;
    getContext(contextId: 'webgl' | 'experimental-webgl', options?: WebGLContextAttributes): WebGLRenderingContext | null;
    getContext(contextId: 'webgl2' | 'experimental-webgl2', options?: WebGLContextAttributes): WebGL2RenderingContext | null;
    getContext(contextId: 'webgpu'): GPUCanvasContext | null;
    getContext(contextId: ContextIds, options?: ContextSettings): RenderingContext | null;
    /**
     * Get the content of the canvas as data URL.
     * @param {string} [type] - A string indicating the image format. The default type is \`image/png\`;
     *      that type is also used if the given type isn't supported.
     * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
     *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
     *      A user agent will use its default quality value if this option is not specified, or if the number
     *      is outside the allowed range.
     * @returns {string} A string containing the requested data URL.
     */
    toDataURL?(type?: string, quality?: number): string;
    /**
     * Creates a Blob from the content of the canvas.
     * @param {(blob: Blob | null) => void} callback - A callback function with the resulting \`Blob\` object
     *      as a single argument. \`null\` may be passed if the image cannot be created for any reason.
     * @param {string} [type] - A string indicating the image format. The default type is \`image/png\`;
     *      that type is also used if the given type isn't supported.
     * @param {string} [quality] - A number between 0 and 1 indicating the image quality to be used when
     *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
     *      A user agent will use its default quality value if this option is not specified, or if the number
     *      is outside the allowed range.
     * @returns {void}
     */
    toBlob?(callback: (blob: Blob | null) => void, type?: string, quality?: number): void;
    /**
     * Get the content of the canvas as Blob.
     * @param {object} [options] - The options for creating Blob.
     * @param {string} [options.type] - A string indicating the image format. The default type is \`image/png\`;
     *      that type is also used if the given type isn't supported.
     * @param {string} [options.quality] - A number between 0 and 1 indicating the image quality to be used when
     *      creating images using file formats that support lossy compression (such as \`image/jpeg\` or \`image/webp\`).
     *      A user agent will use its default quality value if this option is not specified, or if the number
     *      is outside the allowed range.
     * @returns {Promise<Blob>} A \`Promise\` returning a Blob object representing the image contained in the canvas.
     */
    convertToBlob?(options?: {
        type?: string;
        quality?: number;
    }): Promise<Blob>;
    /**
     * Adds the listener for the specified event.
     * @method
     * @param {string} type - The type of event to listen for.
     * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
     * @param {boolean | AddEventListenerOptions} options - The options for adding event listener.
     * @returns {void}
     */
    addEventListener?: {
        (type: string, listener: EventListenerOrEventListenerObject, options?: boolean | AddEventListenerOptions): void;
        <K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | AddEventListenerOptions): void;
    };
    /**
     * Removes the listener for the specified event.
     * @method
     * @param {string} type - The type of event to listen for.
     * @param {EventListenerOrEventListenerObject} listener - The callback to invoke when the event is fired.
     * @param {boolean | EventListenerOptions} options - The options for removing event listener.
     * @returns {void}
     */
    removeEventListener?: {
        (type: string, listener: EventListenerOrEventListenerObject, options?: boolean | EventListenerOptions): void;
        <K extends keyof WebGLContextEventMap>(type: K, listener: (this: ICanvas, ev: WebGLContextEventMap[K]) => any, options?: boolean | EventListenerOptions): void;
    };
    /**
     * Dispatches a event.
     * @param {Event} event - The Event object to dispatch. Its Event.target property will be set to the current EventTarget.
     * @returns {boolean} Returns false if event is cancelable, and at least one of the event handlers which received event
     *                    called Event.preventDefault(). Otherwise true.
     */
    dispatchEvent(event: Event): boolean;
    /** Parent node of the canvas. */
    readonly parentNode?: ICanvasParentNode | null;
    /** Style of the canvas. */
    readonly style?: ICanvasStyle;
    /**
     * Get the position and the size of the canvas.
     * @returns The smallest rectangle which contains the entire canvas.
     */
    getBoundingClientRect?(): ICanvasRect;
}
`,$r=`import type { ICanvas } from './ICanvas';
/**
 * Common interface for CanvasRenderingContext2D, OffscreenCanvasRenderingContext2D, and other custom canvas 2D context.
 * @memberof environment
 */
export interface ICanvasRenderingContext2D extends CanvasState, CanvasTransform, CanvasCompositing, CanvasImageSmoothing, CanvasFillStrokeStyles, CanvasShadowStyles, CanvasFilters, CanvasRect, CanvasDrawPath, CanvasText, CanvasDrawImage, CanvasImageData, CanvasPathDrawingStyles, Omit<CanvasTextDrawingStyles, 'letterSpacing'>, CanvasPath {
    /** creates a pattern using the specified image and repetition. */
    createPattern(image: CanvasImageSource | ICanvas, repetition: string | null): CanvasPattern | null;
    /** provides different ways to draw an image onto the canvas */
    drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number): void;
    drawImage(image: CanvasImageSource | ICanvas, dx: number, dy: number, dw: number, dh: number): void;
    drawImage(image: CanvasImageSource | ICanvas, sx: number, sy: number, sw: number, sh: number, dx: number, dy: number, dw: number, dh: number): void;
    /** sets the horizontal spacing behavior between text characters. */
    letterSpacing?: string;
    /** sets the horizontal spacing behavior between text characters. */
    textLetterSpacing?: string;
}
`,Qr=`export * from './adapter';
export * from './autoDetectEnvironment';
export * from './canvas/ICanvas';
export * from './canvas/ICanvasRenderingContext2D';
`,Zr=`import EventEmitter from 'eventemitter3';
import { Point } from '../maths/point/Point';
import { FederatedPointerEvent } from './FederatedPointerEvent';
import { FederatedWheelEvent } from './FederatedWheelEvent';
import type { Container } from '../scene/container/Container';
import type { TrackingData } from './EventBoundaryTypes';
import type { FederatedEvent } from './FederatedEvent';
import type { Cursor, EventMode } from './FederatedEventTarget';
/**
 * Event boundaries are "barriers" where events coming from an upstream scene are modified before downstream propagation.
 *
 * ## Root event boundary
 *
 * The {@link EventSystem#rootBoundary rootBoundary} handles events coming from the &lt;canvas /&gt;.
 * {@link EventSystem} handles the normalization from native {@link https://dom.spec.whatwg.org/#event Events}
 * into {@link FederatedEvent FederatedEvents}. The rootBoundary then does the hit-testing and event dispatch
 * for the upstream normalized event.
 *
 * ## Additional event boundaries
 *
 * An additional event boundary may be desired within an application's scene graph. For example, if a portion of the scene is
 * is flat with many children at one level - a spatial hash maybe needed to accelerate hit testing. In this scenario, the
 * container can be detached from the scene and glued using a custom event boundary.
 *
 * \`\`\`ts
 * import { Container } from 'pixi.js';
 * import { EventBoundary } from 'pixi.js';
 * import { SpatialHash } from 'pixi-spatial-hash';
 *
 * class HashedHitTestingEventBoundary
 * {
 *     private spatialHash: SpatialHash;
 *
 *     constructor(scene: Container, spatialHash: SpatialHash)
 *     {
 *         super(scene);
 *         this.spatialHash = spatialHash;
 *     }
 *
 *     hitTestRecursive(...)
 *     {
 *         // TODO: If target === this.rootTarget, then use spatial hash to get a
 *         // list of possible children that match the given (x,y) coordinates.
 *     }
 * }
 *
 * class VastScene extends Container
 * {
 *     protected eventBoundary: EventBoundary;
 *     protected scene: Container;
 *     protected spatialHash: SpatialHash;
 *
 *     constructor()
 *     {
 *         this.scene = new Container();
 *         this.spatialHash = new SpatialHash();
 *         this.eventBoundary = new HashedHitTestingEventBoundary(this.scene, this.spatialHash);
 *
 *         // Populate this.scene with a ton of children, while updating this.spatialHash
 *     }
 * }
 * \`\`\`
 * @memberof events
 */
export declare class EventBoundary {
    /**
     * The root event-target residing below the event boundary.
     * All events are dispatched trickling down and bubbling up to this \`rootTarget\`.
     */
    rootTarget: Container;
    /**
     * Emits events after they were dispatched into the scene graph.
     *
     * This can be used for global events listening, regardless of the scene graph being used. It should
     * not be used by interactive libraries for normal use.
     *
     * Special events that do not bubble all the way to the root target are not emitted from here,
     * e.g. pointerenter, pointerleave, click.
     */
    dispatch: EventEmitter;
    /** The cursor preferred by the event targets underneath this boundary. */
    cursor: Cursor | string;
    /**
     * This flag would emit \`pointermove\`, \`touchmove\`, and \`mousemove\` events on all Containers.
     *
     * The \`moveOnAll\` semantics mirror those of earlier versions of PixiJS. This was disabled in favor of
     * the Pointer Event API's approach.
     */
    moveOnAll: boolean;
    /** Enables the global move events. \`globalpointermove\`, \`globaltouchmove\`, and \`globalmousemove\` */
    enableGlobalMoveEvents: boolean;
    /**
     * Maps event types to forwarding handles for them.
     *
     * {@link EventBoundary EventBoundary} provides mapping for "pointerdown", "pointermove",
     * "pointerout", "pointerleave", "pointerover", "pointerup", and "pointerupoutside" by default.
     * @see EventBoundary#addEventMapping
     */
    protected mappingTable: Record<string, Array<{
        fn: (e: FederatedEvent) => void;
        priority: number;
    }>>;
    /**
     * State object for mapping methods.
     * @see EventBoundary#trackingData
     */
    protected mappingState: Record<string, any>;
    /**
     * The event pool maps event constructors to an free pool of instances of those specific events.
     * @see EventBoundary#allocateEvent
     * @see EventBoundary#freeEvent
     */
    protected eventPool: Map<typeof FederatedEvent, FederatedEvent[]>;
    /** Every interactive element gathered from the scene. Only used in \`pointermove\` */
    private readonly _allInteractiveElements;
    /** Every element that passed the hit test. Only used in \`pointermove\` */
    private _hitElements;
    /** Whether or not to collect all the interactive elements from the scene. Enabled in \`pointermove\` */
    private _isPointerMoveEvent;
    /**
     * @param rootTarget - The holder of the event boundary.
     */
    constructor(rootTarget?: Container);
    /**
     * Adds an event mapping for the event \`type\` handled by \`fn\`.
     *
     * Event mappings can be used to implement additional or custom events. They take an event
     * coming from the upstream scene (or directly from the {@link EventSystem}) and dispatch new downstream events
     * generally trickling down and bubbling up to {@link EventBoundary.rootTarget this.rootTarget}.
     *
     * To modify the semantics of existing events, the built-in mapping methods of EventBoundary should be overridden
     * instead.
     * @param type - The type of upstream event to map.
     * @param fn - The mapping method. The context of this function must be bound manually, if desired.
     */
    addEventMapping(type: string, fn: (e: FederatedEvent) => void): void;
    /**
     * Dispatches the given event
     * @param e - The event to dispatch.
     * @param type - The type of event to dispatch. Defaults to \`e.type\`.
     */
    dispatchEvent(e: FederatedEvent, type?: string): void;
    /**
     * Maps the given upstream event through the event boundary and propagates it downstream.
     * @param e - The event to map.
     */
    mapEvent(e: FederatedEvent): void;
    /**
     * Finds the Container that is the target of a event at the given coordinates.
     *
     * The passed (x,y) coordinates are in the world space above this event boundary.
     * @param x - The x coordinate of the event.
     * @param y - The y coordinate of the event.
     */
    hitTest(x: number, y: number): Container;
    /**
     * Propagate the passed event from from {@link EventBoundary.rootTarget this.rootTarget} to its
     * target {@code e.target}.
     * @param e - The event to propagate.
     * @param type - The type of event to propagate. Defaults to \`e.type\`.
     */
    propagate(e: FederatedEvent, type?: string): void;
    /**
     * Emits the event {@code e} to all interactive containers. The event is propagated in the bubbling phase always.
     *
     * This is used in the \`globalpointermove\` event.
     * @param e - The emitted event.
     * @param type - The listeners to notify.
     * @param targets - The targets to notify.
     */
    all(e: FederatedEvent, type?: string | string[], targets?: Container<import("../scene/container/Container").ContainerChild>[]): void;
    /**
     * Finds the propagation path from {@link EventBoundary.rootTarget rootTarget} to the passed
     * {@code target}. The last element in the path is {@code target}.
     * @param target - The target to find the propagation path to.
     */
    propagationPath(target: Container): Container[];
    protected hitTestMoveRecursive(currentTarget: Container, eventMode: EventMode, location: Point, testFn: (object: Container, pt: Point) => boolean, pruneFn: (object: Container, pt: Point) => boolean, ignore?: boolean): Container[];
    /**
     * Recursive implementation for {@link EventBoundary.hitTest hitTest}.
     * @param currentTarget - The Container that is to be hit tested.
     * @param eventMode - The event mode for the \`currentTarget\` or one of its parents.
     * @param location - The location that is being tested for overlap.
     * @param testFn - Callback that determines whether the target passes hit testing. This callback
     *  can assume that \`pruneFn\` failed to prune the container.
     * @param pruneFn - Callback that determiness whether the target and all of its children
     *  cannot pass the hit test. It is used as a preliminary optimization to prune entire subtrees
     *  of the scene graph.
     * @returns An array holding the hit testing target and all its ancestors in order. The first element
     *  is the target itself and the last is {@link EventBoundary.rootTarget rootTarget}. This is the opposite
     *  order w.r.t. the propagation path. If no hit testing target is found, null is returned.
     */
    protected hitTestRecursive(currentTarget: Container, eventMode: EventMode, location: Point, testFn: (object: Container, pt: Point) => boolean, pruneFn: (object: Container, pt: Point) => boolean): Container[];
    private _isInteractive;
    private _interactivePrune;
    /**
     * Checks whether the container or any of its children cannot pass the hit test at all.
     *
     * {@link EventBoundary}'s implementation uses the {@link Container.hitArea hitArea}
     * and {@link Container._maskEffect} for pruning.
     * @param container - The container to prune.
     * @param location - The location to test for overlap.
     */
    protected hitPruneFn(container: Container, location: Point): boolean;
    /**
     * Checks whether the container passes hit testing for the given location.
     * @param container - The container to test.
     * @param location - The location to test for overlap.
     * @returns - Whether \`container\` passes hit testing for \`location\`.
     */
    protected hitTestFn(container: Container, location: Point): boolean;
    /**
     * Notify all the listeners to the event's \`currentTarget\`.
     *
     * If the \`currentTarget\` contains the property \`on<type>\`, then it is called here,
     * simulating the behavior from version 6.x and prior.
     * @param e - The event passed to the target.
     * @param type - The type of event to notify. Defaults to \`e.type\`.
     */
    protected notifyTarget(e: FederatedEvent, type?: string): void;
    /**
     * Maps the upstream \`pointerdown\` events to a downstream \`pointerdown\` event.
     *
     * \`touchstart\`, \`rightdown\`, \`mousedown\` events are also dispatched for specific pointer types.
     * @param from - The upstream \`pointerdown\` event.
     */
    protected mapPointerDown(from: FederatedEvent): void;
    /**
     * Maps the upstream \`pointermove\` to downstream \`pointerout\`, \`pointerover\`, and \`pointermove\` events, in that order.
     *
     * The tracking data for the specific pointer has an updated \`overTarget\`. \`mouseout\`, \`mouseover\`,
     * \`mousemove\`, and \`touchmove\` events are fired as well for specific pointer types.
     * @param from - The upstream \`pointermove\` event.
     */
    protected mapPointerMove(from: FederatedEvent): void;
    /**
     * Maps the upstream \`pointerover\` to downstream \`pointerover\` and \`pointerenter\` events, in that order.
     *
     * The tracking data for the specific pointer gets a new \`overTarget\`.
     * @param from - The upstream \`pointerover\` event.
     */
    protected mapPointerOver(from: FederatedEvent): void;
    /**
     * Maps the upstream \`pointerout\` to downstream \`pointerout\`, \`pointerleave\` events, in that order.
     *
     * The tracking data for the specific pointer is cleared of a \`overTarget\`.
     * @param from - The upstream \`pointerout\` event.
     */
    protected mapPointerOut(from: FederatedEvent): void;
    /**
     * Maps the upstream \`pointerup\` event to downstream \`pointerup\`, \`pointerupoutside\`,
     * and \`click\`/\`rightclick\`/\`pointertap\` events, in that order.
     *
     * The \`pointerupoutside\` event bubbles from the original \`pointerdown\` target to the most specific
     * ancestor of the \`pointerdown\` and \`pointerup\` targets, which is also the \`click\` event's target. \`touchend\`,
     * \`rightup\`, \`mouseup\`, \`touchendoutside\`, \`rightupoutside\`, \`mouseupoutside\`, and \`tap\` are fired as well for
     * specific pointer types.
     * @param from - The upstream \`pointerup\` event.
     */
    protected mapPointerUp(from: FederatedEvent): void;
    /**
     * Maps the upstream \`pointerupoutside\` event to a downstream \`pointerupoutside\` event, bubbling from the original
     * \`pointerdown\` target to \`rootTarget\`.
     *
     * (The most specific ancestor of the \`pointerdown\` event and the \`pointerup\` event must the
     * \`{@link EventBoundary}'s root because the \`pointerup\` event occurred outside of the boundary.)
     *
     * \`touchendoutside\`, \`mouseupoutside\`, and \`rightupoutside\` events are fired as well for specific pointer
     * types. The tracking data for the specific pointer is cleared of a \`pressTarget\`.
     * @param from - The upstream \`pointerupoutside\` event.
     */
    protected mapPointerUpOutside(from: FederatedEvent): void;
    /**
     * Maps the upstream \`wheel\` event to a downstream \`wheel\` event.
     * @param from - The upstream \`wheel\` event.
     */
    protected mapWheel(from: FederatedEvent): void;
    /**
     * Finds the most specific event-target in the given propagation path that is still mounted in the scene graph.
     *
     * This is used to find the correct \`pointerup\` and \`pointerout\` target in the case that the original \`pointerdown\`
     * or \`pointerover\` target was unmounted from the scene graph.
     * @param propagationPath - The propagation path was valid in the past.
     * @returns - The most specific event-target still mounted at the same location in the scene graph.
     */
    protected findMountedTarget(propagationPath: Container[]): Container;
    /**
     * Creates an event whose {@code originalEvent} is {@code from}, with an optional \`type\` and \`target\` override.
     *
     * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
     * @param from - The {@code originalEvent} for the returned event.
     * @param [type=from.type] - The type of the returned event.
     * @param target - The target of the returned event.
     */
    protected createPointerEvent(from: FederatedPointerEvent, type?: string, target?: Container): FederatedPointerEvent;
    /**
     * Creates a wheel event whose {@code originalEvent} is {@code from}.
     *
     * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
     * @param from - The upstream wheel event.
     */
    protected createWheelEvent(from: FederatedWheelEvent): FederatedWheelEvent;
    /**
     * Clones the event {@code from}, with an optional {@code type} override.
     *
     * The event is allocated using {@link EventBoundary#allocateEvent this.allocateEvent}.
     * @param from - The event to clone.
     * @param [type=from.type] - The type of the returned event.
     */
    protected clonePointerEvent(from: FederatedPointerEvent, type?: string): FederatedPointerEvent;
    /**
     * Copies wheel {@link FederatedWheelEvent} data from {@code from} into {@code to}.
     *
     * The following properties are copied:
     * + deltaMode
     * + deltaX
     * + deltaY
     * + deltaZ
     * @param from - The event to copy data from.
     * @param to - The event to copy data into.
     */
    protected copyWheelData(from: FederatedWheelEvent, to: FederatedWheelEvent): void;
    /**
     * Copies pointer {@link FederatedPointerEvent} data from {@code from} into {@code to}.
     *
     * The following properties are copied:
     * + pointerId
     * + width
     * + height
     * + isPrimary
     * + pointerType
     * + pressure
     * + tangentialPressure
     * + tiltX
     * + tiltY
     * @param from - The event to copy data from.
     * @param to - The event to copy data into.
     */
    protected copyPointerData(from: FederatedEvent, to: FederatedEvent): void;
    /**
     * Copies mouse {@link FederatedMouseEvent} data from {@code from} to {@code to}.
     *
     * The following properties are copied:
     * + altKey
     * + button
     * + buttons
     * + clientX
     * + clientY
     * + metaKey
     * + movementX
     * + movementY
     * + pageX
     * + pageY
     * + x
     * + y
     * + screen
     * + shiftKey
     * + global
     * @param from - The event to copy data from.
     * @param to - The event to copy data into.
     */
    protected copyMouseData(from: FederatedEvent, to: FederatedEvent): void;
    /**
     * Copies base {@link FederatedEvent} data from {@code from} into {@code to}.
     *
     * The following properties are copied:
     * + isTrusted
     * + srcElement
     * + timeStamp
     * + type
     * @param from - The event to copy data from.
     * @param to - The event to copy data into.
     */
    protected copyData(from: FederatedEvent, to: FederatedEvent): void;
    /**
     * @param id - The pointer ID.
     * @returns The tracking data stored for the given pointer. If no data exists, a blank
     *  state will be created.
     */
    protected trackingData(id: number): TrackingData;
    /**
     * Allocate a specific type of event from {@link EventBoundary#eventPool this.eventPool}.
     *
     * This allocation is constructor-agnostic, as long as it only takes one argument - this event
     * boundary.
     * @param constructor - The event's constructor.
     */
    protected allocateEvent<T extends FederatedEvent>(constructor: {
        new (boundary: EventBoundary): T;
    }): T;
    /**
     * Frees the event and puts it back into the event pool.
     *
     * It is illegal to reuse the event until it is allocated again, using \`this.allocateEvent\`.
     *
     * It is also advised that events not allocated from {@link EventBoundary#allocateEvent this.allocateEvent}
     * not be freed. This is because of the possibility that the same event is freed twice, which can cause
     * it to be allocated twice & result in overwriting.
     * @param event - The event to be freed.
     * @throws Error if the event is managed by another event boundary.
     */
    protected freeEvent<T extends FederatedEvent>(event: T): void;
    /**
     * Similar to {@link EventEmitter.emit}, except it stops if the \`propagationImmediatelyStopped\` flag
     * is set on the event.
     * @param e - The event to call each listener with.
     * @param type - The event key.
     */
    private _notifyListeners;
}
`,eo=`import type { Container } from '../scene/container/Container';
/**
 * The tracking data for each pointer held in the state of an {@link EventBoundary}.
 *
 * \`\`\`ts
 * pressTargetsByButton: {
 *     [id: number]: Container[];
 * };
 * clicksByButton: {
 *     [id: number]: {
 *         clickCount: number;
 *         target: Container;
 *         timeStamp: number;
 *     };
 * };
 * overTargets: Container[];
 * \`\`\`
 * @typedef {object} TrackingData
 * @property {Record.<number, Container>} pressTargetsByButton - The pressed containers'
 *  propagation paths by each button of the pointer.
 * @property {Record.<number, object>} clicksByButton - Holds clicking data for each button of the pointer.
 * @property {Container[]} overTargets - The Container propagation path over which the pointer is hovering.
 * @memberof events
 */
export type TrackingData = {
    pressTargetsByButton: {
        [id: number]: Container[];
    };
    clicksByButton: {
        [id: number]: {
            clickCount: number;
            target: Container;
            timeStamp: number;
        };
    };
    overTargets: Container[];
};
/**
 * Internal storage of an event listener in EventEmitter.
 * @ignore
 */
type EmitterListener = {
    fn(...args: any[]): any;
    context: any;
    once: boolean;
};
/**
 * Internal storage of event listeners in EventEmitter.
 * @ignore
 */
export type EmitterListeners = Record<string, EmitterListener | EmitterListener[]>;
export {};
/**
 * Fired when a mouse button (usually a mouse left-button) is pressed on the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mousedown
 * @param {FederatedPointerEvent} event - The mousedown event.
 */
/**
 * Capture phase equivalent of {@code mousedown}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mousedowncapture
 * @param {FederatedPointerEvent} event - The capture phase mousedown.
 */
/**
 * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
 * on the container. Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightdown
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code rightdown}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightdowncapture
 * @param {FederatedPointerEvent} event - The rightdowncapture event.
 */
/**
 * Fired when a pointer device button (usually a mouse left-button) is released over the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseup
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mouseup}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseupcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device secondary button (usually a mouse right-button) is released
 * over the container. Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightup
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code rightup}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightupcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button (usually a mouse left-button) is pressed and released on
 * the container. Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * A {@code click} event fires after the {@code pointerdown} and {@code pointerup} events, in that
 * order. If the mouse is moved over another Container after the {@code pointerdown} event, the
 * {@code click} event is fired on the most specific common ancestor of the two target Containers.
 *
 * The {@code detail} property of the event is the number of clicks that occurred within a 200ms
 * window of each other upto the current click. For example, it will be {@code 2} for a double click.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#click
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code click}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#clickcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
 * and released on the container. Container's \`eventMode\`
 * property must be set to \`static\` or 'dynamic' to fire event.
 *
 * This event follows the semantics of {@code click}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightclick
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code rightclick}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightclickcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button (usually a mouse left-button) is released outside the
 * container that initially registered a
 * [mousedown]{@link Container#event:mousedown}.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * This event is specific to the Federated Events API. It does not have a capture phase, unlike most of the
 * other events. It only bubbles to the most specific ancestor of the targets of the corresponding {@code pointerdown}
 * and {@code pointerup} events, i.e. the target of the {@code click} event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseupoutside
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mouseupoutside}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseupoutsidecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device secondary button (usually a mouse right-button) is released
 * outside the container that initially registered a
 * [rightdown]{@link Container#event:rightdown}.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightupoutside
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code rightupoutside}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#rightupoutsidecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device (usually a mouse) is moved globally over the scene.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#globalmousemove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device (usually a mouse) is moved while over the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mousemove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mousemove}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mousemovecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device (usually a mouse) is moved onto the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseover
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mouseover}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseovercapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the mouse pointer is moved over a Container and its descendant's hit testing boundaries.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseenter
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mouseenter}
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseentercapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device (usually a mouse) is moved off the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * This may be fired on a Container that was removed from the scene graph immediately after
 * a {@code mouseover} event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseout
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code mouseout}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseoutcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the mouse pointer exits a Container and its descendants.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseleave
 * @param {FederatedPointerEvent} event
 */
/**
 * Capture phase equivalent of {@code mouseleave}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#mouseleavecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button is pressed on the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerdown
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerdown}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerdowncapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button is released over the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerup
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerup}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerupcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the operating system cancels a pointer event.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointercancel
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointercancel}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointercancelcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button is pressed and released on the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointertap
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointertap}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointertapcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device button is released outside the container that initially
 * registered a [pointerdown]{@link Container#event:pointerdown}.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * This event is specific to the Federated Events API. It does not have a capture phase, unlike most of the
 * other events. It only bubbles to the most specific ancestor of the targets of the corresponding {@code pointerdown}
 * and {@code pointerup} events, i.e. the target of the {@code click} event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerupoutside
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerupoutside}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerupoutsidecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device is moved globally over the scene.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#globalpointermove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device is moved while over the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointermove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointermove}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointermovecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device is moved onto the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerover
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerover}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerovercapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the pointer is moved over a Container and its descendant's hit testing boundaries.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerenter
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerenter}
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerentercapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a pointer device is moved off the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerout
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code pointerout}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointeroutcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the pointer leaves the hit testing boundaries of a Container and its descendants.
 *
 * This event notifies only the target and does not bubble.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerleave
 * @param {FederatedPointerEvent} event - The \`pointerleave\` event.
 */
/**
 * Capture phase equivalent of {@code pointerleave}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#pointerleavecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is placed on the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchstart
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code touchstart}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchstartcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is removed from the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchend
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code touchend}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchendcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when the operating system cancels a touch.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchcancel
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code touchcancel}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchcancelcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is placed and removed from the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#tap
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code tap}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#tapcapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is removed outside of the container that initially
 * registered a [touchstart]{@link Container#event:touchstart}.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchendoutside
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code touchendoutside}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchendoutsidecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is moved globally over the scene.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#globaltouchmove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a touch point is moved along the container.
 * Container's \`eventMode\` property must be set to \`static\` or 'dynamic' to fire event.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchmove
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Capture phase equivalent of {@code touchmove}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#touchmovecapture
 * @param {FederatedPointerEvent} event - Event
 */
/**
 * Fired when a the user scrolls with the mouse cursor over a Container.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#wheel
 * @type {FederatedWheelEvent}
 */
/**
 * Capture phase equivalent of {@code wheel}.
 *
 * These events are propagating from the {@link EventSystem EventSystem}.
 * @event Container#wheelcapture
 * @type {FederatedWheelEvent}
 */
`,no=`import { EventBoundary } from './EventBoundary';
import { FederatedPointerEvent } from './FederatedPointerEvent';
import { FederatedWheelEvent } from './FederatedWheelEvent';
import type { ExtensionMetadata } from '../extensions/Extensions';
import type { PointData } from '../maths/point/PointData';
import type { System } from '../rendering/renderers/shared/system/System';
import type { Renderer } from '../rendering/renderers/types';
import type { EventMode } from './FederatedEventTarget';
/** @ignore */
export interface EventSystemOptions {
    /**
     * The default event mode mode for all display objects.
     * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
     */
    eventMode?: EventMode;
    /**
     * The event features that are enabled by the EventSystem
     * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
     * @example
     * const app = new Application({
     *   view: canvas,
     *   events: {
     *     move: true,
     *     globalMove: false,
     *     click: true,
     *     wheel: true,
     *   },
     * });
     */
    eventFeatures?: Partial<EventSystemFeatures>;
}
/**
 * The event features that are enabled by the EventSystem
 * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
 * @since 7.2.0
 * @memberof events
 */
export interface EventSystemFeatures {
    /**
     * Enables pointer events associated with pointer movement:
     * - \`pointermove\` / \`mousemove\` / \`touchmove\`
     * - \`pointerout\` / \`mouseout\`
     * - \`pointerover\` / \`mouseover\`
     */
    move: boolean;
    /**
     * Enables global pointer move events:
     * - \`globalpointermove\`
     * - \`globalmousemove\`
     * - \`globaltouchemove\`
     */
    globalMove: boolean;
    /**
     * Enables pointer events associated with clicking:
     * - \`pointerup\` / \`mouseup\` / \`touchend\` / 'rightup'
     * - \`pointerupoutside\` / \`mouseupoutside\` / \`touchendoutside\` / 'rightupoutside'
     * - \`pointerdown\` / 'mousedown' / \`touchstart\` / 'rightdown'
     * - \`click\` / \`tap\`
     */
    click: boolean;
    /** - Enables wheel events. */
    wheel: boolean;
}
/**
 * The system for handling UI events.
 * @memberof events
 */
export declare class EventSystem implements System<EventSystemOptions> {
    /** @ignore */
    static extension: ExtensionMetadata;
    /**
     * The event features that are enabled by the EventSystem
     * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
     * @since 7.2.0
     */
    static defaultEventFeatures: EventSystemFeatures;
    private static _defaultEventMode;
    /**
     * The default interaction mode for all display objects.
     * @see Container.eventMode
     * @type {EventMode}
     * @readonly
     * @since 7.2.0
     */
    static get defaultEventMode(): EventMode;
    /**
     * The {@link EventBoundary} for the stage.
     *
     * The {@link EventBoundary#rootTarget rootTarget} of this root boundary is automatically set to
     * the last rendered object before any event processing is initiated. This means the main scene
     * needs to be rendered atleast once before UI events will start propagating.
     *
     * The root boundary should only be changed during initialization. Otherwise, any state held by the
     * event boundary may be lost (like hovered & pressed Containers).
     */
    readonly rootBoundary: EventBoundary;
    /** Does the device support touch events https://www.w3.org/TR/touch-events/ */
    readonly supportsTouchEvents: boolean;
    /** Does the device support pointer events https://www.w3.org/Submission/pointer-events/ */
    readonly supportsPointerEvents: boolean;
    /**
     * Should default browser actions automatically be prevented.
     * Does not apply to pointer events for backwards compatibility
     * preventDefault on pointer events stops mouse events from firing
     * Thus, for every pointer event, there will always be either a mouse of touch event alongside it.
     * @default true
     */
    autoPreventDefault: boolean;
    /**
     * Dictionary of how different cursor modes are handled. Strings are handled as CSS cursor
     * values, objects are handled as dictionaries of CSS values for {@code domElement},
     * and functions are called instead of changing the CSS.
     * Default CSS cursor values are provided for 'default' and 'pointer' modes.
     */
    cursorStyles: Record<string, string | ((mode: string) => void) | CSSStyleDeclaration>;
    /**
     * The DOM element to which the root event listeners are bound. This is automatically set to
     * the renderer's {@link Renderer#view view}.
     */
    domElement: HTMLElement;
    /** The resolution used to convert between the DOM client space into world space. */
    resolution: number;
    /** The renderer managing this {@link EventSystem}. */
    renderer: Renderer;
    /**
     * The event features that are enabled by the EventSystem
     * (included in the **pixi.js** and **pixi.js-legacy** bundle), otherwise it will be ignored.
     * @since 7.2.0
     * @example
     * const app = new Application()
     * app.renderer.events.features.globalMove = false
     *
     * // to override all features use Object.assign
     * Object.assign(app.renderer.events.features, {
     *  move: false,
     *  globalMove: false,
     *  click: false,
     *  wheel: false,
     * })
     */
    readonly features: EventSystemFeatures;
    private _currentCursor;
    private readonly _rootPointerEvent;
    private readonly _rootWheelEvent;
    private _eventsAdded;
    /**
     * @param {Renderer} renderer
     */
    constructor(renderer: Renderer);
    /**
     * Runner init called, view is available at this point.
     * @ignore
     */
    init(options: EventSystemOptions): void;
    /**
     * Handle changing resolution.
     * @ignore
     */
    resolutionChange(resolution: number): void;
    /** Destroys all event listeners and detaches the renderer. */
    destroy(): void;
    /**
     * Sets the current cursor mode, handling any callbacks or CSS style changes.
     * @param mode - cursor mode, a key from the cursorStyles dictionary
     */
    setCursor(mode: string): void;
    /**
     * The global pointer event.
     * Useful for getting the pointer position without listening to events.
     * @since 7.2.0
     */
    get pointer(): Readonly<FederatedPointerEvent>;
    /**
     * Event handler for pointer down events on {@link EventSystem#domElement this.domElement}.
     * @param nativeEvent - The native mouse/pointer/touch event.
     */
    private _onPointerDown;
    /**
     * Event handler for pointer move events on on {@link EventSystem#domElement this.domElement}.
     * @param nativeEvent - The native mouse/pointer/touch events.
     */
    private _onPointerMove;
    /**
     * Event handler for pointer up events on {@link EventSystem#domElement this.domElement}.
     * @param nativeEvent - The native mouse/pointer/touch event.
     */
    private _onPointerUp;
    /**
     * Event handler for pointer over & out events on {@link EventSystem#domElement this.domElement}.
     * @param nativeEvent - The native mouse/pointer/touch event.
     */
    private _onPointerOverOut;
    /**
     * Passive handler for \`wheel\` events on {@link EventSystem.domElement this.domElement}.
     * @param nativeEvent - The native wheel event.
     */
    protected onWheel(nativeEvent: WheelEvent): void;
    /**
     * Sets the {@link EventSystem#domElement domElement} and binds event listeners.
     *
     * To deregister the current DOM element without setting a new one, pass {@code null}.
     * @param element - The new DOM element.
     */
    setTargetElement(element: HTMLElement): void;
    /** Register event listeners on {@link Renderer#domElement this.domElement}. */
    private _addEvents;
    /** Unregister event listeners on {@link EventSystem#domElement this.domElement}. */
    private _removeEvents;
    /**
     * Maps x and y coords from a DOM object and maps them correctly to the PixiJS view. The
     * resulting value is stored in the point. This takes into account the fact that the DOM
     * element could be scaled and positioned anywhere on the screen.
     * @param  {PointData} point - the point that the result will be stored in
     * @param  {number} x - the x coord of the position to map
     * @param  {number} y - the y coord of the position to map
     */
    mapPositionToPoint(point: PointData, x: number, y: number): void;
    /**
     * Ensures that the original event object contains all data that a regular pointer event would have
     * @param event - The original event data from a touch or mouse event
     * @returns An array containing a single normalized pointer event, in the case of a pointer
     *  or mouse event, or a multiple normalized pointer events if there are multiple changed touches
     */
    private _normalizeToPointerData;
    /**
     * Normalizes the native {@link https://w3c.github.io/uievents/#interface-wheelevent WheelEvent}.
     *
     * The returned {@link FederatedWheelEvent} is a shared instance. It will not persist across
     * multiple native wheel events.
     * @param nativeEvent - The native wheel event that occurred on the canvas.
     * @returns A federated wheel event.
     */
    protected normalizeWheelEvent(nativeEvent: WheelEvent): FederatedWheelEvent;
    /**
     * Normalizes the \`nativeEvent\` into a federateed {@link FederatedPointerEvent}.
     * @param event
     * @param nativeEvent
     */
    private _bootstrapEvent;
    /**
     * Transfers base & mouse event data from the {@code nativeEvent} to the federated event.
     * @param event
     * @param nativeEvent
     */
    private _transferMouseData;
}
`,to=`import type { EventSystem } from './EventSystem';
/**
 * This class handles automatic firing of PointerEvents
 * in the case where the pointer is stationary for too long.
 * This is to ensure that hit-tests are still run on moving objects.
 * @since 7.2.0
 * @memberof events
 * @class EventsTicker
 */
declare class EventsTickerClass {
    /** The event system. */
    events: EventSystem;
    /** The DOM element to listen to events on. */
    domElement: HTMLElement;
    /** The frequency that fake events will be fired. */
    interactionFrequency: number;
    private _deltaTime;
    private _didMove;
    private _tickerAdded;
    private _pauseUpdate;
    /**
     * Initializes the event ticker.
     * @param events - The event system.
     */
    init(events: EventSystem): void;
    /** Whether to pause the update checks or not. */
    get pauseUpdate(): boolean;
    set pauseUpdate(paused: boolean);
    /** Adds the ticker listener. */
    addTickerListener(): void;
    /** Removes the ticker listener. */
    removeTickerListener(): void;
    /** Sets flag to not fire extra events when the user has already moved there mouse */
    pointerMoved(): void;
    /** Updates the state of interactive objects. */
    private _update;
    /**
     * Updates the state of interactive objects if at least {@link interactionFrequency}
     * milliseconds have passed since the last invocation.
     *
     * Invoked by a throttled ticker update from {@link Ticker.system}.
     * @param ticker - The throttled ticker.
     */
    private _tickerUpdate;
}
export declare const EventsTicker: EventsTickerClass;
export {};
`,ro=`import type { FederatedEventEmitterTypes } from './FederatedEventMap';
import type { FederatedOptions, IFederatedContainer } from './FederatedEventTarget';

declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface Container extends IFederatedContainer {}

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ContainerOptions extends FederatedOptions {}

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ContainerEvents extends FederatedEventEmitterTypes {}

        interface RendererOptions
        {
            /**
             * The default event mode for all display objects.
             * @since 7.2.0
             */
            eventMode?: import('./FederatedEventTarget').EventMode;
            /**
             * The event features that are enabled by the EventSystem.
             * @since 7.2.0
             */
            eventFeatures?: import('./EventSystem').EventSystemOptions['eventFeatures'];
        }

        interface RendererSystems
        {
            events: import('./EventSystem').EventSystem;
        }
    }
}

export {};
`,oo=`import { Point } from '../maths/point/Point';
import type { Container } from '../scene/container/Container';
import type { EventBoundary } from './EventBoundary';
/**
 * A PixiJS compatible {@code Touch} event.
 * @memberof events
 */
export interface PixiTouch extends Touch {
    button: number;
    buttons: number;
    isPrimary: boolean;
    width: number;
    height: number;
    tiltX: number;
    tiltY: number;
    pointerType: string;
    pointerId: number;
    pressure: number;
    twist: number;
    tangentialPressure: number;
    layerX: number;
    layerY: number;
    offsetX: number;
    offsetY: number;
    isNormalized: boolean;
    type: string;
}
/**
 * An DOM-compatible synthetic event implementation that is "forwarded" on behalf of an original
 * FederatedEvent or native {@link https://dom.spec.whatwg.org/#event Event}.
 * @typeParam N - The type of native event held.
 * @memberof events
 */
export declare class FederatedEvent<N extends UIEvent | PixiTouch = UIEvent | PixiTouch> implements UIEvent {
    /** Flags whether this event bubbles. This will take effect only if it is set before propagation. */
    bubbles: boolean;
    /** @deprecated since 7.0.0 */
    cancelBubble: boolean;
    /**
     * Flags whether this event can be canceled using {@link FederatedEvent.preventDefault}. This is always
     * false (for now).
     */
    readonly cancelable = false;
    /**
     * Flag added for compatibility with DOM {@code Event}. It is not used in the Federated Events
     * API.
     * @see https://dom.spec.whatwg.org/#dom-event-composed
     */
    readonly composed = false;
    /** The listeners of the event target that are being notified. */
    currentTarget: Container;
    /** Flags whether the default response of the user agent was prevent through this event. */
    defaultPrevented: boolean;
    /**
     * The propagation phase.
     * @default {@link FederatedEvent.NONE}
     */
    eventPhase: number;
    /** Flags whether this is a user-trusted event */
    isTrusted: boolean;
    /** @deprecated since 7.0.0 */
    returnValue: boolean;
    /** @deprecated since 7.0.0 */
    srcElement: EventTarget;
    /** The event target that this will be dispatched to. */
    target: Container;
    /** The timestamp of when the event was created. */
    timeStamp: number;
    /** The type of event, e.g. {@code "mouseup"}. */
    type: string;
    /** The native event that caused the foremost original event. */
    nativeEvent: N;
    /** The original event that caused this event, if any. */
    originalEvent: FederatedEvent<N>;
    /** Flags whether propagation was stopped. */
    propagationStopped: boolean;
    /** Flags whether propagation was immediately stopped. */
    propagationImmediatelyStopped: boolean;
    /** The composed path of the event's propagation. The {@code target} is at the end. */
    path: Container[];
    /** The {@link EventBoundary} that manages this event. Null for root events. */
    readonly manager: EventBoundary;
    /** Event-specific detail */
    detail: number;
    /** The global Window object. */
    view: WindowProxy;
    /**
     * Not supported.
     * @deprecated since 7.0.0
     */
    which: number;
    /** The coordinates of the event relative to the nearest DOM layer. This is a non-standard property. */
    layer: Point;
    /** @readonly */
    get layerX(): number;
    /** @readonly */
    get layerY(): number;
    /** The coordinates of the event relative to the DOM document. This is a non-standard property. */
    page: Point;
    /** @readonly */
    get pageX(): number;
    /** @readonly */
    get pageY(): number;
    /**
     * @param manager - The event boundary which manages this event. Propagation can only occur
     *  within the boundary's jurisdiction.
     */
    constructor(manager: EventBoundary);
    /**
     * Fallback for the deprecated @code{InteractionEvent.data}.
     * @deprecated since 7.0.0
     */
    get data(): this;
    /** The propagation path for this event. Alias for {@link EventBoundary.propagationPath}. */
    composedPath(): Container[];
    /**
     * Unimplemented method included for implementing the DOM interface {@code Event}. It will throw an {@code Error}.
     * @deprecated
     * @param _type
     * @param _bubbles
     * @param _cancelable
     */
    initEvent(_type: string, _bubbles?: boolean, _cancelable?: boolean): void;
    /**
     * Unimplemented method included for implementing the DOM interface {@code UIEvent}. It will throw an {@code Error}.
     * @deprecated
     * @param _typeArg
     * @param _bubblesArg
     * @param _cancelableArg
     * @param _viewArg
     * @param _detailArg
     */
    initUIEvent(_typeArg: string, _bubblesArg?: boolean, _cancelableArg?: boolean, _viewArg?: Window | null, _detailArg?: number): void;
    /** Prevent default behavior of PixiJS and the user agent. */
    preventDefault(): void;
    /**
     * Stop this event from propagating to any addition listeners, including on the
     * {@link FederatedEventTarget.currentTarget currentTarget} and also the following
     * event targets on the propagation path.
     */
    stopImmediatePropagation(): void;
    /**
     * Stop this event from propagating to the next {@link FederatedEventTarget}. The rest of the listeners
     * on the {@link FederatedEventTarget.currentTarget currentTarget} will still be notified.
     */
    stopPropagation(): void;
    readonly NONE = 0;
    readonly CAPTURING_PHASE = 1;
    readonly AT_TARGET = 2;
    readonly BUBBLING_PHASE = 3;
}
`,ao=`import type { FederatedPointerEvent } from './FederatedPointerEvent';
import type { FederatedWheelEvent } from './FederatedWheelEvent';
export type FederatedEventMap = {
    click: FederatedPointerEvent;
    mousedown: FederatedPointerEvent;
    mouseenter: FederatedPointerEvent;
    mouseleave: FederatedPointerEvent;
    mousemove: FederatedPointerEvent;
    mouseout: FederatedPointerEvent;
    mouseover: FederatedPointerEvent;
    mouseup: FederatedPointerEvent;
    mouseupoutside: FederatedPointerEvent;
    pointercancel: FederatedPointerEvent;
    pointerdown: FederatedPointerEvent;
    pointerenter: FederatedPointerEvent;
    pointerleave: FederatedPointerEvent;
    pointermove: FederatedPointerEvent;
    pointerout: FederatedPointerEvent;
    pointerover: FederatedPointerEvent;
    pointertap: FederatedPointerEvent;
    pointerup: FederatedPointerEvent;
    pointerupoutside: FederatedPointerEvent;
    rightclick: FederatedPointerEvent;
    rightdown: FederatedPointerEvent;
    rightup: FederatedPointerEvent;
    rightupoutside: FederatedPointerEvent;
    tap: FederatedPointerEvent;
    touchcancel: FederatedPointerEvent;
    touchend: FederatedPointerEvent;
    touchendoutside: FederatedPointerEvent;
    touchmove: FederatedPointerEvent;
    touchstart: FederatedPointerEvent;
    wheel: FederatedWheelEvent;
};
export type GlobalFederatedEventMap = {
    globalmousemove: FederatedPointerEvent;
    globalpointermove: FederatedPointerEvent;
    globaltouchmove: FederatedPointerEvent;
};
export type AllFederatedEventMap = FederatedEventMap & GlobalFederatedEventMap;
export type FederatedEventEmitterTypes = {
    [K in keyof FederatedEventMap as K | \`\${K}capture\`]: [event: FederatedEventMap[K]];
} & {
    [K in keyof GlobalFederatedEventMap]: [event: GlobalFederatedEventMap[K]];
};
`,io=`import { FederatedEvent } from './FederatedEvent';
import type { Container } from '../scene/container/Container';
import type { AllFederatedEventMap } from './FederatedEventMap';
import type { FederatedPointerEvent } from './FederatedPointerEvent';
import type { FederatedWheelEvent } from './FederatedWheelEvent';
/**
 * The type of cursor to use when the mouse pointer is hovering over.
 * @see https://developer.mozilla.org/en-US/docs/Web/CSS/cursor
 *
 * Can be any valid CSS cursor value:
 * \`auto\`, \`default\`, \`none\`, \`context-menu\`, \`help\`, \`pointer\`, \`progress\`,
 * \`wait\`, \`cell\`, \`crosshair\`, \`text\`, \`verticaltext\`, \`alias\`, \`copy\`, \`move\`,
 * \`nodrop\`, \`notallowed\`, \`eresize\`, \`nresize\`, \`neresize\`, \`nwresize\`, \`sresize\`,
 *  \`seresize\`, \`swresize\`, \`wresize\`, \`nsresize\`, \`ewresize\`, \`neswresize\`, \`colresize\`,
 *  \`nwseresize\`, \`rowresize\`, \`allscroll\`, \`zoomin\`, \`zoomout\`, \`grab\`, \`grabbing\`
 * @memberof events
 */
export type Cursor = 'auto' | 'default' | 'none' | 'context-menu' | 'help' | 'pointer' | 'progress' | 'wait' | 'cell' | 'crosshair' | 'text' | 'vertical-text' | 'alias' | 'copy' | 'move' | 'no-drop' | 'not-allowed' | 'e-resize' | 'n-resize' | 'ne-resize' | 'nw-resize' | 's-resize' | 'se-resize' | 'sw-resize' | 'w-resize' | 'ns-resize' | 'ew-resize' | 'nesw-resize' | 'col-resize' | 'nwse-resize' | 'row-resize' | 'all-scroll' | 'zoom-in' | 'zoom-out' | 'grab' | 'grabbing';
/**
 * The hit area specifies the area for which pointer events should be captured by this event target.
 * @memberof events
 */
export interface IHitArea {
    /**
     * Checks if the x and y coordinates given are contained within this hit area.
     * @returns Whether the x and y coordinates are contained within this hit area.
     */
    contains(x: number, y: number): boolean;
}
/**
 * Function type for handlers, e.g., onclick
 * @memberof events
 */
export type FederatedEventHandler<T = FederatedPointerEvent> = (event: T) => void;
/**
 * The type of interaction a Container can be.
 * This is the {@link scene.Container#eventMode|Container.eventMode} property of any {@link scene.Container}.
 *
 * Can be one of the following:
 * - \`'none'\`: Ignores all interaction events, even on its children.
 * - \`'passive'\`: **(default)** Does not emit events and ignores all hit testing on itself and non-interactive children.
 * Interactive children will still emit events.
 * - \`'auto'\`: Does not emit events but is hit tested if parent is interactive. Same as \`interactive = false\` in v7
 * - \`'static'\`: Emit events and is hit tested. Same as \`interaction = true\` in v7
 * - \`'dynamic'\`: Emits events and is hit tested but will also receive mock interaction events fired from a ticker to
 * allow for interaction when the mouse isn't moving
 *
 * \`none\` and \`passive\` are useful for optimizing interaction events on objects as it reduces the number of hit tests
 * PixiJS has to do. \`auto\` is useful for when you want to recreate how the DOM handles interaction events with
 * \`pointer-events: auto\`.
 * @since 7.2.0
 * @memberof events
 */
export type EventMode = 'none' | 'passive' | 'auto' | 'static' | 'dynamic';
/**
 * The properties available for any interactive object.
 * @memberof events
 */
export interface FederatedOptions {
    /** The cursor preferred when the mouse pointer is hovering over. */
    cursor?: Cursor | string;
    /** The mode of interaction for this object */
    eventMode?: EventMode;
    /** Whether this event target should fire UI events. */
    interactive?: boolean;
    /** Whether this event target has any children that need UI events. This can be used optimize event propagation. */
    interactiveChildren?: boolean;
    /** The hit-area specifies the area for which pointer events should be captured by this event target. */
    hitArea?: IHitArea | null;
    /** Handler for 'click' event */
    onclick?: FederatedEventHandler | null;
    /** Handler for 'mousedown' event */
    onmousedown?: FederatedEventHandler | null;
    /** Handler for 'mouseenter' event */
    onmouseenter?: FederatedEventHandler | null;
    /** Handler for 'mouseleave' event */
    onmouseleave?: FederatedEventHandler | null;
    /** Handler for 'mousemove' event */
    onmousemove?: FederatedEventHandler | null;
    /** Handler for 'globalmousemove' event */
    onglobalmousemove?: FederatedEventHandler | null;
    /** Handler for 'mouseout' event */
    onmouseout?: FederatedEventHandler | null;
    /** Handler for 'mouseover' event */
    onmouseover?: FederatedEventHandler | null;
    /** Handler for 'mouseup' event */
    onmouseup?: FederatedEventHandler | null;
    /** Handler for 'mouseupoutside' event */
    onmouseupoutside?: FederatedEventHandler | null;
    /** Handler for 'pointercancel' event */
    onpointercancel?: FederatedEventHandler | null;
    /** Handler for 'pointerdown' event */
    onpointerdown?: FederatedEventHandler | null;
    /** Handler for 'pointerenter' event */
    onpointerenter?: FederatedEventHandler | null;
    /** Handler for 'pointerleave' event */
    onpointerleave?: FederatedEventHandler | null;
    /** Handler for 'pointermove' event */
    onpointermove?: FederatedEventHandler | null;
    /** Handler for 'globalpointermove' event */
    onglobalpointermove?: FederatedEventHandler | null;
    /** Handler for 'pointerout' event */
    onpointerout?: FederatedEventHandler | null;
    /** Handler for 'pointerover' event */
    onpointerover?: FederatedEventHandler | null;
    /** Handler for 'pointertap' event */
    onpointertap?: FederatedEventHandler | null;
    /** Handler for 'pointerup' event */
    onpointerup?: FederatedEventHandler | null;
    /** Handler for 'pointerupoutside' event */
    onpointerupoutside?: FederatedEventHandler | null;
    /** Handler for 'rightclick' event */
    onrightclick?: FederatedEventHandler | null;
    /** Handler for 'rightdown' event */
    onrightdown?: FederatedEventHandler | null;
    /** Handler for 'rightup' event */
    onrightup?: FederatedEventHandler | null;
    /** Handler for 'rightupoutside' event */
    onrightupoutside?: FederatedEventHandler | null;
    /** Handler for 'tap' event */
    ontap?: FederatedEventHandler | null;
    /** Handler for 'touchcancel' event */
    ontouchcancel?: FederatedEventHandler | null;
    /** Handler for 'touchend' event */
    ontouchend?: FederatedEventHandler | null;
    /** Handler for 'touchendoutside' event */
    ontouchendoutside?: FederatedEventHandler | null;
    /** Handler for 'touchmove' event */
    ontouchmove?: FederatedEventHandler | null;
    /** Handler for 'globaltouchmove' event */
    onglobaltouchmove?: FederatedEventHandler | null;
    /** Handler for 'touchstart' event */
    ontouchstart?: FederatedEventHandler | null;
    /** Handler for 'wheel' event */
    onwheel?: FederatedEventHandler<FederatedWheelEvent> | null;
}
type AddListenerOptions = boolean | AddEventListenerOptions;
type RemoveListenerOptions = boolean | EventListenerOptions;
export interface IFederatedContainer extends FederatedOptions {
    /** The parent of this event target. */
    readonly parent?: Container;
    /** The children of this event target. */
    readonly children?: ReadonlyArray<Container>;
    _internalEventMode: EventMode;
    /** Returns true if the Container has interactive 'static' or 'dynamic' */
    isInteractive: () => boolean;
    addEventListener<K extends keyof AllFederatedEventMap>(type: K, listener: (e: AllFederatedEventMap[K]) => any, options?: AddListenerOptions): void;
    addEventListener(type: string, listener: EventListenerOrEventListenerObject, options?: AddListenerOptions): void;
    removeEventListener<K extends keyof AllFederatedEventMap>(type: K, listener: (e: AllFederatedEventMap[K]) => any, options?: RemoveListenerOptions): void;
    removeEventListener(type: string, listener: EventListenerOrEventListenerObject, options?: RemoveListenerOptions): void;
    dispatchEvent(e: FederatedEvent): boolean;
}
export declare const FederatedContainer: IFederatedContainer;
export {};
`,so=`import { Point } from '../maths/point/Point';
import { FederatedEvent } from './FederatedEvent';
import type { PointData } from '../maths/point/PointData';
import type { Container } from '../scene/container/Container';
import type { PixiTouch } from './FederatedEvent';
/**
 * A {@link FederatedEvent} for mouse events.
 * @memberof events
 */
export declare class FederatedMouseEvent extends FederatedEvent<MouseEvent | PointerEvent | PixiTouch> implements MouseEvent {
    /** Whether the "alt" key was pressed when this mouse event occurred. */
    altKey: boolean;
    /** The specific button that was pressed in this mouse event. */
    button: number;
    /** The button depressed when this event occurred. */
    buttons: number;
    /** Whether the "control" key was pressed when this mouse event occurred. */
    ctrlKey: boolean;
    /** Whether the "meta" key was pressed when this mouse event occurred. */
    metaKey: boolean;
    /** This is currently not implemented in the Federated Events API. */
    relatedTarget: EventTarget;
    /** Whether the "shift" key was pressed when this mouse event occurred. */
    shiftKey: boolean;
    /** The coordinates of the mouse event relative to the canvas. */
    client: Point;
    /** @readonly */
    get clientX(): number;
    /** @readonly */
    get clientY(): number;
    /**
     * Alias for {@link FederatedMouseEvent.clientX this.clientX}.
     * @readonly
     */
    get x(): number;
    /**
     * Alias for {@link FederatedMouseEvent.clientY this.clientY}.
     * @readonly
     */
    get y(): number;
    /** This is the number of clicks that occurs in 200ms/click of each other. */
    detail: number;
    /** The movement in this pointer relative to the last \`mousemove\` event. */
    movement: Point;
    /** @readonly */
    get movementX(): number;
    /** @readonly */
    get movementY(): number;
    /** The offset of the pointer coordinates w.r.t. target Container in world space. This is not supported at the moment. */
    offset: Point;
    /** @readonly */
    get offsetX(): number;
    /** @readonly */
    get offsetY(): number;
    /** The pointer coordinates in world space. */
    global: Point;
    /** @readonly */
    get globalX(): number;
    /** @readonly */
    get globalY(): number;
    /**
     * The pointer coordinates in the renderer's {@link Renderer.screen screen}. This has slightly
     * different semantics than native PointerEvent screenX/screenY.
     */
    screen: Point;
    /**
     * The pointer coordinates in the renderer's screen. Alias for {@code screen.x}.
     * @readonly
     */
    get screenX(): number;
    /**
     * The pointer coordinates in the renderer's screen. Alias for {@code screen.y}.
     * @readonly
     */
    get screenY(): number;
    /**
     * This will return the local coordinates of the specified container for this InteractionData
     * @param {Container} container - The Container that you would like the local
     *  coords off
     * @param {PointData} point - A Point object in which to store the value, optional (otherwise
     *  will create a new point)
     * @param {PointData} globalPos - A Point object containing your custom global coords, optional
     *  (otherwise will use the current global coords)
     * @returns - A point containing the coordinates of the InteractionData position relative
     *  to the Container
     */
    getLocalPosition<P extends PointData = Point>(container: Container, point?: P, globalPos?: PointData): P;
    /**
     * Whether the modifier key was pressed when this event natively occurred.
     * @param key - The modifier key.
     */
    getModifierState(key: string): boolean;
    /**
     * Not supported.
     * @param _typeArg
     * @param _canBubbleArg
     * @param _cancelableArg
     * @param _viewArg
     * @param _detailArg
     * @param _screenXArg
     * @param _screenYArg
     * @param _clientXArg
     * @param _clientYArg
     * @param _ctrlKeyArg
     * @param _altKeyArg
     * @param _shiftKeyArg
     * @param _metaKeyArg
     * @param _buttonArg
     * @param _relatedTargetArg
     * @deprecated since 7.0.0
     */
    initMouseEvent(_typeArg: string, _canBubbleArg: boolean, _cancelableArg: boolean, _viewArg: Window, _detailArg: number, _screenXArg: number, _screenYArg: number, _clientXArg: number, _clientYArg: number, _ctrlKeyArg: boolean, _altKeyArg: boolean, _shiftKeyArg: boolean, _metaKeyArg: boolean, _buttonArg: number, _relatedTargetArg: EventTarget): void;
}
`,lo=`import { FederatedMouseEvent } from './FederatedMouseEvent';
/**
 * A {@link FederatedEvent} for pointer events.
 * @memberof events
 */
export declare class FederatedPointerEvent extends FederatedMouseEvent implements PointerEvent {
    /**
     * The unique identifier of the pointer.
     * @see {@link https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerId}
     */
    pointerId: number;
    /**
     * The width of the pointer's contact along the x-axis, measured in CSS pixels.
     * radiusX of TouchEvents will be represented by this value.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/width
     */
    width: number;
    /**
     * The angle in radians of a pointer or stylus measuring the vertical angle between
     * the device's surface to the pointer or stylus.
     * A stylus at 0 degrees would be directly parallel whereas at π/2 degrees it would be perpendicular.
     * @see https://developer.mozilla.org/docs/Web/API/PointerEvent/altitudeAngle)
     */
    altitudeAngle: number;
    /**
     * The angle in radians of a pointer or stylus measuring an arc from the X axis of the device to
     * the pointer or stylus projected onto the screen's plane.
     * A stylus at 0 degrees would be pointing to the "0 o'clock" whereas at π/2 degrees it would be pointing at "6 o'clock".
     * @see https://developer.mozilla.org/docs/Web/API/PointerEvent/azimuthAngle)
     */
    azimuthAngle: number;
    /**
     * The height of the pointer's contact along the y-axis, measured in CSS pixels.
     * radiusY of TouchEvents will be represented by this value.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/height
     */
    height: number;
    /**
     * Indicates whether or not the pointer device that created the event is the primary pointer.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/isPrimary
     */
    isPrimary: boolean;
    /**
     * The type of pointer that triggered the event.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerType
     */
    pointerType: string;
    /**
     * Pressure applied by the pointing device during the event.
     *s
     * A Touch's force property will be represented by this value.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pressure
     */
    pressure: number;
    /**
     * Barrel pressure on a stylus pointer.
     * @see https://w3c.github.io/pointerevents/#pointerevent-interface
     */
    tangentialPressure: number;
    /**
     * The angle, in degrees, between the pointer device and the screen.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltX
     */
    tiltX: number;
    /**
     * The angle, in degrees, between the pointer device and the screen.
     * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltY
     */
    tiltY: number;
    /**
     * Twist of a stylus pointer.
     * @see https://w3c.github.io/pointerevents/#pointerevent-interface
     */
    twist: number;
    /** This is the number of clicks that occurs in 200ms/click of each other. */
    detail: number;
    getCoalescedEvents(): PointerEvent[];
    getPredictedEvents(): PointerEvent[];
}
`,po=`import { FederatedMouseEvent } from './FederatedMouseEvent';
/**
 * A {@link FederatedEvent} for wheel events.
 * @memberof events
 */
export declare class FederatedWheelEvent extends FederatedMouseEvent implements WheelEvent {
    /**
     * The units of \`deltaX\`, \`deltaY\`, and \`deltaZ\`. This is one of \`DOM_DELTA_LINE\`,
     * \`DOM_DELTA_PAGE\`, \`DOM_DELTA_PIXEL\`.
     */
    deltaMode: number;
    /** Horizontal scroll amount */
    deltaX: number;
    /** Vertical scroll amount */
    deltaY: number;
    /** z-axis scroll amount. */
    deltaZ: number;
    /** Units specified in pixels. */
    static readonly DOM_DELTA_PIXEL = 0;
    /** Units specified in pixels. */
    readonly DOM_DELTA_PIXEL = 0;
    /** Units specified in lines. */
    static readonly DOM_DELTA_LINE = 1;
    /** Units specified in lines. */
    readonly DOM_DELTA_LINE = 1;
    /** Units specified in pages. */
    static readonly DOM_DELTA_PAGE = 2;
    /** Units specified in pages. */
    readonly DOM_DELTA_PAGE = 2;
}
`,co=`import type EventEmitter from 'eventemitter3';
import type { EventMode, FederatedOptions } from './FederatedEventTarget';
/**
 * A simplified shape of an interactive object for the \`eventTarget\` property of a {@link FederatedEvent}
 * @memberof events
 * @deprecated since 8.1.4
 */
export interface FederatedEventTarget extends EventEmitter, EventTarget, Required<FederatedOptions> {
    /** The parent of this event target. */
    readonly parent?: FederatedEventTarget;
    /** The children of this event target. */
    readonly children?: ReadonlyArray<FederatedEventTarget>;
    _internalEventMode: EventMode;
    /** Returns true if the Container has interactive 'static' or 'dynamic' */
    isInteractive: () => boolean;
    /** Remove all listeners, or those of the specified event. */
    removeAllListeners(event?: string | symbol): this;
}
`,uo=`export * from './deprecatedTypes';
export * from './EventBoundary';
export * from './EventBoundaryTypes';
export * from './EventSystem';
export * from './EventTicker';
export * from './FederatedEvent';
export * from './FederatedEventMap';
export * from './FederatedEventTarget';
export * from './FederatedMouseEvent';
export * from './FederatedPointerEvent';
export * from './FederatedWheelEvent';
`,mo=`export {};
`,ho=`/**
 * \`extensions\` is a global object that holds all the extensions registered with PixiJS.
 * PixiJS uses a this extensions architecture a lot to make the library more modular and
 * flexible.
 *
 * For example, if you want to add load a new type of asset, you can register a new
 * {@link assets.LoaderParser} with the \`extensions\` object.
 *
 * \`\`\`js
 * import { extensions, ExtensionType } from 'pixi.js';
 *
 * // create a custom asset loader
 * const customAssetLoader = {
 *    extension: {
 *        type: ExtensionType.LoadParser,
 *        name: 'custom-asset-loader',
 *    },
 *    test(url) {
 *       // check if this new loader should be used...
 *    },
 *    load(url) {
 *        // load the asset...
 *    },
 * };
 *
 * // add the custom asset loader to pixi
 * extensions.add(customAssetLoader);
 * \`\`\`
 *
 * This would add the \`customAssetLoader\` to the list of available loaders that PixiJS can use.
 *
 * There are many different types of extensions, which are listed in {@link extensions.ExtensionType}.
 * @namespace extensions
 */
/**
 * Collection of valid extension types.
 * @memberof extensions
 */
declare enum ExtensionType {
    /** extensions that are registered as Application plugins */
    Application = "application",
    /** extensions that are registered as WebGL render pipes */
    WebGLPipes = "webgl-pipes",
    /** extensions that are registered as WebGL render pipes adaptors */
    WebGLPipesAdaptor = "webgl-pipes-adaptor",
    /** extensions that are registered as WebGL render systems */
    WebGLSystem = "webgl-system",
    /** extensions that are registered as WebGPU render pipes */
    WebGPUPipes = "webgpu-pipes",
    /** extensions that are registered as WebGPU render pipes adaptors */
    WebGPUPipesAdaptor = "webgpu-pipes-adaptor",
    /** extensions that are registered as WebGPU render systems */
    WebGPUSystem = "webgpu-system",
    /** extensions that are registered as Canvas render pipes */
    CanvasSystem = "canvas-system",
    /** extensions that are registered as Canvas render pipes adaptors */
    CanvasPipesAdaptor = "canvas-pipes-adaptor",
    /** extensions that are registered as Canvas render systems */
    CanvasPipes = "canvas-pipes",
    /** extensions that combine the other Asset extensions */
    Asset = "asset",
    /** extensions that are used to load assets through Assets */
    LoadParser = "load-parser",
    /** extensions that are used to resolve asset urls through Assets */
    ResolveParser = "resolve-parser",
    /** extensions that are used to handle how urls are cached by Assets */
    CacheParser = "cache-parser",
    /** extensions that are used to add/remove available resources from Assets */
    DetectionParser = "detection-parser",
    /** extensions that are registered with the MaskEffectManager */
    MaskEffect = "mask-effect",
    /** A type of extension for creating a new advanced blend mode */
    BlendMode = "blend-mode",
    /** A type of extension that will be used to auto detect a resource type */
    TextureSource = "texture-source",
    /** A type of extension that will be used to auto detect an environment */
    Environment = "environment",
    /** A type of extension for building and triangulating custom shapes used in graphics. */
    ShapeBuilder = "shape-builder",
    /** A type of extension for creating custom batchers used in rendering. */
    Batcher = "batcher"
}
/**
 * The metadata for an extension.
 * @memberof extensions
 * @ignore
 */
interface ExtensionMetadataDetails {
    /** The extension type, can be multiple types */
    type: ExtensionType | ExtensionType[];
    /** Optional. Some plugins provide an API name/property, to make them more easily accessible */
    name?: string;
    /** Optional, used for sorting the plugins in a particular order */
    priority?: number;
}
/**
 * The metadata for an extension.
 * @memberof extensions
 */
type ExtensionMetadata = ExtensionType | ExtensionMetadataDetails;
/**
 * Format when registering an extension. Generally, the extension
 * should have these values as \`extension\` static property,
 * but you can override name or type by providing an object.
 * @memberof extensions
 */
interface ExtensionFormat {
    /** The extension type, can be multiple types */
    type: ExtensionType | ExtensionType[];
    /** Optional. Some plugins provide an API name/property, such as Renderer plugins */
    name?: string;
    /** Optional, used for sorting the plugins in a particular order */
    priority?: number;
    /** Reference to the plugin object/class */
    ref: any;
}
/**
 * Extension format that is used internally for registrations.
 * @memberof extensions
 * @ignore
 */
interface StrictExtensionFormat extends ExtensionFormat {
    /** The extension type, always expressed as multiple, even if a single */
    type: ExtensionType[];
}
type ExtensionHandler = (extension: StrictExtensionFormat) => void;
/**
 * Get the priority for an extension.
 * @ignore
 * @param ext - Any extension
 * @param defaultPriority - Fallback priority if none is defined.
 * @returns The priority for the extension.
 * @memberof extensions
 */
export declare const normalizeExtensionPriority: (ext: ExtensionFormat | any, defaultPriority: number) => number;
/**
 * Global registration of all PixiJS extensions. One-stop-shop for extensibility.
 *
 * Import the \`extensions\` object and use it to register new functionality via the described methods below.
 * \`\`\`js
 * import { extensions } from 'pixi.js';
 *
 * // register a new extension
 * extensions.add(myExtension);
 * \`\`\`
 * @property {Function} remove - Remove extensions from PixiJS.
 * @property {Function} add - Register new extensions with PixiJS.
 * @property {Function} handle - Internal method to handle extensions by name.
 * @property {Function} handleByMap - Handle a type, but using a map by \`name\` property.
 * @property {Function} handleByNamedList - Handle a type, but using a list of extensions with a \`name\` property.
 * @property {Function} handleByList - Handle a type, but using a list of extensions.
 * @memberof extensions
 */
declare const extensions: {
    /** @ignore */
    _addHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
    /** @ignore */
    _removeHandlers: Partial<Record<ExtensionType, ExtensionHandler>>;
    /** @ignore */
    _queue: Partial<Record<ExtensionType, StrictExtensionFormat[]>>;
    /**
     * Remove extensions from PixiJS.
     * @param extensions - Extensions to be removed.
     * @returns {extensions} For chaining.
     */
    remove(...extensions: Array<ExtensionFormat | any>): any;
    /**
     * Register new extensions with PixiJS.
     * @param extensions - The spread of extensions to add to PixiJS.
     * @returns {extensions} For chaining.
     */
    add(...extensions: Array<ExtensionFormat | any>): any;
    /**
     * Internal method to handle extensions by name.
     * @param type - The extension type.
     * @param onAdd  - Function handler when extensions are added/registered {@link StrictExtensionFormat}.
     * @param onRemove  - Function handler when extensions are removed/unregistered {@link StrictExtensionFormat}.
     * @returns {extensions} For chaining.
     */
    handle(type: ExtensionType, onAdd: ExtensionHandler, onRemove: ExtensionHandler): any;
    /**
     * Handle a type, but using a map by \`name\` property.
     * @param type - Type of extension to handle.
     * @param map - The object map of named extensions.
     * @returns {extensions} For chaining.
     */
    handleByMap(type: ExtensionType, map: Record<string, any>): any;
    /**
     * Handle a type, but using a list of extensions with a \`name\` property.
     * @param type - Type of extension to handle.
     * @param map - The array of named extensions.
     * @param defaultPriority - Fallback priority if none is defined.
     * @returns {extensions} For chaining.
     */
    handleByNamedList(type: ExtensionType, map: {
        name: string;
        value: any;
    }[], defaultPriority?: number): any;
    /**
     * Handle a type, but using a list of extensions.
     * @param type - Type of extension to handle.
     * @param list - The list of extensions.
     * @param defaultPriority - The default priority to use if none is specified.
     * @returns {extensions} For chaining.
     */
    handleByList(type: ExtensionType, list: any[], defaultPriority?: number): any;
    /**
     * Mixin the source object into the target object.
     * @param Target - The target object to mix into.
     * @param sources - The source(s) object to mix from
     */
    mixin(Target: any, ...sources: Parameters<typeof Object.getOwnPropertyDescriptors>[0][]): void;
};
export { extensions, ExtensionType, };
export type { StrictExtensionFormat as ExtensionFormat, ExtensionFormat as ExtensionFormatLoose, ExtensionHandler, ExtensionMetadata, ExtensionMetadataDetails };
`,fo=`export * from './Extensions';
`,bo=`import { Shader } from '../rendering/renderers/shared/shader/Shader';
import { State } from '../rendering/renderers/shared/state/State';
import type { RenderSurface } from '../rendering/renderers/shared/renderTarget/RenderTargetSystem';
import type { IShaderWithResources, ShaderFromResources } from '../rendering/renderers/shared/shader/Shader';
import type { BLEND_MODES } from '../rendering/renderers/shared/state/const';
import type { Texture } from '../rendering/renderers/shared/texture/Texture';
import type { FilterSystem } from './FilterSystem';
/**
 * Filters provide additional shading and post-processing effects to any display object and its children
 * they are attached to.
 *
 * You attached filters to a display object using its \`filters\` array property.
 *
 * \`\`\`js
 * import { Sprite, BlurFilter, HardMixBlend } from 'pixi.js';
 *
 * const sprite = Sprite.from('myTexture.png');
 *
 * // single filter
 * sprite.filters = new BlurFilter({ strength: 8 });
 *
 * // or multiple filters
 * sprite.filters = [new BlurFilter({ strength: 8 }), new HardMixBlend()];
 * \`\`\`
 *
 * Pixi has a number of built-in filters which can be used in your game or application:
 *
 * - {@link filters.AlphaFilter} - Applies alpha to the display object and any of its children.
 * - {@link filters.BlurFilter} - Applies a Gaussian blur to the display object.
 * - {@link filters.BlurFilterPass} - Applies a blur pass to an object.
 * - {@link filters.ColorBurnBlend} - Blend mode to add color burn to display objects.
 * - {@link filters.ColorDodgeBlend} - Blend mode to add color dodge to display objects.
 * - {@link filters.ColorMatrixFilter} - Transform the color channels by matrix multiplication.
 * - {@link filters.DarkenBlend} - Blend mode to darken display objects.
 * - {@link filters.DisplacementFilter} - Applies a displacement map to distort an object.
 * - {@link filters.DivideBlend} - Blend mode to divide display objects.
 * - {@link filters.HardMixBlend} - Blend mode to hard mix display objects.
 * - {@link filters.LinearBurnBlend} - Blend mode to add linear burn to display objects.
 * - {@link filters.LinearDodgeBlend} - Blend mode to add linear dodge to display objects.
 * - {@link filters.LinearLightBlend} - Blend mode to add linear light to display objects.
 * - {@link filters.NoiseFilter} - Applies random noise to an object.
 * - {@link filters.PinLightBlend} - Blend mode to add pin light to display objects.
 * - {@link filters.SubtractBlend} - Blend mode to subtract display objects.
 *
 * <br/>
 * For more available filters, check out the
 *  {@link https://pixijs.io/filters/docs/ pixi-filters} repository.
 *
 * You can also check out the awesome {@link https://pixijs.io/filters/examples/ Filter demo} to see
 * filters in action and combine them!
 * @namespace filters
 */
/**
 * The options to use when creating a new filter.
 * @memberof filters
 */
export interface FilterOptions {
    /** optional blend mode used by the filter when rendering (defaults to 'normal') */
    blendMode?: BLEND_MODES;
    /**
     * the resolution the filter should be rendered at. The lower the resolution, the more performant
     * the filter will be, but the lower the quality of the output. (default 1)
     * If 'inherit', the resolution of the render target is used.
     * Consider lowering this for things like blurs filters
     */
    resolution?: number | 'inherit';
    /**
     * the amount of pixels to pad the container with when applying the filter. For example a blur extends the
     * container out as it blurs, so padding is applied to ensure that extra detail is rendered as well
     * without clipping occurring. (default 0)
     */
    padding?: number;
    /**
     * If true the filter will make use of antialiasing. Although it looks better this can have a performance impact.
     * If set to 'inherit', the filter will detect the antialiasing of the render target and change this automatically.
     * Definitely don't set this to true if the render target has antialiasing set to false. As it will antialias,
     * but you won't see the difference. (default 'off')
     *
     * This can be a boolean or [FilterAntialias]{@link filters.FilterAntialias} string.
     */
    antialias?: FilterAntialias | boolean;
    /**
     * If this is set to true, the filter system will grab a snap shot of the area being rendered
     * to and pass this into the shader. This is useful for blend modes that need to be aware of the pixels
     * they are rendering to. Only use if you need that data, otherwise its an extra gpu copy you don't need!
     * (default false)
     */
    blendRequired?: boolean;
    /**
     * If this is set to true, the filter system will clip filter texture into viewport
     * This is useful for filters that applied to whole texture.
     * (default true)
     */
    clipToViewport?: boolean;
}
/** Filter options mixed with shader resources. A filter needs a shader and some resources to work. */
export type FilterWithShader = FilterOptions & IShaderWithResources;
/**
 * The antialiasing mode of the filter. This can be either:
 * - \`on\` - the filter is always antialiased regardless of the render target settings
 * - \`off\` - (default) the filter is never antialiased regardless of the render target settings
 * - \`inherit\` - the filter uses the antialias settings of the render target
 * @memberof filters
 */
export type FilterAntialias = 'on' | 'off' | 'inherit';
/**
 * The Filter class is the base for all filter effects used in Pixi.js
 * As it extends a shader, it requires that a glProgram is parsed in to work with WebGL and a gpuProgram for WebGPU.
 * If you don't proved one, then the filter is skipped and just rendered as if it wasn't there for that renderer.
 *
 * A filter can be applied to anything that extends Container in Pixi.js which also includes Sprites, Graphics etc.
 *
 * Its worth noting Performance-wise filters can be pretty expensive if used too much in a single scene.
 * The following happens under the hood when a filter is applied:
 *
 * .1. Break the current batch
 * <br>
 * .2. The target is measured using getGlobalBounds
 * (recursively go through all children and figure out how big the object is)
 * <br>
 * .3. Get the closest Po2 Textures from the texture pool
 * <br>
 * .4. Render the target to that texture
 * <br>
 * .5. Render that texture back to the main frame buffer as a quad using the filters program.
 * <br>
 * <br>
 * Some filters (such as blur) require multiple passes too which can result in an even bigger performance hit. So be careful!
 * Its not generally the complexity of the shader that is the bottle neck,
 * but all the framebuffer / shader switching that has to take place.
 * One filter applied to a container with many objects is MUCH faster than many filter applied to many objects.
 * @class
 * @memberof filters
 */
export declare class Filter extends Shader {
    /**
     * The default filter settings
     * @static
     */
    static readonly defaultOptions: FilterOptions;
    /**
     * The padding of the filter. Some filters require extra space to breath such as a blur.
     * Increasing this will add extra width and height to the bounds of the object that the
     * filter is applied to.
     * @default 0
     */
    padding: number;
    /**
     * should the filter use antialiasing?
     * @default inherit
     */
    antialias: FilterAntialias;
    /** If enabled is true the filter is applied, if false it will not. */
    enabled: boolean;
    /**
     * The gpu state the filter requires to render.
     * @internal
     * @ignore
     */
    _state: State;
    /**
     * The resolution of the filter. Setting this to be lower will lower the quality but
     * increase the performance of the filter.
     * @default 1
     */
    resolution: number | 'inherit';
    /**
     * Whether or not this filter requires the previous render texture for blending.
     * @default false
     */
    blendRequired: boolean;
    /**
     * Clip texture into viewport or not
     * @default true
     */
    clipToViewport: boolean;
    /**
     * @param options - The optional parameters of this filter.
     */
    constructor(options: FilterWithShader);
    /**
     * Applies the filter
     * @param filterManager - The renderer to retrieve the filter from
     * @param input - The input render target.
     * @param output - The target to output to.
     * @param clearMode - Should the output be cleared before rendering to it
     */
    apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
    /**
     * Get the blend mode of the filter.
     * @default "normal"
     */
    get blendMode(): BLEND_MODES;
    /** Sets the blend mode of the filter. */
    set blendMode(value: BLEND_MODES);
    /**
     * A short hand function to create a filter based of a vertex and fragment shader src.
     * @param options
     * @returns A shiny new PixiJS filter!
     */
    static from(options: FilterOptions & ShaderFromResources): Filter;
}
`,go=`import type { Rectangle } from '../maths/shapes/Rectangle';
import type { Effect } from '../scene/container/Effect';
import type { Filter } from './Filter';
/**
 * A filter effect is an effect that can be applied to a container that involves applying special pixel effects
 * to that container as it is rendered. Used internally when the filters property is modified on a container
 */
export declare class FilterEffect implements Effect {
    /** read only filters array - to modify, set it again! */
    filters: readonly Filter[];
    /**
     * If specified, rather than calculating the bounds of the container that the filter
     * will apply to, we use this rect instead. This is a local rect - so will have the containers transform
     * applied to it
     */
    filterArea?: Rectangle;
    /** the pipe that knows how to handle this effect */
    pipe: string;
    /** the priority of this effect */
    priority: number;
    destroy(): void;
}
`,yo=`declare global
{
    namespace PixiMixins
    {
        interface RendererSystems
        {
            filter: import('./FilterSystem').FilterSystem;
        }

        interface RendererPipes
        {
            filter: import('./FilterPipe').FilterPipe;
        }
    }
}

export {};
`,xo=`import { ExtensionType } from '../extensions/Extensions';
import type { InstructionSet } from '../rendering/renderers/shared/instructions/InstructionSet';
import type { InstructionPipe } from '../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../rendering/renderers/types';
import type { Container } from '../scene/container/Container';
import type { Effect } from '../scene/container/Effect';
import type { FilterInstruction } from './FilterSystem';
export declare class FilterPipe implements InstructionPipe<FilterInstruction> {
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "filter";
    };
    private _renderer;
    constructor(renderer: Renderer);
    push(filterEffect: Effect, container: Container, instructionSet: InstructionSet): void;
    pop(_filterEffect: Effect, _container: Container, instructionSet: InstructionSet): void;
    execute(instruction: FilterInstruction): void;
    destroy(): void;
}
`,vo=`import { ExtensionType } from '../extensions/Extensions';
import { Matrix } from '../maths/matrix/Matrix';
import { Texture } from '../rendering/renderers/shared/texture/Texture';
import { type Renderer } from '../rendering/renderers/types';
import { Bounds } from '../scene/container/bounds/Bounds';
import type { Instruction } from '../rendering/renderers/shared/instructions/Instruction';
import type { Renderable } from '../rendering/renderers/shared/Renderable';
import type { RenderTarget } from '../rendering/renderers/shared/renderTarget/RenderTarget';
import type { RenderSurface } from '../rendering/renderers/shared/renderTarget/RenderTargetSystem';
import type { System } from '../rendering/renderers/shared/system/System';
import type { Container } from '../scene/container/Container';
import type { Sprite } from '../scene/sprite/Sprite';
import type { Filter } from './Filter';
import type { FilterEffect } from './FilterEffect';
type FilterAction = 'pushFilter' | 'popFilter';
/**
 * The filter pipeline is responsible for applying filters scene items!
 *
 * KNOWN BUGS:
 * 1. Global bounds calculation is incorrect if it is used when flip flopping filters. The maths can be found below
 * eg: filters [noiseFilter, blurFilter] noiseFilter will calculate the global bounds incorrectly.
 *
 * 2. RenderGroups do not work with filters. This is because the renderGroup matrix is not currently taken into account.
 *
 * Implementation notes:
 * 1. Gotcha - nesting filters that require blending will not work correctly. This creates a chicken and egg problem
 * the complexity and performance required to do this is not worth it i feel.. but lets see if others agree!
 *
 * 2. Filters are designed to be changed on the fly, this is means that changing filter information each frame will
 * not trigger an instruction rebuild. If you are constantly turning a filter on and off.. its therefore better to set
 * enabled to true or false on the filter. Or setting an empty array.
 *
 * 3. Need to look at perhaps aliasing when flip flopping filters. Really we should only need to antialias the FIRST
 * Texture we render too. The rest can be non aliased. This might help performance.
 * Currently we flip flop with an antialiased texture if antialiasing is enabled on the filter.
 */
export interface FilterInstruction extends Instruction {
    renderPipeId: 'filter';
    action: FilterAction;
    container?: Container;
    renderables?: Renderable[];
    filterEffect: FilterEffect;
}
export interface FilterData {
    skip: boolean;
    enabledLength?: number;
    inputTexture: Texture;
    bounds: Bounds;
    blendRequired: boolean;
    container: Container;
    filterEffect: FilterEffect;
    previousRenderSurface: RenderSurface;
    backTexture?: Texture;
}
/**
 * System that manages the filter pipeline
 * @memberof rendering
 */
export declare class FilterSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "filter";
    };
    readonly renderer: Renderer;
    private _filterStackIndex;
    private _filterStack;
    private readonly _filterGlobalUniforms;
    private readonly _globalFilterBindGroup;
    private _activeFilterData;
    constructor(renderer: Renderer);
    /**
     * The back texture of the currently active filter. Requires the filter to have \`blendRequired\` set to true.
     * @readonly
     */
    get activeBackTexture(): Texture | undefined;
    push(instruction: FilterInstruction): void;
    pop(): void;
    getBackTexture(lastRenderSurface: RenderTarget, bounds: Bounds, previousBounds?: Bounds): Texture<import("..").TextureSource<any>>;
    applyFilter(filter: Filter, input: Texture, output: RenderSurface, clear: boolean): void;
    private _getFilterData;
    /**
     * Multiply _input normalized coordinates_ to this matrix to get _sprite texture normalized coordinates_.
     *
     * Use \`outputMatrix * vTextureCoord\` in the shader.
     * @param outputMatrix - The matrix to output to.
     * @param {Sprite} sprite - The sprite to map to.
     * @returns The mapped matrix.
     */
    calculateSpriteMatrix(outputMatrix: Matrix, sprite: Sprite): Matrix;
    destroy?: () => void;
}
export {};
`,To=`import { Filter } from '../Filter';
export interface BlendModeFilterOptions {
    source?: string;
    gpu?: {
        functions?: string;
        main?: string;
    };
    gl?: {
        functions?: string;
        main?: string;
    };
}
export declare class BlendModeFilter extends Filter {
    constructor(options: BlendModeFilterOptions);
}
`,So=`/** A helper object containing the hsl shader code for both glsl */
export declare const hslgl = "\\n\\tfloat getLuminosity(vec3 c) {\\n\\t\\treturn 0.3 * c.r + 0.59 * c.g + 0.11 * c.b;\\n\\t}\\n\\n\\tvec3 setLuminosity(vec3 c, float lum) {\\n\\t\\tfloat modLum = lum - getLuminosity(c);\\n\\t\\tvec3 color = c.rgb + vec3(modLum);\\n\\n\\t\\t// clip back into legal range\\n\\t\\tmodLum = getLuminosity(color);\\n\\t\\tvec3 modLumVec = vec3(modLum);\\n\\n\\t\\tfloat cMin = min(color.r, min(color.g, color.b));\\n\\t\\tfloat cMax = max(color.r, max(color.g, color.b));\\n\\n\\t\\tif(cMin < 0.0) {\\n\\t\\t\\tcolor = mix(modLumVec, color, modLum / (modLum - cMin));\\n\\t\\t}\\n\\n\\t\\tif(cMax > 1.0) {\\n\\t\\t\\tcolor = mix(modLumVec, color, (1.0 - modLum) / (cMax - modLum));\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\n\\tfloat getSaturation(vec3 c) {\\n\\t\\treturn max(c.r, max(c.g, c.b)) - min(c.r, min(c.g, c.b));\\n\\t}\\n\\n\\tvec3 setSaturationMinMidMax(vec3 cSorted, float s) {\\n\\t\\tvec3 colorSorted = cSorted;\\n\\n\\t\\tif(colorSorted.z > colorSorted.x) {\\n\\t\\t\\tcolorSorted.y = (((colorSorted.y - colorSorted.x) * s) / (colorSorted.z - colorSorted.x));\\n\\t\\t\\tcolorSorted.z = s;\\n\\t\\t}\\n\\t\\telse {\\n\\t\\t\\tcolorSorted.y = 0.0;\\n\\t\\t\\tcolorSorted.z = 0.0;\\n\\t\\t}\\n\\n\\t\\tcolorSorted.x = 0.0;\\n\\n\\t\\treturn colorSorted;\\n\\t}\\n\\n\\tvec3 setSaturation(vec3 c, float s) {\\n\\t\\tvec3 color = c;\\n\\n\\t\\tif(color.r <= color.g && color.r <= color.b) {\\n\\t\\t\\tif(color.g <= color.b) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.rgb, s).rgb;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.rbg, s).rbg;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse if(color.g <= color.r && color.g <= color.b) {\\n\\t\\t\\tif(color.r <= color.b) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.grb, s).grb;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.gbr, s).gbr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse {\\n\\t\\t\\t// Using bgr for both fixes part of hue\\n\\t\\t\\tif(color.r <= color.g) {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.brg, s).brg;\\n\\t\\t\\t}\\n\\t\\t\\telse {\\n\\t\\t\\t\\tcolor = setSaturationMinMidMax(color.bgr, s).bgr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n    ";
`,wo=`/** A helper object containing the hsl shader code for wgsl */
export declare const hslgpu = "\\n\\tfn getLuminosity(c: vec3<f32>) -> f32\\n\\t{\\n\\t\\treturn 0.3*c.r + 0.59*c.g + 0.11*c.b;\\n\\t}\\n\\n\\tfn setLuminosity(c: vec3<f32>, lum: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar modLum: f32 = lum - getLuminosity(c);\\n\\t\\tvar color: vec3<f32> = c.rgb + modLum;\\n\\n\\t\\t// clip back into legal range\\n\\t\\tmodLum = getLuminosity(color);\\n\\t\\tlet modLumVec = vec3<f32>(modLum);\\n\\n\\t\\tlet cMin: f32 = min(color.r, min(color.g, color.b));\\n\\t\\tlet cMax: f32 = max(color.r, max(color.g, color.b));\\n\\n\\t\\tif(cMin < 0.0)\\n\\t\\t{\\n\\t\\t\\tcolor = mix(modLumVec, color, modLum / (modLum - cMin));\\n\\t\\t}\\n\\n\\t\\tif(cMax > 1.0)\\n\\t\\t{\\n\\t\\t\\tcolor = mix(modLumVec, color, (1 - modLum) / (cMax - modLum));\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\n\\tfn getSaturation(c: vec3<f32>) -> f32\\n\\t{\\n\\t\\treturn max(c.r, max(c.g, c.b)) - min(c.r, min(c.g, c.b));\\n\\t}\\n\\n\\tfn setSaturationMinMidMax(cSorted: vec3<f32>, s: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar colorSorted = cSorted;\\n\\n\\t\\tif(colorSorted.z > colorSorted.x)\\n\\t\\t{\\n\\t\\t\\tcolorSorted.y = (((colorSorted.y - colorSorted.x) * s) / (colorSorted.z - colorSorted.x));\\n\\t\\t\\tcolorSorted.z = s;\\n\\t\\t}\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\tcolorSorted.y = 0;\\n\\t\\t\\tcolorSorted.z = 0;\\n\\t\\t}\\n\\n\\t\\tcolorSorted.x = 0;\\n\\n\\t\\treturn colorSorted;\\n\\t}\\n\\n\\tfn setSaturation(c: vec3<f32>, s: f32) -> vec3<f32>\\n\\t{\\n\\t\\tvar color = c;\\n\\n\\t\\tif (color.r <= color.g && color.r <= color.b)\\n\\t\\t{\\n\\t\\t\\tif (color.g <= color.b)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.rgb, s)).rgb;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.rbg, s)).rbg;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse if (color.g <= color.r && color.g <= color.b)\\n\\t\\t{\\n\\t\\t\\tif (color.r <= color.b)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.grb, s)).grb;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.gbr, s)).gbr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\t// Using bgr for both fixes part of hue\\n\\t\\t\\tif (color.r <= color.g)\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor = vec3<f32>(setSaturationMinMidMax(color.brg, s)).brg;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tcolor  = vec3<f32>(setSaturationMinMidMax(color.bgr, s)).bgr;\\n\\t\\t\\t}\\n\\t\\t}\\n\\n\\t\\treturn color;\\n\\t}\\n\\t";
`,_o=`import { Filter } from '../../Filter';
import type { FilterOptions } from '../../Filter';
/**
 * Options for AlphaFilter
 * @memberof filters
 */
export interface AlphaFilterOptions extends FilterOptions {
    /**
     * Amount of alpha from 0 to 1, where 0 is transparent
     * @default 1
     */
    alpha: number;
}
/**
 * Simplest filter - applies alpha.
 *
 * Use this instead of Container's alpha property to avoid visual layering of individual elements.
 * AlphaFilter applies alpha evenly across the entire display object and any opaque elements it contains.
 * If elements are not opaque, they will blend with each other anyway.
 *
 * Very handy if you want to use common features of all filters:
 *
 * 1. Assign a blendMode to this filter, blend all elements inside display object with background.
 *
 * 2. To use clipping in display coordinates, assign a filterArea to the same container that has this filter.
 * @memberof filters
 */
export declare class AlphaFilter extends Filter {
    /** Default filter options */
    static readonly defaultOptions: AlphaFilterOptions;
    constructor(options?: AlphaFilterOptions);
    /**
     * Coefficient for alpha multiplication
     * @default 1
     */
    get alpha(): number;
    set alpha(value: number);
}
`,Eo=`import { Filter } from '../../Filter';
import { BlurFilterPass } from './BlurFilterPass';
import type { RenderSurface } from '../../../rendering/renderers/shared/renderTarget/RenderTargetSystem';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { FilterOptions } from '../../Filter';
import type { FilterSystem } from '../../FilterSystem';
/**
 * Options for BlurFilter
 * @memberof filters
 */
export interface BlurFilterOptions extends FilterOptions {
    /**
     * The strength of the blur filter.
     * @default 8
     */
    strength?: number;
    /**
     * The horizontal strength of the blur.
     * @default 8
     */
    strengthX?: number;
    /**
     * The vertical strength of the blur.
     * @default 8
     */
    strengthY?: number;
    /**
     * The quality of the blur filter.
     * @default 4
     */
    quality?: number;
    /**
     * The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
     * @default 5
     */
    kernelSize?: number;
}
/**
 * The BlurFilter applies a Gaussian blur to an object.
 *
 * The strength of the blur can be set for the x-axis and y-axis separately.
 * @memberof filters
 */
export declare class BlurFilter extends Filter {
    /** Default blur filter options */
    static defaultOptions: Partial<BlurFilterOptions>;
    /** The horizontal blur filter */
    blurXFilter: BlurFilterPass;
    /** The vertical blur filter */
    blurYFilter: BlurFilterPass;
    private _repeatEdgePixels;
    /**
     * @param {filters.BlurFilterOptions} options - The options of the blur filter.
     */
    constructor(options?: BlurFilterOptions);
    /** @deprecated since 8.0.0 */
    constructor(strength?: number, quality?: number, resolution?: number | null, kernelSize?: number);
    /**
     * Applies the filter.
     * @param filterManager - The manager.
     * @param input - The input target.
     * @param output - The output target.
     * @param clearMode - How to clear
     */
    apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
    protected updatePadding(): void;
    /**
     * Sets the strength of both the blurX and blurY properties simultaneously
     * @default 8
     */
    get strength(): number;
    set strength(value: number);
    /**
     * Sets the number of passes for blur. More passes means higher quality bluring.
     * @default 1
     */
    get quality(): number;
    set quality(value: number);
    /**
     * Sets the strength of horizontal blur
     * @default 8
     */
    get strengthX(): number;
    set strengthX(value: number);
    /**
     * Sets the strength of the vertical blur
     * @default 8
     */
    get strengthY(): number;
    set strengthY(value: number);
    /**
     * Sets the strength of both the blurX and blurY properties simultaneously
     * @default 2
     * @deprecated since 8.3.0
     * @see BlurFilter.strength
     */
    get blur(): number;
    set blur(value: number);
    /**
     * Sets the strength of the blurX property
     * @default 2
     * @deprecated since 8.3.0
     * @see BlurFilter.strengthX
     */
    get blurX(): number;
    set blurX(value: number);
    /**
     * Sets the strength of the blurY property
     * @default 2
     * @deprecated since 8.3.0
     * @see BlurFilter.strengthY
     */
    get blurY(): number;
    set blurY(value: number);
    /**
     * If set to true the edge of the target will be clamped
     * @default false
     */
    get repeatEdgePixels(): boolean;
    set repeatEdgePixels(value: boolean);
}
`,Po=`import { Filter } from '../../Filter';
import type { RenderSurface } from '../../../rendering/renderers/shared/renderTarget/RenderTargetSystem';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { FilterSystem } from '../../FilterSystem';
import type { BlurFilterOptions } from './BlurFilter';
/**
 * Options for BlurFilterPass
 * @memberof filters
 */
export interface BlurFilterPassOptions extends BlurFilterOptions {
    /** Do pass along the x-axis (\`true\`) or y-axis (\`false\`). */
    horizontal: boolean;
}
/**
 * The BlurFilterPass applies a horizontal or vertical Gaussian blur to an object.
 * @memberof filters
 */
export declare class BlurFilterPass extends Filter {
    /** Default blur filter pass options */
    static defaultOptions: Partial<BlurFilterPassOptions>;
    /** Do pass along the x-axis (\`true\`) or y-axis (\`false\`). */
    horizontal: boolean;
    /** The number of passes to run the filter. */
    passes: number;
    /** The strength of the blur filter. */
    strength: number;
    private _quality;
    private readonly _uniforms;
    /**
     * @param options
     * @param options.horizontal - Do pass along the x-axis (\`true\`) or y-axis (\`false\`).
     * @param options.strength - The strength of the blur filter.
     * @param options.quality - The quality of the blur filter.
     * @param options.kernelSize - The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
     */
    constructor(options: BlurFilterPassOptions);
    /**
     * Applies the filter.
     * @param filterManager - The manager.
     * @param input - The input target.
     * @param output - The output target.
     * @param clearMode - How to clear
     */
    apply(filterManager: FilterSystem, input: Texture, output: RenderSurface, clearMode: boolean): void;
    /**
     * Sets the strength of both the blur.
     * @default 16
     */
    get blur(): number;
    set blur(value: number);
    /**
     * Sets the quality of the blur by modifying the number of passes. More passes means higher
     * quality blurring but the lower the performance.
     * @default 4
     */
    get quality(): number;
    set quality(value: number);
}
`,Ao=`export interface IGAUSSIAN_VALUES {
    [x: number]: number[];
}
export declare const GAUSSIAN_VALUES: IGAUSSIAN_VALUES;
`,Co=`export declare function generateBlurFragSource(kernelSize: number): string;
`,Ro=`import { GlProgram } from '../../../../rendering/renderers/gl/shader/GlProgram';
export declare function generateBlurGlProgram(horizontal: boolean, kernelSize: number): GlProgram;
`,Go=`export declare function generateBlurVertSource(kernelSize: number, x: boolean): string;
`,Mo=`import { GpuProgram } from '../../../../rendering/renderers/gpu/shader/GpuProgram';
export declare function generateBlurProgram(horizontal: boolean, kernelSize: number): GpuProgram;
`,ko=`import { Filter } from '../../Filter';
import type { ColorSource } from '../../../color/Color';
import type { ArrayFixed } from '../../../utils/types';
import type { FilterOptions } from '../../Filter';
/**
 * 5x4 matrix for transforming RGBA color and alpha
 * @memberof filters
 */
export type ColorMatrix = ArrayFixed<number, 20>;
/**
 * The ColorMatrixFilter class lets you apply a 5x4 matrix transformation on the RGBA
 * color and alpha values of every pixel on your container to produce a result
 * with a new set of RGBA color and alpha values. It's pretty powerful!
 *
 * \`\`\`js
 *  let colorMatrix = new filters.ColorMatrixFilter();
 *  container.filters = [colorMatrix];
 *  colorMatrix.contrast(2);
 * \`\`\`
 * @author Clément Chenebault <clement@goodboydigital.com>
 * @memberof filters
 */
export declare class ColorMatrixFilter extends Filter {
    constructor(options?: FilterOptions);
    /**
     * Transforms current matrix and set the new one
     * @param {number[]} matrix - 5x4 matrix
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    private _loadMatrix;
    /**
     * Multiplies two mat5's
     * @private
     * @param out - 5x4 matrix the receiving matrix
     * @param a - 5x4 matrix the first operand
     * @param b - 5x4 matrix the second operand
     * @returns {number[]} 5x4 matrix
     */
    private _multiply;
    /**
     * Create a Float32 Array and normalize the offset component to 0-1
     * @param {number[]} matrix - 5x4 matrix
     * @returns {number[]} 5x4 matrix with all values between 0-1
     */
    private _colorMatrix;
    /**
     * Adjusts brightness
     * @param b - value of the brightness (0-1, where 0 is black)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    brightness(b: number, multiply: boolean): void;
    /**
     * Sets each channel on the diagonal of the color matrix.
     * This can be used to achieve a tinting effect on Containers similar to the tint field of some
     * display objects like Sprite, Text, Graphics, and Mesh.
     * @param color - Color of the tint. This is a hex value.
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    tint(color: ColorSource, multiply?: boolean): void;
    /**
     * Set the matrices in grey scales
     * @param scale - value of the grey (0-1, where 0 is black)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    greyscale(scale: number, multiply: boolean): void;
    /**
     * for our american friends!
     * @param scale
     * @param multiply
     */
    grayscale(scale: number, multiply: boolean): void;
    /**
     * Set the black and white matrice.
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    blackAndWhite(multiply: boolean): void;
    /**
     * Set the hue property of the color
     * @param rotation - in degrees
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    hue(rotation: number, multiply: boolean): void;
    /**
     * Set the contrast matrix, increase the separation between dark and bright
     * Increase contrast : shadows darker and highlights brighter
     * Decrease contrast : bring the shadows up and the highlights down
     * @param amount - value of the contrast (0-1)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    contrast(amount: number, multiply: boolean): void;
    /**
     * Set the saturation matrix, increase the separation between colors
     * Increase saturation : increase contrast, brightness, and sharpness
     * @param amount - The saturation amount (0-1)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    saturate(amount?: number, multiply?: boolean): void;
    /** Desaturate image (remove color) Call the saturate function */
    desaturate(): void;
    /**
     * Negative image (inverse of classic rgb matrix)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    negative(multiply: boolean): void;
    /**
     * Sepia image
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    sepia(multiply: boolean): void;
    /**
     * Color motion picture process invented in 1916 (thanks Dominic Szablewski)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    technicolor(multiply: boolean): void;
    /**
     * Polaroid filter
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    polaroid(multiply: boolean): void;
    /**
     * Filter who transforms : Red -> Blue and Blue -> Red
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    toBGR(multiply: boolean): void;
    /**
     * Color reversal film introduced by Eastman Kodak in 1935. (thanks Dominic Szablewski)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    kodachrome(multiply: boolean): void;
    /**
     * Brown delicious browni filter (thanks Dominic Szablewski)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    browni(multiply: boolean): void;
    /**
     * Vintage filter (thanks Dominic Szablewski)
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    vintage(multiply: boolean): void;
    /**
     * We don't know exactly what it does, kind of gradient map, but funny to play with!
     * @param desaturation - Tone values.
     * @param toned - Tone values.
     * @param lightColor - Tone values, example: \`0xFFE580\`
     * @param darkColor - Tone values, example: \`0xFFE580\`
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    colorTone(desaturation: number, toned: number, lightColor: ColorSource, darkColor: ColorSource, multiply: boolean): void;
    /**
     * Night effect
     * @param intensity - The intensity of the night effect.
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    night(intensity: number, multiply: boolean): void;
    /**
     * Predator effect
     *
     * Erase the current matrix by setting a new independent one
     * @param amount - how much the predator feels his future victim
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    predator(amount: number, multiply: boolean): void;
    /**
     * LSD effect
     *
     * Multiply the current matrix
     * @param multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */
    lsd(multiply: boolean): void;
    /** Erase the current matrix by setting the default one. */
    reset(): void;
    /**
     * The matrix of the color matrix filter
     * @member {number[]}
     * @default [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]
     */
    get matrix(): ColorMatrix;
    set matrix(value: ColorMatrix);
    /**
     * The opacity value to use when mixing the original and resultant colors.
     *
     * When the value is 0, the original color is used without modification.
     * When the value is 1, the result color is used.
     * When in the range (0, 1) the color is interpolated between the original and result by this amount.
     * @default 1
     */
    get alpha(): number;
    set alpha(value: number);
}
`,Fo=`import { Point } from '../../../maths/point/Point';
import { Sprite } from '../../../scene/sprite/Sprite';
import { Filter } from '../../Filter';
import type { PointData } from '../../../maths/point/PointData';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { FilterOptions } from '../../Filter';
import type { FilterSystem } from '../../FilterSystem';
/**
 * Options for DisplacementFilter
 * @memberof filters
 */
export interface DisplacementFilterOptions extends FilterOptions {
    /** The texture used for the displacement map. */
    sprite: Sprite;
    /** The scale of the displacement. */
    scale?: number | PointData;
}
/**
 * A Noise effect filter.
 *
 * original filter: https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/noise.js
 * @memberof filters
 * @author Vico @vicocotea
 */
export declare class DisplacementFilter extends Filter {
    private readonly _sprite;
    /**
     * **Note:** Our docs parser struggles to properly understand the constructor signature.
     * This is the correct signature.
     * \`\`\`ts
     * new DisplacementFilter(options?: DisplacementFilterOptions);
     * \`\`\`
     * @param options - The options for the filter.
     * @param options.sprite - The texture used for the displacement map.
     * @param options.scale - The scale of the displacement.
     */
    constructor(options: Sprite | DisplacementFilterOptions);
    constructor(sprite: Sprite, scale?: number | PointData);
    /**
     * Applies the filter.
     * @param filterManager - The manager.
     * @param input - The input target.
     * @param output - The output target.
     * @param clearMode - clearMode.
     */
    apply(filterManager: FilterSystem, input: Texture, output: Texture, clearMode: boolean): void;
    /** scaleX, scaleY for displacements */
    get scale(): Point;
}
`,Oo=`import { Filter } from '../../Filter';
import type { FilterOptions } from '../../Filter';
/**
 * Options for NoiseFilter
 * @memberof filters
 */
export interface NoiseFilterOptions extends FilterOptions {
    /** The amount of noise to apply, this value should be in the range (0, 1]. */
    noise?: number;
    /** A seed value to apply to the random noise generation. \`Math.random()\` is a good value to use. */
    seed?: number;
}
/**
 * A Noise effect filter.
 *
 * original filter: https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/noise.js
 * @memberof filters
 * @author Vico @vicocotea
 */
export declare class NoiseFilter extends Filter {
    static readonly defaultOptions: NoiseFilterOptions;
    /**
     * @param options - The options of the noise filter.
     */
    constructor(options?: NoiseFilterOptions);
    /**
     * The amount of noise to apply, this value should be in the range (0, 1].
     * @default 0.5
     */
    get noise(): number;
    set noise(value: number);
    /** A seed value to apply to the random noise generation. \`Math.random()\` is a good value to use. */
    get seed(): number;
    set seed(value: number);
}
`,Io=`export * from './blend-modes/BlendModeFilter';
export * from './blend-modes/hls/GLhls';
export * from './blend-modes/hls/GPUhls';
export * from './defaults/alpha/AlphaFilter';
export * from './defaults/blur/BlurFilter';
export * from './defaults/blur/BlurFilterPass';
export * from './defaults/blur/const';
export * from './defaults/blur/gl/generateBlurFragSource';
export * from './defaults/blur/gl/generateBlurGlProgram';
export * from './defaults/blur/gl/generateBlurVertSource';
export * from './defaults/blur/gpu/generateBlurProgram';
export * from './defaults/color-matrix/ColorMatrixFilter';
export * from './defaults/displacement/DisplacementFilter';
export * from './defaults/noise/NoiseFilter';
export * from './Filter';
export * from './FilterEffect';
export * from './FilterPipe';
export * from './FilterSystem';
export * from './mask/MaskFilter';
export { default as blendTemplateFrag } from './blend-modes/blend-template.frag';
export { default as blendTemplateVert } from './blend-modes/blend-template.vert';
export { default as blendTemplateWgsl } from './blend-modes/blend-template.wgsl';
export { default as hslWgsl } from './blend-modes/hsl.wgsl';
export { default as alphaFrag } from './defaults/alpha/alpha.frag';
export { default as alphaWgsl } from './defaults/alpha/alpha.wgsl';
export { default as blurTemplateWgsl } from './defaults/blur/gpu/blur-template.wgsl';
export { default as colorMatrixFilterFrag } from './defaults/color-matrix/colorMatrixFilter.frag';
export { default as colorMatrixFilterWgsl } from './defaults/color-matrix/colorMatrixFilter.wgsl';
export { default as defaultFilterVert } from './defaults/defaultFilter.vert';
export { default as displacementFrag } from './defaults/displacement/displacement.frag';
export { default as displacementVert } from './defaults/displacement/displacement.vert';
export { default as displacementWgsl } from './defaults/displacement/displacement.wgsl';
export { default as noiseFrag } from './defaults/noise/noise.frag';
export { default as noiseWgsl } from './defaults/noise/noise.wgsl';
export { default as maskFrag } from './mask/mask.frag';
export { default as maskVert } from './mask/mask.vert';
export { default as maskWgsl } from './mask/mask.wgsl';
`,Lo=`export {};
`,Bo=`import { Filter } from '../Filter';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { Sprite } from '../../scene/sprite/Sprite';
import type { FilterOptions } from '../Filter';
import type { FilterSystem } from '../FilterSystem';
export interface MaskFilterOptions extends FilterOptions {
    sprite: Sprite;
    inverse?: boolean;
    scale?: number | {
        x: number;
        y: number;
    };
}
export declare class MaskFilter extends Filter {
    sprite: Sprite;
    private readonly _textureMatrix;
    constructor(options: MaskFilterOptions);
    set inverse(value: boolean);
    get inverse(): boolean;
    apply(filterManager: FilterSystem, input: Texture, output: Texture, clearMode: boolean): void;
}
`,Do=`import { type GifBufferOptions, GifSource } from './GifSource';
import type { AssetExtension } from '../assets/AssetExtension';
/**
 * Handle the loading of GIF images. Registering this loader plugin will
 * load all \`.gif\` images as an ArrayBuffer and transform into an
 * GifSource object.
 * @memberof gif
 */
declare const GifAsset: AssetExtension<GifSource, GifBufferOptions>;
export { GifAsset };
`,Uo=`import { CanvasSource } from '../rendering/renderers/shared/texture/sources/CanvasSource';
import { Texture } from '../rendering/renderers/shared/texture/Texture';
/**
 * Represents a single frame of a GIF. Includes image and timing data.
 * @memberof gif
 */
interface GifFrame {
    /** Image data for the current frame */
    texture: Texture<CanvasSource>;
    /** The start of the current frame, in milliseconds */
    start: number;
    /** The end of the current frame, in milliseconds */
    end: number;
}
/**
 * Options when constructing from buffer
 * @memberof gif
 */
interface GifBufferOptions {
    /** FPS to use when the GIF animation doesn't define any delay between frames */
    fps: number;
}
/**
 * Resource provided to GifSprite instances. This is very similar to using a shared
 * Texture between Sprites. This source contains all the frames and animation needed
 * to support playback.
 * @memberof gif
 */
declare class GifSource {
    /** Width of the animation */
    readonly width: number;
    /** Height of the animation */
    readonly height: number;
    /** The total time to play the animation in milliseconds */
    readonly duration: number;
    /** Animation frames */
    readonly frames: GifFrame[];
    /** Textures */
    readonly textures: Texture<CanvasSource>[];
    /** Total number of frames in the animation */
    readonly totalFrames: number;
    /**
     * @param frames - Array of GifFrame instances.
     */
    constructor(frames: GifFrame[]);
    /** Destroy animation data and don't use after this */
    destroy(): void;
    /**
     * Create an animated GIF animation from a GIF image's ArrayBuffer. The easiest way to get
     * the buffer is to use Assets.
     * @example
     * import { GifSource, GifSprite } from 'pixi.js/gif';
     *
     * const buffer = await fetch('./file.gif').then(res => res.arrayBuffer());
     * const source = GifSource.from(buffer);
     * const sprite = new GifSprite(source);
     * @param buffer - GIF image arraybuffer from Assets.
     * @param options - Optional options to use when building from buffer.
     */
    static from(buffer: ArrayBuffer, options?: GifBufferOptions): GifSource;
}
export { GifBufferOptions, GifFrame, GifSource };
`,jo=`import { Sprite, type SpriteOptions } from '../scene/sprite/Sprite';
import { Ticker } from '../ticker/Ticker';
import { GifSource } from './GifSource';
import type { SCALE_MODE } from '../rendering/renderers/shared/texture/const';
/**
 * Optional module to import to decode and play animated GIFs.
 * @example
 * import { Assets } from 'pixi.js';
 * import { GifSprite } from 'pixi.js/gif';
 *
 * const source = await Assets.load('example.gif');
 * const gif = new GifSprite({ source });
 * @namespace gif
 */
/**
 * Default options for all GifSprite objects.
 * @memberof gif
 */
interface GifSpriteOptions extends Omit<SpriteOptions, 'texture'> {
    /** Source to the GIF frame and animation data */
    source: GifSource;
    /** Whether to start playing right away */
    autoPlay?: boolean;
    /**
     * Scale Mode to use for the texture
     * @type {PIXI.SCALE_MODE}
     */
    scaleMode?: SCALE_MODE;
    /** To enable looping */
    loop?: boolean;
    /** Speed of the animation */
    animationSpeed?: number;
    /** Set to \`false\` to manage updates yourself */
    autoUpdate?: boolean;
    /** The completed callback, optional */
    onComplete?: null | (() => void);
    /** The loop callback, optional */
    onLoop?: null | (() => void);
    /** The frame callback, optional */
    onFrameChange?: null | ((currentFrame: number) => void);
    /** Fallback FPS if GIF contains no time information */
    fps?: number;
}
/**
 * Runtime object to play animated GIFs. This object is similar to an AnimatedSprite.
 * It support playback (seek, play, stop) as well as animation speed and looping.
 * @memberof gif
 * @see Thanks to {@link https://github.com/matt-way/gifuct-js/ gifuct-js}
 */
declare class GifSprite extends Sprite {
    /**
     * Default options for all GifSprite objects.
     * @property {PIXI.SCALE_MODE} [scaleMode='linear'] - Scale mode to use for the texture.
     * @property {boolean} [loop=true] - To enable looping.
     * @property {number} [animationSpeed=1] - Speed of the animation.
     * @property {boolean} [autoUpdate=true] - Set to \`false\` to manage updates yourself.
     * @property {boolean} [autoPlay=true] - To start playing right away.
     * @property {Function} [onComplete=null] - The completed callback, optional.
     * @property {Function} [onLoop=null] - The loop callback, optional.
     * @property {Function} [onFrameChange=null] - The frame callback, optional.
     * @property {number} [fps=30] - Fallback FPS if GIF contains no time information.
     */
    static defaultOptions: Omit<GifSpriteOptions, 'source'>;
    /**
     * The speed that the animation will play at. Higher is faster, lower is slower.
     * @default 1
     */
    animationSpeed: number;
    /**
     * Whether or not the animate sprite repeats after playing.
     * @default true
     */
    loop: boolean;
    /**
     * User-assigned function to call when animation finishes playing. This only happens
     * if loop is set to \`false\`.
     * @example
     * animation.onComplete = () => {
     *   // finished!
     * };
     */
    onComplete?: () => void;
    /**
     * User-assigned function to call when animation changes which texture is being rendered.
     * @example
     * animation.onFrameChange = () => {
     *   // updated!
     * };
     */
    onFrameChange?: (currentFrame: number) => void;
    /**
     * User-assigned function to call when \`loop\` is true, and animation is played and
     * loops around to start again. This only happens if loop is set to \`true\`.
     * @example
     * animation.onLoop = () => {
     *   // looped!
     * };
     */
    onLoop?: () => void;
    /** The total duration of animation in milliseconds. */
    readonly duration: number;
    /** Whether to play the animation after constructing. */
    readonly autoPlay: boolean;
    /** Collection of frame to render. */
    private _source;
    /** Dirty means the image needs to be redrawn. Set to \`true\` to force redraw. */
    dirty: boolean;
    /** The current frame number (zero-based index). */
    private _currentFrame;
    /** \`true\` uses PIXI.Ticker.shared to auto update animation time.*/
    private _autoUpdate;
    /** \`true\` if the instance is currently connected to PIXI.Ticker.shared to auto update animation time. */
    private _isConnectedToTicker;
    /** If animation is currently playing. */
    private _playing;
    /** Current playback position in milliseconds. */
    private _currentTime;
    /**
     * @param source - Source, default options will be used.
     */
    constructor(source: GifSource);
    /**
     * @param options - Options for the GifSprite
     */
    constructor(options: GifSpriteOptions);
    /** Stops the animation. */
    stop(): void;
    /** Plays the animation. */
    play(): void;
    /**
     * Get the current progress of the animation from 0 to 1.
     * @readonly
     */
    get progress(): number;
    /** \`true\` if the current animation is playing */
    get playing(): boolean;
    /**
     * Updates the object transform for rendering. You only need to call this
     * if the \`autoUpdate\` property is set to \`false\`.
     * @param ticker - Ticker instance
     */
    update(ticker: Ticker): void;
    /** Redraw the current frame, is necessary for the animation to work when */
    private _updateFrame;
    /**
     * Whether to use PIXI.Ticker.shared to auto update animation time.
     * @default true
     */
    get autoUpdate(): boolean;
    set autoUpdate(value: boolean);
    /** Set the current frame number */
    get currentFrame(): number;
    set currentFrame(value: number);
    /** Instance of the data, contains frame textures */
    get source(): GifSource;
    /**
     * Internally handle updating the frame index
     * @param value
     */
    private _updateFrameIndex;
    /** Get the total number of frame in the GIF. */
    get totalFrames(): number;
    /**
     * Destroy and don't use after this.
     * @param destroyData - Destroy the data, cannot be used again.
     */
    destroy(destroyData?: boolean): void;
    /**
     * Cloning the animation is a useful way to create a duplicate animation.
     * This maintains all the properties of the original animation but allows
     * you to control playback independent of the original animation.
     * If you want to create a simple copy, and not control independently,
     * then you can simply create a new Sprite, e.g. \`const sprite = new Sprite(animation.texture)\`.
     *
     * The clone will be flagged as \`dirty\` to immediatly trigger an update
     */
    clone(): GifSprite;
}
export { GifSprite };
export type { GifSpriteOptions };
`,Wo=`export * from './GifAsset';
export * from './GifSource';
export * from './GifSprite';
`,Ho=`export * from './index';
`,Vo=`/// <reference path="./Shaders.d.ts" />
/// <reference path="./accessibility/AccessibilityMixins.d.ts" />
/// <reference path="./app/ApplicationMixins.d.ts" />
/// <reference path="./assets/AssetsMixins.d.ts" />
/// <reference path="./culling/CullingMixins.d.ts" />
/// <reference path="./dom/DOMMixins.d.ts" />
/// <reference path="./events/EventsMixins.d.ts" />
/// <reference path="./filters/FilterMixins.d.ts" />
/// <reference path="./math-extras/MathExtraMixins.d.ts" />
/// <reference path="./prepare/PrepareMixins.d.ts" />
/// <reference path="./rendering/RenderingMixins.d.ts" />
/// <reference path="./scene/graphics/GraphicsMixins.d.ts" />
/// <reference path="./scene/graphics/shared/svg/utils/parse-svg-path.d.ts" />
/// <reference path="./scene/mesh/MeshMixins.d.ts" />
/// <reference path="./scene/particle-container/ParticleMixins.d.ts" />
/// <reference path="./scene/SceneMixins.d.ts" />
/// <reference path="./scene/sprite-nine-slice/NineSliceSpriteMixins.d.ts" />
/// <reference path="./scene/sprite-tiling/TilingSpriteMixins.d.ts" />
/// <reference path="./scene/text-bitmap/TextBitmapMixins.d.ts" />
/// <reference path="./scene/text-html/TextHTMLMixins.d.ts" />
/// <reference path="./scene/text/TextMixins.d.ts" />
import './rendering/init';
import './spritesheet/init';
export * from './accessibility';
export * from './advanced-blend-modes';
export * from './app';
export * from './assets';
export * from './color';
export * from './compressed-textures';
export * from './culling';
export * from './dom';
export * from './environment';
export * from './environment-browser';
export * from './environment-webworker';
export * from './events';
export * from './extensions';
export * from './filters';
export * from './maths';
export * from './prepare';
export * from './rendering';
export * from './scene';
export * from './spritesheet';
export * from './ticker';
export * from './utils';
`,No=`/* eslint-disable max-len */
declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface Point extends Vector2Math
        {
        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ObservablePoint extends Vector2Math
        {
        }

        interface Rectangle
        {
            containsRect(other: import('../maths/shapes/Rectangle').Rectangle): boolean;

            equals(other: import('../maths/shapes/Rectangle').Rectangle): boolean;

            intersection(other: import('../maths/shapes/Rectangle').Rectangle): import('../maths/shapes/Rectangle').Rectangle;
            intersection<T extends import('../maths/shapes/Rectangle').Rectangle>(other: import('../maths/shapes/Rectangle').Rectangle, outRect: T): T;

            union(other: import('../maths/shapes/Rectangle').Rectangle): import('../maths/shapes/Rectangle').Rectangle;
            union<T extends import('../maths/shapes/Rectangle').Rectangle>(other: import('../maths/shapes/Rectangle').Rectangle, outRect: T): T;
        }
    }

    interface Vector2Math
    {
        add(other: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        add<T extends import('../maths/point/PointData').PointData>(other: import('../maths/point/PointData').PointData, outPoint: T): T;

        subtract(other: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        subtract<T extends import('../maths/point/PointData').PointData>(other: import('../maths/point/PointData').PointData, outPoint: T): T;

        multiply(other: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        multiply<T extends import('../maths/point/PointData').PointData>(other: import('../maths/point/PointData').PointData, outPoint: T): T;

        // divide(other: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        // divide<T extends import('../maths/point/PointData').PointData>(other: import('../maths/point/PointData').PointData, outPoint: T): T;

        multiplyScalar(scalar: number): import('../maths/point/Point').Point;
        multiplyScalar<T extends import('../maths/point/PointData').PointData>(scalar: number, outPoint: T): T;

        dot(other: import('../maths/point/PointData').PointData): number;

        cross(other: import('../maths/point/PointData').PointData): number;

        normalize(): import('../maths/point/Point').Point;
        normalize<T extends import('../maths/point/PointData').PointData>(outPoint: T): T;

        magnitude(): number;

        magnitudeSquared(): number;

        project(onto: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        project<T extends import('../maths/point/PointData').PointData>(onto: import('../maths/point/PointData').PointData, outPoint: T): T;

        reflect(normal: import('../maths/point/PointData').PointData): import('../maths/point/Point').Point;
        reflect<T extends import('../maths/point/PointData').PointData>(normal: import('../maths/point/PointData').PointData, outPoint: T): T;
    }
}

export {};
`,zo=`export * from './pointExtras';
export * from './rectangleExtras';
export * from './util';
`,Xo=`export {};
`,Ko=`export declare const pointExtraMixins: any;
`,qo=`import { Rectangle } from '../maths/shapes/Rectangle';
export declare const rectangleExtraMixins: Partial<Rectangle>;
`,Yo=`import { Point } from '../maths/point/Point';
import './pointExtras';
import './rectangleExtras';
import type { PointData } from '../maths/point/PointData';
/**
 * The idea of a relative epsilon comparison is to find the difference between the two numbers,
 * and see if it is less than \`Math.EPSILON\`.
 * @param {number} a - First floating number to compare.
 * @param {number} b - Second floating number to compare.
 * @returns {boolean} Returns \`true\` if the difference between the values is less than \`Math.EPSILON\`; otherwise \`false\`.
 * @memberof maths
 */
export declare function floatEqual(a: number, b: number): boolean;
/**
 * The idea of a relative epsilon comparison is to find the difference between the two numbers,
 * and see if it is less than a given epsilon.
 * A good epsilon would be the N% of the largest of the two values or \`Math.EPSILON\`.
 *
 * _Note: Only available with **pixi.js/math-extras**._
 * @param {number} a - First floating number to compare.
 * @param {number} b - Second floating number to compare.
 * @param {number} epsilon - The epsilon to compare to.
 * The larger the epsilon, the easier for the numbers to be considered equals.
 * @returns {boolean} Returns \`true\` if the difference between the values is less than the given epsilon;
 * otherwise \`false\`.
 * @memberof maths
 */
export declare function floatEqual(a: number, b: number, epsilon: number): boolean;
/**
 * Computes the point where non-coincident and non-parallel Lines intersect.
 * Coincident or parallel lines return a \`NaN\` point \`{x: NaN, y: NaN}\`.
 * The intersection point may land outside the extents of the lines.
 *
 * _Note: Only available with **pixi.js/math-extras**._
 * @param aStart - First point of the first line.
 * @param aEnd - Second point of the first line.
 * @param bStart - First point of the second line.
 * @param bEnd - Second point of the second line.
 * @returns {PointData} The point where the lines intersect.
 * @memberof maths
 */
export declare function lineIntersection(aStart: PointData, aEnd: PointData, bStart: PointData, bEnd: PointData): Point;
/**
 * Computes the point where non-coincident and non-parallel Lines intersect.
 * Coincident or parallel lines return a \`NaN\` point \`{x: NaN, y: NaN}\`.
 * The intersection point may land outside the extents of the lines.
 *
 * _Note: Only available with **pixi.js/math-extras**._
 * @param aStart - First point of the first line.
 * @param aEnd - Second point of the first line.
 * @param bStart - First point of the second line.
 * @param bEnd - Second point of the second line.
 * @param {PointData} outPoint - A Point-like object in which to store the value,
 * optional (otherwise will create a new Point).
 * @returns {PointData} The point where the lines intersect or a \`NaN\` Point.
 * @memberof maths
 */
export declare function lineIntersection<T extends PointData>(aStart: PointData, aEnd: PointData, bStart: PointData, bEnd: PointData, outPoint: T): T;
/**
 * Computes the point where non-coincident and non-parallel segments intersect.
 * Coincident, parallel or non-intersecting segments return a \`NaN\` point \`{x: NaN, y: NaN}\`.
 * The intersection point must land inside the extents of the segments or return a \`NaN\` Point.
 *
 * _Note: Only available with **pixi.js/math-extras**._
 * @param aStart - Starting point of the first segment.
 * @param aEnd - Ending point of the first segment.
 * @param bStart - Starting point of the second segment.
 * @param bEnd - Ending point of the second segment.
 * @returns {PointData} The point where the segments intersect.
 * @memberof maths
 */
export declare function segmentIntersection(aStart: PointData, aEnd: PointData, bStart: PointData, bEnd: PointData): Point;
/**
 * Computes the point where non-coincident and non-parallel segments intersect.
 * Coincident, parallel or non-intersecting segments return a \`NaN\` point \`{x: NaN, y: NaN}\`.
 * The intersection point must land inside the extents of the segments or return a \`NaN\` Point.
 *
 * _Note: Only available with **pixi.js/math-extras**._
 * @param aStart - Starting point of the first segment.
 * @param aEnd - Ending point of the first segment.
 * @param bStart - Starting point of the second segment.
 * @param bEnd - Ending point of the second segment.
 * @param {PointData} outPoint - A Point-like object in which to store the value,
 * optional (otherwise will create a new Point).
 * @returns {PointData} The point where the segments intersect or a \`NaN\` Point.
 * @memberof maths
 */
export declare function segmentIntersection<T extends PointData>(aStart: PointData, aEnd: PointData, bStart: PointData, bEnd: PointData, outPoint: T): T;
`,Jo=`export * from './matrix/groupD8';
export * from './matrix/Matrix';
export * from './misc/const';
export * from './misc/pow2';
export * from './misc/Size';
export * from './misc/squaredDistanceToLineSegment';
export * from './point/ObservablePoint';
export * from './point/Point';
export * from './point/PointData';
export * from './point/pointInTriangle';
export * from './point/PointLike';
export * from './shapes/Circle';
export * from './shapes/Ellipse';
export * from './shapes/Polygon';
export * from './shapes/Rectangle';
export * from './shapes/RoundedRectangle';
export * from './shapes/ShapePrimitive';
export * from './shapes/Triangle';
`,$o=`import { Point } from '../point/Point';
import type { PointData } from '../point/PointData';
interface TransformableObject {
    position: PointData;
    scale: PointData;
    pivot: PointData;
    skew: PointData;
    rotation: number;
}
/**
 * A fast matrix for 2D transformations.
 * \`\`\`js
 * | a | c | tx|
 * | b | d | ty|
 * | 0 | 0 | 1 |
 * \`\`\`
 * @memberof maths
 */
export declare class Matrix {
    /** @default 1 */
    a: number;
    /** @default 0 */
    b: number;
    /** @default 0 */
    c: number;
    /** @default 1 */
    d: number;
    /** @default 0 */
    tx: number;
    /** @default 0 */
    ty: number;
    /** An array of the current matrix. Only populated when \`toArray\` is called */
    array: Float32Array | null;
    /**
     * @param a - x scale
     * @param b - y skew
     * @param c - x skew
     * @param d - y scale
     * @param tx - x translation
     * @param ty - y translation
     */
    constructor(a?: number, b?: number, c?: number, d?: number, tx?: number, ty?: number);
    /**
     * Creates a Matrix object based on the given array. The Element to Matrix mapping order is as follows:
     *
     * a = array[0]
     * b = array[1]
     * c = array[3]
     * d = array[4]
     * tx = array[2]
     * ty = array[5]
     * @param array - The array that the matrix will be populated from.
     */
    fromArray(array: number[]): void;
    /**
     * Sets the matrix properties.
     * @param a - Matrix component
     * @param b - Matrix component
     * @param c - Matrix component
     * @param d - Matrix component
     * @param tx - Matrix component
     * @param ty - Matrix component
     * @returns This matrix. Good for chaining method calls.
     */
    set(a: number, b: number, c: number, d: number, tx: number, ty: number): this;
    /**
     * Creates an array from the current Matrix object.
     * @param transpose - Whether we need to transpose the matrix or not
     * @param [out=new Float32Array(9)] - If provided the array will be assigned to out
     * @returns The newly created array which contains the matrix
     */
    toArray(transpose?: boolean, out?: Float32Array): Float32Array;
    /**
     * Get a new position with the current transformation applied.
     * Can be used to go from a child's coordinate space to the world coordinate space. (e.g. rendering)
     * @param pos - The origin
     * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
     * @returns {Point} The new point, transformed through this matrix
     */
    apply<P extends PointData = Point>(pos: PointData, newPos?: P): P;
    /**
     * Get a new position with the inverse of the current transformation applied.
     * Can be used to go from the world coordinate space to a child's coordinate space. (e.g. input)
     * @param pos - The origin
     * @param {Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
     * @returns {Point} The new point, inverse-transformed through this matrix
     */
    applyInverse<P extends PointData = Point>(pos: PointData, newPos?: P): P;
    /**
     * Translates the matrix on the x and y.
     * @param x - How much to translate x by
     * @param y - How much to translate y by
     * @returns This matrix. Good for chaining method calls.
     */
    translate(x: number, y: number): this;
    /**
     * Applies a scale transformation to the matrix.
     * @param x - The amount to scale horizontally
     * @param y - The amount to scale vertically
     * @returns This matrix. Good for chaining method calls.
     */
    scale(x: number, y: number): this;
    /**
     * Applies a rotation transformation to the matrix.
     * @param angle - The angle in radians.
     * @returns This matrix. Good for chaining method calls.
     */
    rotate(angle: number): this;
    /**
     * Appends the given Matrix to this Matrix.
     * @param matrix - The matrix to append.
     * @returns This matrix. Good for chaining method calls.
     */
    append(matrix: Matrix): this;
    /**
     * Appends two matrix's and sets the result to this matrix. AB = A * B
     * @param a - The matrix to append.
     * @param b - The matrix to append.
     * @returns This matrix. Good for chaining method calls.
     */
    appendFrom(a: Matrix, b: Matrix): this;
    /**
     * Sets the matrix based on all the available properties
     * @param x - Position on the x axis
     * @param y - Position on the y axis
     * @param pivotX - Pivot on the x axis
     * @param pivotY - Pivot on the y axis
     * @param scaleX - Scale on the x axis
     * @param scaleY - Scale on the y axis
     * @param rotation - Rotation in radians
     * @param skewX - Skew on the x axis
     * @param skewY - Skew on the y axis
     * @returns This matrix. Good for chaining method calls.
     */
    setTransform(x: number, y: number, pivotX: number, pivotY: number, scaleX: number, scaleY: number, rotation: number, skewX: number, skewY: number): this;
    /**
     * Prepends the given Matrix to this Matrix.
     * @param matrix - The matrix to prepend
     * @returns This matrix. Good for chaining method calls.
     */
    prepend(matrix: Matrix): this;
    /**
     * Decomposes the matrix (x, y, scaleX, scaleY, and rotation) and sets the properties on to a transform.
     * @param transform - The transform to apply the properties to.
     * @returns The transform with the newly applied properties
     */
    decompose(transform: TransformableObject): TransformableObject;
    /**
     * Inverts this matrix
     * @returns This matrix. Good for chaining method calls.
     */
    invert(): this;
    /** Checks if this matrix is an identity matrix */
    isIdentity(): boolean;
    /**
     * Resets this Matrix to an identity (default) matrix.
     * @returns This matrix. Good for chaining method calls.
     */
    identity(): this;
    /**
     * Creates a new Matrix object with the same values as this one.
     * @returns A copy of this matrix. Good for chaining method calls.
     */
    clone(): Matrix;
    /**
     * Changes the values of the given matrix to be the same as the ones in this matrix
     * @param matrix - The matrix to copy to.
     * @returns The matrix given in parameter with its values updated.
     */
    copyTo(matrix: Matrix): Matrix;
    /**
     * Changes the values of the matrix to be the same as the ones in given matrix
     * @param matrix - The matrix to copy from.
     * @returns this
     */
    copyFrom(matrix: Matrix): this;
    /**
     * check to see if two matrices are the same
     * @param matrix - The matrix to compare to.
     */
    equals(matrix: Matrix): boolean;
    toString(): string;
    /**
     * A default (identity) matrix.
     *
     * This is a shared object, if you want to modify it consider creating a new \`Matrix\`
     * @readonly
     */
    static get IDENTITY(): Readonly<Matrix>;
    /**
     * A static Matrix that can be used to avoid creating new objects.
     * Will always ensure the matrix is reset to identity when requested.
     * Use this object for fast but temporary calculations, as it may be mutated later on.
     * This is a different object to the \`IDENTITY\` object and so can be modified without changing \`IDENTITY\`.
     * @readonly
     */
    static get shared(): Matrix;
}
export {};
`,Qo=`import { Matrix } from './Matrix';
type GD8Symmetry = number;
/**
 * @typedef {number} GD8Symmetry
 * @see groupD8
 */
/**
 * Implements the dihedral group D8, which is similar to
 * [group D4]{@link http://mathworld.wolfram.com/DihedralGroupD4.html};
 * D8 is the same but with diagonals, and it is used for texture
 * rotations.
 *
 * The directions the U- and V- axes after rotation
 * of an angle of \`a: GD8Constant\` are the vectors \`(uX(a), uY(a))\`
 * and \`(vX(a), vY(a))\`. These aren't necessarily unit vectors.
 *
 * **Origin:**<br>
 *  This is the small part of gameofbombs.com portal system. It works.
 * @see maths.groupD8.E
 * @see maths.groupD8.SE
 * @see maths.groupD8.S
 * @see maths.groupD8.SW
 * @see maths.groupD8.W
 * @see maths.groupD8.NW
 * @see maths.groupD8.N
 * @see maths.groupD8.NE
 * @author Ivan @ivanpopelyshev
 * @namespace maths.groupD8
 */
export declare const groupD8: {
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 0°       | East      |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    E: number;
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 45°↻     | Southeast |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    SE: number;
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 90°↻     | South     |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    S: number;
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 135°↻    | Southwest |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    SW: number;
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 180°     | West      |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    W: number;
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -135°/225°↻ | Northwest    |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    NW: number;
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -90°/270°↻  | North        |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    N: number;
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -45°/315°↻  | Northeast    |
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    NE: number;
    /**
     * Reflection about Y-axis.
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    MIRROR_VERTICAL: number;
    /**
     * Reflection about the main diagonal.
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    MAIN_DIAGONAL: number;
    /**
     * Reflection about X-axis.
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    MIRROR_HORIZONTAL: number;
    /**
     * Reflection about reverse diagonal.
     * @memberof maths.groupD8
     * @constant {GD8Symmetry}
     */
    REVERSE_DIAGONAL: number;
    /**
     * @memberof maths.groupD8
     * @param {GD8Symmetry} ind - sprite rotation angle.
     * @returns {GD8Symmetry} The X-component of the U-axis
     *    after rotating the axes.
     */
    uX: (ind: GD8Symmetry) => GD8Symmetry;
    /**
     * @memberof maths.groupD8
     * @param {GD8Symmetry} ind - sprite rotation angle.
     * @returns {GD8Symmetry} The Y-component of the U-axis
     *    after rotating the axes.
     */
    uY: (ind: GD8Symmetry) => GD8Symmetry;
    /**
     * @memberof maths.groupD8
     * @param {GD8Symmetry} ind - sprite rotation angle.
     * @returns {GD8Symmetry} The X-component of the V-axis
     *    after rotating the axes.
     */
    vX: (ind: GD8Symmetry) => GD8Symmetry;
    /**
     * @memberof maths.groupD8
     * @param {GD8Symmetry} ind - sprite rotation angle.
     * @returns {GD8Symmetry} The Y-component of the V-axis
     *    after rotating the axes.
     */
    vY: (ind: GD8Symmetry) => GD8Symmetry;
    /**
     * @memberof maths.groupD8
     * @param {GD8Symmetry} rotation - symmetry whose opposite
     *   is needed. Only rotations have opposite symmetries while
     *   reflections don't.
     * @returns {GD8Symmetry} The opposite symmetry of \`rotation\`
     */
    inv: (rotation: GD8Symmetry) => GD8Symmetry;
    /**
     * Composes the two D8 operations.
     *
     * Taking \`^\` as reflection:
     *
     * |       | E=0 | S=2 | W=4 | N=6 | E^=8 | S^=10 | W^=12 | N^=14 |
     * |-------|-----|-----|-----|-----|------|-------|-------|-------|
     * | E=0   | E   | S   | W   | N   | E^   | S^    | W^    | N^    |
     * | S=2   | S   | W   | N   | E   | S^   | W^    | N^    | E^    |
     * | W=4   | W   | N   | E   | S   | W^   | N^    | E^    | S^    |
     * | N=6   | N   | E   | S   | W   | N^   | E^    | S^    | W^    |
     * | E^=8  | E^  | N^  | W^  | S^  | E    | N     | W     | S     |
     * | S^=10 | S^  | E^  | N^  | W^  | S    | E     | N     | W     |
     * | W^=12 | W^  | S^  | E^  | N^  | W    | S     | E     | N     |
     * | N^=14 | N^  | W^  | S^  | E^  | N    | W     | S     | E     |
     *
     * [This is a Cayley table]{@link https://en.wikipedia.org/wiki/Cayley_table}
     * @memberof maths.groupD8
     * @param {GD8Symmetry} rotationSecond - Second operation, which
     *   is the row in the above cayley table.
     * @param {GD8Symmetry} rotationFirst - First operation, which
     *   is the column in the above cayley table.
     * @returns {GD8Symmetry} Composed operation
     */
    add: (rotationSecond: GD8Symmetry, rotationFirst: GD8Symmetry) => GD8Symmetry;
    /**
     * Reverse of \`add\`.
     * @memberof maths.groupD8
     * @param {GD8Symmetry} rotationSecond - Second operation
     * @param {GD8Symmetry} rotationFirst - First operation
     * @returns {GD8Symmetry} Result
     */
    sub: (rotationSecond: GD8Symmetry, rotationFirst: GD8Symmetry) => GD8Symmetry;
    /**
     * Adds 180 degrees to rotation, which is a commutative
     * operation.
     * @memberof maths.groupD8
     * @param {number} rotation - The number to rotate.
     * @returns {number} Rotated number
     */
    rotate180: (rotation: number) => number;
    /**
     * Checks if the rotation angle is vertical, i.e. south
     * or north. It doesn't work for reflections.
     * @memberof maths.groupD8
     * @param {GD8Symmetry} rotation - The number to check.
     * @returns {boolean} Whether or not the direction is vertical
     */
    isVertical: (rotation: GD8Symmetry) => boolean;
    /**
     * Approximates the vector \`V(dx,dy)\` into one of the
     * eight directions provided by \`groupD8\`.
     * @memberof maths.groupD8
     * @param {number} dx - X-component of the vector
     * @param {number} dy - Y-component of the vector
     * @returns {GD8Symmetry} Approximation of the vector into
     *  one of the eight symmetries.
     */
    byDirection: (dx: number, dy: number) => GD8Symmetry;
    /**
     * Helps sprite to compensate texture packer rotation.
     * @memberof maths.groupD8
     * @param {Matrix} matrix - sprite world matrix
     * @param {GD8Symmetry} rotation - The rotation factor to use.
     * @param {number} tx - sprite anchoring
     * @param {number} ty - sprite anchoring
     */
    matrixAppendRotationInv: (matrix: Matrix, rotation: GD8Symmetry, tx?: number, ty?: number) => void;
};
export {};
`,Zo=`/**
 * Defines a size with a width and a height.
 * @memberof maths
 */
export interface Size {
    /** The width. */
    width: number;
    /** The height. */
    height: number;
}
`,ea=`/**
 * Two Pi.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const PI_2: number;
/**
 * Conversion factor for converting radians to degrees.
 * @static
 * @member {number} RAD_TO_DEG
 * @memberof maths
 */
export declare const RAD_TO_DEG: number;
/**
 * Conversion factor for converting degrees to radians.
 * @static
 * @member {number}
 * @memberof maths
 */
export declare const DEG_TO_RAD: number;
/**
 * Constants that identify shapes, mainly to prevent \`instanceof\` calls.
 * @memberof maths
 */
export type SHAPE_PRIMITIVE = 'polygon' | 'rectangle' | 'circle' | 'ellipse' | 'triangle' | 'roundedRectangle';
/**
 * The \`maths\` folder contains utility classes and functions for mathematical operations used throughout the project.
 * This includes constants such as conversion factors for radians and degrees, as well as shapes such as polygons,
 * rectangles, circles, ellipses, triangles, and rounded rectangles.
 * \`\`\`js
 * import { RAD_TO_DEG, Circle } from 'pixi.js';
 *
 * // Convert 180 degrees to radians
 * const radians = 180 * RAD_TO_DEG;
 *
 * // test if a point is inside a circle
 * const isPointInCircle = new Circle(0, 0, 10).contains(0, 0); // true
 * \`\`\`
 * @namespace maths
 */
`,na=`/**
 * Rounds to next power of two.
 * @function nextPow2
 * @param {number} v - input value
 * @returns {number} - next rounded power of two
 * @memberof maths
 */
export declare function nextPow2(v: number): number;
/**
 * Checks if a number is a power of two.
 * @function isPow2
 * @param {number} v - input value
 * @returns {boolean} \`true\` if value is power of two
 * @memberof maths
 */
export declare function isPow2(v: number): boolean;
/**
 * Computes ceil of log base 2
 * @function log2
 * @param {number} v - input value
 * @returns {number} logarithm base 2
 * @memberof maths
 */
export declare function log2(v: number): number;
`,ta=`export declare function squaredDistanceToLineSegment(x: number, y: number, x1: number, y1: number, x2: number, y2: number): number;
`,ra=`import type { PointData } from './PointData';
import type { PointLike } from './PointLike';
export interface ObservablePoint extends PixiMixins.ObservablePoint {
}
/**
 * Observer used to listen for observable point changes.
 * @memberof maths
 */
export interface Observer<T> {
    /** Callback to call when the point has updated. */
    _onUpdate: (point?: T) => void;
}
/**
 * The ObservablePoint object represents a location in a two-dimensional coordinate system, where \`x\` represents
 * the position on the horizontal axis and \`y\` represents the position on the vertical axis.
 *
 * An \`ObservablePoint\` is a point that triggers the \`onUpdate\` method on an observer when the point's position is changed.
 * @memberof maths
 */
export declare class ObservablePoint implements PointLike {
    /** @ignore */
    _x: number;
    /** @ignore */
    _y: number;
    /** This object used to call the \`onUpdate\` callback when the point changes. */
    private readonly _observer;
    /**
     * Creates a new \`ObservablePoint\`
     * @param observer - Observer to pass to listen for change events.
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=0] - position of the point on the y axis
     */
    constructor(observer: Observer<ObservablePoint>, x?: number, y?: number);
    /**
     * Creates a clone of this point.
     * @param observer - Optional observer to pass to the new observable point.
     * @returns a copy of this observable point
     */
    clone(observer?: Observer<ObservablePoint>): ObservablePoint;
    /**
     * Sets the point to a new \`x\` and \`y\` position.
     * If \`y\` is omitted, both \`x\` and \`y\` will be set to \`x\`.
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=x] - position of the point on the y axis
     * @returns The observable point instance itself
     */
    set(x?: number, y?: number): this;
    /**
     * Copies x and y from the given point (\`p\`)
     * @param p - The point to copy from. Can be any of type that is or extends \`PointData\`
     * @returns The observable point instance itself
     */
    copyFrom(p: PointData): this;
    /**
     * Copies this point's x and y into that of the given point (\`p\`)
     * @param p - The point to copy to. Can be any of type that is or extends \`PointData\`
     * @returns The point (\`p\`) with values updated
     */
    copyTo<T extends PointLike>(p: T): T;
    /**
     * Accepts another point (\`p\`) and returns \`true\` if the given point is equal to this point
     * @param p - The point to check
     * @returns Returns \`true\` if both \`x\` and \`y\` are equal
     */
    equals(p: PointData): boolean;
    toString(): string;
    /** Position of the observable point on the x axis. */
    get x(): number;
    set x(value: number);
    /** Position of the observable point on the y axis. */
    get y(): number;
    set y(value: number);
}
`,oa=`import type { PointData } from './PointData';
import type { PointLike } from './PointLike';
export interface Point extends PixiMixins.Point {
}
/**
 * The Point object represents a location in a two-dimensional coordinate system, where \`x\` represents
 * the position on the horizontal axis and \`y\` represents the position on the vertical axis.
 * <br/>
 * Many Pixi functions accept the \`PointData\` type as an alternative to \`Point\`,
 * which only requires \`x\` and \`y\` properties.
 * @class
 * @implements {PointLike}
 * @memberof maths
 */
export declare class Point implements PointLike {
    /** Position of the point on the x axis */
    x: number;
    /** Position of the point on the y axis */
    y: number;
    /**
     * Creates a new \`Point\`
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=0] - position of the point on the y axis
     */
    constructor(x?: number, y?: number);
    /**
     * Creates a clone of this point
     * @returns A clone of this point
     */
    clone(): Point;
    /**
     * Copies \`x\` and \`y\` from the given point into this point
     * @param p - The point to copy from
     * @returns The point instance itself
     */
    copyFrom(p: PointData): this;
    /**
     * Copies this point's x and y into the given point (\`p\`).
     * @param p - The point to copy to. Can be any of type that is or extends \`PointData\`
     * @returns The point (\`p\`) with values updated
     */
    copyTo<T extends PointLike>(p: T): T;
    /**
     * Accepts another point (\`p\`) and returns \`true\` if the given point is equal to this point
     * @param p - The point to check
     * @returns Returns \`true\` if both \`x\` and \`y\` are equal
     */
    equals(p: PointData): boolean;
    /**
     * Sets the point to a new \`x\` and \`y\` position.
     * If \`y\` is omitted, both \`x\` and \`y\` will be set to \`x\`.
     * @param {number} [x=0] - position of the point on the \`x\` axis
     * @param {number} [y=x] - position of the point on the \`y\` axis
     * @returns The point instance itself
     */
    set(x?: number, y?: number): this;
    toString(): string;
    /**
     * A static Point object with \`x\` and \`y\` values of \`0\`. Can be used to avoid creating new objects multiple times.
     * @readonly
     */
    static get shared(): Point;
}
`,aa=`/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointData {
    /** X coord */
    x: number;
    /** Y coord */
    y: number;
}
`,ia=`import type { PointData } from './PointData';
/**
 * Common interface for points. Both Point and ObservablePoint implement it
 * @memberof maths
 */
export interface PointLike extends PointData {
    /**
     * Copies x and y from the given point
     * @param {PointData} p - The point to copy from
     * @returns {this} Returns itself.
     */
    copyFrom: (p: PointData) => this;
    /**
     * Copies x and y into the given point
     * @param {PointLike} p - The point to copy.
     * @returns {PointLike} Given point with values updated
     */
    copyTo: <T extends PointLike>(p: T) => T;
    /**
     * Returns true if the given point is equal to this point
     * @param {PointData} p - The point to check
     * @returns {boolean} Whether the given point equal to this point
     */
    equals: (p: PointData) => boolean;
    /**
     * Sets the point to a new x and y position.
     * If y is omitted, both x and y will be set to x.
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=x] - position of the point on the y axis
     */
    set: (x?: number, y?: number) => void;
}
`,sa=`/**
 * Check if a point is inside a triangle.
 * @param px - x coordinate of the point
 * @param py - y coordinate of the point
 * @param x1 - x coordinate of the first vertex of the triangle
 * @param y1 - y coordinate of the first vertex of the triangle
 * @param x2 - x coordinate of the second vertex of the triangle
 * @param y2 - y coordinate of the second vertex of the triangle
 * @param x3 - x coordinate of the third vertex of the triangle
 * @param y3 - y coordinate of the third vertex of the triangle
 * @returns \`true\` if the point is inside the triangle, \`false\` otherwise
 */
export declare function pointInTriangle(px: number, py: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): boolean;
`,la=`import { Rectangle } from './Rectangle';
import type { SHAPE_PRIMITIVE } from '../misc/const';
import type { ShapePrimitive } from './ShapePrimitive';
/**
 * The Circle object is used to help draw graphics and can also be used to specify a hit area for containers.
 * @memberof maths
 */
export declare class Circle implements ShapePrimitive {
    /**
     * The X coordinate of the center of this circle
     * @default 0
     */
    x: number;
    /**
     * The Y coordinate of the center of this circle
     * @default 0
     */
    y: number;
    /**
     * The radius of the circle
     *  @default 0
     */
    radius: number;
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'circle'
     */
    readonly type: SHAPE_PRIMITIVE;
    /**
     * @param x - The X coordinate of the center of this circle
     * @param y - The Y coordinate of the center of this circle
     * @param radius - The radius of the circle
     */
    constructor(x?: number, y?: number, radius?: number);
    /**
     * Creates a clone of this Circle instance
     * @returns A copy of the Circle
     */
    clone(): Circle;
    /**
     * Checks whether the x and y coordinates given are contained within this circle
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @returns Whether the x/y coordinates are within this Circle
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this circle including the stroke.
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @param width - The width of the line to check
     * @param alignment - The alignment of the stroke, 0.5 by default
     * @returns Whether the x/y coordinates are within this Circle
     */
    strokeContains(x: number, y: number, width: number, alignment?: number): boolean;
    /**
     * Returns the framing rectangle of the circle as a Rectangle object
     * @param out
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
    /**
     * Copies another circle to this one.
     * @param circle - The circle to copy from.
     * @returns Returns itself.
     */
    copyFrom(circle: Circle): this;
    /**
     * Copies this circle to another one.
     * @param circle - The circle to copy to.
     * @returns Returns given parameter.
     */
    copyTo(circle: Circle): Circle;
    toString(): string;
}
`,da=`import { Rectangle } from './Rectangle';
import type { ShapePrimitive } from './ShapePrimitive';
/**
 * The Ellipse object is used to help draw graphics and can also be used to specify a hit area for containers.
 * \`\`\`js
 * import { Ellipse } from 'pixi.js';
 *
 * const ellipse = new Ellipse(0, 0, 20, 10); // 40x20 rectangle
 * const isPointInEllipse = ellipse.contains(0, 0); // true
 * \`\`\`
 * @memberof maths
 */
export declare class Ellipse implements ShapePrimitive {
    /**
     * The X coordinate of the center of this ellipse
     * @default 0
     */
    x: number;
    /**
     * The Y coordinate of the center of this ellipse
     * @default 0
     */
    y: number;
    /**
     * The half width of this ellipse
     * @default 0
     */
    halfWidth: number;
    /**
     * The half height of this ellipse
     * @default 0
     */
    halfHeight: number;
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'ellipse'
     */
    readonly type = "ellipse";
    /**
     * @param x - The X coordinate of the center of this ellipse
     * @param y - The Y coordinate of the center of this ellipse
     * @param halfWidth - The half width of this ellipse
     * @param halfHeight - The half height of this ellipse
     */
    constructor(x?: number, y?: number, halfWidth?: number, halfHeight?: number);
    /**
     * Creates a clone of this Ellipse instance
     * @returns {Ellipse} A copy of the ellipse
     */
    clone(): Ellipse;
    /**
     * Checks whether the x and y coordinates given are contained within this ellipse
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @returns Whether the x/y coords are within this ellipse
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this ellipse including stroke
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @param strokeWidth - The width of the line to check
     * @param alignment - The alignment of the stroke
     * @returns Whether the x/y coords are within this ellipse
     */
    strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
    /**
     * Returns the framing rectangle of the ellipse as a Rectangle object
     * @param out
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
    /**
     * Copies another ellipse to this one.
     * @param ellipse - The ellipse to copy from.
     * @returns Returns itself.
     */
    copyFrom(ellipse: Ellipse): this;
    /**
     * Copies this ellipse to another one.
     * @param ellipse - The ellipse to copy to.
     * @returns Returns given parameter.
     */
    copyTo(ellipse: Ellipse): Ellipse;
    toString(): string;
}
`,pa=`import { Rectangle } from './Rectangle';
import type { SHAPE_PRIMITIVE } from '../misc/const';
import type { PointData } from '../point/PointData';
import type { ShapePrimitive } from './ShapePrimitive';
/**
 * A class to define a shape via user defined coordinates.
 *
 *
 * \`Polygon\` can accept the following different constructor arguments:
 * - An array of \`Point\` objects
 * - An array of coordinate pairs
 *
 *
 * These can be passed as a single array, or as a sequence of arguments.
 * \`\`\`js
 * import { Polygon } from 'pixi.js';
 *
 * // create a polygon object from an array of points, or an array of coordinate pairs
 * const polygon1 = new Polygon([ new Point(0, 0), new Point(0, 100), new Point(100, 100) ]);
 * const polygon2 = new Polygon([ 0, 0, 0, 100, 100, 100 ]);
 *
 * // or create a polygon object from a sequence of points, or coordinate pairs
 * const polygon3 = new Polygon(new Point(0, 0), new Point(0, 100), new Point(100, 100));
 * const polygon4 = new Polygon(0, 0, 0, 100, 100, 100);
 * \`\`\`
 * @memberof maths
 */
export declare class Polygon implements ShapePrimitive {
    /** An array of the points of this polygon. */
    points: number[];
    /** \`false\` after moveTo, \`true\` after \`closePath\`. In all other cases it is \`true\`. */
    closePath: boolean;
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'polygon'
     */
    readonly type: SHAPE_PRIMITIVE;
    constructor(points: PointData[] | number[]);
    constructor(...points: PointData[] | number[]);
    /**
     * Determines whether the polygon's points are arranged in a clockwise direction.
     * This is calculated using the "shoelace formula" (also known as surveyor's formula) to find the signed area.
     * A positive area indicates clockwise winding, while negative indicates counter-clockwise.
     *
     * The formula sums up the cross products of adjacent vertices:
     * For each pair of adjacent points (x1,y1) and (x2,y2), we calculate (x1*y2 - x2*y1)
     * The final sum divided by 2 gives the signed area - positive for clockwise.
     * @returns \`true\` if the polygon's points are arranged clockwise, \`false\` if counter-clockwise
     */
    isClockwise(): boolean;
    /**
     * Checks if this polygon completely contains another polygon.
     *
     * This is useful for detecting holes in shapes, like when parsing SVG paths.
     * For example, if you have two polygons:
     * \`\`\`ts
     * const outerSquare = new Polygon([0,0, 100,0, 100,100, 0,100]); // A square
     * const innerSquare = new Polygon([25,25, 75,25, 75,75, 25,75]); // A smaller square inside
     *
     * outerSquare.containsPolygon(innerSquare); // Returns true
     * innerSquare.containsPolygon(outerSquare); // Returns false
     * \`\`\`
     * @param polygon - The polygon to test for containment
     * @returns True if this polygon completely contains the other polygon
     */
    containsPolygon(polygon: Polygon): boolean;
    /**
     * Creates a clone of this polygon.
     * @returns - A copy of the polygon.
     */
    clone(): Polygon;
    /**
     * Checks whether the x and y coordinates passed to this function are contained within this polygon.
     * @param x - The X coordinate of the point to test.
     * @param y - The Y coordinate of the point to test.
     * @returns - Whether the x/y coordinates are within this polygon.
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this polygon including the stroke.
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @param strokeWidth - The width of the line to check
     * @param alignment - The alignment of the stroke, 0.5 by default
     * @returns Whether the x/y coordinates are within this polygon
     */
    strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
    /**
     * Returns the framing rectangle of the polygon as a Rectangle object
     * @param out - optional rectangle to store the result
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
    /**
     * Copies another polygon to this one.
     * @param polygon - The polygon to copy from.
     * @returns Returns itself.
     */
    copyFrom(polygon: Polygon): this;
    /**
     * Copies this polygon to another one.
     * @param polygon - The polygon to copy to.
     * @returns Returns given parameter.
     */
    copyTo(polygon: Polygon): Polygon;
    toString(): string;
    /**
     * Get the last X coordinate of the polygon
     * @readonly
     */
    get lastX(): number;
    /**
     * Get the last Y coordinate of the polygon
     * @readonly
     */
    get lastY(): number;
    /**
     * Get the first X coordinate of the polygon
     * @readonly
     */
    get x(): number;
    /**
     * Get the first Y coordinate of the polygon
     * @readonly
     */
    get y(): number;
}
`,ca=`import type { Bounds } from '../../scene/container/bounds/Bounds';
import type { Matrix } from '../matrix/Matrix';
import type { SHAPE_PRIMITIVE } from '../misc/const';
import type { ShapePrimitive } from './ShapePrimitive';
export interface Rectangle extends PixiMixins.Rectangle {
}
/**
 * The \`Rectangle\` object is an area defined by its position, as indicated by its top-left corner
 * point (\`x\`, \`y\`) and by its \`width\` and its \`height\`.
 *
 * It also provides convenience methods to get and set the position and size of the rectangle such as
 * {@link maths.Rectangle#bottom|bottom}, {@link maths.Rectangle#right|right} and {@link maths.Rectangle#isEmpty|isEmpty}.
 * @memberof maths
 */
export declare class Rectangle implements ShapePrimitive {
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'rectangle'
     */
    readonly type: SHAPE_PRIMITIVE;
    /**
     * The X coordinate of the upper-left corner of the rectangle
     * @default 0
     */
    x: number;
    /**
     * The Y coordinate of the upper-left corner of the rectangle
     * @default 0
     */
    y: number;
    /**
     * The overall width of this rectangle
     *  @default 0
     */
    width: number;
    /**
     * The overall height of this rectangle
     * @default 0
     */
    height: number;
    /**
     * @param x - The X coordinate of the upper-left corner of the rectangle
     * @param y - The Y coordinate of the upper-left corner of the rectangle
     * @param width - The overall width of the rectangle
     * @param height - The overall height of the rectangle
     */
    constructor(x?: string | number, y?: string | number, width?: string | number, height?: string | number);
    /** Returns the left edge of the rectangle. */
    get left(): number;
    /** Returns the right edge of the rectangle. */
    get right(): number;
    /** Returns the top edge of the rectangle. */
    get top(): number;
    /** Returns the bottom edge of the rectangle. */
    get bottom(): number;
    /** Determines whether the Rectangle is empty. */
    isEmpty(): boolean;
    /** A constant empty rectangle. This is a new object every time the property is accessed */
    static get EMPTY(): Rectangle;
    /**
     * Creates a clone of this Rectangle
     * @returns a copy of the rectangle
     */
    clone(): Rectangle;
    /**
     * Converts a Bounds object to a Rectangle object.
     * @param bounds - The bounds to copy and convert to a rectangle.
     * @returns Returns itself.
     */
    copyFromBounds(bounds: Bounds): this;
    /**
     * Copies another rectangle to this one.
     * @param rectangle - The rectangle to copy from.
     * @returns Returns itself.
     */
    copyFrom(rectangle: Rectangle): Rectangle;
    /**
     * Copies this rectangle to another one.
     * @param rectangle - The rectangle to copy to.
     * @returns Returns given parameter.
     */
    copyTo(rectangle: Rectangle): Rectangle;
    /**
     * Checks whether the x and y coordinates given are contained within this Rectangle
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @returns Whether the x/y coordinates are within this Rectangle
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this rectangle including the stroke.
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @param strokeWidth - The width of the line to check
     * @param alignment - The alignment of the stroke, 0.5 by default
     * @returns Whether the x/y coordinates are within this rectangle
     */
    strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
    /**
     * Determines whether the \`other\` Rectangle transformed by \`transform\` intersects with \`this\` Rectangle object.
     * Returns true only if the area of the intersection is >0, this means that Rectangles
     * sharing a side are not overlapping. Another side effect is that an arealess rectangle
     * (width or height equal to zero) can't intersect any other rectangle.
     * @param {Rectangle} other - The Rectangle to intersect with \`this\`.
     * @param {Matrix} transform - The transformation matrix of \`other\`.
     * @returns {boolean} A value of \`true\` if the transformed \`other\` Rectangle intersects with \`this\`; otherwise \`false\`.
     */
    intersects(other: Rectangle, transform?: Matrix): boolean;
    /**
     * Pads the rectangle making it grow in all directions.
     * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
     * @param paddingX - The horizontal padding amount.
     * @param paddingY - The vertical padding amount.
     * @returns Returns itself.
     */
    pad(paddingX?: number, paddingY?: number): this;
    /**
     * Fits this rectangle around the passed one.
     * @param rectangle - The rectangle to fit.
     * @returns Returns itself.
     */
    fit(rectangle: Rectangle): this;
    /**
     * Enlarges rectangle that way its corners lie on grid
     * @param resolution - resolution
     * @param eps - precision
     * @returns Returns itself.
     */
    ceil(resolution?: number, eps?: number): this;
    /**
     * Enlarges this rectangle to include the passed rectangle.
     * @param rectangle - The rectangle to include.
     * @returns Returns itself.
     */
    enlarge(rectangle: Rectangle): this;
    /**
     * Returns the framing rectangle of the rectangle as a Rectangle object
     * @param out - optional rectangle to store the result
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
    /**
     * Checks if this rectangle fully contains another rectangle.
     *
     * A rectangle contains another rectangle if all four corners of the other rectangle
     * lie within the bounds of this rectangle.
     *
     * \`\`\`ts
     * const container = new Rectangle(0, 0, 100, 100);
     * const inside = new Rectangle(25, 25, 50, 50);
     * const partial = new Rectangle(75, 75, 50, 50);
     *
     * container.containsRect(inside); // Returns true
     * container.containsRect(partial); // Returns false - partial overlap
     * \`\`\`
     *
     * Note: If either rectangle has a width or height of 0, this method returns false
     * since a zero-area rectangle cannot meaningfully contain another rectangle.
     * @param other - The rectangle to check if it is contained within this one
     * @returns True if the other rectangle is fully contained within this one
     */
    containsRect(other: Rectangle): boolean;
    toString(): string;
}
`,ua=`import { Rectangle } from './Rectangle';
import type { ShapePrimitive } from './ShapePrimitive';
/**
 * The \`RoundedRectangle\` object is an area defined by its position, as indicated by its top-left corner
 * point (\`x\`, \`y\`) and by its \`width\` and its \`height\`, including a \`radius\` property that
 * defines the radius of the rounded corners.
 * @memberof maths
 */
export declare class RoundedRectangle implements ShapePrimitive {
    /**
     * The X coordinate of the upper-left corner of the rounded rectangle
     * @default 0
     */
    x: number;
    /**
     * The Y coordinate of the upper-left corner of the rounded rectangle
     * @default 0
     */
    y: number;
    /**
     * The overall width of this rounded rectangle
     * @default 0
     */
    width: number;
    /**
     * The overall height of this rounded rectangle
     * @default 0
     */
    height: number;
    /**
     * Controls the radius of the rounded corners
     * @default 20
     */
    radius: number;
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'roundedRectangle'
     */
    readonly type = "roundedRectangle";
    /**
     * @param x - The X coordinate of the upper-left corner of the rounded rectangle
     * @param y - The Y coordinate of the upper-left corner of the rounded rectangle
     * @param width - The overall width of this rounded rectangle
     * @param height - The overall height of this rounded rectangle
     * @param radius - Controls the radius of the rounded corners
     */
    constructor(x?: number, y?: number, width?: number, height?: number, radius?: number);
    /**
     * Returns the framing rectangle of the rounded rectangle as a Rectangle object
     * @param out - optional rectangle to store the result
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
    /**
     * Creates a clone of this Rounded Rectangle.
     * @returns - A copy of the rounded rectangle.
     */
    clone(): RoundedRectangle;
    /**
     * Copies another rectangle to this one.
     * @param rectangle - The rectangle to copy from.
     * @returns Returns itself.
     */
    copyFrom(rectangle: RoundedRectangle): this;
    /**
     * Copies this rectangle to another one.
     * @param rectangle - The rectangle to copy to.
     * @returns Returns given parameter.
     */
    copyTo(rectangle: RoundedRectangle): RoundedRectangle;
    /**
     * Checks whether the x and y coordinates given are contained within this Rounded Rectangle
     * @param x - The X coordinate of the point to test.
     * @param y - The Y coordinate of the point to test.
     * @returns - Whether the x/y coordinates are within this Rounded Rectangle.
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this rectangle including the stroke.
     * @param pX - The X coordinate of the point to test
     * @param pY - The Y coordinate of the point to test
     * @param strokeWidth - The width of the line to check
     * @param alignment - The alignment of the stroke, 0.5 by default
     * @returns Whether the x/y coordinates are within this rectangle
     */
    strokeContains(pX: number, pY: number, strokeWidth: number, alignment?: number): boolean;
    toString(): string;
}
`,ma=`import type { SHAPE_PRIMITIVE } from '../misc/const';
import type { Rectangle } from './Rectangle';
/**
 * A basic object to define a Pixi shape.
 * @memberof maths
 */
export interface ShapePrimitive {
    /** The type of the object, mainly used to avoid \`instanceof\` checks */
    readonly type: SHAPE_PRIMITIVE;
    /** Checks whether the x and y coordinates passed to this function are contained within this ShapePrimitive. */
    contains(x: number, y: number): boolean;
    /** Checks whether the x and y coordinates passed to this function are contained within the stroke of this shape */
    strokeContains(x: number, y: number, strokeWidth: number, alignment?: number): boolean;
    /** Creates a clone of this ShapePrimitive instance. */
    clone(): ShapePrimitive;
    /** Copies the properties from another ShapePrimitive to this ShapePrimitive. */
    copyFrom(source: ShapePrimitive): void;
    /** Copies the properties from this ShapePrimitive to another ShapePrimitive. */
    copyTo(destination: ShapePrimitive): void;
    /** Returns the framing rectangle of the ShapePrimitive as a Rectangle object. */
    getBounds(out?: Rectangle): Rectangle;
    /** The X coordinate of the shape */
    readonly x: number;
    /** The Y coordinate of the shape */
    readonly y: number;
}
`,ha=`import { Rectangle } from './Rectangle';
import type { SHAPE_PRIMITIVE } from '../misc/const';
import type { ShapePrimitive } from './ShapePrimitive';
/**
 * A class to define a shape of a triangle via user defined coordinates.
 *
 * Create a \`Triangle\` object with the \`x\`, \`y\`, \`x2\`, \`y2\`, \`x3\`, \`y3\` properties.
 *
 * \`\`\`js
 * import { Triangle } from 'pixi.js';
 *
 * const triangle = new Triangle(0, 0, 100, 0, 50, 50);
 * \`\`\`
 * @memberof maths
 */
export declare class Triangle implements ShapePrimitive {
    /**
     * The type of the object, mainly used to avoid \`instanceof\` checks
     * @default 'triangle'
     */
    readonly type: SHAPE_PRIMITIVE;
    /**
     * The X coord of the first point.
     * @default 0
     */
    x: number;
    /**
     * The Y coord of the first point.
     * @default 0
     */
    y: number;
    /**
     * The X coord of the second point.
     * @default 0
     */
    x2: number;
    /**
     * The Y coord of the second point.
     * @default 0
     */
    y2: number;
    /**
     * The X coord of the third point.
     * @default 0
     */
    x3: number;
    /**
     * The Y coord of the third point.
     * @default 0
     */
    y3: number;
    /**
     * @param x - The X coord of the first point.
     * @param y - The Y coord of the first point.
     * @param x2 - The X coord of the second point.
     * @param y2 - The Y coord of the second point.
     * @param x3 - The X coord of the third point.
     * @param y3 - The Y coord of the third point.
     */
    constructor(x?: number, y?: number, x2?: number, y2?: number, x3?: number, y3?: number);
    /**
     * Checks whether the x and y coordinates given are contained within this triangle
     * @param x - The X coordinate of the point to test
     * @param y - The Y coordinate of the point to test
     * @returns Whether the x/y coordinates are within this Triangle
     */
    contains(x: number, y: number): boolean;
    /**
     * Checks whether the x and y coordinates given are contained within this triangle including the stroke.
     * @param pointX - The X coordinate of the point to test
     * @param pointY - The Y coordinate of the point to test
     * @param strokeWidth - The width of the line to check
     * @param _alignment - The alignment of the stroke
     * @returns Whether the x/y coordinates are within this triangle
     */
    strokeContains(pointX: number, pointY: number, strokeWidth: number, _alignment?: number): boolean;
    /**
     * Creates a clone of this Triangle
     * @returns a copy of the triangle
     */
    clone(): ShapePrimitive;
    /**
     * Copies another triangle to this one.
     * @param triangle - The triangle to copy from.
     * @returns Returns itself.
     */
    copyFrom(triangle: Triangle): this;
    /**
     * Copies this triangle to another one.
     * @param triangle - The triangle to copy to.
     * @returns Returns given parameter.
     */
    copyTo(triangle: Triangle): Triangle;
    /**
     * Returns the framing rectangle of the triangle as a Rectangle object
     * @param out - optional rectangle to store the result
     * @returns The framing rectangle
     */
    getBounds(out?: Rectangle): Rectangle;
}
`,fa=`import { Container } from '../scene/container/Container';
import type { TextureSource } from '../rendering/renderers/shared/texture/sources/TextureSource';
import type { Texture } from '../rendering/renderers/shared/texture/Texture';
import type { Renderer } from '../rendering/renderers/types';
import type { GraphicsContext } from '../scene/graphics/shared/GraphicsContext';
import type { Text } from '../scene/text/Text';
/** The accepted types to pass to the prepare system */
export type PrepareSourceItem = Container | TextureSource | Texture | GraphicsContext;
/** The valid types resolved to the queue ready for upload */
export type PrepareQueueItem = TextureSource | Text | GraphicsContext;
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class provides the base functionality and handles processing the queue asynchronously.
 * @memberof rendering
 */
export declare abstract class PrepareBase {
    /** The number of uploads to process per frame */
    static uploadsPerFrame: number;
    /** Reference to the renderer */
    protected renderer: Renderer;
    /** The queue to process over a async timer */
    protected queue: PrepareQueueItem[];
    /** Collection of callbacks to call when the uploads are finished */
    protected resolves: ((value: void | PromiseLike<void>) => void)[];
    /** Timeout id for next processing call */
    protected timeout?: number;
    /**
     * @param {rendering.Renderer} renderer - A reference to the current renderer
     */
    constructor(renderer: Renderer);
    /** Resolve the given resource type and return an item for the queue */
    protected abstract resolveQueueItem(source: PrepareSourceItem, queue: PrepareQueueItem[]): void;
    protected abstract uploadQueueItem(item: PrepareQueueItem): void;
    /**
     * Return a copy of the queue
     * @returns {PrepareQueueItem[]} The queue
     */
    getQueue(): PrepareQueueItem[];
    /**
     * Add a textures or graphics resource to the queue
     * @param {PrepareSourceItem | PrepareSourceItem[]} resource
     */
    add(resource: PrepareSourceItem | PrepareSourceItem[]): this;
    /**
     * Recursively add a container and its children to the queue
     * @param {Container} container - The container to add to the queue
     */
    private _addContainer;
    /**
     * Upload all the textures and graphics to the GPU (optionally add more resources to the queue first)
     * @param {PrepareSourceItem | PrepareSourceItem[] | undefined} resource
     */
    upload(resource?: PrepareSourceItem | PrepareSourceItem[]): Promise<void>;
    /** eliminate duplicates before processing */
    dedupeQueue(): void;
    /** called per frame by the ticker, defer processing to next tick */
    private readonly _tick;
    /** process the queue up to max item limit per frame */
    private readonly _processQueue;
    /** Call all the resolve callbacks */
    private _resolve;
}
`,ba=`declare global
{
    namespace PixiMixins
    {
        interface RendererSystems
        {
            prepare: import('./PrepareBase').PrepareBase;
        }
    }
}

export {};
`,ga=`import { Container } from '../scene/container/Container';
import { GraphicsContext } from '../scene/graphics/shared/GraphicsContext';
import { PrepareBase } from './PrepareBase';
import type { PrepareQueueItem, PrepareSourceItem } from './PrepareBase';
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class extends the base functionality and resolves given resource items ready for the queue.
 * @memberof rendering
 */
export declare abstract class PrepareQueue extends PrepareBase {
    /**
     * Resolve the given resource type and return an item for the queue
     * @param source
     * @param queue
     */
    protected resolveQueueItem(source: PrepareSourceItem, queue: PrepareQueueItem[]): void;
    /**
     * Resolve the given container and return an item for the queue
     * @param container
     * @param queue
     */
    protected resolveContainerQueueItem(container: Container, queue: PrepareQueueItem[]): void;
    /**
     * Resolve the given graphics context and return an item for the queue
     * @param graphicsContext
     */
    protected resolveGraphicsContextQueueItem(graphicsContext: GraphicsContext): PrepareQueueItem | null;
}
`,ya=`import { ExtensionType } from '../extensions/Extensions';
import { PrepareUpload } from './PrepareUpload';
import type { System } from '../rendering/renderers/shared/system/System';
/**
 * The prepare system provides renderer-specific plugins for pre-rendering DisplayObjects. This is useful for
 * asynchronously preparing and uploading to the GPU assets, textures, graphics waiting to be displayed.
 *
 * Do not instantiate this plugin directly. It is available from the \`renderer.prepare\` property.
 * @example
 * import 'pixi.js/prepare';
 * import { Application, Graphics } from 'pixi.js';
 *
 * // Create a new application (prepare will be auto-added to renderer)
 * const app = new Application();
 * await app.init();
 * document.body.appendChild(app.view);
 *
 * // Don't start rendering right away
 * app.stop();
 *
 * // Create a display object
 * const rect = new Graphics()
 *     .beginFill(0x00ff00)
 *     .drawRect(40, 40, 200, 200);
 *
 * // Add to the stage
 * app.stage.addChild(rect);
 *
 * // Don't start rendering until the graphic is uploaded to the GPU
 * app.renderer.prepare.upload(app.stage, () => {
 *     app.start();
 * });
 * @memberof rendering
 */
export declare class PrepareSystem extends PrepareUpload implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "prepare";
    };
    /** Destroys the plugin, don't use after this. */
    destroy(): void;
}
`,xa=`import { TextureSource } from '../rendering/renderers/shared/texture/sources/TextureSource';
import { GraphicsContext } from '../scene/graphics/shared/GraphicsContext';
import { Text } from '../scene/text/Text';
import { BitmapText } from '../scene/text-bitmap/BitmapText';
import { HTMLText } from '../scene/text-html/HTMLText';
import { PrepareQueue } from './PrepareQueue';
import type { PrepareQueueItem } from './PrepareBase';
/**
 * Part of the prepare system. Responsible for uploading all the items to the GPU.
 * This class extends the resolver functionality and uploads the given queue items.
 * @memberof rendering
 */
export declare abstract class PrepareUpload extends PrepareQueue {
    /**
     * Upload the given queue item
     * @param item
     */
    protected uploadQueueItem(item: PrepareQueueItem): void;
    protected uploadTextureSource(textureSource: TextureSource): void;
    protected uploadText(_text: Text): void;
    protected uploadBitmapText(_text: BitmapText): void;
    protected uploadHTMLText(_text: HTMLText): void;
    /**
     * Resolve the given graphics context and return an item for the queue
     * @param graphicsContext
     */
    protected uploadGraphicsContext(graphicsContext: GraphicsContext): void;
}
`,va=`export * from './PrepareBase';
export * from './PrepareQueue';
export * from './PrepareSystem';
export * from './PrepareUpload';
`,Ta=`export {};
`,Sa=`declare global
{
    namespace PixiMixins
    {

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface ICanvas
        {

        }

        interface RendererOptions
        {
            resolution?: number;
            failIfMajorPerformanceCaveat?: boolean;
            roundPixels?: boolean;
        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGLOptions
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGPUOptions
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface RendererSystems
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGLSystems
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGPUSystems
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface CanvasSystems
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface RendererPipes
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGLPipes
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface WebGPUPipes
        {

        }

        // eslint-disable-next-line @typescript-eslint/no-empty-object-type
        interface CanvasPipes
        {

        }
    }
}

export {};
`,wa=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Geometry } from '../../renderers/shared/geometry/Geometry';
import type { Shader } from '../../renderers/shared/shader/Shader';
import type { Batch } from '../shared/Batcher';
import type { BatcherAdaptor, BatcherPipe } from '../shared/BatcherPipe';
/**
 * A BatcherAdaptor that uses WebGL to render batches.
 * @memberof rendering
 * @ignore
 */
export declare class GlBatchAdaptor implements BatcherAdaptor {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipesAdaptor];
        readonly name: "batch";
    };
    private readonly _tempState;
    /**
     * We only want to sync the a batched shaders uniforms once on first use
     * this is a hash of shader uids to a boolean value.  When the shader is first bound
     * we set the value to true.  When the shader is bound again we check the value and
     * if it is true we know that the uniforms have already been synced and we skip it.
     */
    private _didUploadHash;
    init(batcherPipe: BatcherPipe): void;
    contextChange(): void;
    start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
    execute(batchPipe: BatcherPipe, batch: Batch): void;
}
`,_a=`import type { GlRenderingContext } from '../../../renderers/gl/context/GlRenderingContext';
export declare function checkMaxIfStatementsInShader(maxIfs: number, gl: GlRenderingContext): number;
`,Ea=`/**
 * Returns the maximum number of textures that can be batched. This uses WebGL1's \`MAX_TEXTURE_IMAGE_UNITS\`.
 * The response for this is that to get this info via WebGPU, we would need to make a context, which
 * would make this function async, and we want to avoid that.
 * @private
 * @returns {number} The maximum number of textures that can be batched
 */
export declare function getMaxTexturesPerBatch(): number;
`,Pa=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Geometry } from '../../renderers/shared/geometry/Geometry';
import type { Shader } from '../../renderers/shared/shader/Shader';
import type { Batch } from '../shared/Batcher';
import type { BatcherAdaptor, BatcherPipe } from '../shared/BatcherPipe';
/**
 * A BatcherAdaptor that uses the GPU to render batches.
 * @memberof rendering
 * @ignore
 */
export declare class GpuBatchAdaptor implements BatcherAdaptor {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUPipesAdaptor];
        readonly name: "batch";
    };
    private _shader;
    private _geometry;
    start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
    execute(batchPipe: BatcherPipe, batch: Batch): void;
}
`,Aa=`/// <reference types="@webgpu/types" />
export declare function generateGPULayout(maxTextures: number): GPUBindGroupLayoutEntry[];
`,Ca=`export declare function generateLayout(maxTextures: number): Record<string, number>;
`,Ra=`import { BindGroup } from '../../renderers/gpu/shader/BindGroup';
import type { TextureSource } from '../../renderers/shared/texture/sources/TextureSource';
export declare function getTextureBatchBindGroup(textures: TextureSource[], size: number): BindGroup;
`,Ga=`import { Geometry } from '../../renderers/shared/geometry/Geometry';
export declare class BatchGeometry extends Geometry {
    constructor();
}
`,Ma=`import type { TextureSource } from '../../renderers/shared/texture/sources/TextureSource';
/**
 * Used by the batcher to build texture batches. Holds list of textures and their respective locations.
 * @memberof rendering
 */
export declare class BatchTextureArray {
    /** Inside textures array. */
    textures: TextureSource[];
    /** Respective locations for textures. */
    ids: Record<number, number>;
    /** Number of filled elements. */
    count: number;
    constructor();
    /** Clear the textures and their locations. */
    clear(): void;
}
`,ka=`/// <reference types="@webgpu/types" />
import { ViewableBuffer } from '../../../utils/data/ViewableBuffer';
import { type BLEND_MODES } from '../../renderers/shared/state/const';
import { BatchTextureArray } from './BatchTextureArray';
import type { BoundsData } from '../../../scene/container/bounds/Bounds';
import type { BindGroup } from '../../renderers/gpu/shader/BindGroup';
import type { Topology } from '../../renderers/shared/geometry/const';
import type { Geometry, IndexBufferArray } from '../../renderers/shared/geometry/Geometry';
import type { Instruction } from '../../renderers/shared/instructions/Instruction';
import type { InstructionSet } from '../../renderers/shared/instructions/InstructionSet';
import type { Shader } from '../../renderers/shared/shader/Shader';
import type { Texture } from '../../renderers/shared/texture/Texture';
export type BatchAction = 'startBatch' | 'renderBatch';
/**
 * A batch pool is used to store batches when they are not currently in use.
 * @memberof rendering
 */
export declare class Batch implements Instruction {
    renderPipeId: string;
    action: BatchAction;
    start: number;
    size: number;
    textures: BatchTextureArray;
    blendMode: BLEND_MODES;
    topology: Topology;
    canBundle: boolean;
    /**
     * breaking rules slightly here in the name of performance..
     * storing references to these bindgroups here is just faster for access!
     * keeps a reference to the GPU bind group to set when rendering this batch for WebGPU. Will be null is using WebGL.
     */
    gpuBindGroup: GPUBindGroup;
    /**
     * breaking rules slightly here in the name of performance..
     * storing references to these bindgroups here is just faster for access!
     * keeps a reference to the bind group to set when rendering this batch for WebGPU. Will be null if using WebGl.
     */
    bindGroup: BindGroup;
    batcher: Batcher;
    destroy(): void;
}
/**
 * Represents an element that can be batched for rendering.
 * @interface
 * @memberof rendering
 */
export interface BatchableElement {
    /**
     * The name of the batcher to use. Must be registered.
     * @type {string}
     */
    batcherName: string;
    /**
     * The texture to be used for rendering.
     * @type {Texture}
     */
    texture: Texture;
    /**
     * The blend mode to be applied.
     * @type {BLEND_MODES}
     */
    blendMode: BLEND_MODES;
    /**
     * The size of the index data.
     * @type {number}
     */
    indexSize: number;
    /**
     * The size of the attribute data.
     * @type {number}
     */
    attributeSize: number;
    /**
     * The topology to be used for rendering.
     * @type {Topology}
     */
    topology: Topology;
    /**
     * Whether the element should be packed as a quad for better performance.
     * @type {boolean}
     */
    packAsQuad: boolean;
    /**
     * The texture ID, stored for efficient updating.
     * @type {number}
     * @private
     */
    _textureId: number;
    /**
     * The starting position in the attribute buffer.
     * @type {number}
     * @private
     */
    _attributeStart: number;
    /**
     * The starting position in the index buffer.
     * @type {number}
     * @private
     */
    _indexStart: number;
    /**
     * Reference to the batcher.
     * @type {Batcher}
     * @private
     */
    _batcher: Batcher;
    /**
     * Reference to the batch.
     * @type {Batch}
     * @private
     */
    _batch: Batch;
}
/**
 * Represents a batchable quad element.
 * @extends BatchableElement
 * @memberof rendering
 */
export interface BatchableQuadElement extends BatchableElement {
    /**
     * Indicates that this element should be packed as a quad.
     * @type {true}
     */
    packAsQuad: true;
    /**
     * The size of the attribute data for this quad element.
     * @type {4}
     */
    attributeSize: 4;
    /**
     * The size of the index data for this quad element.
     * @type {6}
     */
    indexSize: 6;
    /**
     * The bounds data for this quad element.
     * @type {BoundsData}
     */
    bounds: BoundsData;
}
/**
 * Represents a batchable mesh element.
 * @extends BatchableElement
 * @memberof rendering
 */
export interface BatchableMeshElement extends BatchableElement {
    /**
     * The UV coordinates of the mesh.
     * @type {number[] | Float32Array}
     */
    uvs: number[] | Float32Array;
    /**
     * The vertex positions of the mesh.
     * @type {number[] | Float32Array}
     */
    positions: number[] | Float32Array;
    /**
     * The indices of the mesh.
     * @type {number[] | Uint16Array | Uint32Array}
     */
    indices: number[] | Uint16Array | Uint32Array;
    /**
     * The offset in the index buffer.
     * @type {number}
     */
    indexOffset: number;
    /**
     * The offset in the attribute buffer.
     * @type {number}
     */
    attributeOffset: number;
    /**
     * Indicates that this element should not be packed as a quad.
     * @type {false}
     */
    packAsQuad: false;
}
/**
 * The options for the batcher.
 * @memberof rendering
 */
export interface BatcherOptions {
    /** The maximum number of textures per batch. */
    maxTextures?: number;
    attributesInitialSize?: number;
    indicesInitialSize?: number;
}
/**
 * A batcher is used to batch together objects with the same texture.
 * It is an abstract class that must be extended. see DefaultBatcher for an example.
 * @memberof rendering
 */
export declare abstract class Batcher {
    static defaultOptions: Partial<BatcherOptions>;
    /** unique id for this batcher */
    readonly uid: number;
    /** The buffer containing attribute data for all elements in the batch. */
    attributeBuffer: ViewableBuffer;
    /** The buffer containing index data for all elements in the batch. */
    indexBuffer: IndexBufferArray;
    /** The current size of the attribute data in the batch. */
    attributeSize: number;
    /** The current size of the index data in the batch. */
    indexSize: number;
    /** The total number of elements currently in the batch. */
    elementSize: number;
    /** The starting index of elements in the current batch. */
    elementStart: number;
    /** Indicates whether the batch data has been modified and needs updating. */
    dirty: boolean;
    /** The current index of the batch being processed. */
    batchIndex: number;
    /** An array of all batches created during the current rendering process. */
    batches: Batch[];
    private _elements;
    private _batchIndexStart;
    private _batchIndexSize;
    /** The maximum number of textures per batch. */
    readonly maxTextures: number;
    /** The name of the batcher. Must be implemented by subclasses. */
    abstract name: string;
    /** The vertex size of the batcher. Must be implemented by subclasses. */
    protected abstract vertexSize: number;
    /** The geometry used by this batcher. Must be implemented by subclasses. */
    abstract geometry: Geometry;
    /**
     * The shader used by this batcher. Must be implemented by subclasses.
     * this can be shared by multiple batchers of the same type.
     */
    abstract shader: Shader;
    /**
     * Packs the attributes of a BatchableMeshElement into the provided views.
     * Must be implemented by subclasses.
     * @param element - The BatchableMeshElement to pack.
     * @param float32View - The Float32Array view to pack into.
     * @param uint32View - The Uint32Array view to pack into.
     * @param index - The starting index in the views.
     * @param textureId - The texture ID to use.
     */
    abstract packAttributes(element: BatchableMeshElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
    /**
     * Packs the attributes of a BatchableQuadElement into the provided views.
     * Must be implemented by subclasses.
     * @param element - The BatchableQuadElement to pack.
     * @param float32View - The Float32Array view to pack into.
     * @param uint32View - The Uint32Array view to pack into.
     * @param index - The starting index in the views.
     * @param textureId - The texture ID to use.
     */
    abstract packQuadAttributes(element: BatchableQuadElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
    constructor(options?: BatcherOptions);
    begin(): void;
    add(batchableObject: BatchableElement): void;
    checkAndUpdateTexture(batchableObject: BatchableElement, texture: Texture): boolean;
    updateElement(batchableObject: BatchableElement): void;
    /**
     * breaks the batcher. This happens when a batch gets too big,
     * or we need to switch to a different type of rendering (a filter for example)
     * @param instructionSet
     */
    break(instructionSet: InstructionSet): void;
    private _finishBatch;
    finish(instructionSet: InstructionSet): void;
    /**
     * Resizes the attribute buffer to the given size (1 = 1 float32)
     * @param size - the size in vertices to ensure (not bytes!)
     */
    ensureAttributeBuffer(size: number): void;
    /**
     * Resizes the index buffer to the given size (1 = 1 float32)
     * @param size - the size in vertices to ensure (not bytes!)
     */
    ensureIndexBuffer(size: number): void;
    private _resizeAttributeBuffer;
    private _resizeIndexBuffer;
    packQuadIndex(indexBuffer: IndexBufferArray, index: number, indicesOffset: number): void;
    packIndex(element: BatchableMeshElement, indexBuffer: IndexBufferArray, index: number, indicesOffset: number): void;
    destroy(): void;
}
`,Fa=`import { ExtensionType } from '../../../extensions/Extensions';
import { State } from '../../renderers/shared/state/State';
import type { Geometry } from '../../renderers/shared/geometry/Geometry';
import type { InstructionSet } from '../../renderers/shared/instructions/InstructionSet';
import type { BatchPipe, InstructionPipe } from '../../renderers/shared/instructions/RenderPipe';
import type { Shader } from '../../renderers/shared/shader/Shader';
import type { Renderer } from '../../renderers/types';
import type { Batch, BatchableElement, Batcher } from './Batcher';
export interface BatcherAdaptor {
    start(batchPipe: BatcherPipe, geometry: Geometry, shader: Shader): void;
    init?(batchPipe: BatcherPipe): void;
    execute(batchPipe: BatcherPipe, batch: Batch): void;
    contextChange?(): void;
}
/**
 * A pipe that batches elements into batches and sends them to the renderer.
 *
 * You can install new Batchers using ExtensionType.Batcher. Each render group will
 * have a default batcher and any required ones will be created on demand.
 * @memberof rendering
 */
export declare class BatcherPipe implements InstructionPipe<Batch>, BatchPipe {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "batch";
    };
    state: State;
    renderer: Renderer;
    private readonly _batchersByInstructionSet;
    private _adaptor;
    /** A record of all active batchers, keyed by their names */
    private _activeBatches;
    /** The currently active batcher being used to batch elements */
    private _activeBatch;
    static _availableBatchers: Record<string, new () => Batcher>;
    static getBatcher(name: string): Batcher;
    constructor(renderer: Renderer, adaptor: BatcherAdaptor);
    buildStart(instructionSet: InstructionSet): void;
    addToBatch(batchableObject: BatchableElement, instructionSet: InstructionSet): void;
    break(instructionSet: InstructionSet): void;
    buildEnd(instructionSet: InstructionSet): void;
    upload(instructionSet: InstructionSet): void;
    execute(batch: Batch): void;
    destroy(): void;
}
`,Oa=`import { ExtensionType } from '../../../extensions/Extensions';
import { Batcher } from './Batcher';
import { BatchGeometry } from './BatchGeometry';
import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Shader } from '../../renderers/shared/shader/Shader';
import type { BatchableMeshElement, BatchableQuadElement } from './Batcher';
/**
 * Represents the common elements for default batch rendering.
 * This interface defines the properties that are used by the DefaultBatcher
 * to render elements efficiently in a batch.
 * @memberof rendering
 */
export interface DefaultBatchElements {
    /**
     * The color of the element that will be multiplied with the texture color.
     * This is typically represented as a 32-bit integer in RGBA format.
     */
    color: number;
    /**
     * Determines whether the element should be rounded to the nearest pixel.
     * - 0: No rounding (default)
     * - 1: Round to nearest pixel
     * This can help with visual consistency, especially for pixel art styles.
     */
    roundPixels: 0 | 1;
    /**
     * The transform matrix of the element.
     * This matrix represents the position, scale, rotation, and skew of the element.
     */
    transform: Matrix;
}
/**
 * Represents a batchable quad element with default batch properties.
 * @memberof rendering
 */
export interface DefaultBatchableQuadElement extends BatchableQuadElement, DefaultBatchElements {
}
/**
 * Represents a batchable mesh element with default batch properties.
 * @memberof rendering
 */
export interface DefaultBatchableMeshElement extends BatchableMeshElement, DefaultBatchElements {
}
/**
 * The default batcher is used to batch quads and meshes. This batcher will batch the following elements:
 * - tints
 * - roundPixels
 * - texture
 * - transform
 * @memberof rendering
 */
export declare class DefaultBatcher extends Batcher {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.Batcher];
        readonly name: "default";
    };
    geometry: BatchGeometry;
    shader: Shader;
    name: "default";
    /** The size of one attribute. 1 = 32 bit. x, y, u, v, color, textureIdAndRound -> total = 6 */
    vertexSize: number;
    /**
     * Packs the attributes of a DefaultBatchableMeshElement into the provided views.
     * @param element - The DefaultBatchableMeshElement to pack.
     * @param float32View - The Float32Array view to pack into.
     * @param uint32View - The Uint32Array view to pack into.
     * @param index - The starting index in the views.
     * @param textureId - The texture ID to use.
     */
    packAttributes(element: DefaultBatchableMeshElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
    /**
     * Packs the attributes of a DefaultBatchableQuadElement into the provided views.
     * @param element - The DefaultBatchableQuadElement to pack.
     * @param float32View - The Float32Array view to pack into.
     * @param uint32View - The Uint32Array view to pack into.
     * @param index - The starting index in the views.
     * @param textureId - The texture ID to use.
     */
    packQuadAttributes(element: DefaultBatchableQuadElement, float32View: Float32Array, uint32View: Uint32Array, index: number, textureId: number): void;
}
`,Ia=`import { Shader } from '../../renderers/shared/shader/Shader';
/**
 * DefaultShader is a specialized shader class designed for batch rendering.
 * It extends the base Shader class and provides functionality for handling
 * color, texture batching, and pixel rounding in both WebGL and WebGPU contexts.
 *
 * It is used by the default batcher
 * @extends Shader
 * @memberof rendering
 */
export declare class DefaultShader extends Shader {
    constructor(maxTextures: number);
}
`,La=`import { GlProgram } from '../renderers/gl/shader/GlProgram';
import { GpuProgram } from '../renderers/gpu/shader/GpuProgram';
import type { HighShaderBit } from './compiler/types';
export declare function compileHighShaderGpuProgram({ bits, name }: {
    bits: HighShaderBit[];
    name: string;
}): GpuProgram;
export declare function compileHighShaderGlProgram({ bits, name }: {
    bits: HighShaderBit[];
    name: string;
}): GlProgram;
`,Ba=`import type { HighShaderBit, HighShaderSource } from './types';
/** A high template consists of vertex and fragment source */
export interface HighShaderTemplate {
    name?: string;
    fragment: string;
    vertex: string;
}
export interface CompileHighShaderOptions {
    template: HighShaderTemplate;
    bits: HighShaderBit[];
}
/**
 * This function will take a HighShader template, some High fragments and then merge them in to a shader source.
 * @param options
 * @param options.template
 * @param options.bits
 */
export declare function compileHighShader({ template, bits }: CompileHighShaderOptions): HighShaderSource;
export declare function compileHighShaderGl({ template, bits }: CompileHighShaderOptions): HighShaderSource;
`,Da=`/** the vertex source code, an obj */
export type Vertex = {
    /** stick uniforms and functions in here all headers will be compiled at the top of the shader */
    header?: string;
    /** code will be added at the start of the shader */
    start?: string;
    /** code will be run here before lighting happens */
    main?: string;
    /** code here will to modify anything before it is passed to the fragment shader */
    end?: string;
};
export type Fragment = {
    /** stick uniforms and functions in here all headers will be compiled at the top of the shader */
    header?: string;
    /** code will be added at the start of the shader */
    start?: string;
    /** code will be run here before lighting happens */
    main?: string;
    /** code here will to modify anything before it is passed to the fragment shader */
    end?: string;
};
/**
 * HighShaderBit is a part of a shader.
 * it is used to compile HighShaders.
 *
 * Internally shaders are made up of many of these.
 * You can even write your own and compile them in.
 */
export interface HighShaderBit {
    /** used to make the shader easier to understand! */
    name?: string;
    /** the snippets of vertex code */
    vertex?: Vertex;
    /** the snippets of fragment code */
    fragment?: Fragment;
}
/** source code to compile a shader. this can be directly used by pixi and should be good to go! */
export interface HighShaderSource {
    fragment: string;
    vertex: string;
}
`,Ua=`/**
 * takes the HighFragment source parts and adds them to the hook hash
 * @param srcParts - the hash of hook arrays
 * @param parts - the code to inject into the hooks
 * @param name - optional the name of the part to add
 */
export declare function addBits(srcParts: Record<string, string>, parts: Record<string, string[]>, name?: string): void;
`,ja=`export declare const findHooksRx: RegExp;
/**
 * takes a program string and returns an hash mapping the hooks to empty arrays
 * @param programSrc - the program containing hooks
 */
export declare function compileHooks(programSrc: string): Record<string, string[]>;
`,Wa=`export declare function compileInputs(fragments: any[], template: string, sort?: boolean): string;
`,Ha=`export declare function compileOutputs(fragments: any[], template: string): string;
`,Va=`/**
 * formats a shader so its more pleasant to read!
 * @param shader - a glsl shader program source
 */
export declare function formatShader(shader: string): string;
`,Na=`/**
 * takes a shader src and replaces any hooks with the HighFragment code.
 * @param templateSrc - the program src template
 * @param fragmentParts - the fragments to inject
 */
export declare function injectBits(templateSrc: string, fragmentParts: Record<string, string[]>): string;
`,za=`declare const vertexGPUTemplate = "\\n    @in aPosition: vec2<f32>;\\n    @in aUV: vec2<f32>;\\n\\n    @out @builtin(position) vPosition: vec4<f32>;\\n    @out vUV : vec2<f32>;\\n    @out vColor : vec4<f32>;\\n\\n    {{header}}\\n\\n    struct VSOutput {\\n        {{struct}}\\n    };\\n\\n    @vertex\\n    fn main( {{in}} ) -> VSOutput {\\n\\n        var worldTransformMatrix = globalUniforms.uWorldTransformMatrix;\\n        var modelMatrix = mat3x3<f32>(\\n            1.0, 0.0, 0.0,\\n            0.0, 1.0, 0.0,\\n            0.0, 0.0, 1.0\\n          );\\n        var position = aPosition;\\n        var uv = aUV;\\n\\n        {{start}}\\n        \\n        vColor = vec4<f32>(1., 1., 1., 1.);\\n\\n        {{main}}\\n\\n        vUV = uv;\\n\\n        var modelViewProjectionMatrix = globalUniforms.uProjectionMatrix * worldTransformMatrix * modelMatrix;\\n\\n        vPosition =  vec4<f32>((modelViewProjectionMatrix *  vec3<f32>(position, 1.0)).xy, 0.0, 1.0);\\n       \\n        vColor *= globalUniforms.uWorldColorAlpha;\\n\\n        {{end}}\\n\\n        {{return}}\\n    };\\n";
declare const fragmentGPUTemplate = "\\n    @in vUV : vec2<f32>;\\n    @in vColor : vec4<f32>;\\n   \\n    {{header}}\\n\\n    @fragment\\n    fn main(\\n        {{in}}\\n      ) -> @location(0) vec4<f32> {\\n        \\n        {{start}}\\n\\n        var outColor:vec4<f32>;\\n      \\n        {{main}}\\n        \\n        var finalColor:vec4<f32> = outColor * vColor;\\n\\n        {{end}}\\n\\n        return finalColor;\\n      };\\n";
declare const vertexGlTemplate = "\\n    in vec2 aPosition;\\n    in vec2 aUV;\\n\\n    out vec4 vColor;\\n    out vec2 vUV;\\n\\n    {{header}}\\n\\n    void main(void){\\n\\n        mat3 worldTransformMatrix = uWorldTransformMatrix;\\n        mat3 modelMatrix = mat3(\\n            1.0, 0.0, 0.0,\\n            0.0, 1.0, 0.0,\\n            0.0, 0.0, 1.0\\n          );\\n        vec2 position = aPosition;\\n        vec2 uv = aUV;\\n        \\n        {{start}}\\n        \\n        vColor = vec4(1.);\\n        \\n        {{main}}\\n        \\n        vUV = uv;\\n        \\n        mat3 modelViewProjectionMatrix = uProjectionMatrix * worldTransformMatrix * modelMatrix;\\n\\n        gl_Position = vec4((modelViewProjectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\\n\\n        vColor *= uWorldColorAlpha;\\n\\n        {{end}}\\n    }\\n";
declare const fragmentGlTemplate = "\\n   \\n    in vec4 vColor;\\n    in vec2 vUV;\\n\\n    out vec4 finalColor;\\n\\n    {{header}}\\n\\n    void main(void) {\\n        \\n        {{start}}\\n\\n        vec4 outColor;\\n      \\n        {{main}}\\n        \\n        finalColor = outColor * vColor;\\n        \\n        {{end}}\\n    }\\n";
export { fragmentGlTemplate, fragmentGPUTemplate, vertexGlTemplate, vertexGPUTemplate };
`,Xa=`export declare const colorBit: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
};
export declare const colorBitGl: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
};
`,Ka=`import type { HighShaderBit } from '../compiler/types';
export declare function generateTextureBatchBit(maxTextures: number): HighShaderBit;
export declare function generateTextureBatchBitGl(maxTextures: number): HighShaderBit;
`,qa=`export declare const globalUniformsBit: {
    name: string;
    vertex: {
        header: string;
    };
};
export declare const globalUniformsUBOBitGl: {
    name: string;
    vertex: {
        header: string;
    };
};
export declare const globalUniformsBitGl: {
    name: string;
    vertex: {
        header: string;
    };
};
`,Ya=`export declare const localUniformBit: {
    name: string;
    vertex: {
        header: string;
        main: string;
        end: string;
    };
};
export declare const localUniformBitGroup2: {
    vertex: {
        header: string;
        main: string;
        end: string;
    };
    name: string;
};
export declare const localUniformBitGl: {
    name: string;
    vertex: {
        header: string;
        main: string;
        end: string;
    };
};
`,Ja=`export declare const roundPixelsBit: {
    name: string;
    vertex: {
        header: string;
    };
};
export declare const roundPixelsBitGl: {
    name: string;
    vertex: {
        header: string;
    };
};
`,$a=`export declare const textureBit: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
export declare const textureBitGl: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
`,Qa=`export * from './batcher/gl/GlBatchAdaptor';
export * from './batcher/gl/utils/checkMaxIfStatementsInShader';
export * from './batcher/gl/utils/maxRecommendedTextures';
export * from './batcher/gpu/generateGPULayout';
export * from './batcher/gpu/generateLayout';
export * from './batcher/gpu/getTextureBatchBindGroup';
export * from './batcher/gpu/GpuBatchAdaptor';
export * from './batcher/shared/Batcher';
export * from './batcher/shared/BatcherPipe';
export * from './batcher/shared/BatchGeometry';
export * from './batcher/shared/BatchTextureArray';
export * from './batcher/shared/DefaultBatcher';
export * from './batcher/shared/DefaultShader';
export * from './high-shader/compileHighShaderToProgram';
export * from './high-shader/compiler/compileHighShader';
export * from './high-shader/compiler/types';
export * from './high-shader/compiler/utils/addBits';
export * from './high-shader/compiler/utils/compileHooks';
export * from './high-shader/compiler/utils/compileInputs';
export * from './high-shader/compiler/utils/compileOutputs';
export * from './high-shader/compiler/utils/formatShader';
export * from './high-shader/compiler/utils/injectBits';
export * from './high-shader/defaultProgramTemplate';
export * from './high-shader/shader-bits/colorBit';
export * from './high-shader/shader-bits/generateTextureBatchBit';
export * from './high-shader/shader-bits/globalUniformsBit';
export * from './high-shader/shader-bits/localUniformBit';
export * from './high-shader/shader-bits/roundPixelsBit';
export * from './high-shader/shader-bits/textureBit';
export * from './mask/alpha/AlphaMask';
export * from './mask/alpha/AlphaMaskPipe';
export * from './mask/color/ColorMask';
export * from './mask/color/ColorMaskPipe';
export * from './mask/MaskEffectManager';
export * from './mask/scissor/ScissorMask';
export * from './mask/stencil/StencilMask';
export * from './mask/stencil/StencilMaskPipe';
export * from './mask/utils/addMaskBounds';
export * from './mask/utils/addMaskLocalBounds';
export * from './renderers/autoDetectRenderer';
export * from './renderers/gl/buffer/const';
export * from './renderers/gl/buffer/GlBuffer';
export * from './renderers/gl/buffer/GlBufferSystem';
export * from './renderers/gl/const';
export * from './renderers/gl/context/GlContextSystem';
export * from './renderers/gl/context/GlRenderingContext';
export * from './renderers/gl/context/WebGLExtensions';
export * from './renderers/gl/geometry/GlGeometrySystem';
export * from './renderers/gl/geometry/utils/getGlTypeFromFormat';
export * from './renderers/gl/GlBackBufferSystem';
export * from './renderers/gl/GlColorMaskSystem';
export * from './renderers/gl/GlEncoderSystem';
export * from './renderers/gl/GlRenderTarget';
export * from './renderers/gl/GlStencilSystem';
export * from './renderers/gl/GlUboSystem';
export * from './renderers/gl/renderTarget/GlRenderTargetAdaptor';
export * from './renderers/gl/renderTarget/GlRenderTargetSystem';
export * from './renderers/gl/shader/const';
export * from './renderers/gl/shader/GenerateShaderSyncCode';
export * from './renderers/gl/shader/getBatchSamplersUniformGroup';
export * from './renderers/gl/shader/GlProgram';
export * from './renderers/gl/shader/GlProgramData';
export * from './renderers/gl/shader/GlShaderSystem';
export * from './renderers/gl/shader/GlUniformGroupSystem';
export * from './renderers/gl/shader/migrateFragmentFromV7toV8';
export * from './renderers/gl/shader/program/compileShader';
export * from './renderers/gl/shader/program/defaultValue';
export * from './renderers/gl/shader/program/ensureAttributes';
export * from './renderers/gl/shader/program/extractAttributesFromGlProgram';
export * from './renderers/gl/shader/program/generateProgram';
export * from './renderers/gl/shader/program/getMaxFragmentPrecision';
export * from './renderers/gl/shader/program/getTestContext';
export * from './renderers/gl/shader/program/getUboData';
export * from './renderers/gl/shader/program/getUniformData';
export * from './renderers/gl/shader/program/logProgramError';
export * from './renderers/gl/shader/program/mapSize';
export * from './renderers/gl/shader/program/mapType';
export * from './renderers/gl/shader/program/preprocessors/addProgramDefines';
export * from './renderers/gl/shader/program/preprocessors/ensurePrecision';
export * from './renderers/gl/shader/program/preprocessors/insertVersion';
export * from './renderers/gl/shader/program/preprocessors/setProgramName';
export * from './renderers/gl/shader/program/preprocessors/stripVersion';
export * from './renderers/gl/shader/utils/createUboElementsSTD40';
export * from './renderers/gl/shader/utils/createUboSyncSTD40';
export * from './renderers/gl/shader/utils/generateArraySyncSTD40';
export * from './renderers/gl/shader/utils/generateUniformsSync';
export * from './renderers/gl/shader/utils/generateUniformsSyncTypes';
export * from './renderers/gl/state/GlStateSystem';
export * from './renderers/gl/state/mapWebGLBlendModesToPixi';
export * from './renderers/gl/texture/const';
export * from './renderers/gl/texture/GlTexture';
export * from './renderers/gl/texture/GlTextureSystem';
export * from './renderers/gl/texture/uploaders/GLTextureUploader';
export * from './renderers/gl/texture/uploaders/glUploadBufferImageResource';
export * from './renderers/gl/texture/uploaders/glUploadCompressedTextureResource';
export * from './renderers/gl/texture/uploaders/glUploadImageResource';
export * from './renderers/gl/texture/uploaders/glUploadVideoResource';
export * from './renderers/gl/texture/utils/applyStyleParams';
export * from './renderers/gl/texture/utils/getSupportedGlCompressedTextureFormats';
export * from './renderers/gl/texture/utils/mapFormatToGlFormat';
export * from './renderers/gl/texture/utils/mapFormatToGlInternalFormat';
export * from './renderers/gl/texture/utils/mapFormatToGlType';
export * from './renderers/gl/texture/utils/pixiToGlMaps';
export * from './renderers/gl/texture/utils/unpremultiplyAlpha';
export * from './renderers/gl/WebGLRenderer';
export * from './renderers/gpu/BindGroupSystem';
export * from './renderers/gpu/buffer/GpuBufferSystem';
export * from './renderers/gpu/buffer/GpuReadBuffer';
export * from './renderers/gpu/buffer/UboBatch';
export * from './renderers/gpu/GpuColorMaskSystem';
export * from './renderers/gpu/GpuDeviceSystem';
export * from './renderers/gpu/GpuEncoderSystem';
export * from './renderers/gpu/GpuStencilSystem';
export * from './renderers/gpu/GpuUboSystem';
export * from './renderers/gpu/GpuUniformBatchPipe';
export * from './renderers/gpu/pipeline/PipelineSystem';
export * from './renderers/gpu/renderTarget/calculateProjection';
export * from './renderers/gpu/renderTarget/GpuRenderTarget';
export * from './renderers/gpu/renderTarget/GpuRenderTargetAdaptor';
export * from './renderers/gpu/renderTarget/GpuRenderTargetSystem';
export * from './renderers/gpu/shader/BindGroup';
export * from './renderers/gpu/shader/BindResource';
export * from './renderers/gpu/shader/GpuProgram';
export * from './renderers/gpu/shader/GpuShaderSystem';
export * from './renderers/gpu/shader/utils/createUboElementsWGSL';
export * from './renderers/gpu/shader/utils/createUboSyncFunctionWGSL';
export * from './renderers/gpu/shader/utils/extractAttributesFromGpuProgram';
export * from './renderers/gpu/shader/utils/extractStructAndGroups';
export * from './renderers/gpu/shader/utils/generateArraySyncWGSL';
export * from './renderers/gpu/shader/utils/generateGpuLayoutGroups';
export * from './renderers/gpu/shader/utils/generateLayoutHash';
export * from './renderers/gpu/shader/utils/removeStructAndGroupDuplicates';
export * from './renderers/gpu/state/GpuBlendModesToPixi';
export * from './renderers/gpu/state/GpuStateSystem';
export * from './renderers/gpu/state/GpuStencilModesToPixi';
export * from './renderers/gpu/texture/GpuTextureSystem';
export * from './renderers/gpu/texture/uploaders/GpuTextureUploader';
export * from './renderers/gpu/texture/uploaders/gpuUploadBufferImageResource';
export * from './renderers/gpu/texture/uploaders/gpuUploadCompressedTextureResource';
export * from './renderers/gpu/texture/uploaders/gpuUploadImageSource';
export * from './renderers/gpu/texture/uploaders/gpuUploadVideoSource';
export * from './renderers/gpu/texture/utils/getSupportedGPUCompressedTextureFormats';
export * from './renderers/gpu/texture/utils/GpuMipmapGenerator';
export * from './renderers/gpu/WebGPURenderer';
export * from './renderers/shared/background/BackgroundSystem';
export * from './renderers/shared/blendModes/BlendModePipe';
export * from './renderers/shared/buffer/Buffer';
export * from './renderers/shared/buffer/BufferResource';
export * from './renderers/shared/buffer/const';
export * from './renderers/shared/buffer/utils/fastCopy';
export * from './renderers/shared/extract/ExtractSystem';
export * from './renderers/shared/extract/GenerateTextureSystem';
export * from './renderers/shared/geometry/const';
export * from './renderers/shared/geometry/Geometry';
export * from './renderers/shared/geometry/utils/buildUvs';
export * from './renderers/shared/geometry/utils/ensureIsBuffer';
export * from './renderers/shared/geometry/utils/getAttributeInfoFromFormat';
export * from './renderers/shared/geometry/utils/getGeometryBounds';
export * from './renderers/shared/geometry/utils/transformVertices';
export * from './renderers/shared/instructions/Instruction';
export * from './renderers/shared/instructions/InstructionSet';
export * from './renderers/shared/instructions/RenderPipe';
export * from './renderers/shared/Renderable';
export * from './renderers/shared/renderTarget/GlobalUniformSystem';
export * from './renderers/shared/renderTarget/isRenderingToScreen';
export * from './renderers/shared/renderTarget/RenderTarget';
export * from './renderers/shared/renderTarget/RenderTargetSystem';
export * from './renderers/shared/renderTarget/viewportFromFrame';
export * from './renderers/shared/SchedulerSystem';
export * from './renderers/shared/shader/const';
export * from './renderers/shared/shader/Shader';
export * from './renderers/shared/shader/ShaderSystem';
export * from './renderers/shared/shader/types';
export * from './renderers/shared/shader/UboSystem';
export * from './renderers/shared/shader/UniformGroup';
export * from './renderers/shared/shader/utils/createUboSyncFunction';
export * from './renderers/shared/shader/utils/getDefaultUniformValue';
export * from './renderers/shared/shader/utils/uboSyncFunctions';
export * from './renderers/shared/shader/utils/uniformParsers';
export * from './renderers/shared/startup/HelloSystem';
export * from './renderers/shared/state/const';
export * from './renderers/shared/state/getAdjustedBlendModeBlend';
export * from './renderers/shared/state/State';
export * from './renderers/shared/system/AbstractRenderer';
export * from './renderers/shared/system/SharedSystems';
export * from './renderers/shared/system/System';
export * from './renderers/shared/system/SystemRunner';
export * from './renderers/shared/system/utils/typeUtils';
export * from './renderers/shared/texture/CanvasPool';
export * from './renderers/shared/texture/const';
export * from './renderers/shared/texture/GenerateCanvas';
export * from './renderers/shared/texture/RenderableGCSystem';
export * from './renderers/shared/texture/RenderTexture';
export * from './renderers/shared/texture/sources/BufferImageSource';
export * from './renderers/shared/texture/sources/CanvasSource';
export * from './renderers/shared/texture/sources/CompressedSource';
export * from './renderers/shared/texture/sources/ImageSource';
export * from './renderers/shared/texture/sources/TextureSource';
export * from './renderers/shared/texture/sources/VideoSource';
export * from './renderers/shared/texture/Texture';
export * from './renderers/shared/texture/TextureGCSystem';
export * from './renderers/shared/texture/TextureMatrix';
export * from './renderers/shared/texture/TexturePool';
export * from './renderers/shared/texture/TextureStyle';
export * from './renderers/shared/texture/TextureUvs';
export * from './renderers/shared/texture/utils/generateUID';
export * from './renderers/shared/texture/utils/getCanvasTexture';
export * from './renderers/shared/texture/utils/getSupportedCompressedTextureFormats';
export * from './renderers/shared/texture/utils/getSupportedTextureFormats';
export * from './renderers/shared/texture/utils/textureFrom';
export * from './renderers/shared/utils/createIdFromString';
export * from './renderers/shared/utils/parseFunctionBody';
export * from './renderers/shared/view/View';
export * from './renderers/shared/view/ViewSystem';
export * from './renderers/types';
`,Za=`import './renderers/shared/texture/utils/textureFrom';
import './mask/MaskEffectManager';
`,ei=`import type { Effect, EffectConstructor } from '../../scene/container/Effect';
import type { PoolItem } from '../../utils/pool/Pool';
interface MaskConversionTest {
    test: (item: any) => boolean;
    maskClass: new (item: any) => Effect & PoolItem;
}
export type MaskEffect = {
    mask: unknown;
} & Effect;
/**
 * A class that manages the conversion of masks to mask effects.
 * @memberof rendering
 * @ignore
 */
export declare class MaskEffectManagerClass {
    /**
     * @private
     */
    readonly _effectClasses: EffectConstructor[];
    private readonly _tests;
    private _initialized;
    init(): void;
    add(test: MaskConversionTest): void;
    getMaskEffect(item: any): MaskEffect;
    returnMaskEffect(effect: Effect & PoolItem): void;
}
export declare const MaskEffectManager: MaskEffectManagerClass;
export {};
`,ni=`import type { ExtensionMetadata } from '../../../extensions/Extensions';
import type { Point } from '../../../maths/point/Point';
import type { Bounds } from '../../../scene/container/bounds/Bounds';
import type { Container } from '../../../scene/container/Container';
import type { Effect } from '../../../scene/container/Effect';
import type { PoolItem } from '../../../utils/pool/Pool';
export declare class AlphaMask implements Effect, PoolItem {
    static extension: ExtensionMetadata;
    priority: number;
    mask: Container;
    inverse: boolean;
    pipe: string;
    renderMaskToTexture: boolean;
    constructor(options?: {
        mask: Container;
    });
    init(mask: Container): void;
    reset(): void;
    addBounds(bounds: Bounds, skipUpdateTransform?: boolean): void;
    addLocalBounds(bounds: Bounds, localRoot: Container): void;
    containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
    destroy(): void;
    static test(mask: any): boolean;
}
`,ti=`import { ExtensionType } from '../../../extensions/Extensions';
import { FilterEffect } from '../../../filters/FilterEffect';
import { Sprite } from '../../../scene/sprite/Sprite';
import { Texture } from '../../renderers/shared/texture/Texture';
import type { Container } from '../../../scene/container/Container';
import type { Effect } from '../../../scene/container/Effect';
import type { PoolItem } from '../../../utils/pool/Pool';
import type { Instruction } from '../../renderers/shared/instructions/Instruction';
import type { InstructionSet } from '../../renderers/shared/instructions/InstructionSet';
import type { InstructionPipe } from '../../renderers/shared/instructions/RenderPipe';
import type { RenderTarget } from '../../renderers/shared/renderTarget/RenderTarget';
import type { Renderer } from '../../renderers/types';
import type { AlphaMask } from './AlphaMask';
type MaskMode = 'pushMaskBegin' | 'pushMaskEnd' | 'popMaskBegin' | 'popMaskEnd';
declare class AlphaMaskEffect extends FilterEffect implements PoolItem {
    constructor();
    get sprite(): Sprite;
    set sprite(value: Sprite);
    get inverse(): boolean;
    set inverse(value: boolean);
    init: () => void;
}
export interface AlphaMaskInstruction extends Instruction {
    renderPipeId: 'alphaMask';
    action: MaskMode;
    mask: AlphaMask;
    inverse: boolean;
    maskedContainer: Container;
    renderMask: boolean;
}
export interface AlphaMaskData {
    filterEffect: AlphaMaskEffect;
    maskedContainer: Container;
    previousRenderTarget?: RenderTarget;
    filterTexture?: Texture;
}
export declare class AlphaMaskPipe implements InstructionPipe<AlphaMaskInstruction> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "alphaMask";
    };
    private _renderer;
    private _activeMaskStage;
    constructor(renderer: Renderer);
    push(mask: Effect, maskedContainer: Container, instructionSet: InstructionSet): void;
    pop(mask: Effect, _maskedContainer: Container, instructionSet: InstructionSet): void;
    execute(instruction: AlphaMaskInstruction): void;
    destroy(): void;
}
export {};
`,ri=`import type { ExtensionMetadata } from '../../../extensions/Extensions';
import type { Effect } from '../../../scene/container/Effect';
import type { PoolItem } from '../../../utils/pool/Pool';
export declare class ColorMask implements Effect, PoolItem {
    static extension: ExtensionMetadata;
    priority: number;
    mask: number;
    pipe: string;
    constructor(options: {
        mask: number;
    });
    init(mask: number): void;
    destroy(): void;
    static test(mask: any): boolean;
}
`,oi=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Container } from '../../../scene/container/Container';
import type { Effect } from '../../../scene/container/Effect';
import type { Instruction } from '../../renderers/shared/instructions/Instruction';
import type { InstructionSet } from '../../renderers/shared/instructions/InstructionSet';
import type { InstructionPipe } from '../../renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../renderers/types';
export interface ColorMaskInstruction extends Instruction {
    renderPipeId: 'colorMask';
    colorMask: number;
}
export declare class ColorMaskPipe implements InstructionPipe<ColorMaskInstruction> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "colorMask";
    };
    private readonly _renderer;
    private _colorStack;
    private _colorStackIndex;
    private _currentColor;
    constructor(renderer: Renderer);
    buildStart(): void;
    push(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
    pop(_mask: Effect, _container: Container, instructionSet: InstructionSet): void;
    execute(instruction: ColorMaskInstruction): void;
    destroy(): void;
}
`,ai=`import type { Point } from '../../../maths/point/Point';
import type { Bounds } from '../../../scene/container/bounds/Bounds';
import type { Container } from '../../../scene/container/Container';
import type { Effect } from '../../../scene/container/Effect';
export declare class ScissorMask implements Effect {
    priority: number;
    mask: Container;
    pipe: string;
    constructor(mask: Container);
    addBounds(bounds: Bounds, skipUpdateTransform?: boolean): void;
    addLocalBounds(bounds: Bounds, localRoot: Container): void;
    containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
    reset(): void;
    destroy(): void;
}
`,ii=`import { Container } from '../../../scene/container/Container';
import type { ExtensionMetadata } from '../../../extensions/Extensions';
import type { Point } from '../../../maths/point/Point';
import type { Bounds } from '../../../scene/container/bounds/Bounds';
import type { Effect } from '../../../scene/container/Effect';
import type { PoolItem } from '../../../utils/pool/Pool';
export declare class StencilMask implements Effect, PoolItem {
    static extension: ExtensionMetadata;
    priority: number;
    mask: Container;
    pipe: string;
    constructor(options: {
        mask: Container;
    });
    init(mask: Container): void;
    reset(): void;
    addBounds(bounds: Bounds, skipUpdateTransform: boolean): void;
    addLocalBounds(bounds: Bounds, localRoot: Container): void;
    containsPoint(point: Point, hitTestFn: (container: Container, point: Point) => boolean): boolean;
    destroy(): void;
    static test(mask: any): boolean;
}
`,si=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Container } from '../../../scene/container/Container';
import type { Effect } from '../../../scene/container/Effect';
import type { Instruction } from '../../renderers/shared/instructions/Instruction';
import type { InstructionSet } from '../../renderers/shared/instructions/InstructionSet';
import type { InstructionPipe } from '../../renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../renderers/types';
import type { StencilMask } from './StencilMask';
type MaskMode = 'pushMaskBegin' | 'pushMaskEnd' | 'popMaskBegin' | 'popMaskEnd';
export interface StencilMaskInstruction extends Instruction {
    renderPipeId: 'stencilMask';
    action: MaskMode;
    inverse: boolean;
    mask: StencilMask;
}
export declare class StencilMaskPipe implements InstructionPipe<StencilMaskInstruction> {
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "stencilMask";
    };
    private _renderer;
    private _maskStackHash;
    private _maskHash;
    constructor(renderer: Renderer);
    push(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
    pop(mask: Effect, _container: Container, instructionSet: InstructionSet): void;
    execute(instruction: StencilMaskInstruction): void;
    destroy(): void;
}
export {};
`,li=`import { Bounds } from '../../../scene/container/bounds/Bounds';
import type { Container } from '../../../scene/container/Container';
export declare function addMaskBounds(mask: Container, bounds: Bounds, skipUpdateTransform: boolean): void;
`,di=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Bounds } from '../../../scene/container/bounds/Bounds';
import type { Container } from '../../../scene/container/Container';
export declare function addMaskLocalBounds(mask: Container, bounds: Bounds, localRoot: Container): void;
export declare function getMatrixRelativeToParent(target: Container, root: Container, matrix: Matrix): Matrix;
`,pi=`import type { WebGLOptions } from './gl/WebGLRenderer';
import type { WebGPUOptions } from './gpu/WebGPURenderer';
import type { Renderer, RendererOptions } from './types';
/**
 * Options for {@link rendering.autoDetectRenderer}.
 * @memberof rendering
 */
export interface AutoDetectOptions extends RendererOptions {
    /** The preferred renderer type. WebGPU is recommended as its generally faster than WebGL. */
    preference?: 'webgl' | 'webgpu';
    /** Optional WebGPUOptions to pass only to WebGPU renderer. */
    webgpu?: Partial<WebGPUOptions>;
    /** Optional WebGLOptions to pass only to the WebGL renderer */
    webgl?: Partial<WebGLOptions>;
}
/**
 * Automatically determines the most appropriate renderer for the current environment.
 *
 * The function will prioritize the WebGL renderer as it is the most tested safe API to use.
 * In the near future as WebGPU becomes more stable and ubiquitous, it will be prioritized over WebGL.
 *
 * The selected renderer's code is then dynamically imported to optimize
 * performance and minimize the initial bundle size.
 *
 * To maximize the benefits of dynamic imports, it's recommended to use a modern bundler
 * that supports code splitting. This will place the renderer code in a separate chunk,
 * which is loaded only when needed.
 * @example
 *
 * // create a renderer
 * const renderer = await autoDetectRenderer({
 *   width: 800,
 *   height: 600,
 *   antialias: true,
 * });
 *
 * // custom for each renderer
 * const renderer = await autoDetectRenderer({
 *   width: 800,
 *   height: 600,
 *   webgpu:{
 *     antialias: true,
 *     backgroundColor: 'red'
 *   },
 *   webgl:{
 *     antialias: true,
 *     backgroundColor: 'green'
 *   }
 *  });
 * @param options - A partial configuration object based on the \`AutoDetectOptions\` type.
 * @returns A Promise that resolves to an instance of the selected renderer.
 * @memberof rendering
 */
export declare function autoDetectRenderer(options: Partial<AutoDetectOptions>): Promise<Renderer>;
`,ci=`import { ExtensionType } from '../../../extensions/Extensions';
import type { RenderOptions } from '../shared/system/AbstractRenderer';
import type { System } from '../shared/system/System';
import type { WebGLRenderer } from './WebGLRenderer';
/**
 * The options for the back buffer system.
 * @memberof rendering
 * @property {boolean} [useBackBuffer=false] - if true will use the back buffer where required
 * @property {boolean} [antialias=false] - if true will ensure the texture is antialiased
 */
export interface GlBackBufferOptions {
    /**
     * if true will use the back buffer where required
     * @default false
     * @memberof rendering.WebGLOptions
     */
    useBackBuffer?: boolean;
    /** if true will ensure the texture is antialiased */
    antialias?: boolean;
}
/**
 * For blend modes you need to know what pixels you are actually drawing to. For this to be possible in WebGL
 * we need to render to a texture and then present that texture to the screen. This system manages that process.
 *
 * As the main scene is rendered to a texture, it means we can sample it and copy its pixels,
 * something not possible on the main canvas.
 *
 * If antialiasing is set to to true and useBackBuffer is set to true, then the back buffer will be antialiased.
 * and the main gl context will not.
 *
 * You only need to activate this back buffer if you are using a blend mode that requires it.
 *
 * to activate is simple, you pass \`useBackBuffer:true\` to your render options
 * @memberof rendering
 */
export declare class GlBackBufferSystem implements System<GlBackBufferOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "backBuffer";
        readonly priority: 1;
    };
    /** default options for the back buffer system */
    static defaultOptions: GlBackBufferOptions;
    /** if true, the back buffer is used */
    useBackBuffer: boolean;
    private _backBufferTexture;
    private readonly _renderer;
    private _targetTexture;
    private _useBackBufferThisRender;
    private _antialias;
    private _state;
    private _bigTriangleShader;
    constructor(renderer: WebGLRenderer);
    init(options?: GlBackBufferOptions): void;
    /**
     * This is called before the RenderTargetSystem is started. This is where
     * we replace the target with the back buffer if required.
     * @param options - The options for this render.
     */
    protected renderStart(options: RenderOptions): void;
    protected renderEnd(): void;
    private _presentBackBuffer;
    private _getBackBufferTexture;
    /** destroys the back buffer */
    destroy(): void;
}
`,ui=`import { ExtensionType } from '../../../extensions/Extensions';
import type { System } from '../shared/system/System';
import type { WebGLRenderer } from './WebGLRenderer';
/**
 * The system that handles color masking for the WebGL.
 * @memberof rendering
 */
export declare class GlColorMaskSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "colorMask";
    };
    private readonly _renderer;
    private _colorMaskCache;
    constructor(renderer: WebGLRenderer);
    setMask(colorMask: number): void;
    destroy?: () => void;
}
`,mi=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Topology } from '../shared/geometry/const';
import type { Geometry } from '../shared/geometry/Geometry';
import type { Shader } from '../shared/shader/Shader';
import type { State } from '../shared/state/State';
import type { System } from '../shared/system/System';
import type { WebGLRenderer } from './WebGLRenderer';
/**
 * The system that handles encoding commands for the WebGL.
 * @memberof rendering
 */
export declare class GlEncoderSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "encoder";
    };
    readonly commandFinished: Promise<void>;
    private readonly _renderer;
    constructor(renderer: WebGLRenderer);
    setGeometry(geometry: Geometry, shader?: Shader): void;
    finishRenderPass(): void;
    draw(options: {
        geometry: Geometry;
        shader: Shader;
        state?: State;
        topology?: Topology;
        size?: number;
        start?: number;
        instanceCount?: number;
        skipSync?: boolean;
    }): void;
    destroy(): void;
}
`,hi=`/**
 * Represents a render target.
 * @memberof rendering
 * @ignore
 */
export declare class GlRenderTarget {
    width: number;
    height: number;
    msaa: boolean;
    framebuffer: WebGLFramebuffer;
    resolveTargetFramebuffer: WebGLFramebuffer;
    msaaRenderBuffer: WebGLRenderbuffer[];
    depthStencilRenderBuffer: WebGLRenderbuffer;
}
`,fi=`import { ExtensionType } from '../../../extensions/Extensions';
import { STENCIL_MODES } from '../shared/state/const';
import type { RenderTarget } from '../shared/renderTarget/RenderTarget';
import type { System } from '../shared/system/System';
import type { WebGLRenderer } from './WebGLRenderer';
/**
 * This manages the stencil buffer. Used primarily for masking
 * @memberof rendering
 */
export declare class GlStencilSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "stencil";
    };
    private _gl;
    private readonly _stencilCache;
    private _renderTargetStencilState;
    private _stencilOpsMapping;
    private _comparisonFuncMapping;
    private _activeRenderTarget;
    constructor(renderer: WebGLRenderer);
    protected contextChange(gl: WebGLRenderingContext): void;
    protected onRenderTargetChange(renderTarget: RenderTarget): void;
    resetState(): void;
    setStencilMode(stencilMode: STENCIL_MODES, stencilReference: number): void;
    destroy?: () => void;
}
`,bi=`import { ExtensionType } from '../../../extensions/Extensions';
import { UboSystem } from '../shared/shader/UboSystem';
/**
 * System plugin to the renderer to manage uniform buffers. But with an WGSL adaptor.
 * @memberof rendering
 */
export declare class GlUboSystem extends UboSystem {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "ubo";
    };
    constructor();
}
`,gi=`import { AbstractRenderer } from '../shared/system/AbstractRenderer';
import { GlBufferSystem } from './buffer/GlBufferSystem';
import { GlContextSystem } from './context/GlContextSystem';
import { GlGeometrySystem } from './geometry/GlGeometrySystem';
import { GlBackBufferSystem } from './GlBackBufferSystem';
import { GlColorMaskSystem } from './GlColorMaskSystem';
import { GlEncoderSystem } from './GlEncoderSystem';
import { GlStencilSystem } from './GlStencilSystem';
import { GlUboSystem } from './GlUboSystem';
import { GlRenderTargetSystem } from './renderTarget/GlRenderTargetSystem';
import { GlShaderSystem } from './shader/GlShaderSystem';
import { GlUniformGroupSystem } from './shader/GlUniformGroupSystem';
import { GlStateSystem } from './state/GlStateSystem';
import { GlTextureSystem } from './texture/GlTextureSystem';
import type { ICanvas } from '../../../environment/canvas/ICanvas';
import type { SharedRendererOptions } from '../shared/system/SharedSystems';
import type { ExtractRendererOptions, ExtractSystemTypes } from '../shared/system/utils/typeUtils';
import type { GlRenderingContext } from './context/GlRenderingContext';
declare const DefaultWebGLSystems: (typeof import("../..").BackgroundSystem | typeof import("../..").GlobalUniformSystem | typeof import("../..").HelloSystem | typeof import("../..").ViewSystem | typeof import("../../..").RenderGroupSystem | typeof import("../..").TextureGCSystem | typeof import("../..").GenerateTextureSystem | typeof import("../..").ExtractSystem | typeof import("../../..").RendererInitHook | typeof import("../..").RenderableGCSystem | typeof import("../..").SchedulerSystem | typeof GlUboSystem | typeof GlBackBufferSystem | typeof GlContextSystem | typeof GlBufferSystem | typeof GlTextureSystem | typeof GlRenderTargetSystem | typeof GlGeometrySystem | typeof GlUniformGroupSystem | typeof GlShaderSystem | typeof GlEncoderSystem | typeof GlStateSystem | typeof GlStencilSystem | typeof GlColorMaskSystem)[];
declare const DefaultWebGLPipes: (typeof import("../..").BlendModePipe | typeof import("../..").BatcherPipe | typeof import("../../..").SpritePipe | typeof import("../../..").RenderGroupPipe | typeof import("../..").AlphaMaskPipe | typeof import("../..").StencilMaskPipe | typeof import("../..").ColorMaskPipe | typeof import("../../..").CustomRenderPipe)[];
/** The default WebGL renderer, uses WebGL2 contexts. */
type WebGLSystems = ExtractSystemTypes<typeof DefaultWebGLSystems> & PixiMixins.RendererSystems & PixiMixins.WebGLSystems;
/** The default WebGL renderer, uses WebGL2 contexts. */
export type WebGLPipes = ExtractSystemTypes<typeof DefaultWebGLPipes> & PixiMixins.RendererPipes & PixiMixins.WebGLPipes;
/**
 * Options for WebGLRenderer.
 * @memberof rendering
 */
export interface WebGLOptions extends SharedRendererOptions, ExtractRendererOptions<typeof DefaultWebGLSystems>, PixiMixins.WebGLOptions {
}
/**
 * The default WebGL renderer, uses WebGL2 contexts.
 * @memberof rendering
 */
export interface WebGLRenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGLPipes, WebGLOptions, T>, WebGLSystems {
}
/**
 * The WebGL PixiJS Renderer. This renderer allows you to use the most common graphics API, WebGL (and WebGL2).
 *
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = new WebGLRenderer();
 * await renderer.init();
 *
 * // Add the renderer to the stage
 * document.body.appendChild(renderer.canvas);
 *
 * // Create a new stage
 * const stage = new Container();
 *
 * // Render the stage
 * renderer.render(stage);
 * \`\`\`
 *
 * You can use {@link rendering.autoDetectRenderer} to create a renderer that will automatically detect the best
 * renderer for the environment.
 *
 *
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = await rendering.autoDetectRenderer({
 *    preference:'webgl',
 * });
 * \`\`\`
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a WebGL renderer:
 *
 * | WebGL Core Systems                          | Systems that are specific to the WebGL renderer                               |
 * | ------------------------------------------- | ----------------------------------------------------------------------------- |
 * | {@link rendering.GlUboSystem}               | This manages WebGL2 uniform buffer objects feature for shaders                |
 * | {@link rendering.GlBackBufferSystem}        | manages the back buffer, used so that we can pixi can pixels from the screen  |
 * | {@link rendering.GlContextSystem}           | This manages the WebGL context and its extensions                             |
 * | {@link rendering.GlBufferSystem}            | This manages buffers and their GPU resources, keeps everything in sync        |
 * | {@link rendering.GlTextureSystem}           | This manages textures and their GPU resources, keeps everything in sync       |
 * | {@link rendering.GlRenderTargetSystem}      | This manages what we render too. For example the screen, or another texture   |
 * | {@link rendering.GlGeometrySystem}          | This manages geometry, used for drawing meshes via the GPU                    |
 * | {@link rendering.GlUniformGroupSystem}      | This manages uniform groups. Syncing shader properties with the GPU           |
 * | {@link rendering.GlShaderSystem}            | This manages shaders, programs that run on the GPU to output lovely pixels    |
 * | {@link rendering.GlEncoderSystem}           | This manages encoders, a WebGPU Paradigm, use it to draw a mesh + shader      |
 * | {@link rendering.GlStateSystem}             | This manages the state of the WebGL context. eg the various flags that can be set blend modes / depthTesting etc |
 * | {@link rendering.GlStencilSystem}           | This manages the stencil buffer. Used primarily for masking                   |
 * | {@link rendering.GlColorMaskSystem}         | This manages the color mask. Used for color masking                           |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @memberof rendering
 * @property {rendering.GlUboSystem} ubo - UboSystem instance.
 * @property {rendering.GlBackBufferSystem} backBuffer - BackBufferSystem instance.
 * @property {rendering.GlContextSystem} context - ContextSystem instance.
 * @property {rendering.GlBufferSystem} buffer - BufferSystem instance.
 * @property {rendering.GlTextureSystem} texture - TextureSystem instance.
 * @property {rendering.GlRenderTargetSystem} renderTarget - RenderTargetSystem instance.
 * @property {rendering.GlGeometrySystem} geometry - GeometrySystem instance.
 * @property {rendering.GlUniformGroupSystem} uniformGroup - UniformGroupSystem instance.
 * @property {rendering.GlShaderSystem} shader - ShaderSystem instance.
 * @property {rendering.GlEncoderSystem} encoder - EncoderSystem instance.
 * @property {rendering.GlStateSystem} state - StateSystem instance.
 * @property {rendering.GlStencilSystem} stencil - StencilSystem instance.
 * @property {rendering.GlColorMaskSystem} colorMask - ColorMaskSystem instance.
 * @extends rendering.AbstractRenderer
 */
export declare class WebGLRenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGLPipes, WebGLOptions, T> implements WebGLSystems {
    gl: GlRenderingContext;
    constructor();
}
export {};
`,yi=`import type { BUFFER_TYPE } from './const';
export declare class GlBuffer {
    buffer: WebGLBuffer;
    updateID: number;
    byteLength: number;
    type: number;
    _lastBindBaseLocation: number;
    _lastBindCallId: number;
    constructor(buffer: WebGLBuffer, type: BUFFER_TYPE);
}
`,xi=`import { ExtensionType } from '../../../../extensions/Extensions';
import { GlBuffer } from './GlBuffer';
import type { Buffer } from '../../shared/buffer/Buffer';
import type { System } from '../../shared/system/System';
import type { WebGLRenderer } from '../WebGLRenderer';
/**
 * System plugin to the renderer to manage buffers.
 *
 * WebGL uses Buffers as a way to store objects to the GPU.
 * This system makes working with them a lot easier.
 *
 * Buffers are used in three main places in WebGL
 * - geometry information
 * - Uniform information (via uniform buffer objects - a WebGL 2 only feature)
 * - Transform feedback information. (WebGL 2 only feature)
 *
 * This system will handle the binding of buffers to the GPU as well as uploading
 * them. With this system, you never need to work directly with GPU buffers, but instead work with
 * the Buffer class.
 * @class
 * @memberof rendering
 */
export declare class GlBufferSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "buffer";
    };
    private _gl;
    private _gpuBuffers;
    /** Cache keeping track of the base bound buffer bases */
    private _boundBufferBases;
    private _renderer;
    private _minBaseLocation;
    private _maxBindings;
    private _nextBindBaseIndex;
    private _bindCallId;
    /**
     * @param {Renderer} renderer - The renderer this System works for.
     */
    constructor(renderer: WebGLRenderer);
    /**
     * @ignore
     */
    destroy(): void;
    /** Sets up the renderer context and necessary buffers. */
    protected contextChange(): void;
    getGlBuffer(buffer: Buffer): GlBuffer;
    /**
     * This binds specified buffer. On first run, it will create the webGL buffers for the context too
     * @param buffer - the buffer to bind to the renderer
     */
    bind(buffer: Buffer): void;
    /**
     * Binds an uniform buffer to at the given index.
     *
     * A cache is used so a buffer will not be bound again if already bound.
     * @param glBuffer - the buffer to bind
     * @param index - the base index to bind it to.
     */
    bindBufferBase(glBuffer: GlBuffer, index: number): void;
    nextBindBase(hasTransformFeedback: boolean): void;
    freeLocationForBufferBase(glBuffer: GlBuffer): number;
    getLastBindBaseLocation(glBuffer: GlBuffer): number;
    /**
     * Binds a buffer whilst also binding its range.
     * This will make the buffer start from the offset supplied rather than 0 when it is read.
     * @param glBuffer - the buffer to bind
     * @param index - the base index to bind at, defaults to 0
     * @param offset - the offset to bind at (this is blocks of 256). 0 = 0, 1 = 256, 2 = 512 etc
     * @param size - the size to bind at (this is blocks of 256).
     */
    bindBufferRange(glBuffer: GlBuffer, index?: number, offset?: number, size?: number): void;
    /**
     * Will ensure the data in the buffer is uploaded to the GPU.
     * @param {Buffer} buffer - the buffer to update
     */
    updateBuffer(buffer: Buffer): GlBuffer;
    /** dispose all WebGL resources of all managed buffers */
    destroyAll(): void;
    /**
     * Disposes buffer
     * @param {Buffer} buffer - buffer with data
     * @param {boolean} [contextLost=false] - If context was lost, we suppress deleteVertexArray
     */
    protected onBufferDestroy(buffer: Buffer, contextLost?: boolean): void;
    /**
     * creates and attaches a GLBuffer object tied to the current context.
     * @param buffer
     * @protected
     */
    protected createGLBuffer(buffer: Buffer): GlBuffer;
    resetState(): void;
}
`,vi=`/**
 * Constants for various buffer types in Pixi
 * @see BUFFER_TYPE
 * @name BUFFER_TYPE
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */
export declare enum BUFFER_TYPE {
    ELEMENT_ARRAY_BUFFER = 34963,
    ARRAY_BUFFER = 34962,
    UNIFORM_BUFFER = 35345
}
`,Ti=`export declare enum CLEAR {
    NONE = 0,
    COLOR = 16384,
    STENCIL = 1024,
    DEPTH = 256,
    COLOR_DEPTH = 16640,
    COLOR_STENCIL = 17408,
    DEPTH_STENCIL = 1280,
    ALL = 17664
}
/** Used for clearing render textures. true is the same as \`ALL\` false is the same as \`NONE\` */
export type CLEAR_OR_BOOL = CLEAR | boolean;
`,Si=`import { ExtensionType } from '../../../../extensions/Extensions';
import { type GpuPowerPreference } from '../../types';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { System } from '../../shared/system/System';
import type { WebGLRenderer } from '../WebGLRenderer';
import type { WebGLExtensions } from './WebGLExtensions';
/**
 * Options for the context system.
 * @memberof rendering
 * @property {WebGL2RenderingContext | null} [context=null] - User-provided WebGL rendering context object.
 * @property {GpuPowerPreference} [powerPreference='default'] - An optional hint indicating what configuration
 * of GPU is suitable for the WebGL context, can be \`'high-performance'\` or \`'low-power'\`. Setting to \`'high-performance'\`
 * will prioritize rendering performance over power consumption, while setting to \`'low-power'\` will prioritize power saving
 * over rendering performance.
 * @property {boolean} [premultipliedAlpha=true] - Whether the compositor will assume the drawing buffer contains
 * colors with premultiplied alpha.
 * @property {boolean} [preserveDrawingBuffer=false] - Whether to enable drawing buffer preservation.
 * If enabled, the drawing buffer will preserve
 * its value until cleared or overwritten. Enable this if you need to call \`toDataUrl\` on the WebGL context.
 * @property {boolean} [antialias] - Whether to enable antialiasing.
 * @property {1 | 2} [preferWebGLVersion=2] - The preferred WebGL version to use.
 */
export interface ContextSystemOptions {
    /**
     * User-provided WebGL rendering context object.
     * @default null
     * @memberof rendering.SharedRendererOptions
     */
    context: WebGL2RenderingContext | null;
    /**
     * An optional hint indicating what configuration of GPU is suitable for the WebGL context,
     * can be \`'high-performance'\` or \`'low-power'\`.
     * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
     * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
     * @memberof rendering.SharedRendererOptions
     * @default undefined
     */
    powerPreference?: GpuPowerPreference;
    /**
     * Whether the compositor will assume the drawing buffer contains colors with premultiplied alpha.
     * @default true
     * @memberof rendering.SharedRendererOptions
     */
    premultipliedAlpha: boolean;
    /**
     * Whether to enable drawing buffer preservation. If enabled, the drawing buffer will preserve
     * its value until cleared or overwritten. Enable this if you need to call \`toDataUrl\` on the WebGL context.
     * @default false
     * @memberof rendering.SharedRendererOptions
     */
    preserveDrawingBuffer: boolean;
    antialias?: boolean;
    /**
     * The preferred WebGL version to use.
     * @default 2
     * @memberof rendering.SharedRendererOptions
     */
    preferWebGLVersion?: 1 | 2;
    /**
     * Whether to enable multi-view rendering. Set to true when rendering to multiple
     * canvases on the dom.
     * @default false
     * @memberof rendering.SharedRendererOptions
     */
    multiView: boolean;
}
/**
 * System plugin to the renderer to manage the context
 * @memberof rendering
 */
export declare class GlContextSystem implements System<ContextSystemOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "context";
    };
    /** The default options for the system. */
    static defaultOptions: ContextSystemOptions;
    protected CONTEXT_UID: number;
    protected gl: WebGL2RenderingContext;
    /**
     * Features supported by current renderer.
     * @type {object}
     * @readonly
     */
    supports: {
        /** Support for 32-bit indices buffer. */
        uint32Indices: boolean;
        /** Support for UniformBufferObjects */
        uniformBufferObject: boolean;
        /** Support for VertexArrayObjects */
        vertexArrayObject: boolean;
        /** Support for SRGB texture format */
        srgbTextures: boolean;
        /** Support for wrapping modes if a texture is non-power of two */
        nonPowOf2wrapping: boolean;
        /** Support for MSAA (antialiasing of dynamic textures) */
        msaa: boolean;
        /** Support for mipmaps if a texture is non-power of two */
        nonPowOf2mipmaps: boolean;
    };
    /**
     * Extensions available.
     * @type {object}
     * @readonly
     * @property {WEBGL_draw_buffers} drawBuffers - WebGL v1 extension
     * @property {WEBGL_depth_texture} depthTexture - WebGL v1 extension
     * @property {OES_texture_float} floatTexture - WebGL v1 extension
     * @property {WEBGL_lose_context} loseContext - WebGL v1 extension
     * @property {OES_vertex_array_object} vertexArrayObject - WebGL v1 extension
     * @property {EXT_texture_filter_anisotropic} anisotropicFiltering - WebGL v1 and v2 extension
     */
    extensions: WebGLExtensions;
    webGLVersion: 1 | 2;
    /**
     * Whether to enable multi-view rendering. Set to true when rendering to multiple
     * canvases on the dom.
     * @default false
     */
    multiView: boolean;
    /**
     * The canvas that the WebGL Context is rendering to.
     * This will be the view canvas. But if multiView is enabled, this canvas will not be attached to the DOM.
     * It will be rendered to and then copied to the target canvas.
     * @readonly
     */
    canvas: ICanvas;
    private _renderer;
    private _contextLossForced;
    /** @param renderer - The renderer this System works for. */
    constructor(renderer: WebGLRenderer);
    /**
     * \`true\` if the context is lost
     * @readonly
     */
    get isLost(): boolean;
    /**
     * Handles the context change event.
     * @param {WebGLRenderingContext} gl - New WebGL context.
     */
    protected contextChange(gl: WebGL2RenderingContext): void;
    init(options: ContextSystemOptions): void;
    ensureCanvasSize(targetCanvas: ICanvas): void;
    /**
     * Initializes the context.
     * @protected
     * @param {WebGLRenderingContext} gl - WebGL context
     */
    protected initFromContext(gl: WebGL2RenderingContext): void;
    /**
     * Initialize from context options
     * @protected
     * @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext
     * @param preferWebGLVersion
     * @param {object} options - context attributes
     */
    protected createContext(preferWebGLVersion: 1 | 2, options: WebGLContextAttributes): void;
    /** Auto-populate the {@link GlContextSystem.extensions extensions}. */
    protected getExtensions(): void;
    /**
     * Handles a lost webgl context
     * @param {WebGLContextEvent} event - The context lost event.
     */
    protected handleContextLost(event: WebGLContextEvent): void;
    /** Handles a restored webgl context. */
    protected handleContextRestored(): void;
    destroy(): void;
    /**
     * this function can be called to force a webGL context loss
     * this will release all resources on the GPU.
     * Useful if you need to put Pixi to sleep, and save some GPU memory
     *
     * As soon as render is called - all resources will be created again.
     */
    forceContextLoss(): void;
    /**
     * Validate context.
     * @param {WebGLRenderingContext} gl - Render context.
     */
    protected validateContext(gl: WebGL2RenderingContext): void;
}
`,wi=`export type GlRenderingContext = WebGL2RenderingContext;
`,_i=`export interface WEBGL_compressed_texture_pvrtc {
    COMPRESSED_RGB_PVRTC_4BPPV1_IMG: number;
    COMPRESSED_RGBA_PVRTC_4BPPV1_IMG: number;
    COMPRESSED_RGB_PVRTC_2BPPV1_IMG: number;
    COMPRESSED_RGBA_PVRTC_2BPPV1_IMG: number;
}
export interface WEBGL_compressed_texture_etc {
    COMPRESSED_R11_EAC: number;
    COMPRESSED_SIGNED_R11_EAC: number;
    COMPRESSED_RG11_EAC: number;
    COMPRESSED_SIGNED_RG11_EAC: number;
    COMPRESSED_RGB8_ETC2: number;
    COMPRESSED_RGBA8_ETC2_EAC: number;
    COMPRESSED_SRGB8_ETC2: number;
    COMPRESSED_SRGB8_ALPHA8_ETC2_EAC: number;
    COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2: number;
    COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2: number;
}
export interface WEBGL_compressed_texture_etc1 {
    COMPRESSED_RGB_ETC1_WEBGL: number;
}
export interface WEBGL_compressed_texture_atc {
    COMPRESSED_RGB_ATC_WEBGL: number;
    COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL: number;
    COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL: number;
}
export interface EXT_texture_compression_bptc {
    COMPRESSED_RGBA_BPTC_UNORM_EXT: number;
    COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT: number;
    COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT: number;
    COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT: number;
}
export interface EXT_texture_compression_rgtc {
    COMPRESSED_RED_RGTC1_EXT: number;
    COMPRESSED_SIGNED_RED_RGTC1_EXT: number;
    COMPRESSED_RED_GREEN_RGTC2_EXT: number;
    COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT: number;
}
export interface WebGLExtensions {
    drawBuffers?: WEBGL_draw_buffers;
    depthTexture?: OES_texture_float;
    loseContext?: WEBGL_lose_context;
    vertexArrayObject?: OES_vertex_array_object;
    anisotropicFiltering?: EXT_texture_filter_anisotropic;
    uint32ElementIndex?: OES_element_index_uint;
    floatTexture?: OES_texture_float;
    floatTextureLinear?: OES_texture_float_linear;
    textureHalfFloat?: OES_texture_half_float;
    textureHalfFloatLinear?: OES_texture_half_float_linear;
    colorBufferFloat?: EXT_color_buffer_float;
    vertexAttribDivisorANGLE?: ANGLE_instanced_arrays;
    s3tc?: WEBGL_compressed_texture_s3tc;
    s3tc_sRGB?: WEBGL_compressed_texture_s3tc_srgb;
    etc?: WEBGL_compressed_texture_etc;
    etc1?: WEBGL_compressed_texture_etc1;
    pvrtc?: WEBGL_compressed_texture_pvrtc;
    atc?: WEBGL_compressed_texture_atc;
    astc?: WEBGL_compressed_texture_astc;
    bptc?: EXT_texture_compression_bptc;
    rgtc?: EXT_texture_compression_rgtc;
    srgb?: EXT_sRGB;
}
`,Ei=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { Topology } from '../../shared/geometry/const';
import type { Geometry } from '../../shared/geometry/Geometry';
import type { System } from '../../shared/system/System';
import type { GlRenderingContext } from '../context/GlRenderingContext';
import type { GlProgram } from '../shader/GlProgram';
import type { WebGLRenderer } from '../WebGLRenderer';
/**
 * System plugin to the renderer to manage geometry.
 * @memberof rendering
 */
export declare class GlGeometrySystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "geometry";
    };
    /**
     * \`true\` if we has \`*_vertex_array_object\` extension.
     * @readonly
     */
    hasVao: boolean;
    /**
     * \`true\` if has \`ANGLE_instanced_arrays\` extension.
     * @readonly
     */
    hasInstance: boolean;
    protected gl: GlRenderingContext;
    protected _activeGeometry: Geometry;
    protected _activeVao: WebGLVertexArrayObject;
    protected _geometryVaoHash: Record<number, Record<string, WebGLVertexArrayObject>>;
    /** Renderer that owns this {@link GeometrySystem}. */
    private _renderer;
    /** @param renderer - The renderer this System works for. */
    constructor(renderer: WebGLRenderer);
    /** Sets up the renderer context and necessary buffers. */
    protected contextChange(): void;
    /**
     * Binds geometry so that is can be drawn. Creating a Vao if required
     * @param geometry - Instance of geometry to bind.
     * @param program - Instance of program to use vao for.
     */
    bind(geometry?: Geometry, program?: GlProgram): void;
    /** Reset and unbind any active VAO and geometry. */
    resetState(): void;
    /** Update buffers of the currently bound geometry. */
    updateBuffers(): void;
    /**
     * Check compatibility between a geometry and a program
     * @param geometry - Geometry instance.
     * @param program - Program instance.
     */
    protected checkCompatibility(geometry: Geometry, program: GlProgram): void;
    /**
     * Takes a geometry and program and generates a unique signature for them.
     * @param geometry - To get signature from.
     * @param program - To test geometry against.
     * @returns - Unique signature of the geometry and program
     */
    protected getSignature(geometry: Geometry, program: GlProgram): string;
    protected getVao(geometry: Geometry, program: GlProgram): WebGLVertexArrayObject;
    /**
     * Creates or gets Vao with the same structure as the geometry and stores it on the geometry.
     * If vao is created, it is bound automatically. We use a shader to infer what and how to set up the
     * attribute locations.
     * @param geometry - Instance of geometry to to generate Vao for.
     * @param program
     * @param _incRefCount - Increment refCount of all geometry buffers.
     */
    protected initGeometryVao(geometry: Geometry, program: GlProgram, _incRefCount?: boolean): WebGLVertexArrayObject;
    /**
     * Disposes geometry.
     * @param geometry - Geometry with buffers. Only VAO will be disposed
     * @param [contextLost=false] - If context was lost, we suppress deleteVertexArray
     */
    protected onGeometryDestroy(geometry: Geometry, contextLost?: boolean): void;
    /**
     * Dispose all WebGL resources of all managed geometries.
     * @param [contextLost=false] - If context was lost, we suppress \`gl.delete\` calls
     */
    destroyAll(contextLost?: boolean): void;
    /**
     * Activate vertex array object.
     * @param geometry - Geometry instance.
     * @param program - Shader program instance.
     */
    protected activateVao(geometry: Geometry, program: GlProgram): void;
    /**
     * Draws the currently bound geometry.
     * @param topology - The type primitive to render.
     * @param size - The number of elements to be rendered. If not specified, all vertices after the
     *  starting vertex will be drawn.
     * @param start - The starting vertex in the geometry to start drawing from. If not specified,
     *  drawing will start from the first vertex.
     * @param instanceCount - The number of instances of the set of elements to execute. If not specified,
     *  all instances will be drawn.
     */
    draw(topology?: Topology, size?: number, start?: number, instanceCount?: number): this;
    /** Unbind/reset everything. */
    protected unbind(): void;
    destroy(): void;
}
`,Pi=`import type { VertexFormat } from '../../../shared/geometry/const';
export declare function getGlTypeFromFormat(format: VertexFormat): number;
`,Ai=`import { Rectangle } from '../../../../maths/shapes/Rectangle';
import { GlRenderTarget } from '../GlRenderTarget';
import type { RgbaArray } from '../../../../color/Color';
import type { RenderTarget } from '../../shared/renderTarget/RenderTarget';
import type { RenderTargetAdaptor, RenderTargetSystem } from '../../shared/renderTarget/RenderTargetSystem';
import type { Texture } from '../../shared/texture/Texture';
import type { CLEAR_OR_BOOL } from '../const';
import type { WebGLRenderer } from '../WebGLRenderer';
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGL renderer
 * @memberof rendering
 * @ignore
 */
export declare class GlRenderTargetAdaptor implements RenderTargetAdaptor<GlRenderTarget> {
    private _renderTargetSystem;
    private _renderer;
    private _clearColorCache;
    private _viewPortCache;
    init(renderer: WebGLRenderer, renderTargetSystem: RenderTargetSystem<GlRenderTarget>): void;
    contextChange(): void;
    copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
        x: number;
        y: number;
    }, size: {
        width: number;
        height: number;
    }, originDest: {
        x: number;
        y: number;
    }): Texture<import("../../..").TextureSource<any>>;
    startRenderPass(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
    finishRenderPass(renderTarget?: RenderTarget): void;
    initGpuRenderTarget(renderTarget: RenderTarget): GlRenderTarget;
    destroyGpuRenderTarget(gpuRenderTarget: GlRenderTarget): void;
    clear(_renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, clearColor?: RgbaArray): void;
    resizeGpuRenderTarget(renderTarget: RenderTarget): void;
    private _initColor;
    private _resizeColor;
    private _initStencil;
    private _resizeStencil;
    prerender(renderTarget: RenderTarget): void;
    postrender(renderTarget: RenderTarget): void;
}
`,Ci=`import { ExtensionType } from '../../../../extensions/Extensions';
import { RenderTargetSystem } from '../../shared/renderTarget/RenderTargetSystem';
import { GlRenderTargetAdaptor } from './GlRenderTargetAdaptor';
import type { GlRenderTarget } from '../GlRenderTarget';
import type { WebGLRenderer } from '../WebGLRenderer';
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGl renderer
 * @memberof rendering
 */
export declare class GlRenderTargetSystem extends RenderTargetSystem<GlRenderTarget> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "renderTarget";
    };
    adaptor: GlRenderTargetAdaptor;
    constructor(renderer: WebGLRenderer);
}
`,Ri=`import type { Shader } from '../../shared/shader/Shader';
import type { GlShaderSystem, ShaderSyncFunction } from './GlShaderSystem';
/**
 * Generates the a function that will efficiently sync shader resources with the GPU.
 * @param shader - The shader to generate the code for
 * @param shaderSystem - An instance of the shader system
 */
export declare function generateShaderSyncCode(shader: Shader, shaderSystem: GlShaderSystem): ShaderSyncFunction;
`,Gi=`import type { TypedArray } from '../../shared/buffer/Buffer';
import type { ExtractedAttributeData } from './program/extractAttributesFromGlProgram';
export interface GlAttributeData {
    type: string;
    size: number;
    location: number;
    name: string;
}
export interface GlUniformData {
    name: string;
    index: number;
    type: string;
    size: number;
    isArray: boolean;
    value: any;
}
export interface GlUniformBlockData {
    index: number;
    name: string;
    size: number;
    value?: TypedArray;
}
/**
 * The options for the gl program
 * @memberof rendering
 */
export interface GlProgramOptions {
    /** The fragment glsl shader source. */
    fragment: string;
    /** The vertex glsl shader source. */
    vertex: string;
    /** the name of the program, defaults to 'pixi-program' */
    name?: string;
    /** the preferred vertex precision for the shader, this may not be used if the device does not support it  */
    preferredVertexPrecision?: string;
    /** the preferred fragment precision for the shader, this may not be used if the device does not support it  */
    preferredFragmentPrecision?: string;
    transformFeedbackVaryings?: {
        names: string[];
        bufferMode: 'separate' | 'interleaved';
    };
}
/**
 * A wrapper for a WebGL Program. You can create one and then pass it to a shader.
 * This will manage the WebGL program that is compiled and uploaded to the GPU.
 *
 * To get the most out of this class, you should be familiar with glsl shaders and how they work.
 * @see https://developer.mozilla.org/en-US/docs/Web/API/WebGLProgram
 * @example
 *
 * // Create a new program
 * const program = new GlProgram({
 *   vertex: '...',
 *   fragment: '...',
 * });
 *
 *
 * There are a few key things that pixi shader will do for you automatically:
 * <br>
 * - If no precision is provided in the shader, it will be injected into the program source for you.
 * This precision will be taken form the options provided, if none is provided,
 * then the program will default to the defaultOptions.
 * <br>
 * - It will inject the program name into the shader source if none is provided.
 * <br>
 *  - It will set the program version to 300 es.
 *
 * For optimal usage and best performance, its best to reuse programs as much as possible.
 * You should use the {@link GlProgram.from} helper function to create programs.
 * @class
 * @memberof rendering
 */
export declare class GlProgram {
    /** The default options used by the program. */
    static defaultOptions: Partial<GlProgramOptions>;
    /** the fragment glsl shader source. */
    readonly fragment?: string;
    /** the vertex glsl shader source */
    readonly vertex?: string;
    /**
     * attribute data extracted from the program once created this happens when the program is used for the first time
     * @internal
     * @ignore
     */
    _attributeData: Record<string, ExtractedAttributeData>;
    /**
     * uniform data extracted from the program once created this happens when the program is used for the first time
     * @internal
     * @ignore
     */
    _uniformData: Record<string, GlUniformData>;
    /**
     * uniform data extracted from the program once created this happens when the program is used for the first time
     * @internal
     * @ignore
     */
    _uniformBlockData: Record<string, GlUniformBlockData>;
    /** details on how to use this program with transform feedback */
    transformFeedbackVaryings?: {
        names: string[];
        bufferMode: 'separate' | 'interleaved';
    };
    /**
     * the key that identifies the program via its source vertex + fragment
     * @internal
     * @ignore
     */
    readonly _key: number;
    /**
     * Creates a shiny new GlProgram. Used by WebGL renderer.
     * @param options - The options for the program.
     */
    constructor(options: GlProgramOptions);
    /** destroys the program */
    destroy(): void;
    /**
     * Helper function that creates a program for a given source.
     * It will check the program cache if the program has already been created.
     * If it has that one will be returned, if not a new one will be created and cached.
     * @param options - The options for the program.
     * @returns A program using the same source
     */
    static from(options: GlProgramOptions): GlProgram;
}
`,Mi=`/**
 * @private
 */
export declare class IGLUniformData {
    location: WebGLUniformLocation;
    value: number | boolean | Float32Array | Int32Array | Uint32Array | boolean[];
}
/**
 * Helper class to create a WebGL Program
 * @private
 */
export declare class GlProgramData {
    /** The shader program. */
    program: WebGLProgram;
    /**
     * Holds the uniform data which contains uniform locations
     * and current uniform values used for caching and preventing unneeded GPU commands.
     */
    uniformData: Record<string, any>;
    /**
     * UniformGroups holds the various upload functions for the shader. Each uniform group
     * and program have a unique upload function generated.
     */
    uniformGroups: Record<string, any>;
    /** A hash that stores where UBOs are bound to on the program. */
    uniformBlockBindings: Record<string, any>;
    /** A hash for lazily-generated uniform uploading functions. */
    uniformSync: Record<string, any>;
    /**
     * A place where dirty ticks are stored for groups
     * If a tick here does not match with the Higher level Programs tick, it means
     * we should re upload the data.
     */
    uniformDirtyGroups: Record<string, any>;
    /**
     * Makes a new Pixi program.
     * @param program - webgl program
     * @param uniformData - uniforms
     */
    constructor(program: WebGLProgram, uniformData: {
        [key: string]: IGLUniformData;
    });
    /** Destroys this program. */
    destroy(): void;
}
`,ki=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { BufferResource } from '../../shared/buffer/BufferResource';
import type { Shader } from '../../shared/shader/Shader';
import type { ShaderSystem } from '../../shared/shader/ShaderSystem';
import type { UniformGroup } from '../../shared/shader/UniformGroup';
import type { GlRenderingContext } from '../context/GlRenderingContext';
import type { WebGLRenderer } from '../WebGLRenderer';
import type { GlProgram } from './GlProgram';
import type { GlProgramData } from './GlProgramData';
export interface ShaderSyncData {
    textureCount: number;
    blockIndex: number;
}
export type ShaderSyncFunction = (renderer: WebGLRenderer, shader: Shader, syncData: ShaderSyncData) => void;
/**
 * System plugin to the renderer to manage the shaders for WebGL.
 * @memberof rendering
 */
export declare class GlShaderSystem implements ShaderSystem {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "shader";
    };
    maxTextures: number;
    /**
     * @internal
     * @private
     */
    _activeProgram: GlProgram;
    private _programDataHash;
    private readonly _renderer;
    _gl: WebGL2RenderingContext;
    private _shaderSyncFunctions;
    constructor(renderer: WebGLRenderer);
    protected contextChange(gl: GlRenderingContext): void;
    /**
     * Changes the current shader to the one given in parameter.
     * @param shader - the new shader
     * @param skipSync - false if the shader should automatically sync its uniforms.
     * @returns the glProgram that belongs to the shader.
     */
    bind(shader: Shader, skipSync?: boolean): void;
    /**
     * Updates the uniform group.
     * @param uniformGroup - the uniform group to update
     */
    updateUniformGroup(uniformGroup: UniformGroup): void;
    /**
     * Binds a uniform block to the shader.
     * @param uniformGroup - the uniform group to bind
     * @param name - the name of the uniform block
     * @param index - the index of the uniform block
     */
    bindUniformBlock(uniformGroup: UniformGroup | BufferResource, name: string, index?: number): void;
    private _setProgram;
    /**
     * @param program - the program to get the data for
     * @internal
     * @private
     */
    _getProgramData(program: GlProgram): GlProgramData;
    private _createProgramData;
    destroy(): void;
    /**
     * Creates a function that can be executed that will sync the shader as efficiently as possible.
     * Overridden by the unsafe eval package if you don't want eval used in your project.
     * @param shader - the shader to generate the sync function for
     * @param shaderSystem - the shader system to use
     * @returns - the generated sync function
     * @ignore
     */
    _generateShaderSync(shader: Shader, shaderSystem: GlShaderSystem): ShaderSyncFunction;
    resetState(): void;
}
`,Fi=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { UniformGroup } from '../../shared/shader/UniformGroup';
import type { System } from '../../shared/system/System';
import type { GlRenderingContext } from '../context/GlRenderingContext';
import type { WebGLRenderer } from '../WebGLRenderer';
import type { GlProgram } from './GlProgram';
/**
 * System plugin to the renderer to manage shaders.
 * @memberof rendering
 */
export declare class GlUniformGroupSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "uniformGroup";
    };
    /**
     * The current WebGL rendering context.
     * @member {WebGLRenderingContext}
     */
    protected gl: GlRenderingContext;
    /** Cache to holds the generated functions. Stored against UniformObjects unique signature. */
    private _cache;
    private _renderer;
    private _uniformGroupSyncHash;
    /** @param renderer - The renderer this System works for. */
    constructor(renderer: WebGLRenderer);
    protected contextChange(gl: GlRenderingContext): void;
    /**
     * Uploads the uniforms values to the currently bound shader.
     * @param group - the uniforms values that be applied to the current shader
     * @param program
     * @param syncData
     * @param syncData.textureCount
     */
    updateUniformGroup(group: UniformGroup, program: GlProgram, syncData: {
        textureCount: number;
    }): void;
    /**
     * Overridable by the pixi.js/unsafe-eval package to use static syncUniforms instead.
     * @param group
     * @param program
     */
    private _getUniformSyncFunction;
    private _createUniformSyncFunction;
    private _generateUniformsSync;
    /**
     * Takes a uniform group and data and generates a unique signature for them.
     * @param group - The uniform group to get signature of
     * @param group.uniforms
     * @param uniformData - Uniform information generated by the shader
     * @param preFix
     * @returns Unique signature of the uniform group
     */
    private _getSignature;
    /** Destroys this System and removes all its textures. */
    destroy(): void;
}
`,Oi="export type PRECISION = `highp` | `mediump` | `lowp`;\n",Ii=`import { UniformGroup } from '../../shared/shader/UniformGroup';
/**
 * Automatically generates a uniform group that holds the texture samplers for a shader.
 * This is used mainly by the shaders that batch textures!
 * @param maxTextures - the number of textures that this uniform group will contain.
 * @returns a uniform group that holds the texture samplers.
 */
export declare function getBatchSamplersUniformGroup(maxTextures: number): UniformGroup<any>;
`,Li=`export declare function migrateFragmentFromV7toV8(fragmentShader: string): string;
`,Bi=`/**
 * @private
 * @param {WebGLRenderingContext} gl - The current WebGL context {WebGLProgram}
 * @param {number} type - the type, can be either VERTEX_SHADER or FRAGMENT_SHADER
 * @param {string} src - The vertex shader source as an array of strings.
 * @returns {WebGLShader} the shader
 */
export declare function compileShader(gl: WebGLRenderingContextBase, type: number, src: string): WebGLShader;
`,Di=`/**
 * @method defaultValue
 * @param {string} type - Type of value
 * @param {number} size
 * @private
 */
export declare function defaultValue(type: string, size: number): number | Float32Array | Int32Array | Uint32Array | boolean | boolean[];
`,Ui=`import type { Geometry } from '../../../shared/geometry/Geometry';
import type { ExtractedAttributeData } from './extractAttributesFromGlProgram';
/**
 * This function looks at the attribute information provided to the geometry and attempts
 * to fill in an gaps. WE do this by looking at the extracted data from the shader and
 * making best guesses.
 *
 * Most of th etime users don't need to provide all the attribute info beyond the data itself, so we
 * can fill in the gaps for them. If you are using attributes in a more advanced way, you can
 * don't forget to add all the info at creation!
 * @param geometry - the geometry to ensure attributes for
 * @param extractedData - the extracted data from the shader
 */
export declare function ensureAttributes(geometry: Geometry, extractedData: Record<string, ExtractedAttributeData>): void;
`,ji=`import type { Attribute } from '../../../shared/geometry/Geometry';
export interface ExtractedAttributeData extends Omit<Attribute, 'buffer'> {
    /** set where the shader location is for this attribute */
    location?: number;
}
/**
 * returns the attribute data from the program
 * @private
 * @param {WebGLProgram} [program] - the WebGL program
 * @param {WebGLRenderingContext} [gl] - the WebGL context
 * @returns {object} the attribute data for this program
 */
export declare function extractAttributesFromGlProgram(program: WebGLProgram, gl: WebGLRenderingContextBase, sortAttributes?: boolean): Record<string, ExtractedAttributeData>;
`,Wi=`import { GlProgramData } from '../GlProgramData';
import type { GlRenderingContext } from '../../context/GlRenderingContext';
import type { GlProgram } from '../GlProgram';
/**
 * generates a WebGL Program object from a high level Pixi Program.
 * @param gl - a rendering context on which to generate the program
 * @param program - the high level Pixi Program.
 * @private
 */
export declare function generateProgram(gl: GlRenderingContext, program: GlProgram): GlProgramData;
`,Hi=`import type { PRECISION } from '../const';
export declare function getMaxFragmentPrecision(): PRECISION;
`,Vi=`import type { GlRenderingContext } from '../../context/GlRenderingContext';
/**
 * returns a little WebGL context to use for program inspection.
 * @static
 * @private
 * @returns {WebGLRenderingContext} a gl context to test with
 */
export declare function getTestContext(): GlRenderingContext;
`,Ni=`import type { GlUniformBlockData } from '../GlProgram';
/**
 * returns the uniform block data from the program
 * @private
 * @param program - the webgl program
 * @param gl - the WebGL context
 * @returns {object} the uniform data for this program
 */
export declare function getUboData(program: WebGLProgram, gl: WebGL2RenderingContext): Record<string, GlUniformBlockData>;
`,zi=`import type { GlUniformData } from '../GlProgram';
/**
 * returns the uniform data from the program
 * @private
 * @param program - the webgl program
 * @param gl - the WebGL context
 * @returns {object} the uniform data for this program
 */
export declare function getUniformData(program: WebGLProgram, gl: WebGLRenderingContextBase): {
    [key: string]: GlUniformData;
};
`,Xi=`/**
 *
 * logs out any program errors
 * @param gl - The current WebGL context
 * @param program - the WebGL program to display errors for
 * @param vertexShader  - the fragment WebGL shader program
 * @param fragmentShader - the vertex WebGL shader program
 * @private
 */
export declare function logProgramError(gl: WebGLRenderingContext, program: WebGLProgram, vertexShader: WebGLShader, fragmentShader: WebGLShader): void;
`,Ki=`/**
 * @private
 * @method mapSize
 * @param {string} type
 */
export declare function mapSize(type: string): number;
`,qi=`import type { VertexFormat } from '../../../shared/geometry/const';
export declare function mapType(gl: any, type: number): string;
export declare function mapGlToVertexFormat(gl: any, type: number): VertexFormat;
`,Yi=`export declare function addProgramDefines(src: string, isES300: boolean, isFragment?: boolean): string;
`,Ji=`import type { PRECISION } from '../../const';
interface EnsurePrecisionOptions {
    requestedVertexPrecision: PRECISION;
    requestedFragmentPrecision: PRECISION;
    maxSupportedVertexPrecision: PRECISION;
    maxSupportedFragmentPrecision: PRECISION;
}
/**
 * Sets the float precision on the shader, ensuring the device supports the request precision.
 * If the precision is already present, it just ensures that the device is able to handle it.
 * @param src
 * @param options
 * @param options.requestedVertexPrecision
 * @param options.requestedFragmentPrecision
 * @param options.maxSupportedVertexPrecision
 * @param options.maxSupportedFragmentPrecision
 * @param isFragment
 * @private
 */
export declare function ensurePrecision(src: string, options: EnsurePrecisionOptions, isFragment: boolean): string;
export {};
`,$i=`export declare function insertVersion(src: string, isES300: boolean): string;
`,Qi=`export declare function setProgramName(src: string, { name }: {
    name: string;
}, isFragment?: boolean): string;
`,Zi=`export declare function stripVersion(src: string, isES300: boolean): string;
`,es=`import type { UboLayout, UniformData } from '../../../shared/shader/types';
export declare const WGSL_TO_STD40_SIZE: Record<string, number>;
export declare function createUboElementsSTD40(uniformData: UniformData[]): UboLayout;
`,ns=`import type { UboElement, UniformsSyncCallback } from '../../../shared/shader/types';
export declare function createUboSyncFunctionSTD40(uboElements: UboElement[]): UniformsSyncCallback;
`,ts=`import type { UboElement } from '../../../shared/shader/types';
/**
 * This generates a function that will sync an array to the uniform buffer
 * following the std140 layout
 * @param uboElement - the element to generate the array sync for
 * @param offsetToAdd - the offset to append at the start of the code
 * @returns - the generated code
 */
export declare function generateArraySyncSTD40(uboElement: UboElement, offsetToAdd: number): string;
`,rs=`import { UniformGroup } from '../../../shared/shader/UniformGroup';
import type { UniformsSyncCallback } from '../../../shared/shader/types';
export declare function generateUniformsSync(group: UniformGroup, uniformData: Record<string, any>): UniformsSyncCallback;
`,os=`import type { UNIFORM_TYPES } from '../../../shared/shader/types';
export type ArraySetterFunction = (v: any, location: WebGLUniformLocation, gl: any) => void;
export declare const UNIFORM_TO_SINGLE_SETTERS: Record<UNIFORM_TYPES | string, string>;
export declare const UNIFORM_TO_ARRAY_SETTERS: Record<UNIFORM_TYPES | string, string>;
`,as=`import { ExtensionType } from '../../../../extensions/Extensions';
import { type RenderTarget } from '../../shared/renderTarget/RenderTarget';
import { State } from '../../shared/state/State';
import { type WebGLRenderer } from '../WebGLRenderer';
import type { BLEND_MODES } from '../../shared/state/const';
import type { System } from '../../shared/system/System';
import type { GlRenderingContext } from '../context/GlRenderingContext';
/**
 * System plugin to the renderer to manage WebGL state machines
 * @memberof rendering
 */
export declare class GlStateSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "state";
    };
    /**
     * State ID
     * @readonly
     */
    stateId: number;
    /**
     * Polygon offset
     * @readonly
     */
    polygonOffset: number;
    /**
     * Blend mode
     * @default 'none'
     * @readonly
     */
    blendMode: BLEND_MODES;
    /** Whether current blend equation is different */
    protected _blendEq: boolean;
    /**
     * GL context
     * @member {WebGLRenderingContext}
     * @readonly
     */
    protected gl: GlRenderingContext;
    protected blendModesMap: Record<BLEND_MODES, number[]>;
    /**
     * Collection of calls
     * @member {Function[]}
     */
    protected readonly map: ((value: boolean) => void)[];
    /**
     * Collection of check calls
     * @member {Function[]}
     */
    protected readonly checks: ((system: this, state: State) => void)[];
    /**
     * Default WebGL State
     * @readonly
     */
    protected defaultState: State;
    /**
     * Whether to invert the front face when rendering
     * This is used for render textures where the Y-coordinate is flipped
     * @default false
     */
    private _invertFrontFace;
    private _glFrontFace;
    private _cullFace;
    private _frontFaceDirty;
    private _frontFace;
    constructor(renderer: WebGLRenderer);
    protected onRenderTargetChange(renderTarget: RenderTarget): void;
    protected contextChange(gl: GlRenderingContext): void;
    /**
     * Sets the current state
     * @param {*} state - The state to set.
     */
    set(state: State): void;
    /**
     * Sets the state, when previous state is unknown.
     * @param {*} state - The state to set
     */
    forceState(state: State): void;
    /**
     * Sets whether to enable or disable blending.
     * @param value - Turn on or off WebGl blending.
     */
    setBlend(value: boolean): void;
    /**
     * Sets whether to enable or disable polygon offset fill.
     * @param value - Turn on or off webgl polygon offset testing.
     */
    setOffset(value: boolean): void;
    /**
     * Sets whether to enable or disable depth test.
     * @param value - Turn on or off webgl depth testing.
     */
    setDepthTest(value: boolean): void;
    /**
     * Sets whether to enable or disable depth mask.
     * @param value - Turn on or off webgl depth mask.
     */
    setDepthMask(value: boolean): void;
    /**
     * Sets whether to enable or disable cull face.
     * @param {boolean} value - Turn on or off webgl cull face.
     */
    setCullFace(value: boolean): void;
    /**
     * Sets the gl front face.
     * @param {boolean} value - true is clockwise and false is counter-clockwise
     */
    setFrontFace(value: boolean): void;
    /**
     * Sets the blend mode.
     * @param {number} value - The blend mode to set to.
     */
    setBlendMode(value: BLEND_MODES): void;
    /**
     * Sets the polygon offset.
     * @param {number} value - the polygon offset
     * @param {number} scale - the polygon offset scale
     */
    setPolygonOffset(value: number, scale: number): void;
    /** Resets all the logic and disables the VAOs. */
    resetState(): void;
    /**
     * Checks to see which updates should be checked based on which settings have been activated.
     *
     * For example, if blend is enabled then we should check the blend modes each time the state is changed
     * or if polygon fill is activated then we need to check if the polygon offset changes.
     * The idea is that we only check what we have too.
     * @param func - the checking function to add or remove
     * @param value - should the check function be added or removed.
     */
    private _updateCheck;
    /**
     * A private little wrapper function that we call to check the blend mode.
     * @param system - the System to perform the state check on
     * @param state - the state that the blendMode will pulled from
     */
    private static _checkBlendMode;
    /**
     * A private little wrapper function that we call to check the polygon offset.
     * @param system - the System to perform the state check on
     * @param state - the state that the blendMode will pulled from
     */
    private static _checkPolygonOffset;
    /**
     * @ignore
     */
    destroy(): void;
}
`,is=`import type { BLEND_MODES } from '../../shared/state/const';
import type { GlRenderingContext } from '../context/GlRenderingContext';
/**
 * Maps gl blend combinations to WebGL.
 * @param gl
 * @returns {object} Map of gl blend combinations to WebGL.
 */
export declare function mapWebGLBlendModesToPixi(gl: GlRenderingContext): Record<BLEND_MODES, number[]>;
`,ss=`import { GL_FORMATS, GL_TARGETS } from './const';
/**
 * Internal texture for WebGL context
 * @memberof rendering
 * @ignore
 */
export declare class GlTexture {
    target: GL_TARGETS;
    /** The WebGL texture. */
    texture: WebGLTexture;
    /** Width of texture that was used in texImage2D. */
    width: number;
    /** Height of texture that was used in texImage2D. */
    height: number;
    /** Whether mip levels has to be generated. */
    mipmap: boolean;
    /** Type copied from texture source. */
    type: number;
    /** Type copied from texture source. */
    internalFormat: number;
    /** Type of sampler corresponding to this texture. See {@link SAMPLER_TYPES} */
    samplerType: number;
    format: GL_FORMATS;
    constructor(texture: WebGLTexture);
}
`,ls=`import { ExtensionType } from '../../../../extensions/Extensions';
import { Texture } from '../../shared/texture/Texture';
import { GlTexture } from './GlTexture';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { System } from '../../shared/system/System';
import type { CanvasGenerator, GetPixelsOutput } from '../../shared/texture/GenerateCanvas';
import type { TextureSource } from '../../shared/texture/sources/TextureSource';
import type { BindableTexture } from '../../shared/texture/Texture';
import type { GlRenderingContext } from '../context/GlRenderingContext';
import type { WebGLRenderer } from '../WebGLRenderer';
/**
 * The system for managing textures in WebGL.
 * @memberof rendering
 */
export declare class GlTextureSystem implements System, CanvasGenerator {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem];
        readonly name: "texture";
    };
    readonly managedTextures: TextureSource[];
    private readonly _renderer;
    private _glTextures;
    private _glSamplers;
    private _boundTextures;
    private _activeTextureLocation;
    private _boundSamplers;
    private readonly _uploads;
    private _gl;
    private _mapFormatToInternalFormat;
    private _mapFormatToType;
    private _mapFormatToFormat;
    private _premultiplyAlpha;
    private readonly _useSeparateSamplers;
    constructor(renderer: WebGLRenderer);
    protected contextChange(gl: GlRenderingContext): void;
    initSource(source: TextureSource): void;
    bind(texture: BindableTexture, location?: number): void;
    bindSource(source: TextureSource, location?: number): void;
    private _bindSampler;
    unbind(texture: BindableTexture): void;
    private _activateLocation;
    private _initSource;
    protected onStyleChange(source: TextureSource): void;
    protected updateStyle(source: TextureSource, firstCreation: boolean): void;
    protected onSourceUnload(source: TextureSource): void;
    protected onSourceUpdate(source: TextureSource): void;
    protected onUpdateMipmaps(source: TextureSource, bind?: boolean): void;
    protected onSourceDestroy(source: TextureSource): void;
    private _initSampler;
    private _getGlSampler;
    getGlSource(source: TextureSource): GlTexture;
    generateCanvas(texture: Texture): ICanvas;
    getPixels(texture: Texture): GetPixelsOutput;
    destroy(): void;
    resetState(): void;
}
`,ds=`/**
 * Various GL texture/resources formats.
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} [RGBA=6408] -
 * @property {number} [RGB=6407] -
 * @property {number} [RG=33319] -
 * @property {number} [RED=6403] -
 * @property {number} [RGBA_INTEGER=36249] -
 * @property {number} [RGB_INTEGER=36248] -
 * @property {number} [RG_INTEGER=33320] -
 * @property {number} [RED_INTEGER=36244] -
 * @property {number} [ALPHA=6406] -
 * @property {number} [LUMINANCE=6409] -
 * @property {number} [LUMINANCE_ALPHA=6410] -
 * @property {number} [DEPTH_COMPONENT=6402] -
 * @property {number} [DEPTH_STENCIL=34041] -
 */
export declare enum GL_FORMATS {
    RGBA = 6408,
    RGB = 6407,
    RG = 33319,
    RED = 6403,
    RGBA_INTEGER = 36249,
    RGB_INTEGER = 36248,
    RG_INTEGER = 33320,
    RED_INTEGER = 36244,
    ALPHA = 6406,
    LUMINANCE = 6409,
    LUMINANCE_ALPHA = 6410,
    DEPTH_COMPONENT = 6402,
    DEPTH_STENCIL = 34041
}
/**
 * Various GL target types.
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} [TEXTURE_2D=3553] -
 * @property {number} [TEXTURE_CUBE_MAP=34067] -
 * @property {number} [TEXTURE_2D_ARRAY=35866] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_X=34069] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_X=34070] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_Y=34071] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_Y=34072] -
 * @property {number} [TEXTURE_CUBE_MAP_POSITIVE_Z=34073] -
 * @property {number} [TEXTURE_CUBE_MAP_NEGATIVE_Z=34074] -
 */
export declare enum GL_TARGETS {
    TEXTURE_2D = 3553,
    TEXTURE_CUBE_MAP = 34067,
    TEXTURE_2D_ARRAY = 35866,
    TEXTURE_CUBE_MAP_POSITIVE_X = 34069,
    TEXTURE_CUBE_MAP_NEGATIVE_X = 34070,
    TEXTURE_CUBE_MAP_POSITIVE_Y = 34071,
    TEXTURE_CUBE_MAP_NEGATIVE_Y = 34072,
    TEXTURE_CUBE_MAP_POSITIVE_Z = 34073,
    TEXTURE_CUBE_MAP_NEGATIVE_Z = 34074
}
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 * @name WRAP_MODES
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */
export declare enum GL_WRAP_MODES {
    CLAMP = 33071,
    REPEAT = 10497,
    MIRRORED_REPEAT = 33648
}
export declare enum GL_TYPES {
    /**
     * 8 bits per channel for gl.RGBA
     * @default 5121
     */
    UNSIGNED_BYTE = 5121,
    /**
     * @default 5123
     */
    UNSIGNED_SHORT = 5123,
    /**
     * 5 red bits, 6 green bits, 5 blue bits.
     * @default 33635
     */
    UNSIGNED_SHORT_5_6_5 = 33635,
    /**
     * 4 red bits, 4 green bits, 4 blue bits, 4 alpha bits.
     * @default 32819
     */
    UNSIGNED_SHORT_4_4_4_4 = 32819,
    /**
     * 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit.
     * @default 32820
     */
    UNSIGNED_SHORT_5_5_5_1 = 32820,
    /**
     * @default 5125
     */
    UNSIGNED_INT = 5125,
    /**
     * @default 35899
     */
    UNSIGNED_INT_10F_11F_11F_REV = 35899,
    /**
     * @default 33640
     */
    UNSIGNED_INT_2_10_10_10_REV = 33640,
    /**
     * @default 34042
     */
    UNSIGNED_INT_24_8 = 34042,
    /**
     * @default 35902
     */
    UNSIGNED_INT_5_9_9_9_REV = 35902,
    /**
     * @default 5120
     */
    BYTE = 5120,
    /**
     * @default 5122
     */
    SHORT = 5122,
    /**
     * @default 5124
     */
    INT = 5124,
    /**
     * @default 5126
     */
    FLOAT = 5126,
    /**
     * @default 36269
     */
    FLOAT_32_UNSIGNED_INT_24_8_REV = 36269,
    /**
     * @default 36193
     */
    HALF_FLOAT = 36193
}
`,ps=`import type { TextureSource } from '../../../shared/texture/sources/TextureSource';
import type { GlRenderingContext } from '../../context/GlRenderingContext';
import type { GlTexture } from '../GlTexture';
export interface GLTextureUploader {
    id: string;
    upload(source: TextureSource, glTexture: GlTexture, gl: GlRenderingContext, webGLVersion: number): void;
}
`,cs=`import type { GLTextureUploader } from './GLTextureUploader';
export declare const glUploadBufferImageResource: GLTextureUploader;
`,us=`import type { GLTextureUploader } from './GLTextureUploader';
export declare const glUploadCompressedTextureResource: GLTextureUploader;
`,ms=`import type { GLTextureUploader } from './GLTextureUploader';
export declare const glUploadImageResource: GLTextureUploader;
`,hs=`import type { GLTextureUploader } from './GLTextureUploader';
export declare const glUploadVideoResource: GLTextureUploader;
`,fs=`import type { TextureStyle } from '../../../shared/texture/TextureStyle';
export declare function applyStyleParams(style: TextureStyle, gl: WebGL2RenderingContext, mipmaps: boolean, anisotropicExt: EXT_texture_filter_anisotropic, glFunctionName: 'samplerParameteri' | 'texParameteri', firstParam: 3553 | WebGLSampler, forceClamp: boolean, 
/** if true we can skip setting certain values if the values is the same as the default gl values */
firstCreation: boolean): void;
`,bs=`import type { TEXTURE_FORMATS } from '../../../shared/texture/const';
export declare function getSupportedGlCompressedTextureFormats(): TEXTURE_FORMATS[];
`,gs=`import type { GlRenderingContext } from '../../context/GlRenderingContext';
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @returns Lookup table.
 */
export declare function mapFormatToGlFormat(gl: GlRenderingContext): Record<string, number>;
`,ys=`import type { GlRenderingContext } from '../../context/GlRenderingContext';
import type { WebGLExtensions } from '../../context/WebGLExtensions';
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param gl - The rendering context.
 * @param extensions - The WebGL extensions.
 * @returns Lookup table.
 */
export declare function mapFormatToGlInternalFormat(gl: GlRenderingContext, extensions: WebGLExtensions): Record<string, number>;
`,xs=`import type { GlRenderingContext } from '../../context/GlRenderingContext';
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @returns Lookup table.
 */
export declare function mapFormatToGlType(gl: GlRenderingContext): Record<string, number>;
`,vs=`export declare const scaleModeToGlFilter: {
    linear: number;
    nearest: number;
};
export declare const mipmapScaleModeToGlFilter: {
    linear: {
        linear: number;
        nearest: number;
    };
    nearest: {
        linear: number;
        nearest: number;
    };
};
export declare const wrapModeToGlAddress: {
    'clamp-to-edge': number;
    repeat: number;
    'mirror-repeat': number;
};
export declare const compareModeToGlCompare: {
    never: number;
    less: number;
    equal: number;
    'less-equal': number;
    greater: number;
    'not-equal': number;
    'greater-equal': number;
    always: number;
};
`,Ts=`export declare function unpremultiplyAlpha(pixels: Uint8Array | Uint8ClampedArray): void;
`,Ss=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../extensions/Extensions';
import type { System } from '../shared/system/System';
import type { GPU } from './GpuDeviceSystem';
import type { BindGroup } from './shader/BindGroup';
import type { GpuProgram } from './shader/GpuProgram';
import type { WebGPURenderer } from './WebGPURenderer';
/**
 * This manages the WebGPU bind groups. this is how data is bound to a shader when rendering
 * @memberof rendering
 */
export declare class BindGroupSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "bindGroup";
    };
    private readonly _renderer;
    private _hash;
    private _gpu;
    constructor(renderer: WebGPURenderer);
    protected contextChange(gpu: GPU): void;
    getBindGroup(bindGroup: BindGroup, program: GpuProgram, groupIndex: number): GPUBindGroup;
    private _createBindGroup;
    destroy(): void;
}
`,ws=`import { ExtensionType } from '../../../extensions/Extensions';
import type { System } from '../shared/system/System';
import type { WebGPURenderer } from './WebGPURenderer';
/**
 * The system that handles color masking for the GPU.
 * @memberof rendering
 */
export declare class GpuColorMaskSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "colorMask";
    };
    private readonly _renderer;
    private _colorMaskCache;
    constructor(renderer: WebGPURenderer);
    setMask(colorMask: number): void;
    destroy(): void;
}
`,_s=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../extensions/Extensions';
import type { System } from '../shared/system/System';
import type { GpuPowerPreference } from '../types';
import type { WebGPURenderer } from './WebGPURenderer';
/** The GPU object. */
export interface GPU {
    /** The GPU adapter */
    adapter: GPUAdapter;
    /** The GPU device */
    device: GPUDevice;
}
/**
 * Options for the WebGPU context.
 * @property {GpuPowerPreference} [powerPreference=default] - An optional hint indicating what configuration of GPU
 * is suitable for the WebGPU context, can be \`'high-performance'\` or \`'low-power'\`.
 * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
 * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
 * @property {boolean} [forceFallbackAdapter=false] - Force the use of the fallback adapter
 * @memberof rendering
 */
export interface GpuContextOptions {
    /**
     * An optional hint indicating what configuration of GPU is suitable for the WebGPU context,
     * can be \`'high-performance'\` or \`'low-power'\`.
     * Setting to \`'high-performance'\` will prioritize rendering performance over power consumption,
     * while setting to \`'low-power'\` will prioritize power saving over rendering performance.
     * @default undefined
     * @memberof rendering.WebGPUOptions
     */
    powerPreference?: GpuPowerPreference;
    /**
     * Force the use of the fallback adapter
     * @default false
     * @memberof rendering.WebGPUOptions
     */
    forceFallbackAdapter: boolean;
}
/**
 * System plugin to the renderer to manage the context.
 * @class
 * @memberof rendering
 */
export declare class GpuDeviceSystem implements System<GpuContextOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "device";
    };
    /** The default options for the GpuDeviceSystem. */
    static defaultOptions: GpuContextOptions;
    /** The GPU device */
    gpu: GPU;
    private _renderer;
    private _initPromise;
    /**
     * @param {WebGPURenderer} renderer - The renderer this System works for.
     */
    constructor(renderer: WebGPURenderer);
    init(options: GpuContextOptions): Promise<void>;
    /**
     * Handle the context change event
     * @param gpu
     */
    protected contextChange(gpu: GPU): void;
    /**
     * Helper class to create a WebGL Context
     * @param {object} options - An options object that gets passed in to the canvas element containing the
     *    context attributes
     * @see https://developer.mozilla.org/en/docs/Web/API/HTMLCanvasElement/getContext
     * @returns {WebGLRenderingContext} the WebGL context
     */
    private _createDeviceAndAdaptor;
    destroy(): void;
}
`,Es=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../extensions/Extensions';
import type { Rectangle } from '../../../maths/shapes/Rectangle';
import type { Topology } from '../shared/geometry/const';
import type { Geometry } from '../shared/geometry/Geometry';
import type { Shader } from '../shared/shader/Shader';
import type { State } from '../shared/state/State';
import type { System } from '../shared/system/System';
import type { GPU } from './GpuDeviceSystem';
import type { GpuRenderTarget } from './renderTarget/GpuRenderTarget';
import type { BindGroup } from './shader/BindGroup';
import type { GpuProgram } from './shader/GpuProgram';
import type { WebGPURenderer } from './WebGPURenderer';
/**
 * The system that handles encoding commands for the GPU.
 * @memberof rendering
 */
export declare class GpuEncoderSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "encoder";
        readonly priority: 1;
    };
    commandEncoder: GPUCommandEncoder;
    renderPassEncoder: GPURenderPassEncoder;
    commandFinished: Promise<void>;
    private _resolveCommandFinished;
    private _gpu;
    private _boundBindGroup;
    private _boundVertexBuffer;
    private _boundIndexBuffer;
    private _boundPipeline;
    private readonly _renderer;
    constructor(renderer: WebGPURenderer);
    renderStart(): void;
    beginRenderPass(gpuRenderTarget: GpuRenderTarget): void;
    endRenderPass(): void;
    setViewport(viewport: Rectangle): void;
    setPipelineFromGeometryProgramAndState(geometry: Geometry, program: GpuProgram, state: any, topology?: Topology): void;
    setPipeline(pipeline: GPURenderPipeline): void;
    private _setVertexBuffer;
    private _setIndexBuffer;
    resetBindGroup(index: number): void;
    setBindGroup(index: number, bindGroup: BindGroup, program: GpuProgram): void;
    setGeometry(geometry: Geometry, program: GpuProgram): void;
    private _setShaderBindGroups;
    private _syncBindGroup;
    draw(options: {
        geometry: Geometry;
        shader: Shader;
        state?: State;
        topology?: Topology;
        size?: number;
        start?: number;
        instanceCount?: number;
        skipSync?: boolean;
    }): void;
    finishRenderPass(): void;
    postrender(): void;
    restoreRenderPass(): void;
    private _clearCache;
    destroy(): void;
    protected contextChange(gpu: GPU): void;
}
`,Ps=`import { ExtensionType } from '../../../extensions/Extensions';
import { STENCIL_MODES } from '../shared/state/const';
import type { RenderTarget } from '../shared/renderTarget/RenderTarget';
import type { System } from '../shared/system/System';
import type { WebGPURenderer } from './WebGPURenderer';
/**
 * This manages the stencil buffer. Used primarily for masking
 * @memberof rendering
 */
export declare class GpuStencilSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "stencil";
    };
    private readonly _renderer;
    private _renderTargetStencilState;
    private _activeRenderTarget;
    constructor(renderer: WebGPURenderer);
    protected onRenderTargetChange(renderTarget: RenderTarget): void;
    setStencilMode(stencilMode: STENCIL_MODES, stencilReference: number): void;
    destroy(): void;
}
`,As=`import { ExtensionType } from '../../../extensions/Extensions';
import { UboSystem } from '../shared/shader/UboSystem';
/**
 * System plugin to the renderer to manage uniform buffers. With a WGSL twist!
 * @memberof rendering
 */
export declare class GpuUboSystem extends UboSystem {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "ubo";
    };
    constructor();
}
`,Cs=`import { ExtensionType } from '../../../extensions/Extensions';
import { BufferResource } from '../shared/buffer/BufferResource';
import { BindGroup } from './shader/BindGroup';
import type { UniformGroup } from '../shared/shader/UniformGroup';
import type { WebGPURenderer } from './WebGPURenderer';
export declare class GpuUniformBatchPipe {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUPipes];
        readonly name: "uniformBatch";
    };
    private _renderer;
    private _bindGroupHash;
    private readonly _batchBuffer;
    private _buffers;
    private _bindGroups;
    private _bufferResources;
    constructor(renderer: WebGPURenderer);
    renderEnd(): void;
    private _resetBindGroups;
    getUniformBindGroup(group: UniformGroup<any>, duplicate: boolean): BindGroup;
    getUboResource(group: UniformGroup<any>): BufferResource;
    getArrayBindGroup(data: Float32Array): BindGroup;
    getArrayBufferResource(data: Float32Array): BufferResource;
    private _getBufferResource;
    private _getBindGroup;
    private _uploadBindGroups;
    destroy(): void;
}
`,Rs=`import { AbstractRenderer } from '../shared/system/AbstractRenderer';
import { BindGroupSystem } from './BindGroupSystem';
import { GpuBufferSystem } from './buffer/GpuBufferSystem';
import { GpuColorMaskSystem } from './GpuColorMaskSystem';
import { type GPU, GpuDeviceSystem } from './GpuDeviceSystem';
import { GpuEncoderSystem } from './GpuEncoderSystem';
import { GpuStencilSystem } from './GpuStencilSystem';
import { GpuUboSystem } from './GpuUboSystem';
import { GpuUniformBatchPipe } from './GpuUniformBatchPipe';
import { PipelineSystem } from './pipeline/PipelineSystem';
import { GpuRenderTargetSystem } from './renderTarget/GpuRenderTargetSystem';
import { GpuShaderSystem } from './shader/GpuShaderSystem';
import { GpuStateSystem } from './state/GpuStateSystem';
import { GpuTextureSystem } from './texture/GpuTextureSystem';
import type { ICanvas } from '../../../environment/canvas/ICanvas';
import type { SharedRendererOptions } from '../shared/system/SharedSystems';
import type { ExtractRendererOptions, ExtractSystemTypes } from '../shared/system/utils/typeUtils';
declare const DefaultWebGPUSystems: (typeof import("../..").BackgroundSystem | typeof import("../..").GlobalUniformSystem | typeof import("../..").HelloSystem | typeof import("../..").ViewSystem | typeof import("../../..").RenderGroupSystem | typeof import("../..").TextureGCSystem | typeof import("../..").GenerateTextureSystem | typeof import("../..").ExtractSystem | typeof import("../../..").RendererInitHook | typeof import("../..").RenderableGCSystem | typeof import("../..").SchedulerSystem | typeof GpuUboSystem | typeof GpuEncoderSystem | typeof GpuDeviceSystem | typeof GpuBufferSystem | typeof GpuTextureSystem | typeof GpuRenderTargetSystem | typeof GpuShaderSystem | typeof GpuStateSystem | typeof PipelineSystem | typeof GpuColorMaskSystem | typeof GpuStencilSystem | typeof BindGroupSystem)[];
declare const DefaultWebGPUPipes: (typeof import("../..").BlendModePipe | typeof import("../..").BatcherPipe | typeof import("../../..").SpritePipe | typeof import("../../..").RenderGroupPipe | typeof import("../..").AlphaMaskPipe | typeof import("../..").StencilMaskPipe | typeof import("../..").ColorMaskPipe | typeof import("../../..").CustomRenderPipe | typeof GpuUniformBatchPipe)[];
type WebGPUSystems = ExtractSystemTypes<typeof DefaultWebGPUSystems> & PixiMixins.RendererSystems & PixiMixins.WebGPUSystems;
export type WebGPUPipes = ExtractSystemTypes<typeof DefaultWebGPUPipes> & PixiMixins.RendererPipes & PixiMixins.WebGPUPipes;
/**
 * Options for WebGPURenderer.
 * @memberof rendering
 */
export interface WebGPUOptions extends SharedRendererOptions, ExtractRendererOptions<typeof DefaultWebGPUSystems>, PixiMixins.WebGPUOptions {
}
export interface WebGPURenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGPUPipes, WebGPUOptions, T>, WebGPUSystems {
}
/**
 * The WebGPU PixiJS Renderer. This renderer allows you to use the next-generation graphics API, WebGPU.
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = new WebGPURenderer();
 * await renderer.init();
 *
 * // Add the renderer to the stage
 * document.body.appendChild(renderer.canvas);
 *
 * // Create a new stage
 * const stage = new Container();
 *
 * // Render the stage
 * renderer.render(stage);
 * \`\`\`
 *
 * You can use {@link rendering.autoDetectRenderer} to create a renderer that will automatically detect the best
 * renderer for the environment.
 * \`\`\`ts
 * // Create a new renderer
 * const renderer = await rendering.autoDetectRenderer();
 * \`\`\`
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a WebGPU renderer:
 *
 * | WebGPU Core Systems                      | Systems that are specific to the WebGL renderer                               |
 * | ---------------------------------------- | ----------------------------------------------------------------------------- |
 * | {@link rendering.GpuUboSystem}           | This manages WebGPU uniform buffer objects feature for shaders                |
 * | {@link rendering.GpuEncoderSystem}       | This manages the WebGPU command encoder                                       |
 * | {@link rendering.GpuDeviceSystem}        | This manages the WebGPU Device and its extensions                             |
 * | {@link rendering.GpuBufferSystem}        | This manages buffers and their GPU resources, keeps everything in sync        |
 * | {@link rendering.GpuTextureSystem}       | This manages textures and their GPU resources, keeps everything in sync       |
 * | {@link rendering.GpuRenderTargetSystem}  | This manages what we render too. For example the screen, or another texture   |
 * | {@link rendering.GpuShaderSystem}        | This manages shaders, programs that run on the GPU to output lovely pixels    |
 * | {@link rendering.GpuStateSystem}         | This manages the state of the WebGPU Pipelines. eg the various flags that can be set blend modes / depthTesting etc |
 * | {@link rendering.PipelineSystem}         | This manages the WebGPU pipelines, used for rendering                         |
 * | {@link rendering.GpuColorMaskSystem}     | This manages the color mask. Used for color masking                           |
 * | {@link rendering.GpuStencilSystem}       | This manages the stencil buffer. Used primarily for masking                   |
 * | {@link rendering.BindGroupSystem}        | This manages the WebGPU bind groups. this is how data is bound to a shader when rendering |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @memberof rendering
 * @property {rendering.GpuUboSystem} ubo - UboSystem instance.
 * @property {rendering.GpuEncoderSystem} encoder - EncoderSystem instance.
 * @property {rendering.GpuDeviceSystem} device - DeviceSystem instance.
 * @property {rendering.GpuBufferSystem} buffer - BufferSystem instance.
 * @property {rendering.GpuTextureSystem} texture - TextureSystem instance.
 * @property {rendering.GpuRenderTargetSystem} renderTarget - RenderTargetSystem instance.
 * @property {rendering.GpuShaderSystem} shader - ShaderSystem instance.
 * @property {rendering.GpuStateSystem} state - StateSystem instance.
 * @property {rendering.PipelineSystem} pipeline - PipelineSystem instance.
 * @property {rendering.GpuColorMaskSystem} colorMask - ColorMaskSystem instance.
 * @property {rendering.GpuStencilSystem} stencil - StencilSystem instance.
 * @property {rendering.BindGroupSystem} bindGroup - BindGroupSystem instance.
 * @extends rendering.AbstractRenderer
 */
export declare class WebGPURenderer<T extends ICanvas = HTMLCanvasElement> extends AbstractRenderer<WebGPUPipes, WebGPUOptions, T> implements WebGPUSystems {
    /** The WebGPU Device. */
    gpu: GPU;
    constructor();
}
export {};
`,Gs=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../../extensions/Extensions';
import type { Buffer } from '../../shared/buffer/Buffer';
import type { System } from '../../shared/system/System';
import type { GPU } from '../GpuDeviceSystem';
import type { WebGPURenderer } from '../WebGPURenderer';
/**
 * System plugin to the renderer to manage buffers.
 * @memberof rendering
 */
export declare class GpuBufferSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "buffer";
    };
    protected CONTEXT_UID: number;
    private _gpuBuffers;
    private readonly _managedBuffers;
    private _gpu;
    constructor(renderer: WebGPURenderer);
    protected contextChange(gpu: GPU): void;
    getGPUBuffer(buffer: Buffer): GPUBuffer;
    updateBuffer(buffer: Buffer): GPUBuffer;
    /** dispose all WebGL resources of all managed buffers */
    destroyAll(): void;
    createGPUBuffer(buffer: Buffer): GPUBuffer;
    protected onBufferChange(buffer: Buffer): void;
    /**
     * Disposes buffer
     * @param buffer - buffer with data
     */
    protected onBufferDestroy(buffer: Buffer): void;
    destroy(): void;
    private _destroyBuffer;
}
`,Ms=`import { Buffer } from '../../shared/buffer/Buffer';
import type { WebGPURenderer } from '../WebGPURenderer';
export declare function GpuReadBuffer(buffer: Buffer, renderer: WebGPURenderer): void;
`,ks=`export declare class UboBatch {
    data: Float32Array;
    private readonly _minUniformOffsetAlignment;
    byteIndex: number;
    constructor({ minUniformOffsetAlignment }: {
        minUniformOffsetAlignment: number;
    });
    clear(): void;
    addEmptyGroup(size: number): number;
    addGroup(array: Float32Array): number;
    destroy(): void;
}
`,Fs=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../../extensions/Extensions';
import { STENCIL_MODES } from '../../shared/state/const';
import type { Topology } from '../../shared/geometry/const';
import type { Geometry } from '../../shared/geometry/Geometry';
import type { State } from '../../shared/state/State';
import type { System } from '../../shared/system/System';
import type { GPU } from '../GpuDeviceSystem';
import type { GpuRenderTarget } from '../renderTarget/GpuRenderTarget';
import type { GpuProgram } from '../shader/GpuProgram';
import type { WebGPURenderer } from '../WebGPURenderer';
/**
 * A system that creates and manages the GPU pipelines.
 *
 * Caching Mechanism: At its core, the system employs a two-tiered caching strategy to minimize
 * the redundant creation of GPU pipelines (or "pipes"). This strategy is based on generating unique
 * keys that represent the state of the graphics settings and the specific requirements of the
 * item being rendered. By caching these pipelines, subsequent draw calls with identical configurations
 * can reuse existing pipelines instead of generating new ones.
 *
 * State Management: The system differentiates between "global" state properties (like color masks
 * and stencil masks, which do not change frequently) and properties that may vary between draw calls
 * (such as geometry, shaders, and blend modes). Unique keys are generated for both these categories
 * using getStateKey for global state and getGraphicsStateKey for draw-specific settings. These keys are
 * then then used to caching the pipe. The next time we need a pipe we can check
 * the cache by first looking at the state cache and then the pipe cache.
 * @memberof rendering
 */
export declare class PipelineSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "pipeline";
    };
    private readonly _renderer;
    protected CONTEXT_UID: number;
    private _moduleCache;
    private _bufferLayoutsCache;
    private readonly _bindingNamesCache;
    private _pipeCache;
    private readonly _pipeStateCaches;
    private _gpu;
    private _stencilState;
    private _stencilMode;
    private _colorMask;
    private _multisampleCount;
    private _depthStencilAttachment;
    constructor(renderer: WebGPURenderer);
    protected contextChange(gpu: GPU): void;
    setMultisampleCount(multisampleCount: number): void;
    setRenderTarget(renderTarget: GpuRenderTarget): void;
    setColorMask(colorMask: number): void;
    setStencilMode(stencilMode: STENCIL_MODES): void;
    setPipeline(geometry: Geometry, program: GpuProgram, state: State, passEncoder: GPURenderPassEncoder): void;
    getPipeline(geometry: Geometry, program: GpuProgram, state: State, topology?: Topology): GPURenderPipeline;
    private _createPipeline;
    private _getModule;
    private _createModule;
    private _generateBufferKey;
    private _generateAttributeLocationsKey;
    /**
     * Returns a hash of buffer names mapped to bind locations.
     * This is used to bind the correct buffer to the correct location in the shader.
     * @param geometry - The geometry where to get the buffer names
     * @param program - The program where to get the buffer names
     * @returns An object of buffer names mapped to the bind location.
     */
    getBufferNamesToBind(geometry: Geometry, program: GpuProgram): Record<string, string>;
    private _createVertexBufferLayouts;
    private _updatePipeHash;
    destroy(): void;
}
`,Os=`/// <reference types="@webgpu/types" />
import type { TextureSource } from '../../shared/texture/sources/TextureSource';
/**
 * A class which holds the canvas contexts and textures for a render target.
 * @memberof rendering
 * @ignore
 */
export declare class GpuRenderTarget {
    contexts: GPUCanvasContext[];
    msaaTextures: TextureSource[];
    msaa: boolean;
    msaaSamples: number;
    width: number;
    height: number;
    descriptor: GPURenderPassDescriptor;
}
`,Is=`/// <reference types="@webgpu/types" />
import { TextureSource } from '../../shared/texture/sources/TextureSource';
import { GpuRenderTarget } from './GpuRenderTarget';
import type { RgbaArray } from '../../../../color/Color';
import type { Rectangle } from '../../../../maths/shapes/Rectangle';
import type { CLEAR_OR_BOOL } from '../../gl/const';
import type { RenderTarget } from '../../shared/renderTarget/RenderTarget';
import type { RenderTargetAdaptor, RenderTargetSystem } from '../../shared/renderTarget/RenderTargetSystem';
import type { Texture } from '../../shared/texture/Texture';
import type { WebGPURenderer } from '../WebGPURenderer';
/**
 * The WebGPU adaptor for the render target system. Allows the Render Target System to
 * be used with the WebGPU renderer
 * @memberof rendering
 * @ignore
 */
export declare class GpuRenderTargetAdaptor implements RenderTargetAdaptor<GpuRenderTarget> {
    private _renderTargetSystem;
    private _renderer;
    init(renderer: WebGPURenderer, renderTargetSystem: RenderTargetSystem<GpuRenderTarget>): void;
    copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
        x: number;
        y: number;
    }, size: {
        width: number;
        height: number;
    }, originDest: {
        x: number;
        y: number;
    }): Texture<TextureSource<any>>;
    startRenderPass(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
    finishRenderPass(): void;
    /**
     * returns the gpu texture for the first color texture in the render target
     * mainly used by the filter manager to get copy the texture for blending
     * @param renderTarget
     * @returns a gpu texture
     */
    private _getGpuColorTexture;
    getDescriptor(renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, clearValue: RgbaArray): GPURenderPassDescriptor;
    clear(renderTarget: RenderTarget, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, viewport?: Rectangle): void;
    initGpuRenderTarget(renderTarget: RenderTarget): GpuRenderTarget;
    destroyGpuRenderTarget(gpuRenderTarget: GpuRenderTarget): void;
    ensureDepthStencilTexture(renderTarget: RenderTarget): void;
    resizeGpuRenderTarget(renderTarget: RenderTarget): void;
}
`,Ls=`import { ExtensionType } from '../../../../extensions/Extensions';
import { RenderTargetSystem } from '../../shared/renderTarget/RenderTargetSystem';
import { GpuRenderTargetAdaptor } from './GpuRenderTargetAdaptor';
import type { WebGPURenderer } from '../WebGPURenderer';
import type { GpuRenderTarget } from './GpuRenderTarget';
/**
 * The WebGL adaptor for the render target system. Allows the Render Target System to be used with the WebGl renderer
 * @memberof rendering
 */
export declare class GpuRenderTargetSystem extends RenderTargetSystem<GpuRenderTarget> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "renderTarget";
    };
    adaptor: GpuRenderTargetAdaptor;
    constructor(renderer: WebGPURenderer);
}
`,Bs=`import type { Matrix } from '../../../../maths/matrix/Matrix';
export declare function calculateProjection(pm: Matrix, x: number, y: number, width: number, height: number, flipY: boolean): Matrix;
`,Ds=`import type { BindResource } from './BindResource';
/**
 * A bind group is a collection of resources that are bound together for use by a shader.
 * They are essentially a wrapper for the WebGPU BindGroup class. But with the added bonus
 * that WebGL can also work with them.
 * @see https://gpuweb.github.io/gpuweb/#dictdef-gpubindgroupdescriptor
 * @example
 * // Create a bind group with a single texture and sampler
 * const bindGroup = new BindGroup({
 *    uTexture: texture.source,
 *    uTexture: texture.style,
 * });
 *
 * Bind groups resources must implement the {@link BindResource} interface.
 * The following resources are supported:
 * - {@link TextureSource}
 * - {@link TextureStyle}
 * - {@link Buffer}
 * - {@link BufferResource}
 * - {@link UniformGroup}
 *
 * The keys in the bind group must correspond to the names of the resources in the GPU program.
 *
 * This bind group class will also watch for changes in its resources ensuring that the changes
 * are reflected in the WebGPU BindGroup.
 * @memberof rendering
 */
export declare class BindGroup {
    /** The resources that are bound together for use by a shader. */
    resources: Record<string, BindResource>;
    /**
     * a key used internally to match it up to a WebGPU Bindgroup
     * @internal
     * @ignore
     */
    _key: string;
    private _dirty;
    /**
     * Create a new instance eof the Bind Group.
     * @param resources - The resources that are bound together for use by a shader.
     */
    constructor(resources?: Record<string, BindResource>);
    /**
     * Updates the key if its flagged as dirty. This is used internally to
     * match this bind group to a WebGPU BindGroup.
     * @internal
     * @ignore
     */
    _updateKey(): void;
    /**
     * Set a resource at a given index. this function will
     * ensure that listeners will be removed from the current resource
     * and added to the new resource.
     * @param resource - The resource to set.
     * @param index - The index to set the resource at.
     */
    setResource(resource: BindResource, index: number): void;
    /**
     * Returns the resource at the current specified index.
     * @param index - The index of the resource to get.
     * @returns - The resource at the specified index.
     */
    getResource(index: number): BindResource;
    /**
     * Used internally to 'touch' each resource, to ensure that the GC
     * knows that all resources in this bind group are still being used.
     * @param tick - The current tick.
     * @internal
     * @ignore
     */
    _touch(tick: number): void;
    /** Destroys this bind group and removes all listeners. */
    destroy(): void;
    protected onResourceChange(resource: BindResource): void;
}
`,Us=`import type { BindGroup } from './BindGroup';
/**
 * an interface that allows a resource to be bound to the gpu in a bind group
 * @memberof rendering
 */
export interface BindResource {
    /**
     * The type of resource this is
     * @ignore
     */
    _resourceType: string;
    /**
     * Unique id for this resource this can change and is used to link the gpu
     * @ignore
     */
    _resourceId: number;
    _touched: number;
    /**
     * a boolean that indicates if the resource has been destroyed.
     * If true, the resource should not be used and any bind groups
     * that will release any references to this resource.
     * @ignore
     */
    destroyed: boolean;
    /**
     * event dispatch whenever the underlying resource needs to change
     * this could be a texture or buffer that has been resized.
     * This is important as it allows the renderer to know that it needs to rebind the resource
     */
    on?(event: 'change', listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
    /** @todo */
    off?(event: 'change', listenerFunction: (resource: BindResource) => void, listener: BindGroup): void;
}
`,js=`/// <reference types="@webgpu/types" />
import type { ExtractedAttributeData } from '../../gl/shader/program/extractAttributesFromGlProgram';
import type { StructsAndGroups } from './utils/extractStructAndGroups';
/**
 * a WebGPU descriptions of how the program is laid out
 * @see https://gpuweb.github.io/gpuweb/#gpupipelinelayout
 * @memberof rendering
 */
export type ProgramPipelineLayoutDescription = GPUBindGroupLayoutEntry[][];
/**
 * a map the maps names of uniforms to group indexes
 * @memberof rendering
 */
export type ProgramLayout = Record<string, number>[];
/**
 * the program source
 * @memberof rendering
 */
export interface ProgramSource {
    /** The wgsl source code of the shader. */
    source: string;
    /** The main function to run in this shader */
    entryPoint?: string;
}
/**
 * The options for the gpu program
 * @memberof rendering
 */
export interface GpuProgramOptions {
    /**
     * the name of the program, this is added to the label of the GPU Program created
     * under the hood. Makes it much easier to debug!
     */
    name?: string;
    /** The fragment glsl shader source. */
    fragment?: ProgramSource;
    /** The vertex glsl shader source. */
    vertex?: ProgramSource;
    /** The layout of the program. If not provided, it will be generated from the shader sources. */
    layout?: ProgramLayout;
    /** The gpu layout of the program. If not provided, it will be generated from the shader sources. */
    gpuLayout?: ProgramPipelineLayoutDescription;
}
/**
 * A wrapper for a WebGPU Program, specifically designed for the WebGPU renderer.
 * This class facilitates the creation and management of shader code that integrates with the WebGPU pipeline.
 *
 * To leverage the full capabilities of this class, familiarity with WGSL shaders is recommended.
 * @see https://gpuweb.github.io/gpuweb/#index
 * @example
 *
 * // Create a new program
 * const program = new GpuProgram({
 *   vertex: {
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 *   fragment:{
 *    source: '...',
 *    entryPoint: 'main',
 *   },
 * });
 *
 *
 * Note: Both fragment and vertex shader sources can coexist within a single WGSL source file
 * this can make things a bit simpler.
 *
 * For optimal usage and best performance, it help to reuse programs whenever possible.
 * The {@link GpuProgram.from} helper function is designed for this purpose, utilizing an
 * internal cache to efficiently manage and retrieve program instances.
 * By leveraging this function, you can significantly reduce overhead and enhance the performance of your rendering pipeline.
 *
 * An important distinction between WebGL and WebGPU regarding program data retrieval:
 * While WebGL allows extraction of program information directly from its compiled state,
 * WebGPU does not offer such a capability. Therefore, in the context of WebGPU, we're required
 * to manually extract the program layout information from the source code itself.
 * @memberof rendering
 */
export declare class GpuProgram {
    /** The fragment glsl shader source. */
    readonly fragment?: ProgramSource;
    /** The vertex glsl shader source */
    readonly vertex?: ProgramSource;
    /**
     * Mapping of uniform names to group indexes for organizing shader program uniforms.
     * Automatically generated from shader sources if not provided.
     * @example
     * // Assuming a shader with two uniforms, \`u_time\` and \`u_resolution\`, grouped respectively:
     * [
     *   { "u_time": 0 },
     *   { "u_resolution": 1 }
     * ]
     */
    readonly layout: ProgramLayout;
    /**
     * Configuration for the WebGPU bind group layouts, detailing resource organization for the shader.
     * Generated from shader sources if not explicitly provided.
     * @example
     * // Assuming a shader program that requires two bind groups:
     * [
     *   // First bind group layout entries
     *   [{ binding: 0, visibility: GPUShaderStage.VERTEX, type: "uniform-buffer" }],
     *   // Second bind group layout entries
     *   [{ binding: 1, visibility: GPUShaderStage.FRAGMENT, type: "sampler" },
     *    { binding: 2, visibility: GPUShaderStage.FRAGMENT, type: "sampled-texture" }]
     * ]
     */
    readonly gpuLayout: ProgramPipelineLayoutDescription;
    /**
     * @internal
     * @ignore
     */
    _layoutKey: number;
    /**
     * @internal
     * @ignore
     */
    _attributeLocationsKey: number;
    /** the structs and groups extracted from the shader sources */
    readonly structsAndGroups: StructsAndGroups;
    /**
     * the name of the program, this is added to the label of the GPU Program created under the hood.
     * Makes it much easier to debug!
     */
    readonly name: string;
    private _attributeData;
    /** if true, the program will automatically assign global uniforms to group[0] */
    autoAssignGlobalUniforms: boolean;
    /** if true, the program will automatically assign local uniforms to group[1] */
    autoAssignLocalUniforms: boolean;
    /**
     * Create a new GpuProgram
     * @param options - The options for the gpu program
     */
    constructor(options: GpuProgramOptions);
    private _generateProgramKey;
    get attributeData(): Record<string, ExtractedAttributeData>;
    /** destroys the program */
    destroy(): void;
    /**
     * Helper function that creates a program for a given source.
     * It will check the program cache if the program has already been created.
     * If it has that one will be returned, if not a new one will be created and cached.
     * @param options - The options for the program.
     * @returns A program using the same source
     */
    static from(options: GpuProgramOptions): GpuProgram;
}
`,Ws=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../../extensions/Extensions';
import type { ShaderSystem } from '../../shared/shader/ShaderSystem';
import type { GPU } from '../GpuDeviceSystem';
import type { GpuProgram } from './GpuProgram';
export interface GPUProgramData {
    bindGroups: GPUBindGroupLayout[];
    pipeline: GPUPipelineLayout;
}
/**
 * A system that manages the rendering of GpuPrograms.
 * @memberof rendering
 */
export declare class GpuShaderSystem implements ShaderSystem {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "shader";
    };
    maxTextures: number;
    private _gpu;
    private readonly _gpuProgramData;
    protected contextChange(gpu: GPU): void;
    getProgramData(program: GpuProgram): GPUProgramData;
    private _createGPUProgramData;
    destroy(): void;
}
`,Hs=`import type { UboLayout, UNIFORM_TYPES, UniformData } from '../../../shared/shader/types';
export declare const WGSL_ALIGN_SIZE_DATA: Record<UNIFORM_TYPES | string, {
    align: number;
    size: number;
}>;
export declare function createUboElementsWGSL(uniformData: UniformData[]): UboLayout;
`,Vs=`import type { UboElement, UniformsSyncCallback } from '../../../shared/shader/types';
export declare function createUboSyncFunctionWGSL(uboElements: UboElement[]): UniformsSyncCallback;
`,Ns=`import type { ExtractedAttributeData } from '../../../gl/shader/program/extractAttributesFromGlProgram';
import type { ProgramSource } from '../GpuProgram';
export declare function extractAttributesFromGpuProgram({ source, entryPoint }: ProgramSource): Record<string, ExtractedAttributeData>;
`,zs=`export interface StructsAndGroups {
    groups: {
        group: number;
        binding: number;
        name: string;
        isUniform: boolean;
        type: string;
    }[];
    structs: {
        name: string;
        members: Record<string, string>;
    }[];
}
export declare function extractStructAndGroups(wgsl: string): StructsAndGroups;
`,Xs=`import type { UboElement } from '../../../shared/shader/types';
/**
 * This generates a function that will sync an array to the uniform buffer
 * following the wgsl layout
 * @param uboElement - the element to generate the array sync for
 * @param offsetToAdd - the offset to append at the start of the code
 * @returns - the generated code
 */
export declare function generateArraySyncWGSL(uboElement: UboElement, offsetToAdd: number): string;
`,Ks=`import type { ProgramPipelineLayoutDescription } from '../GpuProgram';
import type { StructsAndGroups } from './extractStructAndGroups';
export declare function generateGpuLayoutGroups({ groups }: StructsAndGroups): ProgramPipelineLayoutDescription;
`,qs=`import type { ProgramLayout } from '../GpuProgram';
import type { StructsAndGroups } from './extractStructAndGroups';
export declare function generateLayoutHash({ groups }: StructsAndGroups): ProgramLayout;
`,Ys=`import type { StructsAndGroups } from './extractStructAndGroups';
export declare function removeStructAndGroupDuplicates(vertexStructsAndGroups: StructsAndGroups, fragmentStructsAndGroups: StructsAndGroups): {
    structs: {
        name: string;
        members: Record<string, string>;
    }[];
    groups: {
        group: number;
        binding: number;
        name: string;
        isUniform: boolean;
        type: string;
    }[];
};
`,Js=`/// <reference types="@webgpu/types" />
import type { BLEND_MODES } from '../../shared/state/const';
export declare const GpuBlendModesToPixi: Partial<Record<BLEND_MODES, GPUBlendState>>;
`,$s=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../../extensions/Extensions';
import { State } from '../../shared/state/State';
import type { BLEND_MODES } from '../../shared/state/const';
import type { System } from '../../shared/system/System';
import type { GPU } from '../GpuDeviceSystem';
/**
 * System plugin to the renderer to manage WebGL state machines.
 * @memberof rendering
 */
export declare class GpuStateSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "state";
    };
    /**
     * State ID
     * @readonly
     */
    stateId: number;
    /**
     * Polygon offset
     * @readonly
     */
    polygonOffset: number;
    /**
     * Blend mode
     * @default 'none'
     * @readonly
     */
    blendMode: BLEND_MODES;
    /** Whether current blend equation is different */
    protected _blendEq: boolean;
    /**
     * GL context
     * @member {WebGLRenderingContext}
     * @readonly
     */
    protected gpu: GPU;
    /**
     * Default WebGL State
     * @readonly
     */
    protected defaultState: State;
    constructor();
    protected contextChange(gpu: GPU): void;
    /**
     * Gets the blend mode data for the current state
     * @param state - The state to get the blend mode from
     */
    getColorTargets(state: State): GPUColorTargetState[];
    destroy(): void;
}
`,Qs=`export interface StencilState {
    stencilWriteMask?: number;
    stencilReadMask?: number;
    stencilFront?: {
        compare: 'always' | 'equal' | 'not-equal';
        passOp: 'increment-clamp' | 'decrement-clamp' | 'keep' | 'replace';
    };
    stencilBack?: {
        compare: 'always' | 'equal' | 'not-equal';
        passOp: 'increment-clamp' | 'decrement-clamp' | 'keep' | 'replace';
    };
}
export declare const GpuStencilModesToPixi: StencilState[];
`,Zs=`/// <reference types="@webgpu/types" />
import { ExtensionType } from '../../../../extensions/Extensions';
import { BindGroup } from '../shader/BindGroup';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { System } from '../../shared/system/System';
import type { CanvasGenerator, GetPixelsOutput } from '../../shared/texture/GenerateCanvas';
import type { TextureSource } from '../../shared/texture/sources/TextureSource';
import type { BindableTexture, Texture } from '../../shared/texture/Texture';
import type { TextureStyle } from '../../shared/texture/TextureStyle';
import type { GPU } from '../GpuDeviceSystem';
import type { WebGPURenderer } from '../WebGPURenderer';
/**
 * The system that handles textures for the GPU.
 * @memberof rendering
 */
export declare class GpuTextureSystem implements System, CanvasGenerator {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUSystem];
        readonly name: "texture";
    };
    readonly managedTextures: TextureSource[];
    protected CONTEXT_UID: number;
    private _gpuSources;
    private _gpuSamplers;
    private _bindGroupHash;
    private _textureViewHash;
    private readonly _uploads;
    private _gpu;
    private _mipmapGenerator?;
    private readonly _renderer;
    constructor(renderer: WebGPURenderer);
    protected contextChange(gpu: GPU): void;
    initSource(source: TextureSource): GPUTexture;
    protected onSourceUpdate(source: TextureSource): void;
    protected onSourceUnload(source: TextureSource): void;
    protected onUpdateMipmaps(source: TextureSource): void;
    protected onSourceDestroy(source: TextureSource): void;
    protected onSourceResize(source: TextureSource): void;
    private _initSampler;
    getGpuSampler(sampler: TextureStyle): GPUSampler;
    getGpuSource(source: TextureSource): GPUTexture;
    /**
     * this returns s bind group for a specific texture, the bind group contains
     * - the texture source
     * - the texture style
     * - the texture matrix
     * This is cached so the bind group should only be created once per texture
     * @param texture - the texture you want the bindgroup for
     * @returns the bind group for the texture
     */
    getTextureBindGroup(texture: Texture): BindGroup;
    private _createTextureBindGroup;
    getTextureView(texture: BindableTexture): GPUTextureView;
    private _createTextureView;
    generateCanvas(texture: Texture): ICanvas;
    getPixels(texture: Texture): GetPixelsOutput;
    destroy(): void;
}
`,el=`/// <reference types="@webgpu/types" />
import type { TextureSource } from '../../../shared/texture/sources/TextureSource';
import type { GPU } from '../../GpuDeviceSystem';
export interface GpuTextureUploader<T extends TextureSource = TextureSource> {
    type: string;
    upload(source: T, gpuTexture: GPUTexture, gpu: GPU): void;
}
`,nl=`import type { BufferImageSource } from '../../../shared/texture/sources/BufferImageSource';
import type { GpuTextureUploader } from './GpuTextureUploader';
export declare const gpuUploadBufferImageResource: GpuTextureUploader<BufferImageSource>;
`,tl=`import type { CompressedSource } from '../../../shared/texture/sources/CompressedSource';
import type { GpuTextureUploader } from './GpuTextureUploader';
export declare const blockDataMap: Record<string, {
    blockBytes: number;
    blockWidth: number;
    blockHeight: number;
}>;
export declare const gpuUploadCompressedTextureResource: GpuTextureUploader<CompressedSource>;
`,rl=`import type { TextureSource } from '../../../shared/texture/sources/TextureSource';
import type { GpuTextureUploader } from './GpuTextureUploader';
export declare const gpuUploadImageResource: GpuTextureUploader<TextureSource<any>>;
`,ol=`import type { VideoSource } from '../../../shared/texture/sources/VideoSource';
import type { GpuTextureUploader } from './GpuTextureUploader';
export declare const gpuUploadVideoResource: GpuTextureUploader<VideoSource>;
`,al=`/// <reference types="@webgpu/types" />
/**
 * A class which generates mipmaps for a GPUTexture.
 * Thanks to @toji for the original implementation
 * https://github.com/toji/web-texture-tool/blob/main/src/webgpu-mipmap-generator.js
 * @memberof rendering
 * @ignore
 */
export declare class GpuMipmapGenerator {
    device: GPUDevice;
    sampler: GPUSampler;
    pipelines: Record<string, GPURenderPipeline>;
    mipmapShaderModule: any;
    constructor(device: GPUDevice);
    private _getMipmapPipeline;
    /**
     * Generates mipmaps for the given GPUTexture from the data in level 0.
     * @param {module:External.GPUTexture} texture - Texture to generate mipmaps for.
     * @returns {module:External.GPUTexture} - The originally passed texture
     */
    generateMipmap(texture: GPUTexture): GPUTexture;
}
`,il=`import type { TEXTURE_FORMATS } from '../../../shared/texture/const';
export declare function getSupportedGPUCompressedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
`,sl=`import type { Container } from '../../../scene/container/Container';
import type { View } from './view/View';
export interface Renderable extends Container, View {
}
`,ll=`import { ExtensionType } from '../../../extensions/Extensions';
import type { System } from './system/System';
/**
 * The SchedulerSystem manages scheduled tasks with specific intervals.
 * @memberof rendering
 */
export declare class SchedulerSystem implements System<null> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "scheduler";
        readonly priority: 0;
    };
    private readonly _tasks;
    /** a small off set to apply to the repeat schedules. This is just to make sure they run at slightly different times */
    private _offset;
    /** Initializes the scheduler system and starts the ticker. */
    init(): void;
    /**
     * Schedules a repeating task.
     * @param func - The function to execute.
     * @param duration - The interval duration in milliseconds.
     * @param useOffset - this will spread out tasks so that they do not all run at the same time
     * @returns The unique identifier for the scheduled task.
     */
    repeat(func: (elapsed: number) => void, duration: number, useOffset?: boolean): number;
    /**
     * Cancels a scheduled task.
     * @param id - The unique identifier of the task to cancel.
     */
    cancel(id: number): void;
    /**
     * Updates and executes the scheduled tasks.
     * @private
     */
    private _update;
    /**
     * Destroys the scheduler system and removes all tasks.
     * @internal
     * @ignore
     */
    destroy(): void;
}
`,dl=`import { Color } from '../../../../color/Color';
import { ExtensionType } from '../../../../extensions/Extensions';
import type { ColorSource, RgbaArray } from '../../../../color/Color';
import type { System } from '../system/System';
/**
 * Options for the background system.
 * @property {ColorSource} [backgroundColor='black']
 * The background color used to clear the canvas. See {@link ColorSource} for accepted color values.
 * @property {ColorSource} [background] - Alias for backgroundColor
 * @property {number} [backgroundAlpha=1] -
 * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
 * @property {boolean} [clearBeforeRender=true] - Whether to clear the canvas before new render passes.
 * @memberof rendering
 */
export interface BackgroundSystemOptions {
    /**
     * The background color used to clear the canvas. See {@link ColorSource} for accepted color values.
     * @memberof rendering.SharedRendererOptions
     * @default 'black'
     */
    backgroundColor: ColorSource;
    /**
     * Alias for backgroundColor
     * @memberof rendering.SharedRendererOptions
     */
    background?: ColorSource;
    /**
     * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
     * @memberof rendering.SharedRendererOptions
     * @default 1
     */
    backgroundAlpha: number;
    /**
     * Whether to clear the canvas before new render passes.
     * @memberof rendering.SharedRendererOptions
     * @default true
     */
    clearBeforeRender: boolean;
}
/**
 * The background system manages the background color and alpha of the main view.
 * @memberof rendering
 */
export declare class BackgroundSystem implements System<BackgroundSystemOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "background";
        readonly priority: 0;
    };
    /** default options used by the system */
    static defaultOptions: BackgroundSystemOptions;
    /**
     * This sets if the CanvasRenderer will clear the canvas or not before the new render pass.
     * If the scene is NOT transparent PixiJS will use a canvas sized fillRect operation every
     * frame to set the canvas background color. If the scene is transparent PixiJS will use clearRect
     * to clear the canvas every frame. Disable this by setting this to false. For example, if
     * your game has a canvas filling background image you often don't need this set.
     */
    clearBeforeRender: boolean;
    private readonly _backgroundColor;
    constructor();
    /**
     * initiates the background system
     * @param options - the options for the background colors
     */
    init(options: BackgroundSystemOptions): void;
    /** The background color to fill if not transparent */
    get color(): Color;
    set color(value: ColorSource);
    /** The background color alpha. Setting this to 0 will make the canvas transparent. */
    get alpha(): number;
    set alpha(value: number);
    /** The background color as an [R, G, B, A] array. */
    get colorRgba(): RgbaArray;
    /**
     * destroys the background system
     * @internal
     * @ignore
     */
    destroy(): void;
}
`,pl=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { Renderer } from '../../types';
import type { Instruction } from '../instructions/Instruction';
import type { InstructionSet } from '../instructions/InstructionSet';
import type { InstructionPipe } from '../instructions/RenderPipe';
import type { Renderable } from '../Renderable';
import type { BLEND_MODES } from '../state/const';
interface AdvancedBlendInstruction extends Instruction {
    renderPipeId: 'blendMode';
    blendMode: BLEND_MODES;
    activeBlend: Renderable[];
}
/**
 * This Pipe handles the blend mode switching of the renderer.
 * It will insert instructions into the {@link renderers.InstructionSet} to switch the blend mode according to the
 * blend modes of the scene graph.
 *
 * This pipe is were wwe handle Advanced blend modes. Advanced blend modes essentially wrap the renderables
 * in a filter that applies the blend mode.
 *
 * You only need to use this class if you are building your own render instruction set rather than letting PixiJS build
 * the instruction set for you by traversing the scene graph
 * @memberof rendering
 */
export declare class BlendModePipe implements InstructionPipe<AdvancedBlendInstruction> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "blendMode";
    };
    private _renderer;
    private _renderableList;
    private _activeBlendMode;
    private _isAdvanced;
    private _filterHash;
    constructor(renderer: Renderer);
    prerender(): void;
    /**
     * This ensures that a blendMode switch is added to the instruction set if the blend mode has changed.
     * @param renderable - The renderable we are adding to the instruction set
     * @param blendMode - The blend mode of the renderable
     * @param instructionSet - The instruction set we are adding to
     */
    setBlendMode(renderable: Renderable, blendMode: BLEND_MODES, instructionSet: InstructionSet): void;
    private _beginAdvancedBlendMode;
    private _endAdvancedBlendMode;
    /**
     * called when the instruction build process is starting this will reset internally to the default blend mode
     * @internal
     * @ignore
     */
    buildStart(): void;
    /**
     * called when the instruction build process is finished, ensuring that if there is an advanced blend mode
     * active, we add the final render instructions added to the instruction set
     * @param instructionSet - The instruction set we are adding to
     * @internal
     * @ignore
     */
    buildEnd(instructionSet: InstructionSet): void;
    /**
     * @internal
     * @ignore
     */
    destroy(): void;
}
export {};
`,cl=`/// <reference types="@webgpu/types" />
import EventEmitter from 'eventemitter3';
import { BufferUsage } from './const';
import type { BindResource } from '../../gpu/shader/BindResource';
/** All the various typed arrays that exist in js */
export type TypedArray = Int8Array | Uint8Array | Int16Array | Uint16Array | Int32Array | Uint32Array | Uint8ClampedArray | Float32Array | Float64Array;
/** Options for creating a buffer */
export interface BufferOptions {
    /**
     * the data to initialize the buffer with, this can be a typed array,
     * or a regular number array. If it is a number array, it will be converted to a Float32Array
     */
    data?: TypedArray | number[];
    /** the size of the buffer in bytes, if not supplied, it will be inferred from the data */
    size?: number;
    /** the usage of the buffer, see {@link rendering.BufferUsage} */
    usage: number;
    /** a label for the buffer, this is useful for debugging */
    label?: string;
    /**
     * should the GPU buffer be shrunk when the data becomes smaller?
     * changing this will cause the buffer to be destroyed and a new one created on the GPU
     * this can be expensive, especially if the buffer is already big enough!
     * setting this to false will prevent the buffer from being shrunk. This will yield better performance
     * if you are constantly setting data that is changing size often.
     * @default true
     */
    shrinkToFit?: boolean;
}
export interface BufferDescriptor {
    label?: string;
    size: GPUSize64;
    usage: BufferUsage;
    mappedAtCreation?: boolean;
}
/**
 * A wrapper for a WebGPU/WebGL Buffer.
 * In PixiJS, the Buffer class is used to manage the data that is sent to the GPU rendering pipeline.
 * It abstracts away the underlying GPU buffer and provides an interface for uploading typed arrays or other data to the GPU,
 * They are used in the following places:
 * <br><br>
 * .1. {@link Geometry} as attribute data or index data for geometry
 * <br>
 * .2. {@link UniformGroup} as an underlying buffer for uniform data
 * <br>
 * .3. {@link BufferResource} as an underlying part of a buffer used directly by the GPU program
 * <br>
 *
 * It is important to note that you must provide a usage type when creating a buffer. This is because
 * the underlying GPU buffer needs to know how it will be used. For example, if you are creating a buffer
 * to hold vertex data, you would use \`BufferUsage.VERTEX\`. This will tell the GPU that this buffer will be
 * used as a vertex buffer. This is important because it will affect how you can use the buffer.
 *
 * Buffers are updated by calling the {@link Buffer.update} method. This immediately updates the buffer on the GPU.
 * Be mindful of calling this more often than you need to. It is recommended to update buffers only when needed.
 *
 * In WebGPU, a GPU buffer cannot resized. This limitation is abstracted away, but know that resizing a buffer means
 * creating a brand new one and destroying the old, so it is best to limit this if possible.
 * @example
 *
 * const buffer = new Buffer({
 *     data: new Float32Array([1, 2, 3, 4]),
 *     usage: BufferUsage.VERTEX,
 * });
 * @memberof rendering
 */
export declare class Buffer extends EventEmitter<{
    change: BindResource;
    update: Buffer;
    destroy: Buffer;
}> implements BindResource {
    /**
     * emits when the underlying buffer has changed shape (i.e. resized)
     * letting the renderer know that it needs to discard the old buffer on the GPU and create a new one
     * @event change
     */
    /**
     * emits when the underlying buffer data has been updated. letting the renderer know
     * that it needs to update the buffer on the GPU
     * @event update
     */
    /**
     * emits when the buffer is destroyed. letting the renderer know that it needs to destroy the buffer on the GPU
     * @event destroy
     */
    /** a unique id for this uniform group used through the renderer */
    readonly uid: number;
    /**
     * a resource type, used to identify how to handle it when its in a bind group / shader resource
     * @internal
     * @ignore
     */
    readonly _resourceType = "buffer";
    /**
     * the resource id used internally by the renderer to build bind group keys
     * @internal
     * @ignore
     */
    _resourceId: number;
    /**
     * used internally to know if a uniform group was used in the last render pass
     * @internal
     * @ignore
     */
    _touched: number;
    /**
     * a description of the buffer and how it should be set up on the GPU
     * @internal
     * @ignore
     */
    readonly descriptor: BufferDescriptor;
    /**
     * @internal
     * @ignore
     */
    _updateID: number;
    /**
     * @internal
     * @ignore
     */
    _updateSize: number;
    private _data;
    private _dataInt32;
    /**
     * should the GPU buffer be shrunk when the data becomes smaller?
     * changing this will cause the buffer to be destroyed and a new one created on the GPU
     * this can be expensive, especially if the buffer is already big enough!
     * setting this to false will prevent the buffer from being shrunk. This will yield better performance
     * if you are constantly setting data that is changing size often.
     * @default true
     */
    shrinkToFit: boolean;
    /**
     * Has the buffer been destroyed?
     * @readonly
     */
    destroyed: boolean;
    /**
     * Creates a new Buffer with the given options
     * @param options - the options for the buffer
     */
    constructor(options: BufferOptions);
    /** the data in the buffer */
    get data(): TypedArray;
    set data(value: TypedArray);
    get dataInt32(): Int32Array;
    /** whether the buffer is static or not */
    get static(): boolean;
    set static(value: boolean);
    /**
     * Sets the data in the buffer to the given value. This will immediately update the buffer on the GPU.
     * If you only want to update a subset of the buffer, you can pass in the size of the data.
     * @param value - the data to set
     * @param size - the size of the data in bytes
     * @param syncGPU - should the buffer be updated on the GPU immediately?
     */
    setDataWithSize(value: TypedArray, size: number, syncGPU: boolean): void;
    /**
     * updates the buffer on the GPU to reflect the data in the buffer.
     * By default it will update the entire buffer. If you only want to update a subset of the buffer,
     * you can pass in the size of the buffer to update.
     * @param sizeInBytes - the new size of the buffer in bytes
     */
    update(sizeInBytes?: number): void;
    /** Destroys the buffer */
    destroy(): void;
}
`,ul=`import EventEmitter from 'eventemitter3';
import type { BindResource } from '../../gpu/shader/BindResource';
import type { Buffer } from './Buffer';
/**
 * A resource that can be bound to a bind group and used in a shader.
 * Whilst a buffer can be used as a resource, this class allows you to specify an offset and size of the buffer to use.
 * This is useful if you have a large buffer and only part of it is used in a shader.
 *
 * This resource, will listen for changes on the underlying buffer and emit a itself if the buffer changes shape.
 * @example
 *
 * const buffer = new Buffer({
 *     data: new Float32Array(1000),
 *    usage: BufferUsage.UNIFORM,
 * });
 * // Create a buffer resource that uses the first 100 bytes of a buffer
 * const bufferResource = new BufferResource({
 *    buffer,
 *    offset: 0,
 *    size: 100,
 * });
 * @memberof rendering
 */
export declare class BufferResource extends EventEmitter<{
    change: BindResource;
}> implements BindResource {
    /**
     * emits when the underlying buffer has changed shape (i.e. resized)
     * letting the renderer know that it needs to discard the old buffer on the GPU and create a new one
     * @event change
     */
    /** a unique id for this uniform group used through the renderer */
    readonly uid: number;
    /**
     * a resource type, used to identify how to handle it when its in a bind group / shader resource
     * @internal
     * @ignore
     */
    readonly _resourceType = "bufferResource";
    /**
     * used internally to know if a uniform group was used in the last render pass
     * @internal
     * @ignore
     */
    _touched: number;
    /**
     * the resource id used internally by the renderer to build bind group keys
     * @internal
     * @ignore
     */
    _resourceId: number;
    /** the underlying buffer that this resource is using */
    buffer: Buffer;
    /** the offset of the buffer this resource is using. If not provided, then it will use the offset of the buffer. */
    readonly offset: number;
    /** the size of the buffer this resource is using. If not provided, then it will use the size of the buffer. */
    readonly size: number;
    /**
     * A cheeky hint to the GL renderer to let it know this is a BufferResource
     * @internal
     * @ignore
     */
    readonly _bufferResource = true;
    /**
     * Has the Buffer resource been destroyed?
     * @readonly
     */
    destroyed: boolean;
    /**
     * Create a new Buffer Resource.
     * @param options - The options for the buffer resource
     * @param options.buffer - The underlying buffer that this resource is using
     * @param options.offset - The offset of the buffer this resource is using.
     * If not provided, then it will use the offset of the buffer.
     * @param options.size - The size of the buffer this resource is using.
     * If not provided, then it will use the size of the buffer.
     */
    constructor({ buffer, offset, size }: {
        buffer: Buffer;
        offset?: number;
        size?: number;
    });
    protected onBufferChange(): void;
    /**
     * Destroys this resource. Make sure the underlying buffer is not used anywhere else
     * if you want to destroy it as well, or code will explode
     * @param destroyBuffer - Should the underlying buffer be destroyed as well?
     */
    destroy(destroyBuffer?: boolean): void;
}
`,ml=`/**
 * Buffer usage flags. they can be combined using the bitwise OR operator
 * eg : BufferUsage.VERTEX | BufferUsage.INDEX
 * @memberof rendering
 */
export declare enum BufferUsage {
    /**
     * The buffer can be mapped for reading. (Example: calling mapAsync() with GPUMapMode.READ)
     * May only be combined with COPY_DST.
     */
    MAP_READ = 1,
    /**
     * The buffer can be mapped for writing. (Example: calling mapAsync() with GPUMapMode.WRITE)
     * May only be combined with COPY_SRC.
     */
    MAP_WRITE = 2,
    /**
     * The buffer can be used as the source of a copy operation.
     * (Examples: as the source argument of a copyBufferToBuffer() or copyBufferToTexture() call.)
     */
    COPY_SRC = 4,
    /**
     * The buffer can be used as the destination of a copy or write operation.
     * (Examples: as the destination argument of a copyBufferToBuffer() or
     * copyTextureToBuffer() call, or as the target of a writeBuffer() call.)
     */
    COPY_DST = 8,
    /** The buffer can be used as an index buffer. (Example: passed to setIndexBuffer().) */
    INDEX = 16,
    /** The buffer can be used as a vertex buffer. (Example: passed to setVertexBuffer().) */
    VERTEX = 32,
    /**
     * The buffer can be used as a uniform buffer.
     * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "uniform".)
     */
    UNIFORM = 64,
    /**
     * The buffer can be used as a storage buffer.
     * (Example: as a bind group entry for a GPUBufferBindingLayout with a buffer.type of "storage" or "read-only-storage".)
     */
    STORAGE = 128,
    /**
     * The buffer can be used as to store indirect command arguments.
     * (Examples: as the indirectBuffer argument of a drawIndirect() or dispatchWorkgroupsIndirect() call.)
     */
    INDIRECT = 256,
    /**
     * The buffer can be used to capture query results.
     * (Example: as the destination argument of a resolveQuerySet() call.)
     */
    QUERY_RESOLVE = 512,
    /** the buffer will not be updated frequently */
    STATIC = 1024
}
`,hl=`/**
 * Copies from one buffer to another.
 * This is an optimised function that will use \`Float64Array\` window.
 * This means it can copy twice as fast!
 * @param sourceBuffer - the array buffer to copy from
 * @param destinationBuffer - the array buffer to copy to
 * @private
 */
export declare function fastCopy(sourceBuffer: ArrayBuffer, destinationBuffer: ArrayBuffer): void;
`,fl=`import { ExtensionType } from '../../../../extensions/Extensions';
import { Container } from '../../../../scene/container/Container';
import { Texture } from '../texture/Texture';
import type { ColorSource } from '../../../../color/Color';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { Rectangle } from '../../../../maths/shapes/Rectangle';
import type { Renderer } from '../../types';
import type { System } from '../system/System';
import type { GetPixelsOutput } from '../texture/GenerateCanvas';
declare const imageTypes: {
    png: string;
    jpg: string;
    webp: string;
};
type Formats = keyof typeof imageTypes;
/**
 * Options for creating an image from a renderer.
 * @memberof rendering
 */
export interface ImageOptions {
    /** The format of the image. */
    format?: Formats;
    /** The quality of the image. */
    quality?: number;
}
/**
 * Options for extracting content from a renderer.
 * @memberof rendering
 */
export interface BaseExtractOptions {
    /** The target to extract. */
    target: Container | Texture;
    /** The region of the target to extract. */
    frame?: Rectangle;
    /** The resolution of the extracted content. */
    resolution?: number;
    /** The color used to clear the extracted content. */
    clearColor?: ColorSource;
    /** Whether to enable anti-aliasing. This may affect performance. */
    antialias?: boolean;
}
/**
 * Options for extracting an HTMLImage from the renderer.
 * @memberof rendering
 */
export type ExtractImageOptions = BaseExtractOptions & ImageOptions;
/**
 * Options for extracting and downloading content from a renderer.
 * @memberof rendering
 */
export type ExtractDownloadOptions = BaseExtractOptions & {
    /** The filename to use when downloading the content. */
    filename: string;
};
/**
 * Options for extracting content from a renderer.
 * @memberof rendering
 */
export type ExtractOptions = BaseExtractOptions | ExtractImageOptions | ExtractDownloadOptions;
/**
 * This class provides renderer-specific plugins for exporting content from a renderer.
 * For instance, these plugins can be used for saving an Image, Canvas element or for exporting the raw image data (pixels).
 *
 * Do not instantiate these plugins directly. It is available from the \`renderer.extract\` property.
 * @example
 * import { Application, Graphics } from 'pixi.js';
 *
 * // Create a new application (extract will be auto-added to renderer)
 * const app = new Application();
 * await app.init();
 *
 * // Draw a red circle
 * const graphics = new Graphics()
 *     .circle(0, 0, 50);
 *     .fill(0xFF0000)
 *
 * // Render the graphics as an HTMLImageElement
 * const image = await app.renderer.extract.image(graphics);
 * document.body.appendChild(image);
 * @memberof rendering
 */
export declare class ExtractSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "extract";
    };
    /** Default options for creating an image. */
    static defaultImageOptions: ImageOptions;
    private _renderer;
    /** @param renderer - The renderer this System works for. */
    constructor(renderer: Renderer);
    private _normalizeOptions;
    /**
     * Will return a HTML Image of the target
     * @param options - The options for creating the image, or the target to extract
     * @returns - HTML Image of the target
     */
    image(options: ExtractImageOptions | Container | Texture): Promise<HTMLImageElement>;
    /**
     * Will return a base64 encoded string of this target. It works by calling
     * \`Extract.canvas\` and then running toDataURL on that.
     * @param options - The options for creating the image, or the target to extract
     */
    base64(options: ExtractImageOptions | Container | Texture): Promise<string>;
    /**
     * Creates a Canvas element, renders this target to it and then returns it.
     * @param options - The options for creating the canvas, or the target to extract
     * @returns - A Canvas element with the texture rendered on.
     */
    canvas(options: ExtractOptions | Container | Texture): ICanvas;
    /**
     * Will return a one-dimensional array containing the pixel data of the entire texture in RGBA
     * order, with integer values between 0 and 255 (included).
     * @param options - The options for extracting the image, or the target to extract
     * @returns - One-dimensional array containing the pixel data of the entire texture
     */
    pixels(options: ExtractOptions | Container | Texture): GetPixelsOutput;
    /**
     * Will return a texture of the target
     * @param options - The options for creating the texture, or the target to extract
     * @returns - A texture of the target
     */
    texture(options: ExtractOptions | Container | Texture): Texture;
    /**
     * Will extract a HTMLImage of the target and download it
     * @param options - The options for downloading and extracting the image, or the target to extract
     */
    download(options: ExtractDownloadOptions | Container | Texture): void;
    /**
     * Logs the target to the console as an image. This is a useful way to debug what's happening in the renderer.
     * @param options - The options for logging the image, or the target to log
     */
    log(options: (ExtractOptions & {
        width?: number;
    }) | Container | Texture): void;
    destroy(): void;
}
export {};
`,bl=`import { type ColorSource } from '../../../../color/Color';
import { ExtensionType } from '../../../../extensions/Extensions';
import { Rectangle } from '../../../../maths/shapes/Rectangle';
import { Container } from '../../../../scene/container/Container';
import { RenderTexture } from '../texture/RenderTexture';
import type { Renderer } from '../../types';
import type { System } from '../system/System';
import type { TextureSourceOptions } from '../texture/sources/TextureSource';
export type GenerateTextureSourceOptions = Omit<TextureSourceOptions, 'resource' | 'width' | 'height' | 'resolution'>;
/**
 * Options for generating a texture from a container.
 * @memberof rendering
 */
export type GenerateTextureOptions = {
    /** The container to generate the texture from */
    target: Container;
    /**
     * The region of the container, that shall be rendered,
     * if no region is specified, defaults to the local bounds of the container.
     */
    frame?: Rectangle;
    /** The resolution of the texture being generated. */
    resolution?: number;
    /** The color used to clear the texture. */
    clearColor?: ColorSource;
    /** Whether to enable anti-aliasing. This may affect performance. */
    antialias?: boolean;
    /** The options passed to the texture source. */
    textureSourceOptions?: GenerateTextureSourceOptions;
};
/**
 * System that manages the generation of textures from the renderer
 *
 *
 * Do not instantiate these plugins directly. It is available from the \`renderer.textureGenerator\` property.
 * @memberof rendering
 */
export declare class GenerateTextureSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "textureGenerator";
    };
    private readonly _renderer;
    constructor(renderer: Renderer);
    /**
     * A Useful function that returns a texture of the display object that can then be used to create sprites
     * This can be quite useful if your container is complicated and needs to be reused multiple times.
     * @param {GenerateTextureOptions | Container} options - Generate texture options.
     * @param {Container} [options.container] - If not given, the renderer's resolution is used.
     * @param {Rectangle} options.region - The region of the container, that shall be rendered,
     * @param {number} [options.resolution] - The resolution of the texture being generated.
     *        if no region is specified, defaults to the local bounds of the container.
     * @param {GenerateTextureSourceOptions} [options.textureSourceOptions] - Texture options for GPU.
     * @returns a shiny new texture of the container passed in
     */
    generateTexture(options: GenerateTextureOptions | Container): RenderTexture;
    destroy(): void;
}
`,gl=`import EventEmitter from 'eventemitter3';
import { Bounds } from '../../../../scene/container/bounds/Bounds';
import { Buffer } from '../buffer/Buffer';
import type { TypedArray } from '../buffer/Buffer';
import type { Topology, VertexFormat } from './const';
export type IndexBufferArray = Uint16Array | Uint32Array;
/**
 * The attribute data for a geometries attributes
 * @memberof rendering
 */
export interface Attribute {
    /** the buffer that this attributes data belongs to */
    buffer: Buffer;
    /** the format of the attribute */
    format?: VertexFormat;
    /** the stride of the data in the buffer - in bytes*/
    stride?: number;
    /** the offset of the attribute from the buffer, defaults to 0 - in bytes*/
    offset?: number;
    /** is this an instanced buffer? (defaults to false) */
    instance?: boolean;
    /** the number of elements to be rendered. If not specified, all vertices after the starting vertex will be drawn. */
    size?: number;
    /**
     * the starting vertex in the geometry to start drawing from. If not specified,
     *  drawing will start from the first vertex.
     */
    start?: number;
    /**
     * attribute divisor for instanced rendering. Note: this is a **WebGL-only** feature, the WebGPU renderer will
     * issue a warning if one of the attributes has divisor set.
     */
    divisor?: number;
}
/**
 * The attribute options used by the constructor for adding geometries attributes
 * extends {@link rendering.Attribute} but allows for the buffer to be a typed or number array
 * @memberof rendering
 */
type AttributeOption = Omit<Attribute, 'buffer'> & {
    buffer: Buffer | TypedArray | number[];
} | Buffer | TypedArray | number[];
export type AttributeOptions = Record<string, AttributeOption>;
/**
 * the interface that describes the structure of the geometry
 * @memberof rendering
 */
export interface GeometryDescriptor {
    /** an optional label to easily identify the geometry */
    label?: string;
    /** the attributes that make up the geometry */
    attributes?: AttributeOptions;
    /** optional index buffer for this geometry */
    indexBuffer?: Buffer | TypedArray | number[];
    /** the topology of the geometry, defaults to 'triangle-list' */
    topology?: Topology;
    instanceCount?: number;
}
/**
 * A Geometry is a low-level object that represents the structure of 2D shapes in terms of vertices and attributes.
 * It's a crucial component for rendering as it describes the shape and format of the data that will go through the shaders.
 * Essentially, a Geometry object holds the data you'd send to a GPU buffer.
 *
 * A geometry is basically made of two components:
 * <br>
 * <b>Attributes</b>: These are essentially arrays that define properties of the vertices like position, color,
 * texture coordinates, etc. They map directly to attributes in your vertex shaders.
 * <br>
 * <b>Indices</b>: An optional array that describes how the vertices are connected.
 * If not provided, vertices will be interpreted in the sequence they're given.
 * @example
 *
 * const geometry = new Geometry({
 *   attributes: {
 *     aPosition: [ // add some positions
 *       0, 0,
 *       0, 100,
 *       100, 100,
 *       100,   0,
 *     ],
 *     aUv: [ // add some uvs
 *       0, 0,
 *       0, 1,
 *       1, 1,
 *       1, 0,
 *     ]
 *   }
 * });
 * @memberof rendering
 * @class
 */
export declare class Geometry extends EventEmitter<{
    update: Geometry;
    destroy: Geometry;
}> {
    /** The topology of the geometry. */
    topology: Topology;
    /** The unique id of the geometry. */
    readonly uid: number;
    /** A record of the attributes of the geometry. */
    readonly attributes: Record<string, Attribute>;
    /** The buffers that the attributes use */
    readonly buffers: Buffer[];
    /** The index buffer of the geometry */
    indexBuffer: Buffer;
    /**
     * the layout key will be generated by WebGPU all geometries that have the same structure
     * will have the same layout key. This is used to cache the pipeline layout
     * @internal
     * @ignore
     */
    _layoutKey: number;
    /** the instance count of the geometry to draw */
    instanceCount: number;
    private readonly _bounds;
    private _boundsDirty;
    /**
     * Create a new instance of a geometry
     * @param options - The options for the geometry.
     */
    constructor(options?: GeometryDescriptor);
    protected onBufferUpdate(): void;
    /**
     * Returns the requested attribute.
     * @param id - The name of the attribute required
     * @returns - The attribute requested.
     */
    getAttribute(id: string): Attribute;
    /**
     * Returns the index buffer
     * @returns - The index buffer.
     */
    getIndex(): Buffer;
    /**
     * Returns the requested buffer.
     * @param id - The name of the buffer required.
     * @returns - The buffer requested.
     */
    getBuffer(id: string): Buffer;
    /**
     * Used to figure out how many vertices there are in this geometry
     * @returns the number of vertices in the geometry
     */
    getSize(): number;
    /**
     * Adds an attribute to the geometry.
     * @param name - The name of the attribute to add.
     * @param attributeOption - The attribute option to add.
     */
    addAttribute(name: string, attributeOption: AttributeOption): void;
    /**
     * Adds an index buffer to the geometry.
     * @param indexBuffer - The index buffer to add. Can be a Buffer, TypedArray, or an array of numbers.
     */
    addIndex(indexBuffer: Buffer | TypedArray | number[]): void;
    /** Returns the bounds of the geometry. */
    get bounds(): Bounds;
    /**
     * destroys the geometry.
     * @param destroyBuffers - destroy the buffers associated with this geometry
     */
    destroy(destroyBuffers?: boolean): void;
}
export {};
`,yl=`/**
 * The different topology types supported by the renderer used to describe how the geometry should be renderer
 * @memberof rendering
 */
export type Topology = 'point-list' | 'line-list' | 'line-strip' | 'triangle-list' | 'triangle-strip';
/** @deprecated since 8.0.0 */
export declare const DRAW_MODES: {
    POINTS: string;
    LINES: string;
    LINE_STRIP: string;
    TRIANGLES: string;
    TRIANGLE_STRIP: string;
};
/**
 * The different types of vertex formats supported by the renderer
 * @memberof rendering
 */
export type VertexFormat = 'uint8x2' | 'uint8x4' | 'sint8x2' | 'sint8x4' | 'unorm8x2' | 'unorm8x4' | 'snorm8x2' | 'snorm8x4' | 'uint16x2' | 'uint16x4' | 'sint16x2' | 'sint16x4' | 'unorm16x2' | 'unorm16x4' | 'snorm16x2' | 'snorm16x4' | 'float16x2' | 'float16x4' | 'float32' | 'float32x2' | 'float32x3' | 'float32x4' | 'uint32' | 'uint32x2' | 'uint32x3' | 'uint32x4' | 'sint32' | 'sint32x2' | 'sint32x3' | 'sint32x4';
`,xl=`import type { Matrix } from '../../../../../maths/matrix/Matrix';
/**
 * Takes a vertices array and a matrix and transforms the vertices based on the matrix.
 * this out put is written to the uvs array
 * @param vertices - the vertices to calculate uvs from
 * @param verticesStride - the stride of the vertice
 * @param verticesOffset - the offset of the vertices
 * @param uvs - the uvs to fill
 * @param uvsOffset - the offset of the uvs
 * @param uvsStride - the stride of the uvs
 * @param size - the size of the vertices
 * @param matrix - the matrix to apply to the uvs
 * @memberof rendering
 */
export declare function buildUvs(vertices: number[], verticesStride: number, verticesOffset: number, uvs: number[], uvsOffset: number, uvsStride: number, size: number, matrix?: Matrix): void;
export declare function buildSimpleUvs(uvs: number[], uvsOffset: number, uvsStride: number, size: number): void;
`,vl=`import { Buffer } from '../../buffer/Buffer';
import type { TypedArray } from '../../buffer/Buffer';
/**
 * Converts something into a buffer. If it is already a buffer it will pass it through
 * if it is a number array it will convert it to a float32 array before being passed into a buffer
 * the buffer will be created with the correct usage flags for geometry attributes
 * @param buffer - number array
 * @param index - is this an index buffer?
 * @returns a buffer
 * @memberof rendering
 */
export declare function ensureIsBuffer(buffer: Buffer | TypedArray | number[], index: boolean): Buffer;
`,Tl=`import type { VertexFormat } from '../const';
export declare function getAttributeInfoFromFormat(format: VertexFormat): {
    size: number;
    stride: number;
    normalised: boolean;
};
`,Sl=`import type { Bounds } from '../../../../../scene/container/bounds/Bounds';
import type { Geometry } from '../Geometry';
/**
 * Gets the 2D bounds of a geometry, based on a specific attribute.
 * @param geometry - Geometry to to measure
 * @param attributeId - AttributeId that contains the x,y data
 * @param bounds - Bounds to store the result in
 * @returns the bounds
 */
export declare function getGeometryBounds(geometry: Geometry, attributeId: string, bounds: Bounds): Bounds;
`,wl=`import type { Matrix } from '../../../../../maths/matrix/Matrix';
/**
 * Transforms the vertices in an array with the given matrix.
 * @param vertices - the vertices to transform
 * @param m - the matrix to apply to the vertices
 * @param offset - the offset of the vertices (defaults to 0)
 * @param stride - the stride of the vertices (defaults to 2)
 * @param size - the size of the vertices (defaults to vertices.length / stride - offset)
 * @memberof rendering
 */
export declare function transformVertices(vertices: number[], m: Matrix, offset?: number, stride?: number, size?: number): void;
`,_l=`/**
 * An instruction that can be executed by the renderer
 * @memberof rendering
 */
export interface Instruction {
    /** a the id of the render pipe that can run this instruction */
    renderPipeId: string;
    /** the name of the instruction */
    action?: string;
    /** true if this instruction can be compiled into a WebGPU bundle */
    canBundle: boolean;
}
`,El=`import type { Renderable } from '../Renderable';
import type { Instruction } from './Instruction';
/**
 * A set of instructions that can be executed by the renderer.
 * Basically wraps an array, but with some extra properties that help the renderer
 * to keep things nice and optimised.
 *
 * Note:
 * InstructionSet.instructions contains all the instructions, but does not resize (for performance).
 * So for the true length of the instructions you need to use InstructionSet.instructionSize
 * @memberof rendering
 */
export declare class InstructionSet {
    /** a unique id for this instruction set used through the renderer */
    readonly uid: number;
    /** the array of instructions */
    readonly instructions: Instruction[];
    /** the actual size of the array (any instructions passed this should be ignored) */
    instructionSize: number;
    /** allows for access to the render pipes of the renderer */
    renderPipes: any;
    renderables: Renderable[];
    /** used by the garbage collector to track when the instruction set was last used */
    gcTick: number;
    /** reset the instruction set so it can be reused set size back to 0 */
    reset(): void;
    /**
     * Add an instruction to the set
     * @param instruction - add an instruction to the set
     */
    add(instruction: Instruction): void;
    /**
     * Log the instructions to the console (for debugging)
     * @internal
     * @ignore
     */
    log(): void;
}
`,Pl=`import type { Container } from '../../../../scene/container/Container';
import type { Effect } from '../../../../scene/container/Effect';
import type { BatchableElement } from '../../../batcher/shared/Batcher';
import type { Renderer } from '../../types';
import type { Renderable } from '../Renderable';
import type { Instruction } from './Instruction';
import type { InstructionSet } from './InstructionSet';
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * InstructionPipes are specifically  used to manage the state of the renderer.
 * For example, the BlendModePipe is used to set the blend mode of the renderer.
 * @memberof rendering
 */
export interface InstructionPipe<INSTRUCTION extends Instruction> {
    /**
     * called just before we execute the draw calls , this is where the pipes have an opportunity to
     * upload data to the GPU. This is only called if data changes.
     * @param instructionSet - the instruction set currently being built
     */
    upload?: (instructionSet: InstructionSet) => void;
    /**
     * this is where the actual instruction is executed - eg make the draw call
     * activate a filter. Any instructions that have the same renderPipeId have their
     * execute method called
     * @param instruction - the instruction to execute
     */
    execute?: (instruction: INSTRUCTION) => void;
    buildReset?: (instructionSet: InstructionSet) => void;
    buildStart?: (instructionSet: InstructionSet) => void;
    buildEnd?: (instructionSet: InstructionSet) => void;
    /** Called just after the render ends giving the RenderPipes a chance to do any cleanup */
    renderEnd?: () => void;
    /** Called just before the render starts giving the RenderPipes a chance to do any setup */
    renderStart?: () => void;
    /**
     * Used by the effect pipes push and pop effects to the renderer. A push effect allows
     * the renderer to change its state to support the effect. A pop effect allows the renderer
     * to return to its previous state. An example of this would be the filter effect.
     * @param effect - the effect to push
     * @param targetContainer - the container that the effect is being applied to
     * @param instructionSet - the instruction set currently being built
     */
    push?: (effect: Effect, targetContainer: Container, instructionSet: InstructionSet) => void;
    /**
     * Used by effect pipes to pop effects from the renderer.
     * @param effect - the effect to pop
     * @param targetContainer - the container that the effect is being applied to
     * @param instructionSet - the instruction set currently being built
     */
    pop?: (effect: Effect, targetContainer: Container, instructionSet: InstructionSet) => void;
}
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * RenderPipes are specifically used to render Renderables like a Mesh.
 * @memberof rendering
 */
export interface RenderPipe<RENDERABLE = Renderable> {
    /**
     * This is where the renderable is added to the instruction set. This is called once per renderable.
     * For instance, a MeshRenderPipe could be used to enqueue a 'draw mesh' command
     * to the rendering instruction set, catering to the rendering of mesh geometry.
     * In more complex scenarios, such as the SpritePipe, this seamlessly coordinates
     * with a batchPipe to efficiently batch and add batch instructions to the instructions set
     *
     * Add is called when the instructions set is being built.
     * @param renderable - the renderable that needs to be rendered
     * @param instructionSet - the instruction set currently being built
     */
    addRenderable: (renderable: RENDERABLE, instructionSet: InstructionSet) => void;
    /**
     * Called whenever a renderable has been been updated, eg its position has changed.
     * This is only called in the render loop if the instructions set is being reused
     * from the last frame. Otherwise addRenderable is called.
     * @param renderable - the renderable that needs to be rendered
     */
    updateRenderable: (renderable: RENDERABLE) => void;
    /**
     * Called whenever a renderable is destroyed, often the pipes keep a webGL / webGPU specific representation
     * of the renderable that needs to be tidied up when the renderable is destroyed.
     * @param renderable - the renderable that needs to be rendered
     */
    destroyRenderable: (renderable: RENDERABLE) => void;
    /**
     * This function is called when the renderer is determining if it can use the same instruction set again to
     * improve performance. If this function returns true, the renderer will rebuild the whole instruction set
     * for the scene. This is only called if the scene has not its changed its structure .
     * @param renderable
     * @returns {boolean}
     */
    validateRenderable: (renderable: RENDERABLE) => boolean;
}
/**
 * An interface for a pipe that can be used to build instructions for the renderer.
 * BatchPipes are specifically used to build and render Batches.
 */
export interface BatchPipe {
    /**
     * Add a add a batchable object to the batch.
     * @param renderable - a batchable object that can be added to the batch
     * @param instructionSet - the instruction set currently being built
     */
    addToBatch: (renderable: BatchableElement, instructionSet: InstructionSet) => void;
    /**
     * Forces the batch to break. This can happen if for example you need to render everything and then
     * change the render target.
     * @param instructionSet - the instruction set currently being built
     */
    break: (instructionSet: InstructionSet) => void;
}
/** A helpful type that can be used to create a new RenderPipe, BatchPipe or InstructionPipe */
export interface PipeConstructor {
    new (renderer: Renderer, adaptor?: any): RenderPipe | BatchPipe | InstructionPipe<any>;
}
`,Al=`import { ExtensionType } from '../../../../extensions/Extensions';
import { Matrix } from '../../../../maths/matrix/Matrix';
import { BindGroup } from '../../gpu/shader/BindGroup';
import { type Renderer, RendererType } from '../../types';
import { UniformGroup } from '../shader/UniformGroup';
import type { PointData } from '../../../../maths/point/PointData';
import type { GlRenderTargetSystem } from '../../gl/renderTarget/GlRenderTargetSystem';
import type { GpuRenderTargetSystem } from '../../gpu/renderTarget/GpuRenderTargetSystem';
import type { UboSystem } from '../shader/UboSystem';
import type { System } from '../system/System';
export type GlobalUniformGroup = UniformGroup<{
    uProjectionMatrix: {
        value: Matrix;
        type: 'mat3x3<f32>';
    };
    uWorldTransformMatrix: {
        value: Matrix;
        type: 'mat3x3<f32>';
    };
    uWorldColorAlpha: {
        value: Float32Array;
        type: 'vec4<f32>';
    };
    uResolution: {
        value: number[];
        type: 'vec2<f32>';
    };
}>;
export interface GlobalUniformOptions {
    size?: number[];
    projectionMatrix?: Matrix;
    worldTransformMatrix?: Matrix;
    worldColor?: number;
    offset?: PointData;
}
export interface GlobalUniformData {
    projectionMatrix: Matrix;
    worldTransformMatrix: Matrix;
    worldColor: number;
    resolution: number[];
    offset: PointData;
    bindGroup: BindGroup;
}
export interface GlobalUniformRenderer {
    renderTarget: GlRenderTargetSystem | GpuRenderTargetSystem;
    renderPipes: Renderer['renderPipes'];
    ubo: UboSystem;
    type: RendererType;
}
/**
 * System plugin to the renderer to manage global uniforms for the renderer.
 * @memberof rendering
 */
export declare class GlobalUniformSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "globalUniforms";
    };
    private readonly _renderer;
    private _stackIndex;
    private _globalUniformDataStack;
    private readonly _uniformsPool;
    private readonly _activeUniforms;
    private readonly _bindGroupPool;
    private readonly _activeBindGroups;
    private _currentGlobalUniformData;
    constructor(renderer: GlobalUniformRenderer);
    reset(): void;
    start(options: GlobalUniformOptions): void;
    bind({ size, projectionMatrix, worldTransformMatrix, worldColor, offset, }: GlobalUniformOptions): void;
    push(options: GlobalUniformOptions): void;
    pop(): void;
    get bindGroup(): BindGroup;
    get globalUniformData(): GlobalUniformData;
    get uniformGroup(): UniformGroup<any>;
    private _createUniforms;
    destroy(): void;
}
`,Cl=`import { TextureSource } from '../texture/sources/TextureSource';
import type { BindableTexture } from '../texture/Texture';
/**
 * Options for creating a render target.
 * @memberof rendering
 */
export interface RenderTargetOptions {
    /** the width of the RenderTarget */
    width?: number;
    /** the height of the RenderTarget */
    height?: number;
    /** the resolution of the RenderTarget */
    resolution?: number;
    /** an array of textures, or a number indicating how many color textures there should be */
    colorTextures?: BindableTexture[] | number;
    /** should this render target have a stencil buffer? */
    stencil?: boolean;
    /** should this render target have a depth buffer? */
    depth?: boolean;
    /** a depth stencil texture that the depth and stencil outputs will be written to */
    depthStencilTexture?: BindableTexture | boolean;
    /** should this render target be antialiased? */
    antialias?: boolean;
    /** is this a root element, true if this is gl context owners render target */
    isRoot?: boolean;
}
/**
 * A class that describes what the renderers are rendering to.
 * This can be as simple as a Texture, or as complex as a multi-texture, multi-sampled render target.
 * Support for stencil and depth buffers is also included.
 *
 * If you need something more complex than a Texture to render to, you should use this class.
 * Under the hood, all textures you render to have a RenderTarget created on their behalf.
 * @memberof rendering
 */
export declare class RenderTarget {
    /** The default options for a render target */
    static defaultOptions: RenderTargetOptions;
    /** unique id for this render target */
    readonly uid: number;
    /**
     * An array of textures that can be written to by the GPU - mostly this has one texture in Pixi, but you could
     * write to multiple if required! (eg deferred lighting)
     */
    colorTextures: TextureSource[];
    /** the stencil and depth buffer will right to this texture in WebGPU */
    depthStencilTexture: TextureSource;
    /** if true, will ensure a stencil buffer is added. For WebGPU, this will automatically create a depthStencilTexture */
    stencil: boolean;
    /** if true, will ensure a depth buffer is added. For WebGPU, this will automatically create a depthStencilTexture */
    depth: boolean;
    dirtyId: number;
    isRoot: boolean;
    private readonly _size;
    /** if true, then when the render target is destroyed, it will destroy all the textures that were created for it. */
    private readonly _managedColorTextures;
    /**
     * @param [descriptor] - Options for creating a render target.
     */
    constructor(descriptor?: RenderTargetOptions);
    get size(): [number, number];
    get width(): number;
    get height(): number;
    get pixelWidth(): number;
    get pixelHeight(): number;
    get resolution(): number;
    get colorTexture(): TextureSource;
    protected onSourceResize(source: TextureSource): void;
    /**
     * This will ensure a depthStencil texture is created for this render target.
     * Most likely called by the mask system to make sure we have stencil buffer added.
     * @internal
     * @ignore
     */
    ensureDepthStencilTexture(): void;
    resize(width: number, height: number, resolution?: number, skipColorTexture?: boolean): void;
    destroy(): void;
}
`,Rl=`import { Matrix } from '../../../../maths/matrix/Matrix';
import { Rectangle } from '../../../../maths/shapes/Rectangle';
import { CLEAR } from '../../gl/const';
import { SystemRunner } from '../system/SystemRunner';
import { TextureSource } from '../texture/sources/TextureSource';
import { Texture } from '../texture/Texture';
import { RenderTarget } from './RenderTarget';
import type { RgbaArray } from '../../../../color/Color';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { CLEAR_OR_BOOL } from '../../gl/const';
import type { GlRenderTarget } from '../../gl/GlRenderTarget';
import type { GpuRenderTarget } from '../../gpu/renderTarget/GpuRenderTarget';
import type { Renderer } from '../../types';
import type { System } from '../system/System';
import type { BindableTexture } from '../texture/Texture';
/**
 * A render surface is a texture, canvas, or render target
 * @memberof rendering
 * @see environment.ICanvas
 * @see rendering.Texture
 * @see rendering.RenderTarget
 */
export type RenderSurface = ICanvas | BindableTexture | RenderTarget;
/**
 * An adaptor interface for RenderTargetSystem to support WebGL and WebGPU.
 * This is used internally by the renderer, and is not intended to be used directly.
 * @ignore
 */
export interface RenderTargetAdaptor<RENDER_TARGET extends GlRenderTarget | GpuRenderTarget> {
    init(
    /** the renderer */
    renderer: Renderer, 
    /** the render target system */
    renderTargetSystem: RenderTargetSystem<RENDER_TARGET>): void;
    /** A function copies the contents of a render surface to a texture */
    copyToTexture(
    /** the render surface to copy from  */
    sourceRenderSurfaceTexture: RenderTarget, 
    /** the texture to copy to */
    destinationTexture: Texture, 
    /** the origin of the copy */
    originSrc: {
        x: number;
        y: number;
    }, 
    /** the size of the copy */
    size: {
        width: number;
        height: number;
    }, 
    /** the destination origin (top left to paste from!) */
    originDest?: {
        x: number;
        y: number;
    }): Texture;
    /** starts a render pass on the render target */
    startRenderPass(
    /** the render target to start the render pass on */
    renderTarget: RenderTarget, clear: CLEAR_OR_BOOL, 
    /** the color to clear to */
    clearColor?: RgbaArray, 
    /** the viewport to use */
    viewport?: Rectangle): void;
    /** clears the current render target to the specified color */
    clear(
    /** the render target to clear */
    renderTarget: RenderTarget, 
    /** the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111 */
    clear: CLEAR_OR_BOOL, 
    /** the color to clear to   */
    clearColor?: RgbaArray, 
    /** the viewport to use */
    viewport?: Rectangle): void;
    /** finishes the current render pass */
    finishRenderPass(renderTarget: RenderTarget): void;
    /** called after the render pass is finished */
    postrender?(renderTarget: RenderTarget): void;
    /** called before the render main pass is started */
    prerender?(renderTarget: RenderTarget): void;
    /**
     * initializes a gpu render target. Both renderers use this function to initialize a gpu render target
     * Its different type of object depending on the renderer.
     */
    initGpuRenderTarget(
    /** the render target to initialize */
    renderTarget: RenderTarget): RENDER_TARGET;
    /** called when a render target is resized */
    resizeGpuRenderTarget(
    /** the render target to resize */
    renderTarget: RenderTarget): void;
    /** destroys the gpu render target */
    destroyGpuRenderTarget(
    /** the render target to destroy */
    gpuRenderTarget: RENDER_TARGET): void;
}
/**
 * A system that manages render targets. A render target is essentially a place where the shaders can color in the pixels.
 * The render target system is responsible for binding the render target to the renderer, and managing the viewport.
 * Render targets can be pushed and popped.
 *
 * To make it easier, you can also bind textures and canvases too. This will automatically create a render target for you.
 * The render target itself is a lot more powerful than just a texture or canvas,
 * as it can have multiple textures attached to it.
 * It will also give ou fine grain control over the stencil buffer / depth texture.
 * @example
 *
 * \`\`\`js
 *
 * // create a render target
 * const renderTarget = new RenderTarget({
 *   colorTextures: [new TextureSource({ width: 100, height: 100 })],
 * });
 *
 * // bind the render target
 * renderer.renderTarget.bind(renderTarget);
 *
 * // draw something!
 * \`\`\`
 * @memberof rendering
 */
export declare class RenderTargetSystem<RENDER_TARGET extends GlRenderTarget | GpuRenderTarget> implements System {
    /** When rendering of a scene begins, this is where the root render surface is stored */
    rootRenderTarget: RenderTarget;
    /** This is the root viewport for the render pass*/
    rootViewPort: Rectangle;
    /** A boolean that lets the dev know if the current render pass is rendering to the screen. Used by some plugins */
    renderingToScreen: boolean;
    /** the current active render target */
    renderTarget: RenderTarget;
    /** the current active render surface that the render target is created from */
    renderSurface: RenderSurface;
    /** the current viewport that the gpu is using */
    readonly viewport: Rectangle;
    /**
     * a runner that lets systems know if the active render target has changed.
     * Eg the Stencil System needs to know so it can manage the stencil buffer
     */
    readonly onRenderTargetChange: SystemRunner;
    /** the projection matrix that is used by the shaders based on the active render target and the viewport */
    readonly projectionMatrix: Matrix;
    /** the default clear color for render targets */
    readonly defaultClearColor: RgbaArray;
    /** a reference to the adaptor that interfaces with WebGL / WebGP */
    readonly adaptor: RenderTargetAdaptor<RENDER_TARGET>;
    /**
     * a hash that stores the render target for a given render surface. When you pass in a texture source,
     * a render target is created for it. This map stores and makes it easy to retrieve the render target
     */
    private readonly _renderSurfaceToRenderTargetHash;
    /** A hash that stores a gpu render target for a given render target. */
    private _gpuRenderTargetHash;
    /**
     * A stack that stores the render target and frame that is currently being rendered to.
     * When push is called, the current render target is stored in this stack.
     * When pop is called, the previous render target is restored.
     */
    private readonly _renderTargetStack;
    /** A reference to the renderer */
    private readonly _renderer;
    constructor(renderer: Renderer);
    /** called when dev wants to finish a render pass */
    finishRenderPass(): void;
    /**
     * called when the renderer starts to render a scene.
     * @param options
     * @param options.target - the render target to render to
     * @param options.clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
     * @param options.clearColor - the color to clear to
     * @param options.frame - the frame to render to
     */
    renderStart({ target, clear, clearColor, frame }: {
        target: RenderSurface;
        clear: CLEAR_OR_BOOL;
        clearColor: RgbaArray;
        frame?: Rectangle;
    }): void;
    postrender(): void;
    /**
     * Binding a render surface! This is the main function of the render target system.
     * It will take the RenderSurface (which can be a texture, canvas, or render target) and bind it to the renderer.
     * Once bound all draw calls will be rendered to the render surface.
     *
     * If a frame is not provide and the render surface is a texture, the frame of the texture will be used.
     * @param renderSurface - the render surface to bind
     * @param clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
     * @param clearColor - the color to clear to
     * @param frame - the frame to render to
     * @returns the render target that was bound
     */
    bind(renderSurface: RenderSurface, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray, frame?: Rectangle): RenderTarget;
    clear(target?: RenderSurface, clear?: CLEAR_OR_BOOL, clearColor?: RgbaArray): void;
    protected contextChange(): void;
    /**
     * Push a render surface to the renderer. This will bind the render surface to the renderer,
     * @param renderSurface - the render surface to push
     * @param clear - the clear mode to use. Can be true or a CLEAR number 'COLOR | DEPTH | STENCIL' 0b111
     * @param clearColor - the color to clear to
     * @param frame - the frame to use when rendering to the render surface
     */
    push(renderSurface: RenderSurface, clear?: CLEAR | boolean, clearColor?: RgbaArray, frame?: Rectangle): RenderTarget;
    /** Pops the current render target from the renderer and restores the previous render target. */
    pop(): void;
    /**
     * Gets the render target from the provide render surface. Eg if its a texture,
     * it will return the render target for the texture.
     * If its a render target, it will return the same render target.
     * @param renderSurface - the render surface to get the render target for
     * @returns the render target for the render surface
     */
    getRenderTarget(renderSurface: RenderSurface): RenderTarget;
    /**
     * Copies a render surface to another texture.
     *
     * NOTE:
     * for sourceRenderSurfaceTexture, The render target must be something that is written too by the renderer
     *
     * The following is not valid:
     * @example
     * const canvas = document.createElement('canvas')
     * canvas.width = 200;
     * canvas.height = 200;
     *
     * const ctx = canvas2.getContext('2d')!
     * ctx.fillStyle = 'red'
     * ctx.fillRect(0, 0, 200, 200);
     *
     * const texture = RenderTexture.create({
     *   width: 200,
     *   height: 200,
     * })
     * const renderTarget = renderer.renderTarget.getRenderTarget(canvas2);
     *
     * renderer.renderTarget.copyToTexture(renderTarget,texture, {x:0,y:0},{width:200,height:200},{x:0,y:0});
     *
     * The best way to copy a canvas is to create a texture from it. Then render with that.
     *
     * Parsing in a RenderTarget canvas context (with a 2d context)
     * @param sourceRenderSurfaceTexture - the render surface to copy from
     * @param destinationTexture - the texture to copy to
     * @param originSrc - the origin of the copy
     * @param originSrc.x - the x origin of the copy
     * @param originSrc.y - the y origin of the copy
     * @param size - the size of the copy
     * @param size.width - the width of the copy
     * @param size.height - the height of the copy
     * @param originDest - the destination origin (top left to paste from!)
     * @param originDest.x - the x origin of the paste
     * @param originDest.y - the y origin of the paste
     */
    copyToTexture(sourceRenderSurfaceTexture: RenderTarget, destinationTexture: Texture, originSrc: {
        x: number;
        y: number;
    }, size: {
        width: number;
        height: number;
    }, originDest: {
        x: number;
        y: number;
    }): Texture<TextureSource<any>>;
    /**
     * ensures that we have a depth stencil buffer available to render to
     * This is used by the mask system to make sure we have a stencil buffer.
     */
    ensureDepthStencil(): void;
    /** nukes the render target system */
    destroy(): void;
    private _initRenderTarget;
    getGpuRenderTarget(renderTarget: RenderTarget): RENDER_TARGET;
    resetState(): void;
}
`,Gl=`import type { RenderTarget } from './RenderTarget';
/**
 * Checks if the render target is viewable on the screen
 * Basically, is it a canvas element and is that canvas element in the DOM
 * @param renderTarget - the render target to check
 * @returns true if the render target is viewable on the screen
 */
export declare function isRenderingToScreen(renderTarget: RenderTarget): boolean;
`,Ml=`import { Rectangle } from '../../../../maths/shapes/Rectangle';
import type { TextureSource } from '../texture/sources/TextureSource';
/**
 * Takes a Texture source and a normalised frame
 * and returns a viewport for that frame.
 * @param viewport - The viewport rectangle to set.
 * @param source - The source to get the pixel width and height from.
 * @param frame - The frame to get the viewport from.
 * @returns the passed in viewport.
 */
export declare function viewportFromFrame(viewport: Rectangle, source: TextureSource, frame?: Rectangle): Rectangle;
`,kl=`import EventEmitter from 'eventemitter3';
import { GlProgram } from '../../gl/shader/GlProgram';
import { BindGroup } from '../../gpu/shader/BindGroup';
import { GpuProgram } from '../../gpu/shader/GpuProgram';
import type { GlProgramOptions } from '../../gl/shader/GlProgram';
import type { GpuProgramOptions } from '../../gpu/shader/GpuProgram';
/**
 * A record of {@link BindGroup}'s used by the shader.
 *
 * \`Record<number, BindGroup>\`
 * @memberof rendering
 */
export type ShaderGroups = Record<number, BindGroup>;
interface ShaderBase {
    /** The WebGL program used by the WebGL renderer. */
    glProgram?: GlProgram;
    /** The WebGPU program used by the WebGPU renderer. */
    gpuProgram?: GpuProgram;
    /**
     * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
     * 0b00 - not compatible with either
     * 0b01 - compatible with WebGL
     * 0b10 - compatible with WebGPU
     * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
     */
    compatibleRenderers?: number;
}
export interface GlShaderWith extends ShaderBase {
    /** The WebGL program used by the WebGL renderer. */
    glProgram: GlProgram;
}
export interface GpuShaderWith extends ShaderBase {
    /** The WebGPU program used by the WebGPU renderer. */
    gpuProgram: GpuProgram;
}
export interface ShaderWithGroupsDescriptor {
    /** A record of {@link BindGroup}'s used by the shader. */
    groups: ShaderGroups;
    /** an optional map of how to bind the groups. This is automatically generated by reading the WebGPU program */
    groupMap?: Record<string, Record<string, any>>;
}
interface ShaderWithResourcesDescriptor {
    /**
     * A key value of uniform resources used by the shader.
     * Under the hood pixi will look at the provided shaders and figure out where
     * the resources are mapped. Its up to you to make sure the resource key
     * matches the uniform name in the webGPU program. WebGL is a little more forgiving!
     */
    resources?: Record<string, any>;
}
/**
 * A descriptor for a shader
 * @memberof rendering
 */
export type ShaderWith = GlShaderWith | GpuShaderWith;
/**
 * A descriptor for a shader with groups.
 * @memberof rendering
 */
export type ShaderWithGroups = ShaderWithGroupsDescriptor & ShaderWith;
export interface IShaderWithGroups extends ShaderWithGroupsDescriptor, ShaderBase {
}
/**
 * A descriptor for a shader with resources. This is an easier way to work with uniforms.
 * especially when you are not working with bind groups
 * @memberof rendering
 */
export type ShaderWithResources = ShaderWithResourcesDescriptor & ShaderWith;
export interface IShaderWithResources extends ShaderWithResourcesDescriptor, ShaderBase {
}
export type ShaderDescriptor = ShaderWithGroups & ShaderWithResources;
type GlShaderFromWith = {
    gpu?: GpuProgramOptions;
    gl: GlProgramOptions;
};
type GpuShaderFromWith = {
    gpu: GpuProgramOptions;
    gl?: GlProgramOptions;
};
export type ShaderFromGroups = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithGroups, 'glProgram' | 'gpuProgram'>;
export type ShaderFromResources = (GlShaderFromWith | GpuShaderFromWith) & Omit<ShaderWithResources, 'glProgram' | 'gpuProgram'>;
/**
 * The Shader class is an integral part of the PixiJS graphics pipeline.
 * Central to rendering in PixiJS are two key elements: A [shader] and a [geometry].
 * The shader incorporates a {@link GlProgram} for WebGL or a {@link GpuProgram} for WebGPU,
 * instructing the respective technology on how to render the geometry.
 *
 * The primary goal of the Shader class is to offer a unified interface compatible with both WebGL and WebGPU.
 * When constructing a shader, you need to provide both a WebGL program and a WebGPU program due to the distinctions
 * between the two rendering engines. If only one is provided, the shader won't function with the omitted renderer.
 *
 * Both WebGL and WebGPU utilize the same resource object when passed into the shader.
 * Post-creation, the shader's interface remains consistent across both WebGL and WebGPU.
 * The sole distinction lies in whether a glProgram or a gpuProgram is employed.
 *
 * Modifying shader uniforms, which can encompass:
 *  - TextureSampler {@link TextureStyle}
 *  - TextureSource {@link TextureSource}
 *  - UniformsGroups {@link UniformGroup}
 * @example
 *
 * const shader = new Shader({
 *     glProgram: glProgram,
 *     gpuProgram: gpuProgram,
 *     resources: {
 *         uTexture: texture.source,
 *         uSampler: texture.sampler,
 *         uColor: [1, 0, 0, 1],
 *     },
 * });
 *
 * // update the uniforms
 * shader.resources.uColor[1] = 1;
 * shader.resources.uTexture = texture2.source;
 * @class
 * @memberof rendering
 */
export declare class Shader extends EventEmitter<{
    'destroy': Shader;
}> {
    /** A unique identifier for the shader */
    readonly uid: number;
    /** An instance of the GPU program used by the WebGPU renderer */
    gpuProgram: GpuProgram;
    /** An instance of the GL program used by the WebGL renderer */
    glProgram: GlProgram;
    /**
     * A number that uses two bits on whether the shader is compatible with the WebGL renderer and/or the WebGPU renderer.
     * 0b00 - not compatible with either
     * 0b01 - compatible with WebGL
     * 0b10 - compatible with WebGPU
     * This is automatically set based on if a {@link GlProgram} or {@link GpuProgram} is provided.
     */
    readonly compatibleRenderers: number;
    /** */
    groups: Record<number, BindGroup>;
    /** A record of the resources used by the shader. */
    resources: Record<string, any>;
    /**
     * A record of the uniform groups and resources used by the shader.
     * This is used by WebGL renderer to sync uniform data.
     * @internal
     * @ignore
     */
    _uniformBindMap: Record<number, Record<number, string>>;
    private readonly _ownedBindGroups;
    /**
     * Fired after rendering finishes.
     * @event rendering.Shader#destroy
     */
    /**
     * There are two ways to create a shader.
     * one is to pass in resources which is a record of uniform groups and resources.
     * another is to pass in groups which is a record of {@link BindGroup}s.
     * this second method is really to make use of shared {@link BindGroup}s.
     * For most cases you will want to use resources as they are easier to work with.
     * USe Groups if you want to share {@link BindGroup}s between shaders.
     * you cannot mix and match - either use resources or groups.
     * @param {ShaderWithResourcesDescriptor} options - The options for the shader using ShaderWithResourcesDescriptor.
     */
    constructor(options: ShaderWithResources);
    constructor(options: ShaderWithGroups);
    /**
     * Sometimes a resource group will be provided later (for example global uniforms)
     * In such cases, this method can be used to let the shader know about the group.
     * @param name - the name of the resource group
     * @param groupIndex - the index of the group (should match the webGPU shader group location)
     * @param bindIndex - the index of the bind point (should match the webGPU shader bind point)
     */
    addResource(name: string, groupIndex: number, bindIndex: number): void;
    private _buildResourceAccessor;
    /**
     * Use to destroy the shader when its not longer needed.
     * It will destroy the resources and remove listeners.
     * @param destroyPrograms - if the programs should be destroyed as well.
     * Make sure its not being used by other shaders!
     */
    destroy(destroyPrograms?: boolean): void;
    /**
     * A short hand function to create a shader based of a vertex and fragment shader.
     * @param options
     * @returns A shiny new PixiJS shader!
     */
    static from(options: ShaderFromGroups): Shader;
    static from(options: ShaderFromResources): Shader;
}
export {};
`,Fl=`import type { System } from '../system/System';
/**
 * System plugin to the renderer to manage the shaders.
 * @memberof rendering
 */
export interface ShaderSystem extends System {
    /** the maximum number of textures that can be bound to a shader */
    readonly maxTextures: number;
}
`,Ol=`import type { System } from '../system/System';
import type { UboElement, UboLayout, UniformData, UniformsSyncCallback } from './types';
import type { UniformGroup } from './UniformGroup';
export interface UboAdaptor {
    createUboElements: (uniformData: UniformData[]) => UboLayout;
    generateUboSync: (uboElements: UboElement[]) => UniformsSyncCallback;
}
/**
 * System plugin to the renderer to manage uniform buffers.
 * @memberof rendering
 */
export declare class UboSystem implements System {
    /** Cache of uniform buffer layouts and sync functions, so we don't have to re-create them */
    private _syncFunctionHash;
    private readonly _adaptor;
    constructor(adaptor: UboAdaptor);
    /**
     * Overridable function by \`pixi.js/unsafe-eval\` to silence
     * throwing an error if platform doesn't support unsafe-evals.
     * @private
     */
    private _systemCheck;
    ensureUniformGroup(uniformGroup: UniformGroup): void;
    getUniformGroupData(uniformGroup: UniformGroup): {
        layout: UboLayout;
        syncFunction: (uniforms: Record<string, any>, data: Float32Array, dataInt32: Int32Array, offset: number) => void;
    };
    private _initUniformGroup;
    private _generateUboSync;
    syncUniformGroup(uniformGroup: UniformGroup, data?: Float32Array, offset?: number): boolean;
    updateUniformGroup(uniformGroup: UniformGroup): boolean;
    destroy(): void;
}
`,Il=`import { type UniformData } from './types';
import type { BindResource } from '../../gpu/shader/BindResource';
import type { Buffer } from '../buffer/Buffer';
type FLOPS<T = UniformData> = T extends {
    value: infer V;
} ? V : never;
type ExtractUniformObject<T = Record<string, UniformData>> = {
    [K in keyof T]: FLOPS<T[K]>;
};
/**
 * Uniform group options
 * @memberof rendering
 */
export type UniformGroupOptions = {
    /**
     * if true the UniformGroup is handled as an Uniform buffer object.
     * This is the only way WebGPU can work with uniforms. WebGL2 can also use this.
     * So don't set to true if you want to use WebGPU :D
     */
    ubo?: boolean;
    /** if true, then you are responsible for when the data is uploaded to the GPU by calling \`update()\` */
    isStatic?: boolean;
};
/**
 * Uniform group holds uniform map and some ID's for work
 *
 * \`UniformGroup\` has two modes:
 *
 * 1: Normal mode
 * Normal mode will upload the uniforms with individual function calls as required. This is the default mode
 * for WebGL rendering.
 *
 * 2: Uniform buffer mode
 * This mode will treat the uniforms as a uniform buffer. You can pass in either a buffer that you manually handle, or
 * or a generic object that PixiJS will automatically map to a buffer for you.
 * For maximum benefits, make Ubo UniformGroups static, and only update them each frame.
 * This is the only way uniforms can be used with WebGPU.
 *
 * Rules of UBOs:
 * - UBOs only work with WebGL2, so make sure you have a fallback!
 * - Only floats are supported (including vec[2,3,4], mat[2,3,4])
 * - Samplers cannot be used in ubo's (a GPU limitation)
 * - You must ensure that the object you pass in exactly matches in the shader ubo structure.
 * Otherwise, weirdness will ensue!
 * - The name of the ubo object added to the group must match exactly the name of the ubo in the shader.
 *
 * When declaring your uniform options, you ust parse in the value and the type of the uniform.
 * The types correspond to the WebGPU types {@link UNIFORM_TYPES}
 *
 Uniforms can be modified via the classes 'uniforms' property. It will contain all the uniforms declared in the constructor.
 *
 * \`\`\`glsl
 * // UBO in shader:
 * uniform myCoolData { // Declaring a UBO...
 *     mat4 uCoolMatrix;
 *     float uFloatyMcFloatFace;
 * };
 * \`\`\`
 *
 * \`\`\`js
 * // A new Uniform Buffer Object...
 * const myCoolData = new UniformGroup({
 *     uCoolMatrix: {value:new Matrix(), type: 'mat4<f32>'},
 *     uFloatyMcFloatFace: {value:23, type: 'f32'},
 * }}
 *
 * // modify the data
 * myCoolData.uniforms.uFloatyMcFloatFace = 42;
 * // Build a shader...
 * const shader = Shader.from(srcVert, srcFrag, {
 *     myCoolData // Name matches the UBO name in the shader. Will be processed accordingly.
 * })
 *
 *
 *  \`\`\`
 * @memberof rendering
 */
export declare class UniformGroup<UNIFORMS extends {
    [key: string]: UniformData;
} = any> implements BindResource {
    /** The default options used by the uniform group. */
    static defaultOptions: UniformGroupOptions;
    /** used internally to know if a uniform group was used in the last render pass */
    _touched: number;
    /** a unique id for this uniform group used through the renderer */
    readonly uid: number;
    /** a resource type, used to identify how to handle it when its in a bind group / shader resource */
    _resourceType: string;
    /** the resource id used internally by the renderer to build bind group keys */
    _resourceId: number;
    /** the structures of the uniform group */
    uniformStructures: UNIFORMS;
    /** the uniforms as an easily accessible map of properties */
    uniforms: ExtractUniformObject<UNIFORMS>;
    /** true if it should be used as a uniform buffer object */
    ubo: boolean;
    /** an underlying buffer that will be uploaded to the GPU when using this UniformGroup */
    buffer?: Buffer;
    /**
     * if true, then you are responsible for when the data is uploaded to the GPU.
     * otherwise, the data is reuploaded each frame.
     */
    isStatic: boolean;
    /** used ito identify if this is a uniform group */
    readonly isUniformGroup = true;
    /**
     * used to flag if this Uniform groups data is different from what it has stored in its buffer / on the GPU
     * @internal
     * @ignore
     */
    _dirtyId: number;
    /**
     * a signature string generated for internal use
     * @internal
     * @ignore
     */
    readonly _signature: number;
    readonly destroyed = false;
    /**
     * Create a new Uniform group
     * @param uniformStructures - The structures of the uniform group
     * @param options - The optional parameters of this uniform group
     */
    constructor(uniformStructures: UNIFORMS, options?: UniformGroupOptions);
    /** Call this if you want the uniform groups data to be uploaded to the GPU only useful if \`isStatic\` is true. */
    update(): void;
}
export {};
`,Ll=`export declare enum ShaderStage {
    VERTEX = 1,
    FRAGMENT = 2,
    COMPUTE = 4
}
`,Bl=`export declare const UNIFORM_TYPES_VALUES: readonly ["f32", "i32", "vec2<f32>", "vec3<f32>", "vec4<f32>", "mat2x2<f32>", "mat3x3<f32>", "mat4x4<f32>", "mat3x2<f32>", "mat4x2<f32>", "mat2x3<f32>", "mat4x3<f32>", "mat2x4<f32>", "mat3x4<f32>", "vec2<i32>", "vec3<i32>", "vec4<i32>"];
/** useful for checking if a type is supported - a map of supported types with a true value. */
export declare const UNIFORM_TYPES_MAP: Record<UNIFORM_TYPES, boolean>;
export type UNIFORM_TYPES_SINGLE = typeof UNIFORM_TYPES_VALUES[number];
type OPTIONAL_SPACE = ' ' | '';
export type UNIFORM_TYPES_ARRAY = \`array<\${UNIFORM_TYPES_SINGLE},\${OPTIONAL_SPACE}\${number}>\`;
export type UNIFORM_TYPES = UNIFORM_TYPES_SINGLE | UNIFORM_TYPES_ARRAY;
export interface UniformData {
    /** the value of the uniform, this could be any object - a parser will figure out how to write it to the buffer */
    value: unknown;
    type: UNIFORM_TYPES;
    /** the size of the variable (eg 2 for vec2, 3 for vec3, 4 for vec4) */
    size?: number;
    name?: string;
}
export interface UboElement {
    data: UniformData;
    offset: number;
    size: number;
}
export interface UboLayout {
    uboElements: UboElement[];
    /** float32 size // TODO change to bytes */
    size: number;
}
export type UniformsSyncCallback = (...args: any[]) => void;
export {};
`,Dl=`import type { UboElement, UNIFORM_TYPES_SINGLE, UniformsSyncCallback } from '../types';
export declare function createUboSyncFunction(uboElements: UboElement[], parserCode: 'uboWgsl' | 'uboStd40', arrayGenerationFunction: (uboElement: UboElement, offsetToAdd: number) => string, singleSettersMap: Record<UNIFORM_TYPES_SINGLE, string>): UniformsSyncCallback;
`,Ul=`/**
 * @method defaultValue
 * @param {string} type - Type of value
 * @param {number} size
 * @private
 */
export declare function getDefaultUniformValue(type: string, size: number): number | Float32Array | Int32Array | Uint32Array | boolean | boolean[];
`,jl=`import type { UNIFORM_TYPES_SINGLE } from '../types';
export declare const uboSyncFunctionsSTD40: Record<UNIFORM_TYPES_SINGLE, string>;
export declare const uboSyncFunctionsWGSL: Record<UNIFORM_TYPES_SINGLE, string>;
`,Wl=`import type { UNIFORM_TYPES, UniformData } from '../types';
export interface UniformParserDefinition {
    type: UNIFORM_TYPES;
    test(data: UniformData): boolean;
    ubo?: string;
    uboWgsl?: string;
    uboStd40?: string;
    uniform?: string;
}
export declare const uniformParsers: UniformParserDefinition[];
`,Hl=`import { ExtensionType } from '../../../../extensions/Extensions';
import { type Renderer } from '../../types';
import type { System } from '../system/System';
/**
 * Options for the startup system.
 * @property {boolean} [hello=false] - Whether to log the version and type information of renderer to console.
 * @memberof rendering
 */
export interface HelloSystemOptions {
    /**
     * Whether to log the version and type information of renderer to console.
     * @memberof rendering.SharedRendererOptions
     * @default false
     */
    hello: boolean;
}
/**
 * A simple system responsible for initiating the renderer.
 * @memberof rendering
 */
export declare class HelloSystem implements System<HelloSystemOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "hello";
        readonly priority: -2;
    };
    /** The default options for the system. */
    static defaultOptions: HelloSystemOptions;
    private readonly _renderer;
    constructor(renderer: Renderer);
    /**
     * It all starts here! This initiates every system, passing in the options for any system by name.
     * @param options - the config for the renderer and all its systems
     */
    init(options: HelloSystemOptions): void;
}
`,Vl=`import type { BLEND_MODES, CULL_MODES } from './const';
/**
 * This is a WebGL state, and is is passed to {@link StateSystem}.
 *
 * Each mesh rendered may require WebGL to be in a different state.
 * For example you may want different blend mode or to enable polygon offsets
 * @memberof rendering
 */
export declare class State {
    /**
     * The data is a unique number based on the states settings.
     * This lets us quickly compare states with a single number rather than looking
     * at all the individual settings.
     */
    data: number;
    _blendModeId: number;
    private _blendMode;
    private _polygonOffset;
    constructor();
    /**
     * Activates blending of the computed fragment color values.
     * @default true
     */
    get blend(): boolean;
    set blend(value: boolean);
    /**
     * Activates adding an offset to depth values of polygon's fragments
     * @default false
     */
    get offsets(): boolean;
    set offsets(value: boolean);
    /** The culling settings for this state none - No culling back - Back face culling front - Front face culling */
    set cullMode(value: CULL_MODES);
    get cullMode(): CULL_MODES;
    /**
     * Activates culling of polygons.
     * @default false
     */
    get culling(): boolean;
    set culling(value: boolean);
    /**
     * Activates depth comparisons and updates to the depth buffer.
     * @default false
     */
    get depthTest(): boolean;
    set depthTest(value: boolean);
    /**
     * Enables or disables writing to the depth buffer.
     * @default true
     */
    get depthMask(): boolean;
    set depthMask(value: boolean);
    /**
     * Specifies whether or not front or back-facing polygons can be culled.
     * @default false
     */
    get clockwiseFrontFace(): boolean;
    set clockwiseFrontFace(value: boolean);
    /**
     * The blend mode to be applied when this state is set. Apply a value of \`normal\` to reset the blend mode.
     * Setting this mode to anything other than NO_BLEND will automatically switch blending on.
     * @default 'normal'
     */
    get blendMode(): BLEND_MODES;
    set blendMode(value: BLEND_MODES);
    /**
     * The polygon offset. Setting this property to anything other than 0 will automatically enable polygon offset fill.
     * @default 0
     */
    get polygonOffset(): number;
    set polygonOffset(value: number);
    toString(): string;
    /**
     * A quickly getting an instance of a State that is configured for 2d rendering.
     * @returns a new State with values set for 2d rendering
     */
    static for2d(): State;
    static default2d: State;
}
`,Nl=`/**
 * Various blend modes supported by Pixi
 * @memberof filters
 */
export type BLEND_MODES = 'inherit' | 'normal' | 'add' | 'multiply' | 'screen' | 'darken' | 'lighten' | 'erase' | 'color-dodge' | 'color-burn' | 'linear-burn' | 'linear-dodge' | 'linear-light' | 'hard-light' | 'soft-light' | 'pin-light' | 'difference' | 'exclusion' | 'overlay' | 'saturation' | 'color' | 'luminosity' | 'normal-npm' | 'add-npm' | 'screen-npm' | 'none' | 'subtract' | 'divide' | 'vivid-light' | 'hard-mix' | 'negation' | 'min' | 'max';
/**
 * The map of blend modes supported by Pixi
 * @memberof rendering
 */
export declare const BLEND_TO_NPM: {
    normal: string;
    add: string;
    screen: string;
};
/**
 * The stencil operation to perform when using the stencil buffer
 * @memberof rendering
 */
export declare enum STENCIL_MODES {
    DISABLED = 0,
    RENDERING_MASK_ADD = 1,
    MASK_ACTIVE = 2,
    INVERSE_MASK_ACTIVE = 3,
    RENDERING_MASK_REMOVE = 4,
    NONE = 5
}
/**
 * The culling mode to use. It can be either \`none\`, \`front\` or \`back\`.
 * @memberof rendering
 */
export type CULL_MODES = 'none' | 'back' | 'front';
`,zl=`import { type BLEND_MODES } from './const';
import type { TextureSource } from '../texture/sources/TextureSource';
/**
 * Adjusts a blend mode for the current alpha mode. Returns the blend mode that works with that format.
 * eg 'normal' blend mode will return 'normal-npm' when rendering with premultiplied alpha.
 * and 'normal' if the texture is already premultiplied (the default)
 * @param blendMode - The blend mode to get the adjusted blend mode for.
 * @param textureSource - The texture to test the format of.
 * @returns - the blend mode that should be used to render this texture correctly based on its alphaMode
 */
export declare function getAdjustedBlendModeBlend(blendMode: BLEND_MODES, textureSource: TextureSource): BLEND_MODES;
`,Xl=`import { Container } from '../../../../scene/container/Container';
import { EventEmitter } from '../../../../utils/utils';
import { SystemRunner } from './SystemRunner';
import type { ColorSource } from '../../../../color/Color';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { Matrix } from '../../../../maths/matrix/Matrix';
import type { Rectangle } from '../../../../maths/shapes/Rectangle';
import type { TypeOrBool } from '../../../../scene/container/destroyTypes';
import type { CLEAR_OR_BOOL } from '../../gl/const';
import type { BackgroundSystem } from '../background/BackgroundSystem';
import type { GenerateTextureOptions, GenerateTextureSystem } from '../extract/GenerateTextureSystem';
import type { PipeConstructor } from '../instructions/RenderPipe';
import type { RenderSurface } from '../renderTarget/RenderTargetSystem';
import type { Texture } from '../texture/Texture';
import type { ViewSystem, ViewSystemDestroyOptions } from '../view/ViewSystem';
import type { SharedRendererOptions } from './SharedSystems';
import type { SystemConstructor } from './System';
export interface RendererConfig {
    type: number;
    name: string;
    runners?: string[];
    systems: {
        name: string;
        value: SystemConstructor;
    }[];
    renderPipes: {
        name: string;
        value: PipeConstructor;
    }[];
    renderPipeAdaptors: {
        name: string;
        value: any;
    }[];
}
/**
 * The options for rendering a view.
 * @memberof rendering
 */
export interface RenderOptions extends ClearOptions {
    /** The container to render. */
    container: Container;
    /** the transform to apply to the container. */
    transform?: Matrix;
}
/**
 * The options for clearing the render target.
 * @memberof rendering
 */
export interface ClearOptions {
    /**
     * The render target to render. if this target is a canvas and  you are using the WebGL renderer,
     * please ensure you have set \`multiView\` to \`true\` on renderer.
     */
    target?: RenderSurface;
    /** The color to clear with. */
    clearColor?: ColorSource;
    /** The clear mode to use. */
    clear?: CLEAR_OR_BOOL;
}
export type RendererDestroyOptions = TypeOrBool<ViewSystemDestroyOptions>;
declare const defaultRunners: readonly ["init", "destroy", "contextChange", "resolutionChange", "resetState", "renderEnd", "renderStart", "render", "update", "postrender", "prerender"];
type DefaultRunners = typeof defaultRunners[number];
type Runners = {
    [key in DefaultRunners]: SystemRunner;
} & {
    [K: ({} & string) | ({} & symbol)]: SystemRunner;
};
/**
 * The base class for a PixiJS Renderer. It contains the shared logic for all renderers.
 *
 * You should not use this class directly, but instead use {@linkrendering.WebGLRenderer}
 * or {@link rendering.WebGPURenderer}.
 * Alternatively, you can also use {@link rendering.autoDetectRenderer} if you want us to
 * determine the best renderer for you.
 *
 * The renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a renderer:
 *
 *
 * | Generic Systems                      | Systems that manage functionality that all renderer types share               |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.ViewSystem}              | This manages the main view of the renderer usually a Canvas              |
 * | {@link rendering.BackgroundSystem}        | This manages the main views background color and alpha                   |
 * | {@link events.EventSystem}           | This manages UI events.                                                       |
 * | {@link accessibility.AccessibilitySystem} | This manages accessibility features. Requires \`import 'pixi.js/accessibility'\`|
 *
 * | Core Systems                   | Provide an optimised, easy to use API to work with WebGL/WebGPU               |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.RenderGroupSystem} | This manages the what what we are rendering to (eg - canvas or texture)   |
 * | {@link rendering.GlobalUniformSystem} | This manages shaders, programs that run on the GPU to calculate 'em pixels.   |
 * | {@link rendering.TextureGCSystem}     | This will automatically remove textures from the GPU if they are not used.    |
 *
 * | PixiJS High-Level Systems            | Set of specific systems designed to work with PixiJS objects                  |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link rendering.HelloSystem}               | Says hello, buy printing out the pixi version into the console log (along with the renderer type)       |
 * | {@link rendering.GenerateTextureSystem} | This adds the ability to generate textures from any Container       |
 * | {@link rendering.FilterSystem}          | This manages the filtering pipeline for post-processing effects.             |
 * | {@link rendering.PrepareSystem}               | This manages uploading assets to the GPU. Requires \`import 'pixi.js/prepare'\`|
 * | {@link rendering.ExtractSystem}               | This extracts image data from display objects.                               |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 * @abstract
 * @memberof rendering
 * @property {rendering.HelloSystem} hello - HelloSystem instance.
 * @property {rendering.RenderGroupSystem} renderGroup - RenderGroupSystem instance.
 * @property {rendering.TextureGCSystem} textureGC - TextureGCSystem instance.
 * @property {rendering.FilterSystem} filter - FilterSystem instance.
 * @property {rendering.GlobalUniformSystem} globalUniforms - GlobalUniformSystem instance.
 * @property {rendering.TextureSystem} texture - TextureSystem instance.
 * @property {rendering.EventSystem} events - EventSystem instance.
 * @property {rendering.ExtractSystem} extract - ExtractSystem instance. Requires \`import 'pixi.js/extract'\`.
 * @property {rendering.PrepareSystem} prepare - PrepareSystem instance. Requires \`import 'pixi.js/prepare'\`.
 * @property {rendering.AccessibilitySystem} accessibility - AccessibilitySystem instance. Requires \`import 'pixi.js/accessibility'\`.
 */
export declare class AbstractRenderer<PIPES, OPTIONS extends SharedRendererOptions, CANVAS extends ICanvas = HTMLCanvasElement> extends EventEmitter<{
    resize: [screenWidth: number, screenHeight: number, resolution: number];
}> {
    /** The default options for the renderer. */
    static defaultOptions: {
        /**
         * Default resolution / device pixel ratio of the renderer.
         * @default 1
         */
        resolution: number;
        /**
         * Should the \`failIfMajorPerformanceCaveat\` flag be enabled as a context option used in the \`isWebGLSupported\`
         * function. If set to true, a WebGL renderer can fail to be created if the browser thinks there could be
         * performance issues when using WebGL.
         *
         * In PixiJS v6 this has changed from true to false by default, to allow WebGL to work in as many
         * scenarios as possible. However, some users may have a poor experience, for example, if a user has a gpu or
         * driver version blacklisted by the
         * browser.
         *
         * If your application requires high performance rendering, you may wish to set this to false.
         * We recommend one of two options if you decide to set this flag to false:
         *
         * 1: Use the Canvas renderer as a fallback in case high performance WebGL is
         *    not supported.
         *
         * 2: Call \`isWebGLSupported\` (which if found in the utils package) in your code before attempting to create a
         *    PixiJS renderer, and show an error message to the user if the function returns false, explaining that their
         *    device & browser combination does not support high performance WebGL.
         *    This is a much better strategy than trying to create a PixiJS renderer and finding it then fails.
         * @default false
         */
        failIfMajorPerformanceCaveat: boolean;
        /**
         * Should round pixels be forced when rendering?
         * @default false
         */
        roundPixels: boolean;
    };
    readonly type: number;
    /** The name of the renderer. */
    readonly name: string;
    _roundPixels: 0 | 1;
    readonly runners: Runners;
    readonly renderPipes: PIPES;
    /** The view system manages the main canvas that is attached to the DOM */
    view: ViewSystem;
    /** The background system manages the background color and alpha of the main view. */
    background: BackgroundSystem;
    /** System that manages the generation of textures from the renderer */
    textureGenerator: GenerateTextureSystem;
    protected _initOptions: OPTIONS;
    protected config: RendererConfig;
    private _systemsHash;
    private _lastObjectRendered;
    /**
     * Set up a system with a collection of SystemClasses and runners.
     * Systems are attached dynamically to this class when added.
     * @param config - the config for the system manager
     */
    constructor(config: RendererConfig);
    /**
     * Initialize the renderer.
     * @param options - The options to use to create the renderer.
     */
    init(options?: Partial<OPTIONS>): Promise<void>;
    /**
     * Renders the object to its view.
     * @param options - The options to render with.
     * @param options.container - The container to render.
     * @param [options.target] - The target to render to.
     */
    render(options: RenderOptions | Container): void;
    /** @deprecated since 8.0.0 */
    render(container: Container, options: {
        renderTexture: any;
    }): void;
    /**
     * Resizes the WebGL view to the specified width and height.
     * @param desiredScreenWidth - The desired width of the screen.
     * @param desiredScreenHeight - The desired height of the screen.
     * @param resolution - The resolution / device pixel ratio of the renderer.
     */
    resize(desiredScreenWidth: number, desiredScreenHeight: number, resolution?: number): void;
    clear(options?: ClearOptions): void;
    /** The resolution / device pixel ratio of the renderer. */
    get resolution(): number;
    set resolution(value: number);
    /**
     * Same as view.width, actual number of pixels in the canvas by horizontal.
     * @member {number}
     * @readonly
     * @default 800
     */
    get width(): number;
    /**
     * Same as view.height, actual number of pixels in the canvas by vertical.
     * @default 600
     */
    get height(): number;
    /**
     * The canvas element that everything is drawn to.
     * @type {environment.ICanvas}
     */
    get canvas(): CANVAS;
    /**
     * the last object rendered by the renderer. Useful for other plugins like interaction managers
     * @readonly
     */
    get lastObjectRendered(): Container;
    /**
     * Flag if we are rendering to the screen vs renderTexture
     * @readonly
     * @default true
     */
    get renderingToScreen(): boolean;
    /**
     * Measurements of the screen. (0, 0, screenWidth, screenHeight).
     *
     * Its safe to use as filterArea or hitArea for the whole stage.
     */
    get screen(): Rectangle;
    /**
     * Create a bunch of runners based of a collection of ids
     * @param runnerIds - the runner ids to add
     */
    private _addRunners;
    private _addSystems;
    /**
     * Add a new system to the renderer.
     * @param ClassRef - Class reference
     * @param name - Property name for system, if not specified
     *        will use a static \`name\` property on the class itself. This
     *        name will be assigned as s property on the Renderer so make
     *        sure it doesn't collide with properties on Renderer.
     * @returns Return instance of renderer
     */
    private _addSystem;
    private _addPipes;
    destroy(options?: RendererDestroyOptions): void;
    /**
     * Generate a texture from a container.
     * @param options - options or container target to use when generating the texture
     * @returns a texture
     */
    generateTexture(options: GenerateTextureOptions | Container): Texture;
    /**
     * Whether the renderer will round coordinates to whole pixels when rendering.
     * Can be overridden on a per scene item basis.
     */
    get roundPixels(): boolean;
    /**
     * Overridable function by \`pixi.js/unsafe-eval\` to silence
     * throwing an error if platform doesn't support unsafe-evals.
     * @private
     * @ignore
     */
    _unsafeEvalCheck(): void;
    /**
     * Resets the rendering state of the renderer.
     * This is useful when you want to use the WebGL context directly and need to ensure PixiJS's internal state
     * stays synchronized. When modifying the WebGL context state externally, calling this method before the next Pixi
     * render will reset all internal caches and ensure it executes correctly.
     *
     * This is particularly useful when combining PixiJS with other rendering engines like Three.js:
     * \`\`\`js
     * // Reset Three.js state
     * threeRenderer.resetState();
     *
     * // Render a Three.js scene
     * threeRenderer.render(threeScene, threeCamera);
     *
     * // Reset PixiJS state since Three.js modified the WebGL context
     * pixiRenderer.resetState();
     *
     * // Now render Pixi content
     * pixiRenderer.render(pixiScene);
     * \`\`\`
     */
    resetState(): void;
}
export {};
`,Kl=`import { CustomRenderPipe } from '../../../../scene/container/CustomRenderPipe';
import { RenderGroupPipe } from '../../../../scene/container/RenderGroupPipe';
import { RenderGroupSystem } from '../../../../scene/container/RenderGroupSystem';
import { SpritePipe } from '../../../../scene/sprite/SpritePipe';
import { RendererInitHook } from '../../../../utils/global/globalHooks';
import { BatcherPipe } from '../../../batcher/shared/BatcherPipe';
import { AlphaMaskPipe } from '../../../mask/alpha/AlphaMaskPipe';
import { ColorMaskPipe } from '../../../mask/color/ColorMaskPipe';
import { StencilMaskPipe } from '../../../mask/stencil/StencilMaskPipe';
import { BackgroundSystem } from '../background/BackgroundSystem';
import { BlendModePipe } from '../blendModes/BlendModePipe';
import { ExtractSystem } from '../extract/ExtractSystem';
import { GenerateTextureSystem } from '../extract/GenerateTextureSystem';
import { GlobalUniformSystem } from '../renderTarget/GlobalUniformSystem';
import { SchedulerSystem } from '../SchedulerSystem';
import { HelloSystem } from '../startup/HelloSystem';
import { RenderableGCSystem } from '../texture/RenderableGCSystem';
import { TextureGCSystem } from '../texture/TextureGCSystem';
import { ViewSystem } from '../view/ViewSystem';
import type { ExtractRendererOptions } from './utils/typeUtils';
export declare const SharedSystems: (typeof BackgroundSystem | typeof GlobalUniformSystem | typeof HelloSystem | typeof ViewSystem | typeof RenderGroupSystem | typeof TextureGCSystem | typeof GenerateTextureSystem | typeof ExtractSystem | typeof RendererInitHook | typeof RenderableGCSystem | typeof SchedulerSystem)[];
export declare const SharedRenderPipes: (typeof BlendModePipe | typeof BatcherPipe | typeof SpritePipe | typeof RenderGroupPipe | typeof AlphaMaskPipe | typeof StencilMaskPipe | typeof ColorMaskPipe | typeof CustomRenderPipe)[];
/**
 * Options for the shared systems of a renderer.
 * @memberof rendering
 */
export interface SharedRendererOptions extends ExtractRendererOptions<typeof SharedSystems>, PixiMixins.RendererOptions {
    /**
     * Whether to stop PixiJS from dynamically importing default extensions for the renderer.
     * It is false by default, and means PixiJS will load all the default extensions, based
     * on the environment e.g browser/webworker.
     * If you set this to true, then you will need to manually import the systems and extensions you need.
     *
     * e.g.
     * \`\`\`js
     * import 'accessibility';
     * import 'app';
     * import 'events';
     * import 'spritesheet';
     * import 'graphics';
     * import 'mesh';
     * import 'text';
     * import 'text-bitmap';
     * import 'text-html';
     * import { autoDetectRenderer } from 'pixi.js';
     *
     * const renderer = await autoDetectRenderer({
     *   width: 800,
     *   height: 600,
     *   skipExtensionImports: true,
     * });
     * \`\`\`
     * @default false
     */
    skipExtensionImports?: boolean;
    /**
     * @default true
     * @deprecated since 8.1.6
     * @see \`skipExtensionImports\`
     */
    manageImports?: boolean;
}
`,ql=`import type { Renderer } from '../../types';
import type { RendererDestroyOptions } from './AbstractRenderer';
export interface System<INIT_OPTIONS = null, DESTROY_OPTIONS = RendererDestroyOptions> {
    init?: (options: INIT_OPTIONS) => void;
    /** Generic destroy methods to be overridden by the subclass */
    destroy?: (options?: DESTROY_OPTIONS) => void;
}
export interface SystemConstructor {
    new (renderer: Renderer): System;
}
`,Yl=`/**
 * SystemRunner is used internally by the renderers as an efficient way for systems to
 * be notified about what the renderer is up to during the rendering phase.
 *
 * \`\`\`
 * import { SystemRunner } from 'pixi.js';
 *
 * const myObject = {
 *     loaded: new SystemRunner('loaded')
 * }
 *
 * const listener = {
 *     loaded: function(){
 *         // thin
 *     }
 * }
 *
 * myObject.loaded.add(listener);
 *
 * myObject.loaded.emit();
 * \`\`\`
 *
 * Or for handling calling the same function on many items
 * \`\`\`
 * import { SystemRunner } from 'pixi.js';
 *
 * const myGame = {
 *     update: new SystemRunner('update')
 * }
 *
 * const gameObject = {
 *     update: function(time){
 *         // update my gamey state
 *     }
 * }
 *
 * myGame.update.add(gameObject);
 *
 * myGame.update.emit(time);
 * \`\`\`
 * @memberof rendering
 */
export declare class SystemRunner {
    items: any[];
    private _name;
    /**
     * @param name - The function name that will be executed on the listeners added to this Runner.
     */
    constructor(name: string);
    /**
     * Dispatch/Broadcast Runner to all listeners added to the queue.
     * @param {...any} params - (optional) parameters to pass to each listener
     */
    emit(a0?: unknown, a1?: unknown, a2?: unknown, a3?: unknown, a4?: unknown, a5?: unknown, a6?: unknown, a7?: unknown): this;
    /**
     * Add a listener to the Runner
     *
     * Runners do not need to have scope or functions passed to them.
     * All that is required is to pass the listening object and ensure that it has contains a function that has the same name
     * as the name provided to the Runner when it was created.
     *
     * Eg A listener passed to this Runner will require a 'complete' function.
     *
     * \`\`\`
     * import { Runner } from 'pixi.js';
     *
     * const complete = new Runner('complete');
     * \`\`\`
     *
     * The scope used will be the object itself.
     * @param {any} item - The object that will be listening.
     */
    add(item: unknown): this;
    /**
     * Remove a single listener from the dispatch queue.
     * @param {any} item - The listener that you would like to remove.
     */
    remove(item: unknown): this;
    /**
     * Check to see if the listener is already in the Runner
     * @param {any} item - The listener that you would like to check.
     */
    contains(item: unknown): boolean;
    /** Remove all listeners from the Runner */
    removeAll(): this;
    /** Remove all references, don't use after this. */
    destroy(): void;
    /**
     * \`true\` if there are no this Runner contains no listeners
     * @readonly
     */
    get empty(): boolean;
    /**
     * The name of the runner.
     * @readonly
     */
    get name(): string;
}
`,Jl=`/**
 * TS for extracting the system as a record based on a list of systems
 * @example
 *
 * type Systems = [
 *   { extension: { name: 'foo' }, defaultOptions: { foo: 1 } },
 *   { extension: { name: 'bar' }, defaultOptions: { bar: 2 } },
 *   { extension: { name: 'baz' }, defaultOptions: { baz: 3 } },
 * ];
 *
 * type SystemTypes = ExtractSystemTypes<Systems>;
 *
 * SystemTypes = {
 *     foo: { extension: { name: 'foo' }, defaultOptions: { foo: 1 } },
 *     bar: { extension: { name: 'bar' }, defaultOptions: { bar: 2 } },
 *     baz: { extension: { name: 'baz' }, defaultOptions: { baz: 3 } },
 * }
 */
interface System {
    extension: {
        name: string;
    };
    defaultOptions?: any;
    new (...args: any): any;
}
type SystemsWithExtensionList = System[];
type InstanceType<T extends new (...args: any) => any> = T extends new (...args: any) => infer R ? R : any;
type NameType<T extends SystemsWithExtensionList> = T[number]['extension']['name'];
export type ExtractSystemTypes<T extends SystemsWithExtensionList> = {
    [K in NameType<T>]: InstanceType<Extract<T[number], {
        extension: {
            name: K;
        };
    }>>;
};
/**
 *   TS for extracting the init options based on a list of systems
 *   @example
 *
 *   const list = [
 *      { extension: { name: 'foo' }, defaultOptions: { foo: 1 } },
 *      { extension: { name: 'bar' }, defaultOptions: { bar: 2 } },
 *      { extension: { name: 'baz' }, defaultOptions: { baz: 3 } },
 *   ]
 *
 *   type Options = ExtractRendererOptions<typeof list> // { foo: 1 } & { bar: 2 } & { baz: 3 }
 */
type NotUnknown<T> = T extends unknown ? keyof T extends never ? never : T : T;
type KnownProperties<T> = {
    [K in keyof T as NotUnknown<T[K]> extends never ? never : K]: T[K];
};
type FlattenOptions<T> = T extends {
    [K: string]: infer U;
} ? U : never;
type OptionsUnion<T extends SystemsWithExtensionList> = FlattenOptions<SeparateOptions<T>>;
type DefaultOptionsTypes<T extends SystemsWithExtensionList> = {
    [K in NameType<T>]: Extract<T[number], {
        extension: {
            name: K;
        };
    }>['defaultOptions'];
};
type SeparateOptions<T extends SystemsWithExtensionList> = KnownProperties<DefaultOptionsTypes<T>>;
type UnionToIntersection<U> = (U extends any ? (k: U) => void : never) extends ((k: infer I) => void) ? I : never;
export type ExtractRendererOptions<T extends SystemsWithExtensionList> = UnionToIntersection<OptionsUnion<T>>;
export {};
`,$l=`import type { ICanvas, ICanvasRenderingContext2DSettings } from '../../../../environment/canvas/ICanvas';
import type { ICanvasRenderingContext2D } from '../../../../environment/canvas/ICanvasRenderingContext2D';
export interface CanvasAndContext {
    canvas: ICanvas;
    context: ICanvasRenderingContext2D;
}
/**
 * Texture pool, used by FilterSystem and plugins.
 *
 * Stores collection of temporary pow2 or screen-sized renderTextures
 *
 * If you use custom RenderTexturePool for your filters, you can use methods
 * \`getFilterTexture\` and \`returnFilterTexture\` same as in
 * @name CanvasPool
 * @memberof rendering
 */
export declare class CanvasPoolClass {
    canvasOptions: ICanvasRenderingContext2DSettings;
    /**
     * Allow renderTextures of the same size as screen, not just pow2
     *
     * Automatically sets to true after \`setScreenSize\`
     * @default false
     */
    enableFullScreen: boolean;
    private _canvasPool;
    constructor(canvasOptions?: ICanvasRenderingContext2DSettings);
    /**
     * Creates texture with params that were specified in pool constructor.
     * @param pixelWidth - Width of texture in pixels.
     * @param pixelHeight - Height of texture in pixels.
     */
    private _createCanvasAndContext;
    /**
     * Gets a Power-of-Two render texture or fullScreen texture
     * @param minWidth - The minimum width of the render texture.
     * @param minHeight - The minimum height of the render texture.
     * @param resolution - The resolution of the render texture.
     * @returns The new render texture.
     */
    getOptimalCanvasAndContext(minWidth: number, minHeight: number, resolution?: number): CanvasAndContext;
    /**
     * Place a render texture back into the pool.
     * @param canvasAndContext
     */
    returnCanvasAndContext(canvasAndContext: CanvasAndContext): void;
    clear(): void;
}
export declare const CanvasPool: CanvasPoolClass;
`,Ql=`import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { Texture } from './Texture';
export type GetPixelsOutput = {
    pixels: Uint8ClampedArray;
    width: number;
    height: number;
};
export interface CanvasGenerator {
    generateCanvas(texture: Texture): ICanvas;
    getPixels(texture: Texture): GetPixelsOutput;
}
`,Zl=`import { Texture } from './Texture';
import type { TextureSourceOptions } from './sources/TextureSource';
/**
 * A render texture, extends \`Texture\`.
 * @see {@link rendering.Texture}
 * @memberof rendering
 */
export declare class RenderTexture extends Texture {
    static create(options: TextureSourceOptions): RenderTexture;
    /**
     * Resizes the render texture.
     * @param width - The new width of the render texture.
     * @param height - The new height of the render texture.
     * @param resolution - The new resolution of the render texture.
     * @returns This texture.
     */
    resize(width: number, height: number, resolution?: number): this;
}
`,ed=`import { ExtensionType } from '../../../../extensions/Extensions';
import { type RenderOptions } from '../system/AbstractRenderer';
import type { Renderer } from '../../types';
import type { Renderable } from '../Renderable';
import type { System } from '../system/System';
/**
 * Options for the {@link RenderableGCSystem}.
 * @memberof rendering
 * @property {boolean} [renderableGCActive=true] - If set to true, this will enable the garbage collector on the renderables.
 * @property {number} [renderableGCAMaxIdle=60000] -
 * The maximum idle frames before a texture is destroyed by garbage collection.
 * @property {number} [renderableGCCheckCountMax=60000] - time between two garbage collections.
 */
export interface RenderableGCSystemOptions {
    /**
     * If set to true, this will enable the garbage collector on the GPU.
     * @default true
     * @memberof rendering.SharedRendererOptions
     */
    renderableGCActive: boolean;
    /**
     * The maximum idle frames before a texture is destroyed by garbage collection.
     * @default 60 * 60
     * @memberof rendering.SharedRendererOptions
     */
    renderableGCMaxUnusedTime: number;
    /**
     * Frames between two garbage collections.
     * @default 600
     * @memberof rendering.SharedRendererOptions
     */
    renderableGCFrequency: number;
}
/**
 * The RenderableGCSystem is responsible for cleaning up GPU resources that are no longer being used.
 *
 * When rendering objects like sprites, text, etc - GPU resources are created and managed by the renderer.
 * If these objects are no longer needed but not properly destroyed (via sprite.destroy()), their GPU resources
 * would normally leak. This system prevents that by automatically cleaning up unused GPU resources.
 *
 * Key features:
 * - Runs every 30 seconds by default to check for unused resources
 * - Cleans up resources not rendered for over 1 minute
 * - Works independently of rendering - will clean up even when not actively rendering
 * - When cleaned up resources are needed again, new GPU objects are quickly assigned from a pool
 * - Can be disabled with renderableGCActive:false for manual control
 *
 * Best practices:
 * - Always call destroy() explicitly when done with renderables (e.g. sprite.destroy())
 * - This system is a safety net, not a replacement for proper cleanup
 * - Adjust frequency and timeouts via options if needed
 *
 * Example:
 * \`\`\`js
 * // Sprite created but reference lost without destroy
 * let sprite = new Sprite(texture);
 *
 * // internally the renderer will assign a resource to the sprite
 * renderer.render(sprite);
 *
 * sprite = null; // Reference lost but GPU resources still exist
 *
 * // After 1 minute of not being rendered:
 * // - RenderableGC will clean up the sprite's GPU resources
 * // - JS garbage collector can then clean up the sprite itself
 * \`\`\`
 * @implements {System<RenderableGCSystemOptions>}
 */
export declare class RenderableGCSystem implements System<RenderableGCSystemOptions> {
    /**
     * Extension metadata for registering this system with the renderer.
     * @ignore
     */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "renderableGC";
        readonly priority: 0;
    };
    /**
     * Default configuration options for the garbage collection system.
     * These can be overridden when initializing the renderer.
     */
    static defaultOptions: RenderableGCSystemOptions;
    /** Maximum time in ms a resource can be unused before being garbage collected */
    maxUnusedTime: number;
    /** Reference to the renderer this system belongs to */
    private _renderer;
    /** Array of renderables being tracked for garbage collection */
    private readonly _managedRenderables;
    /** ID of the main GC scheduler handler */
    private _handler;
    /** How frequently GC runs in ms */
    private _frequency;
    /** Current timestamp used for age calculations */
    private _now;
    /** Array of hash objects being tracked for cleanup */
    private readonly _managedHashes;
    /** ID of the hash cleanup scheduler handler */
    private _hashHandler;
    /** Array of arrays being tracked for cleanup */
    private readonly _managedArrays;
    /** ID of the array cleanup scheduler handler */
    private _arrayHandler;
    /**
     * Creates a new RenderableGCSystem instance.
     * @param renderer - The renderer this garbage collection system works for
     */
    constructor(renderer: Renderer);
    /**
     * Initializes the garbage collection system with the provided options.
     * @param options - Configuration options for the renderer
     */
    init(options: RenderableGCSystemOptions): void;
    /**
     * Gets whether the garbage collection system is currently enabled.
     * @returns True if GC is enabled, false otherwise
     */
    get enabled(): boolean;
    /**
     * Enables or disables the garbage collection system.
     * When enabled, schedules periodic cleanup of resources.
     * When disabled, cancels all scheduled cleanups.
     */
    set enabled(value: boolean);
    /**
     * Adds a hash table to be managed by the garbage collector.
     * @param context - The object containing the hash table
     * @param hash - The property name of the hash table
     */
    addManagedHash<T>(context: T, hash: string): void;
    /**
     * Adds an array to be managed by the garbage collector.
     * @param context - The object containing the array
     * @param hash - The property name of the array
     */
    addManagedArray<T>(context: T, hash: string): void;
    /**
     * Updates the GC timestamp and tracking before rendering.
     * @param options - The render options
     * @param options.container - The container to render
     */
    prerender({ container }: RenderOptions): void;
    /**
     * Starts tracking a renderable for garbage collection.
     * @param renderable - The renderable to track
     */
    addRenderable(renderable: Renderable): void;
    /**
     * Performs garbage collection by cleaning up unused renderables.
     * Removes renderables that haven't been used for longer than maxUnusedTime.
     */
    run(): void;
    /** Cleans up the garbage collection system. Disables GC and removes all tracked resources. */
    destroy(): void;
    /**
     * Removes a renderable from being tracked when it's destroyed.
     * @param renderable - The renderable to stop tracking
     */
    private _removeRenderable;
    /**
     * Updates the GC tick counter for a render group and its children.
     * @param renderGroup - The render group to update
     * @param gcTick - The new tick value
     */
    private _updateInstructionGCTick;
}
`,nd=`import EventEmitter from 'eventemitter3';
import { Rectangle } from '../../../../maths/shapes/Rectangle';
import { BufferImageSource } from './sources/BufferImageSource';
import { TextureSource } from './sources/TextureSource';
import { TextureMatrix } from './TextureMatrix';
import type { TextureResourceOrOptions } from './utils/textureFrom';
/**
 * Stores the width of the non-scalable borders, for example when used with {@link scene.NineSlicePlane} texture.
 * @memberof rendering
 */
export interface TextureBorders {
    /** left border in pixels */
    left: number;
    /** top border in pixels */
    top: number;
    /** right border in pixels */
    right: number;
    /** bottom border in pixels */
    bottom: number;
}
/**
 * The UVs data structure for a texture.
 * @memberof rendering
 */
export type UVs = {
    x0: number;
    y0: number;
    x1: number;
    y1: number;
    x2: number;
    y2: number;
    x3: number;
    y3: number;
};
/**
 * The options that can be passed to a new Texture
 * @memberof rendering
 */
export interface TextureOptions<TextureSourceType extends TextureSource = TextureSource> {
    /** the underlying texture data that this texture will use  */
    source?: TextureSourceType;
    /** optional label, for debugging */
    label?: string;
    /** The rectangle frame of the texture to show */
    frame?: Rectangle;
    /** The area of original texture */
    orig?: Rectangle;
    /** Trimmed rectangle of original texture */
    trim?: Rectangle;
    /** Default anchor point used for sprite placement / rotation */
    defaultAnchor?: {
        x: number;
        y: number;
    };
    /** Default borders used for 9-slice scaling {@link NineSlicePlane}*/
    defaultBorders?: TextureBorders;
    /** indicates how the texture was rotated by texture packer. See {@link groupD8} */
    rotate?: number;
    /**
     * Set to true if you plan on modifying this texture's frame, UVs, or swapping its source at runtime.
     * This is false by default as it improves performance. Generally, it's recommended to create new
     * textures and swap those rather than modifying an existing texture's properties unless you are
     * working with a dynamic frames.
     * Not setting this to true when modifying the texture can lead to visual artifacts.
     *
     * If this is false and you modify the texture, you can manually update the sprite's texture by calling
     * \`sprite.onViewUpdate()\`.
     */
    dynamic?: boolean;
}
export interface BindableTexture {
    source: TextureSource;
}
export type TextureSourceLike = TextureSource | TextureResourceOrOptions | string;
/**
 * A texture stores the information that represents an image or part of an image.
 *
 * A texture must have a loaded resource passed to it to work. It does not contain any
 * loading mechanisms.
 *
 * The Assets class can be used to load a texture from a file. This is the recommended
 * way as it will handle the loading and caching for you.
 *
 * \`\`\`js
 *
 * const texture = await Assets.load('assets/image.png');
 *
 * // once Assets has loaded the image it will be available via the from method
 * const sameTexture = Texture.from('assets/image.png');
 * // another way to access the texture once loaded
 * const sameAgainTexture = Asset.get('assets/image.png');
 *
 * const sprite1 = new Sprite(texture);
 *
 * \`\`\`
 *
 * It cannot be added to the display list directly; instead use it as the texture for a Sprite.
 * If no frame is provided for a texture, then the whole image is used.
 *
 * You can directly create a texture from an image and then reuse it multiple times like this :
 *
 * \`\`\`js
 * import { Sprite, Texture } from 'pixi.js';
 *
 * const texture = await Assets.load('assets/image.png');
 * const sprite1 = new Sprite(texture);
 * const sprite2 = new Sprite(texture);
 * \`\`\`
 *
 * If you didn't pass the texture frame to constructor, it enables \`noFrame\` mode:
 * it subscribes on baseTexture events, it automatically resizes at the same time as baseTexture.
 * @memberof rendering
 * @class
 */
export declare class Texture<TextureSourceType extends TextureSource = TextureSource> extends EventEmitter<{
    update: Texture;
    destroy: Texture;
}> implements BindableTexture {
    /**
     * Helper function that creates a returns Texture based on the source you provide.
     * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
     * @param id - String or Source to create texture from
     * @param skipCache - Skip adding the texture to the cache
     * @returns The texture based on the Id provided
     */
    static from: (id: TextureSourceLike, skipCache?: boolean) => Texture;
    /** label used for debugging */
    label?: string;
    /** unique id for this texture */
    readonly uid: number;
    /**
     * Has the texture been destroyed?
     * @readonly
     */
    destroyed: boolean;
    _source: TextureSourceType;
    /**
     * Indicates whether the texture is rotated inside the atlas
     * set to 2 to compensate for texture packer rotation
     * set to 6 to compensate for spine packer rotation
     * can be used to rotate or mirror sprites
     * See {@link maths.groupD8} for explanation
     */
    readonly rotate: number;
    /** A uvs object based on the given frame and the texture source */
    readonly uvs: UVs;
    /**
     * Anchor point that is used as default if sprite is created with this texture.
     * Changing the \`defaultAnchor\` at a later point of time will not update Sprite's anchor point.
     * @default {0,0}
     */
    readonly defaultAnchor?: {
        x: number;
        y: number;
    };
    /**
     * Default width of the non-scalable border that is used if 9-slice plane is created with this texture.
     * @since 7.2.0
     * @see scene.NineSliceSprite
     */
    readonly defaultBorders?: TextureBorders;
    /**
     * This is the area of the BaseTexture image to actually copy to the Canvas / WebGL when rendering,
     * irrespective of the actual frame size or placement (which can be influenced by trimmed texture atlases)
     */
    readonly frame: Rectangle;
    /** This is the area of original texture, before it was put in atlas. */
    readonly orig: Rectangle;
    /**
     * This is the trimmed area of original texture, before it was put in atlas
     * Please call \`updateUvs()\` after you change coordinates of \`trim\` manually.
     */
    readonly trim: Rectangle;
    /**
     * Does this Texture have any frame data assigned to it?
     *
     * This mode is enabled automatically if no frame was passed inside constructor.
     *
     * In this mode texture is subscribed to baseTexture events, and fires \`update\` on any change.
     *
     * Beware, after loading or resize of baseTexture event can fired two times!
     * If you want more control, subscribe on baseTexture itself.
     * @example
     * texture.on('update', () => {});
     */
    noFrame: boolean;
    /**
     * Set to true if you plan on modifying the uvs of this texture.
     * When this is the case, sprites and other objects using the texture will
     * make sure to listen for changes to the uvs and update their vertices accordingly.
     */
    dynamic: boolean;
    private _textureMatrix;
    /** is it a texture? yes! used for type checking */
    readonly isTexture = true;
    /**
     * @param {rendering.TextureOptions} options - Options for the texture
     */
    constructor({ source, label, frame, orig, trim, defaultAnchor, defaultBorders, rotate, dynamic }?: TextureOptions<TextureSourceType>);
    set source(value: TextureSourceType);
    /** the underlying source of the texture (equivalent of baseTexture in v7) */
    get source(): TextureSourceType;
    /** returns a TextureMatrix instance for this texture. By default, that object is not created because its heavy. */
    get textureMatrix(): TextureMatrix;
    /** The width of the Texture in pixels. */
    get width(): number;
    /** The height of the Texture in pixels. */
    get height(): number;
    /** Call this function when you have modified the frame of this texture. */
    updateUvs(): void;
    /**
     * Destroys this texture
     * @param destroySource - Destroy the source when the texture is destroyed.
     */
    destroy(destroySource?: boolean): void;
    /**
     * Call this if you have modified the \`texture outside\` of the constructor.
     *
     * If you have modified this texture's source, you must separately call \`texture.source.update()\` to see those changes.
     */
    update(): void;
    /** @deprecated since 8.0.0 */
    get baseTexture(): TextureSource;
    /** an Empty Texture used internally by the engine */
    static EMPTY: Texture;
    /** a White texture used internally by the engine */
    static WHITE: Texture<BufferImageSource>;
}
`,td=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { Renderer } from '../../types';
import type { System } from '../system/System';
/**
 * Options for the {@link TextureGCSystem}.
 * @memberof rendering
 * @property {boolean} [textureGCActive=true] - If set to true, this will enable the garbage collector on the GPU.
 * @property {number} [textureGCAMaxIdle=60 * 60] -
 * The maximum idle frames before a texture is destroyed by garbage collection.
 * @property {number} [textureGCCheckCountMax=600] - Frames between two garbage collections.
 */
export interface TextureGCSystemOptions {
    /**
     * If set to true, this will enable the garbage collector on the GPU.
     * @default true
     * @memberof rendering.SharedRendererOptions
     */
    textureGCActive: boolean;
    /**
     * @deprecated since 8.3.0
     * @see {@link TextureGCSystem.textureGCMaxIdle}
     * @memberof rendering.SharedRendererOptions
     */
    textureGCAMaxIdle: number;
    /**
     * The maximum idle frames before a texture is destroyed by garbage collection.
     * @default 60 * 60
     * @memberof rendering.SharedRendererOptions
     */
    textureGCMaxIdle: number;
    /**
     * Frames between two garbage collections.
     * @default 600
     * @memberof rendering.SharedRendererOptions
     */
    textureGCCheckCountMax: number;
}
/**
 * System plugin to the renderer to manage texture garbage collection on the GPU,
 * ensuring that it does not get clogged up with textures that are no longer being used.
 * @memberof rendering
 */
export declare class TextureGCSystem implements System<TextureGCSystemOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "textureGC";
    };
    /** default options for the TextureGCSystem */
    static defaultOptions: TextureGCSystemOptions;
    /**
     * Frame count since started.
     * @readonly
     */
    count: number;
    /**
     * Frame count since last garbage collection.
     * @readonly
     */
    checkCount: number;
    /**
     * Maximum idle frames before a texture is destroyed by garbage collection.
     * @see TextureGCSystem.defaultMaxIdle
     */
    maxIdle: number;
    /**
     * Frames between two garbage collections.
     * @see TextureGCSystem.defaultCheckCountMax
     */
    checkCountMax: number;
    /**
     * Current garbage collection mode.
     * @see TextureGCSystem.defaultMode
     */
    active: boolean;
    private _renderer;
    /** @param renderer - The renderer this System works for. */
    constructor(renderer: Renderer);
    init(options: TextureGCSystemOptions): void;
    /**
     * Checks to see when the last time a texture was used.
     * If the texture has not been used for a specified amount of time, it will be removed from the GPU.
     */
    protected postrender(): void;
    /**
     * Checks to see when the last time a texture was used.
     * If the texture has not been used for a specified amount of time, it will be removed from the GPU.
     */
    run(): void;
    destroy(): void;
}
`,rd=`import { Matrix } from '../../../../maths/matrix/Matrix';
import type { Texture } from './Texture';
/**
 * Class controls uv mapping from Texture normal space to BaseTexture normal space.
 *
 * Takes \`trim\` and \`rotate\` into account. May contain clamp settings for Meshes and TilingSprite.
 *
 * Can be used in Texture \`uvMatrix\` field, or separately, you can use different clamp settings on the same texture.
 * If you want to add support for texture region of certain feature or filter, that's what you're looking for.
 *
 * Takes track of Texture changes through \`_lastTextureID\` private field.
 * Use \`update()\` method call to track it from outside.
 * @see Texture
 * @see Mesh
 * @see TilingSprite
 * @memberof rendering
 */
export declare class TextureMatrix {
    /**
     * Matrix operation that converts texture region coords to texture coords
     * @readonly
     */
    mapCoord: Matrix;
    /**
     * Changes frame clamping
     * Works with TilingSprite and Mesh
     * Change to 1.5 if you texture has repeated right and bottom lines, that leads to smoother borders
     * @default 0
     */
    clampOffset: number;
    /**
     * Changes frame clamping
     * Works with TilingSprite and Mesh
     * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
     * @default 0.5
     */
    clampMargin: number;
    /**
     * Clamp region for normalized coords, left-top pixel center in xy , bottom-right in zw.
     * Calculated based on clampOffset.
     */
    readonly uClampFrame: Float32Array;
    /** Normalized clamp offset. Calculated based on clampOffset. */
    readonly uClampOffset: Float32Array;
    /**
     * Tracks Texture frame changes.
     * @ignore
     */
    _updateID: number;
    /**
     * Tracks Texture frame changes.
     * @protected
     */
    protected _textureID: number;
    protected _texture: Texture;
    /**
     * If texture size is the same as baseTexture.
     * @default false
     * @readonly
     */
    isSimple: boolean;
    /**
     * @param texture - observed texture
     * @param clampMargin - Changes frame clamping, 0.5 by default. Use -0.5 for extra border.
     */
    constructor(texture: Texture, clampMargin?: number);
    /** Texture property. */
    get texture(): Texture;
    set texture(value: Texture);
    /**
     * Multiplies uvs array to transform
     * @param uvs - mesh uvs
     * @param [out=uvs] - output
     * @returns - output
     */
    multiplyUvs(uvs: Float32Array, out?: Float32Array): Float32Array;
    /**
     * Updates matrices if texture was changed
     * @returns - whether or not it was updated
     */
    update(): boolean;
}
`,od=`import { TextureSource } from './sources/TextureSource';
import { Texture } from './Texture';
import type { TextureSourceOptions } from './sources/TextureSource';
/**
 * Texture pool, used by FilterSystem and plugins.
 *
 * Stores collection of temporary pow2 or screen-sized renderTextures
 *
 * If you use custom RenderTexturePool for your filters, you can use methods
 * \`getFilterTexture\` and \`returnFilterTexture\` same as in default pool
 * @memberof rendering
 * @name TexturePool
 */
export declare class TexturePoolClass {
    /** The default options for texture pool */
    textureOptions: TextureSourceOptions;
    /**
     * Allow renderTextures of the same size as screen, not just pow2
     *
     * Automatically sets to true after \`setScreenSize\`
     * @default false
     */
    enableFullScreen: boolean;
    private _texturePool;
    private _poolKeyHash;
    /**
     * @param textureOptions - options that will be passed to BaseRenderTexture constructor
     * @param {SCALE_MODE} [textureOptions.scaleMode] - See {@link SCALE_MODE} for possible values.
     */
    constructor(textureOptions?: TextureSourceOptions);
    /**
     * Creates texture with params that were specified in pool constructor.
     * @param pixelWidth - Width of texture in pixels.
     * @param pixelHeight - Height of texture in pixels.
     * @param antialias
     */
    createTexture(pixelWidth: number, pixelHeight: number, antialias: boolean): Texture;
    /**
     * Gets a Power-of-Two render texture or fullScreen texture
     * @param frameWidth - The minimum width of the render texture.
     * @param frameHeight - The minimum height of the render texture.
     * @param resolution - The resolution of the render texture.
     * @param antialias
     * @returns The new render texture.
     */
    getOptimalTexture(frameWidth: number, frameHeight: number, resolution: number, antialias: boolean): Texture;
    /**
     * Gets extra texture of the same size as input renderTexture
     * @param texture - The texture to check what size it is.
     * @param antialias - Whether to use antialias.
     * @returns A texture that is a power of two
     */
    getSameSizeTexture(texture: Texture, antialias?: boolean): Texture<TextureSource<any>>;
    /**
     * Place a render texture back into the pool.
     * @param renderTexture - The renderTexture to free
     */
    returnTexture(renderTexture: Texture): void;
    /**
     * Clears the pool.
     * @param destroyTextures - Destroy all stored textures.
     */
    clear(destroyTextures?: boolean): void;
}
export declare const TexturePool: TexturePoolClass;
`,ad=`import EventEmitter from 'eventemitter3';
import type { BindResource } from '../../gpu/shader/BindResource';
import type { COMPARE_FUNCTION, SCALE_MODE, WRAP_MODE } from './const';
export interface TextureStyleOptions extends Partial<TextureStyle> {
    /** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
    addressMode?: WRAP_MODE;
    /** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
    addressModeU?: WRAP_MODE;
    /** specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
    addressModeV?: WRAP_MODE;
    /** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
    addressModeW?: WRAP_MODE;
    /** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
    scaleMode?: SCALE_MODE;
    /** specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
    magFilter?: SCALE_MODE;
    /** specifies the sampling behavior when the sample footprint is larger than one texel. */
    minFilter?: SCALE_MODE;
    /** specifies behavior for sampling between mipmap levels. */
    mipmapFilter?: SCALE_MODE;
    /** specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
    lodMinClamp?: number;
    /** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
    lodMaxClamp?: number;
    /**
     * When provided the sampler will be a comparison sampler with the specified
     * {@link GPUCompareFunction}.
     * Note: Comparison samplers may use filtering, but the sampling results will be
     * implementation-dependent and may differ from the normal filtering rules.
     */
    compare?: COMPARE_FUNCTION;
    /**
     * Specifies the maximum anisotropy value clamp used by the sampler.
     * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
     * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
     * be clamped to the maximum value that the platform supports.
     *
     * setting this to anything higher than 1 will set scale modes to 'linear'
     */
    maxAnisotropy?: number;
}
/**
 * A texture style describes how a texture should be sampled by a shader.
 * @memberof rendering
 */
export declare class TextureStyle extends EventEmitter<{
    change: TextureStyle;
    destroy: TextureStyle;
}> implements BindResource {
    _resourceType: string;
    _touched: number;
    private _sharedResourceId;
    /** default options for the style */
    static readonly defaultOptions: TextureStyleOptions;
    /** */
    addressModeU?: WRAP_MODE;
    /** */
    addressModeV?: WRAP_MODE;
    /** Specifies the {{GPUAddressMode|address modes}} for the texture width, height, and depth coordinates, respectively. */
    addressModeW?: WRAP_MODE;
    /** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
    magFilter?: SCALE_MODE;
    /** Specifies the sampling behavior when the sample footprint is larger than one texel. */
    minFilter?: SCALE_MODE;
    /** Specifies behavior for sampling between mipmap levels. */
    mipmapFilter?: SCALE_MODE;
    /** */
    lodMinClamp?: number;
    /** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
    lodMaxClamp?: number;
    /**
     * When provided the sampler will be a comparison sampler with the specified
     * {@link GPUCompareFunction}.
     * Note: Comparison samplers may use filtering, but the sampling results will be
     * implementation-dependent and may differ from the normal filtering rules.
     */
    compare?: COMPARE_FUNCTION;
    /**
     * Specifies the maximum anisotropy value clamp used by the sampler.
     * Note: Most implementations support {@link GPUSamplerDescriptor#maxAnisotropy} values in range
     * between 1 and 16, inclusive. The used value of {@link GPUSamplerDescriptor#maxAnisotropy} will
     * be clamped to the maximum value that the platform supports.
     * @internal
     * @ignore
     */
    _maxAnisotropy?: number;
    /**
     * Has the style been destroyed?
     * @readonly
     */
    destroyed: boolean;
    /**
     * @param options - options for the style
     */
    constructor(options?: TextureStyleOptions);
    set addressMode(value: WRAP_MODE);
    /** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
    get addressMode(): WRAP_MODE;
    set wrapMode(value: WRAP_MODE);
    get wrapMode(): WRAP_MODE;
    set scaleMode(value: SCALE_MODE);
    /** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
    get scaleMode(): SCALE_MODE;
    /** Specifies the maximum anisotropy value clamp used by the sampler. */
    set maxAnisotropy(value: number);
    get maxAnisotropy(): number;
    get _resourceId(): number;
    update(): void;
    private _generateResourceId;
    /** Destroys the style */
    destroy(): void;
}
`,id=`import type { Size } from '../../../../maths/misc/Size';
import type { Rectangle } from '../../../../maths/shapes/Rectangle';
/**
 * Stores a texture's frame in UV coordinates, in
 * which everything lies in the rectangle \`[(0,0), (1,0),
 * (1,1), (0,1)]\`.
 *
 * | Corner       | Coordinates |
 * |--------------|-------------|
 * | Top-Left     | \`(x0,y0)\`   |
 * | Top-Right    | \`(x1,y1)\`   |
 * | Bottom-Right | \`(x2,y2)\`   |
 * | Bottom-Left  | \`(x3,y3)\`   |
 * @protected
 * @memberof rendering
 */
export declare class TextureUvs {
    /** X-component of top-left corner \`(x0,y0)\`. */
    x0: number;
    /** Y-component of top-left corner \`(x0,y0)\`. */
    y0: number;
    /** X-component of top-right corner \`(x1,y1)\`. */
    x1: number;
    /** Y-component of top-right corner \`(x1,y1)\`. */
    y1: number;
    /** X-component of bottom-right corner \`(x2,y2)\`. */
    x2: number;
    /** Y-component of bottom-right corner \`(x2,y2)\`. */
    y2: number;
    /** X-component of bottom-left corner \`(x3,y3)\`. */
    x3: number;
    /** Y-component of bottom-right corner \`(x3,y3)\`. */
    y3: number;
    uvsFloat32: Float32Array;
    constructor();
    /**
     * Sets the texture Uvs based on the given frame information.
     * @protected
     * @param frame - The frame of the texture
     * @param baseFrame - The base frame of the texture
     * @param rotate - Rotation of frame, see {@link groupD8}
     */
    set(frame: Rectangle, baseFrame: Size, rotate: number): void;
    toString(): string;
}
`,sd=`/**
 * Specifies the alpha composition mode for textures.
 *
 * - \`no-premultiply-alpha\`: Does not premultiply alpha.
 * - \`premultiply-alpha-on-upload\`: Premultiplies alpha on texture upload.
 * - \`premultiplied-alpha\`: Assumes the texture is already in premultiplied alpha format.
 * @typedef {'no-premultiply-alpha' | 'premultiply-alpha-on-upload' | 'premultiplied-alpha'} ALPHA_MODES
 */
export type ALPHA_MODES = 'no-premultiply-alpha' | 'premultiply-alpha-on-upload' | 'premultiplied-alpha';
/**
 * Constants for multi-sampling antialiasing.
 * @see Framebuffer#multisample
 * @name MSAA_QUALITY
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */
export declare enum MSAA_QUALITY {
    NONE = 0,
    LOW = 2,
    MEDIUM = 4,
    HIGH = 8
}
export type TEXTURE_FORMATS = 'r8unorm' | 'r8snorm' | 'r8uint' | 'r8sint' | 'r16uint' | 'r16sint' | 'r16float' | 'rg8unorm' | 'rg8snorm' | 'rg8uint' | 'rg8sint' | 'r32uint' | 'r32sint' | 'r32float' | 'rg16uint' | 'rg16sint' | 'rg16float' | 'rgba8unorm' | 'rgba8unorm-srgb' | 'rgba8snorm' | 'rgba8uint' | 'rgba8sint' | 'bgra8unorm' | 'bgra8unorm-srgb' | 'rgb9e5ufloat' | 'rgb10a2unorm' | 'rg11b10ufloat' | 'rg32uint' | 'rg32sint' | 'rg32float' | 'rgba16uint' | 'rgba16sint' | 'rgba16float' | 'rgba32uint' | 'rgba32sint' | 'rgba32float' | 'stencil8' | 'depth16unorm' | 'depth24plus' | 'depth24plus-stencil8' | 'depth32float' | 'depth32float-stencil8' | 'bc1-rgba-unorm' | 'bc1-rgba-unorm-srgb' | 'bc2-rgba-unorm' | 'bc2-rgba-unorm-srgb' | 'bc3-rgba-unorm' | 'bc3-rgba-unorm-srgb' | 'bc4-r-unorm' | 'bc4-r-snorm' | 'bc5-rg-unorm' | 'bc5-rg-snorm' | 'bc6h-rgb-ufloat' | 'bc6h-rgb-float' | 'bc7-rgba-unorm' | 'bc7-rgba-unorm-srgb' | 'etc2-rgb8unorm' | 'etc2-rgb8unorm-srgb' | 'etc2-rgb8a1unorm' | 'etc2-rgb8a1unorm-srgb' | 'etc2-rgba8unorm' | 'etc2-rgba8unorm-srgb' | 'eac-r11unorm' | 'eac-r11snorm' | 'eac-rg11unorm' | 'eac-rg11snorm' | 'astc-4x4-unorm' | 'astc-4x4-unorm-srgb' | 'astc-5x4-unorm' | 'astc-5x4-unorm-srgb' | 'astc-5x5-unorm' | 'astc-5x5-unorm-srgb' | 'astc-6x5-unorm' | 'astc-6x5-unorm-srgb' | 'astc-6x6-unorm' | 'astc-6x6-unorm-srgb' | 'astc-8x5-unorm' | 'astc-8x5-unorm-srgb' | 'astc-8x6-unorm' | 'astc-8x6-unorm-srgb' | 'astc-8x8-unorm' | 'astc-8x8-unorm-srgb' | 'astc-10x5-unorm' | 'astc-10x5-unorm-srgb' | 'astc-10x6-unorm' | 'astc-10x6-unorm-srgb' | 'astc-10x8-unorm' | 'astc-10x8-unorm-srgb' | 'astc-10x10-unorm' | 'astc-10x10-unorm-srgb' | 'astc-12x10-unorm' | 'astc-12x10-unorm-srgb' | 'astc-12x12-unorm' | 'astc-12x12-unorm-srgb';
export type TEXTURE_VIEW_DIMENSIONS = '1d' | '2d' | '2d-array' | 'cube' | 'cube-array' | '3d';
export type TEXTURE_DIMENSIONS = '1d' | '2d' | '3d';
export type WRAP_MODE = 
/**
 * The texture uvs are clamped
 * @default 33071
 */
'clamp-to-edge'
/**
 * The texture uvs tile and repeat
 * @default 10497
 */
 | 'repeat'
/**
 * The texture uvs tile and repeat with mirroring
 * @default 33648
 */
 | 'mirror-repeat';
export declare enum DEPRECATED_WRAP_MODES {
    CLAMP = "clamp-to-edge",
    REPEAT = "repeat",
    MIRRORED_REPEAT = "mirror-repeat"
}
/** @deprecated since 8.0.0 */
export declare const WRAP_MODES: typeof DEPRECATED_WRAP_MODES;
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 * @static
 */
export type SCALE_MODE = 
/** Pixelating scaling */
'nearest'
/** Smooth scaling */
 | 'linear';
export declare enum DEPRECATED_SCALE_MODES {
    NEAREST = "nearest",
    LINEAR = "linear"
}
/**
 * @deprecated since 8.0.0
 */
export declare const SCALE_MODES: typeof DEPRECATED_SCALE_MODES;
export type COMPARE_FUNCTION = 'never' | 'less' | 'equal' | 'less-equal' | 'greater' | 'not-equal' | 'greater-equal' | 'always';
`,ld=`import { TextureSource } from './TextureSource';
import type { ExtensionMetadata } from '../../../../../extensions/Extensions';
import type { TypedArray } from '../../buffer/Buffer';
import type { TextureSourceOptions } from './TextureSource';
export interface BufferSourceOptions extends TextureSourceOptions<TypedArray | ArrayBuffer> {
    width: number;
    height: number;
}
export declare class BufferImageSource extends TextureSource<TypedArray | ArrayBuffer> {
    static extension: ExtensionMetadata;
    uploadMethodId: string;
    constructor(options: BufferSourceOptions);
    static test(resource: any): resource is TypedArray | ArrayBuffer;
}
`,dd=`import { TextureSource } from './TextureSource';
import type { ICanvas } from '../../../../../environment/canvas/ICanvas';
import type { ExtensionMetadata } from '../../../../../extensions/Extensions';
import type { TextureSourceOptions } from './TextureSource';
export interface CanvasSourceOptions extends TextureSourceOptions<ICanvas> {
    /**
     * Should the canvas be resized to preserve its screen width and height regardless
     * of the resolution of the renderer, this is only supported for HTMLCanvasElement
     * and will be ignored if the canvas is an OffscreenCanvas.
     */
    autoDensity?: boolean;
    /** if true, this canvas will be set up to be transparent where possible */
    transparent?: boolean;
}
export declare class CanvasSource extends TextureSource<ICanvas> {
    static extension: ExtensionMetadata;
    uploadMethodId: string;
    autoDensity: boolean;
    transparent: boolean;
    private _context2D;
    constructor(options: CanvasSourceOptions);
    resizeCanvas(): void;
    resize(width?: number, height?: number, resolution?: number): boolean;
    static test(resource: any): resource is ICanvas;
    /**
     * Returns the 2D rendering context for the canvas.
     * Caches the context after creating it.
     * @returns The 2D rendering context of the canvas.
     */
    get context2D(): CanvasRenderingContext2D;
}
`,pd=`import { TextureSource } from './TextureSource';
import type { TextureSourceOptions } from './TextureSource';
export declare class CompressedSource extends TextureSource<Uint8Array[]> {
    readonly uploadMethodId = "compressed";
    constructor(options: TextureSourceOptions);
}
`,cd=`import { TextureSource } from './TextureSource';
import type { ICanvas } from '../../../../../environment/canvas/ICanvas';
import type { ExtensionMetadata } from '../../../../../extensions/Extensions';
import type { TextureSourceOptions } from './TextureSource';
export type ImageResource = ImageBitmap | HTMLCanvasElement | OffscreenCanvas | ICanvas | VideoFrame | HTMLImageElement | HTMLVideoElement;
export declare class ImageSource extends TextureSource<ImageResource> {
    static extension: ExtensionMetadata;
    uploadMethodId: string;
    constructor(options: TextureSourceOptions<ImageResource>);
    static test(resource: any): resource is ImageResource;
}
`,ud=`import EventEmitter from 'eventemitter3';
import { TextureStyle } from '../TextureStyle';
import type { BindResource } from '../../../gpu/shader/BindResource';
import type { ALPHA_MODES, SCALE_MODE, TEXTURE_DIMENSIONS, TEXTURE_FORMATS, WRAP_MODE } from '../const';
import type { TextureStyleOptions } from '../TextureStyle';
import type { TextureResourceOrOptions } from '../utils/textureFrom';
/**
 * options for creating a new TextureSource
 * @memberof rendering
 */
export interface TextureSourceOptions<T extends Record<string, any> = any> extends TextureStyleOptions {
    /**
     * the resource that will be uploaded to the GPU. This is where we get our pixels from
     * eg an ImageBimt / Canvas / Video etc
     */
    resource?: T;
    /** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
    width?: number;
    /** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
    height?: number;
    /** the resolution of the texture. */
    resolution?: number;
    /** the format that the texture data has */
    format?: TEXTURE_FORMATS;
    /**
     * Used by internal textures
     * @ignore
     */
    sampleCount?: number;
    /**
     * Only really affects RenderTextures.
     * Should we use antialiasing for this texture. It will look better, but may impact performance as a
     * Blit operation will be required to resolve the texture.
     */
    antialias?: boolean;
    /** how many dimensions does this texture have? currently v8 only supports 2d */
    dimensions?: TEXTURE_DIMENSIONS;
    /** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
    mipLevelCount?: number;
    /**
     * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
     * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
     * can look better when scaled down.
     *
     * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
     * If you do, make sure to call \`updateMipmaps\` after you update the texture.
     */
    autoGenerateMipmaps?: boolean;
    /** the alpha mode of the texture */
    alphaMode?: ALPHA_MODES;
    /** optional label, can be used for debugging */
    label?: string;
    /** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
    autoGarbageCollect?: boolean;
}
/**
 * A TextureSource stores the information that represents an image.
 * All textures have require TextureSource, which contains information about the source.
 * Therefore you can have many textures all using a single TextureSource (eg a sprite sheet)
 *
 * This is an class is extended depending on the source of the texture.
 * Eg if you are using an an image as your resource, then an ImageSource is used.
 * @memberof rendering
 * @typeParam T - The TextureSource's Resource type.
 */
export declare class TextureSource<T extends Record<string, any> = any> extends EventEmitter<{
    change: BindResource;
    update: TextureSource;
    unload: TextureSource;
    destroy: TextureSource;
    resize: TextureSource;
    styleChange: TextureSource;
    updateMipmaps: TextureSource;
    error: Error;
}> implements BindResource {
    protected readonly options: TextureSourceOptions<T>;
    /** The default options used when creating a new TextureSource. override these to add your own defaults */
    static defaultOptions: TextureSourceOptions;
    /** unique id for this Texture source */
    readonly uid: number;
    /** optional label, can be used for debugging */
    label: string;
    /**
     * The resource type used by this TextureSource. This is used by the bind groups to determine
     * how to handle this resource.
     * @ignore
     * @internal
     */
    readonly _resourceType = "textureSource";
    /**
     * i unique resource id, used by the bind group systems.
     * This can change if the texture is resized or its resource changes
     */
    _resourceId: number;
    /**
     * this is how the backends know how to upload this texture to the GPU
     * It changes depending on the resource type. Classes that extend TextureSource
     * should override this property.
     * @ignore
     * @internal
     */
    uploadMethodId: string;
    _resolution: number;
    /** the pixel width of this texture source. This is the REAL pure number, not accounting resolution */
    pixelWidth: number;
    /** the pixel height of this texture source. This is the REAL pure number, not accounting resolution */
    pixelHeight: number;
    /**
     * the width of this texture source, accounting for resolution
     * eg pixelWidth 200, resolution 2, then width will be 100
     */
    width: number;
    /**
     * the height of this texture source, accounting for resolution
     * eg pixelHeight 200, resolution 2, then height will be 100
     */
    height: number;
    /**
     * the resource that will be uploaded to the GPU. This is where we get our pixels from
     * eg an ImageBimt / Canvas / Video etc
     */
    resource: T;
    /**
     * The number of samples of a multisample texture. This is always 1 for non-multisample textures.
     * To enable multisample for a texture, set antialias to true
     * @internal
     * @ignore
     */
    sampleCount: number;
    /** The number of mip levels to generate for this texture. this is  overridden if autoGenerateMipmaps is true */
    mipLevelCount: number;
    /**
     * Should we auto generate mipmaps for this texture? This will automatically generate mipmaps
     * for this texture when uploading to the GPU. Mipmapped textures take up more memory, but
     * can look better when scaled down.
     *
     * For performance reasons, it is recommended to NOT use this with RenderTextures, as they are often updated every frame.
     * If you do, make sure to call \`updateMipmaps\` after you update the texture.
     */
    autoGenerateMipmaps: boolean;
    /** the format that the texture data has */
    format: TEXTURE_FORMATS;
    /** how many dimensions does this texture have? currently v8 only supports 2d */
    dimension: TEXTURE_DIMENSIONS;
    /** the alpha mode of the texture */
    alphaMode: ALPHA_MODES;
    private _style;
    /**
     * Only really affects RenderTextures.
     * Should we use antialiasing for this texture. It will look better, but may impact performance as a
     * Blit operation will be required to resolve the texture.
     */
    antialias: boolean;
    /**
     * Has the source been destroyed?
     * @readonly
     */
    destroyed: boolean;
    /**
     * Used by automatic texture Garbage Collection, stores last GC tick when it was bound
     * @protected
     */
    _touched: number;
    /**
     * Used by the batcher to build texture batches. faster to have the variable here!
     * @protected
     */
    _batchTick: number;
    /**
     * A temporary batch location for the texture batching. Here for performance reasons only!
     * @protected
     */
    _textureBindLocation: number;
    isPowerOfTwo: boolean;
    /** If true, the Garbage Collector will unload this texture if it is not used after a period of time */
    autoGarbageCollect: boolean;
    /**
     * used internally to know where a texture came from. Usually assigned by the asset loader!
     * @ignore
     */
    _sourceOrigin: string;
    /**
     * @param options - options for creating a new TextureSource
     */
    constructor(options?: TextureSourceOptions<T>);
    /** returns itself */
    get source(): TextureSource;
    /** the style of the texture */
    get style(): TextureStyle;
    set style(value: TextureStyle);
    /** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
    get addressMode(): WRAP_MODE;
    set addressMode(value: WRAP_MODE);
    /** setting this will set wrapModeU,wrapModeV and wrapModeW all at once! */
    get repeatMode(): WRAP_MODE;
    set repeatMode(value: WRAP_MODE);
    /** Specifies the sampling behavior when the sample footprint is smaller than or equal to one texel. */
    get magFilter(): SCALE_MODE;
    set magFilter(value: SCALE_MODE);
    /** Specifies the sampling behavior when the sample footprint is larger than one texel. */
    get minFilter(): SCALE_MODE;
    set minFilter(value: SCALE_MODE);
    /** Specifies behavior for sampling between mipmap levels. */
    get mipmapFilter(): SCALE_MODE;
    set mipmapFilter(value: SCALE_MODE);
    /** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
    get lodMinClamp(): number;
    set lodMinClamp(value: number);
    /** Specifies the minimum and maximum levels of detail, respectively, used internally when sampling a texture. */
    get lodMaxClamp(): number;
    set lodMaxClamp(value: number);
    private _onStyleChange;
    /** call this if you have modified the texture outside of the constructor */
    update(): void;
    /** Destroys this texture source */
    destroy(): void;
    /**
     * This will unload the Texture source from the GPU. This will free up the GPU memory
     * As soon as it is required fore rendering, it will be re-uploaded.
     */
    unload(): void;
    /** the width of the resource. This is the REAL pure number, not accounting resolution   */
    get resourceWidth(): number;
    /** the height of the resource. This is the REAL pure number, not accounting resolution */
    get resourceHeight(): number;
    /**
     * the resolution of the texture. Changing this number, will not change the number of pixels in the actual texture
     * but will the size of the texture when rendered.
     *
     * changing the resolution of this texture to 2 for example will make it appear twice as small when rendered (as pixel
     * density will have increased)
     */
    get resolution(): number;
    set resolution(resolution: number);
    /**
     * Resize the texture, this is handy if you want to use the texture as a render texture
     * @param width - the new width of the texture
     * @param height - the new height of the texture
     * @param resolution - the new resolution of the texture
     * @returns - if the texture was resized
     */
    resize(width?: number, height?: number, resolution?: number): boolean;
    /**
     * Lets the renderer know that this texture has been updated and its mipmaps should be re-generated.
     * This is only important for RenderTexture instances, as standard Texture instances will have their
     * mipmaps generated on upload. You should call this method after you make any change to the texture
     *
     * The reason for this is is can be quite expensive to update mipmaps for a texture. So by default,
     * We want you, the developer to specify when this action should happen.
     *
     * Generally you don't want to have mipmaps generated on Render targets that are changed every frame,
     */
    updateMipmaps(): void;
    set wrapMode(value: WRAP_MODE);
    get wrapMode(): WRAP_MODE;
    set scaleMode(value: SCALE_MODE);
    /** setting this will set magFilter,minFilter and mipmapFilter all at once!  */
    get scaleMode(): SCALE_MODE;
    /**
     * Refresh check for isPowerOfTwo texture based on size
     * @private
     */
    protected _refreshPOT(): void;
    static test(_resource: any): any;
    /**
     * A helper function that creates a new TextureSource based on the resource you provide.
     * @param resource - The resource to create the texture source from.
     */
    static from: (resource: TextureResourceOrOptions) => TextureSource;
}
`,md=`import { TextureSource } from './TextureSource';
import type { ExtensionMetadata } from '../../../../../extensions/Extensions';
import type { Dict } from '../../../../../utils/types';
import type { ALPHA_MODES } from '../const';
import type { TextureSourceOptions } from './TextureSource';
type VideoResource = HTMLVideoElement;
/**
 * Options for video sources.
 * @memberof rendering
 */
export interface VideoSourceOptions extends TextureSourceOptions<VideoResource> {
    /** If true, the video will start loading immediately. */
    autoLoad?: boolean;
    /** If true, the video will start playing as soon as it is loaded. */
    autoPlay?: boolean;
    /** The number of times a second to update the texture from the video. Leave at 0 to update at every render. */
    updateFPS?: number;
    /** If true, the video will be loaded with the \`crossorigin\` attribute. */
    crossorigin?: boolean | string;
    /** If true, the video will loop when it ends. */
    loop?: boolean;
    /** If true, the video will be muted. */
    muted?: boolean;
    /** If true, the video will play inline. */
    playsinline?: boolean;
    /** If true, the video will be preloaded. */
    preload?: boolean;
    /** The time in milliseconds to wait for the video to preload before timing out. */
    preloadTimeoutMs?: number;
    /** The alpha mode of the video. */
    alphaMode?: ALPHA_MODES;
}
export interface VideoResourceOptionsElement {
    src: string;
    mime: string;
}
/**
 * A source for video-based textures.
 * @memberof rendering
 */
export declare class VideoSource extends TextureSource<VideoResource> {
    static extension: ExtensionMetadata;
    /** The default options for video sources. */
    static defaultOptions: VideoSourceOptions;
    /** Whether or not the video is ready to play. */
    isReady: boolean;
    /** The upload method for this texture. */
    uploadMethodId: string;
    /**
     * When set to true will automatically play videos used by this texture once
     * they are loaded. If false, it will not modify the playing state.
     * @default true
     */
    protected autoPlay: boolean;
    /**
     * \`true\` to use Ticker.shared to auto update the base texture.
     * @default true
     */
    private _autoUpdate;
    /**
     * \`true\` if the instance is currently connected to Ticker.shared to auto update the base texture.
     * @default false
     */
    private _isConnectedToTicker;
    /**
     * Promise when loading.
     * @default null
     */
    private _load;
    private _msToNextUpdate;
    private _preloadTimeout;
    /** Callback when completed with load. */
    private _resolve;
    private _reject;
    private _updateFPS;
    private _videoFrameRequestCallbackHandle;
    constructor(options: VideoSourceOptions);
    /** Update the video frame if the source is not destroyed and meets certain conditions. */
    protected updateFrame(): void;
    /** Callback to update the video frame and potentially request the next frame update. */
    private _videoFrameRequestCallback;
    /**
     * Checks if the resource has valid dimensions.
     * @returns {boolean} True if width and height are set, otherwise false.
     */
    get isValid(): boolean;
    /**
     * Start preloading the video resource.
     * @returns {Promise<this>} Handle the validate event
     */
    load(): Promise<this>;
    /**
     * Handle video error events.
     * @param event - The error event
     */
    private _onError;
    /**
     * Checks if the underlying source is playing.
     * @returns True if playing.
     */
    private _isSourcePlaying;
    /**
     * Checks if the underlying source is ready for playing.
     * @returns True if ready.
     */
    private _isSourceReady;
    /** Runs the update loop when the video is ready to play. */
    private _onPlayStart;
    /** Stops the update loop when a pause event is triggered. */
    private _onPlayStop;
    /** Handles behavior when the video completes seeking to the current playback position. */
    private _onSeeked;
    private _onCanPlay;
    private _onCanPlayThrough;
    /** Fired when the video is loaded and ready to play. */
    private _mediaReady;
    /** Cleans up resources and event listeners associated with this texture. */
    destroy(): void;
    /** Should the base texture automatically update itself, set to true by default. */
    get autoUpdate(): boolean;
    set autoUpdate(value: boolean);
    /**
     * How many times a second to update the texture from the video.
     * Leave at 0 to update at every render.
     * A lower fps can help performance, as updating the texture at 60fps on a 30ps video may not be efficient.
     */
    get updateFPS(): number;
    set updateFPS(value: number);
    /**
     * Configures the updating mechanism based on the current state and settings.
     *
     * This method decides between using the browser's native video frame callback or a custom ticker
     * for updating the video frame. It ensures optimal performance and responsiveness
     * based on the video's state, playback status, and the desired frames-per-second setting.
     *
     * - If \`_autoUpdate\` is enabled and the video source is playing:
     *   - It will prefer the native video frame callback if available and no specific FPS is set.
     *   - Otherwise, it will use a custom ticker for manual updates.
     * - If \`_autoUpdate\` is disabled or the video isn't playing, any active update mechanisms are halted.
     */
    private _configureAutoUpdate;
    /**
     * Map of video MIME types that can't be directly derived from file extensions.
     * @readonly
     */
    static MIME_TYPES: Dict<string>;
    static test(resource: any): resource is VideoResource;
}
export {};
`,hd=`export declare function generateUID(): number;
`,fd=`import { CanvasSource } from '../sources/CanvasSource';
import { Texture } from '../Texture';
import type { ICanvas } from '../../../../../environment/canvas/ICanvas';
import type { CanvasSourceOptions } from '../sources/CanvasSource';
export declare function getCanvasTexture(canvas: ICanvas, options?: CanvasSourceOptions): Texture<CanvasSource>;
export declare function hasCachedCanvasTexture(canvas: ICanvas): boolean;
`,bd=`import type { TEXTURE_FORMATS } from '../const';
export declare function getSupportedCompressedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
`,gd=`import type { TEXTURE_FORMATS } from '../const';
export declare const nonCompressedFormats: TEXTURE_FORMATS[];
export declare function getSupportedTextureFormats(): Promise<TEXTURE_FORMATS[]>;
`,yd=`import { TextureSource } from '../sources/TextureSource';
import { Texture } from '../Texture';
import type { BufferSourceOptions } from '../sources/BufferImageSource';
import type { CanvasSourceOptions } from '../sources/CanvasSource';
import type { ImageResource } from '../sources/ImageSource';
import type { TextureSourceOptions } from '../sources/TextureSource';
import type { TextureSourceLike } from '../Texture';
export type TextureResourceOrOptions = ImageResource | TextureSourceOptions<ImageResource> | BufferSourceOptions | CanvasSourceOptions;
/**
 * @param options
 * @deprecated since v8.2.0
 * @see TextureSource.from
 */
export declare function autoDetectSource(options?: TextureResourceOrOptions): TextureSource;
export declare function resourceToTexture(options?: TextureResourceOrOptions, skipCache?: boolean): Texture;
/**
 * Helper function that creates a returns Texture based on the source you provide.
 * The source should be loaded and ready to go. If not its best to grab the asset using Assets.
 * @param id - String or Source to create texture from
 * @param skipCache - Skip adding the texture to the cache
 * @returns The texture based on the Id provided
 */
export declare function textureFrom(id: TextureSourceLike, skipCache?: boolean): Texture;
`,xd=`export declare function createIdFromString(value: string, groupId: string): number;
`,vd=`export declare function parseFunctionBody(fn: (...args: any[]) => any): string;
`,Td=`import type { Point } from '../../../../maths/point/Point';
import type { BoundsData } from '../../../../scene/container/bounds/Bounds';
export interface ViewObserver {
    onViewUpdate: () => void;
}
/**
 * A view is something that is able to be rendered by the renderer.
 * @memberof scene
 */
export interface View {
    /** a unique id for this view */
    readonly uid: number;
    /** whether or not this view should be batched */
    batched: boolean;
    /**
     * an identifier that is used to identify the type of system that will be used to render this renderable
     * eg, 'sprite' will use the sprite system (based on the systems name
     */
    readonly renderPipeId: string;
    /** this is an int because it is packed directly into an attribute in the shader */
    _roundPixels: 0 | 1;
    /** @private */
    _lastUsed: number;
    /**
     *  Whether or not to round the x/y position of the object.
     * @type {boolean}
     */
    get roundPixels(): boolean;
    /** if true, the view will have its position rounded to the nearest whole number */
    set roundPixels(value: boolean);
    /** this is the AABB rectangle bounds of the view in local untransformed space. */
    bounds: BoundsData;
    /** Checks if the point is within the view */
    containsPoint: (point: Point) => boolean;
}
`,Sd=`import { ExtensionType } from '../../../../extensions/Extensions';
import { Rectangle } from '../../../../maths/shapes/Rectangle';
import { RenderTarget } from '../renderTarget/RenderTarget';
import type { ICanvas } from '../../../../environment/canvas/ICanvas';
import type { TypeOrBool } from '../../../../scene/container/destroyTypes';
import type { System } from '../system/System';
import type { CanvasSource } from '../texture/sources/CanvasSource';
import type { Texture } from '../texture/Texture';
/**
 * Options passed to the ViewSystem
 * @memberof rendering
 * @property {number} [width=800] - The width of the screen.
 * @property {number} [height=600] - The height of the screen.
 * @property {ICanvas} [canvas] - The canvas to use as a view, optional.
 * @property {boolean} [autoDensity=false] - Resizes renderer view in CSS pixels to allow for resolutions other than 1.
 *  This is only supported for HTMLCanvasElement and will be ignored if the canvas is an OffscreenCanvas.
 * @property {number} [resolution] - The resolution / device pixel ratio of the renderer.
 * @property {boolean} [antialias=false] - Whether to enable anti-aliasing. This may affect performance.
 * @property {boolean} [depth] -
 * Whether to ensure the main view has can make use of the depth buffer. Always true for WebGL renderer.
 * @property {boolean} [multiView] - TODO: multiView
 * @property {number} [backgroundAlpha] - The alpha of the background.
 */
export interface ViewSystemOptions {
    /**
     * The width of the screen.
     * @default 800
     * @memberof rendering.SharedRendererOptions
     */
    width?: number;
    /**
     * The height of the screen.
     * @default 600
     * @memberof rendering.SharedRendererOptions
     */
    height?: number;
    /**
     * The canvas to use as a view, optional.
     * @memberof rendering.SharedRendererOptions
     */
    canvas?: ICanvas;
    /** @deprecated */
    view?: ICanvas;
    /**
     * Resizes renderer view in CSS pixels to allow for resolutions other than 1.
     *
     * This is only supported for HTMLCanvasElement
     * and will be ignored if the canvas is an OffscreenCanvas.
     * @memberof rendering.SharedRendererOptions
     */
    autoDensity?: boolean;
    /**
     * The resolution / device pixel ratio of the renderer.
     * @memberof rendering.SharedRendererOptions
     */
    resolution?: number;
    /**
     * Whether to enable anti-aliasing. This may affect performance.
     * @memberof rendering.SharedRendererOptions
     */
    antialias?: boolean;
    /**
     * Whether to ensure the main view has can make use of the depth buffer. Always true for WebGL renderer.
     * @memberof rendering.SharedRendererOptions
     */
    depth?: boolean;
    /**
     * Transparency of the background color, value from \`0\` (fully transparent) to \`1\` (fully opaque).
     * @default 1
     */
    backgroundAlpha?: number;
}
export interface ViewSystemDestroyOptions {
    /** Whether to remove the view element from the DOM. Defaults to \`false\`. */
    removeView?: boolean;
}
/**
 * The view system manages the main canvas that is attached to the DOM.
 * This main role is to deal with how the holding the view reference and dealing with how it is resized.
 * @memberof rendering
 */
export declare class ViewSystem implements System<ViewSystemOptions, TypeOrBool<ViewSystemDestroyOptions>> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "view";
        readonly priority: 0;
    };
    /** The default options for the view system. */
    static defaultOptions: ViewSystemOptions;
    /** The canvas element that everything is drawn to. */
    canvas: ICanvas;
    /** The texture that is used to draw the canvas to the screen. */
    texture: Texture<CanvasSource>;
    /**
     * Whether CSS dimensions of canvas view should be resized to screen dimensions automatically.
     * This is only supported for HTMLCanvasElement and will be ignored if the canvas is an OffscreenCanvas.
     * @member {boolean}
     */
    get autoDensity(): boolean;
    set autoDensity(value: boolean);
    /** Whether to enable anti-aliasing. This may affect performance. */
    antialias: boolean;
    /**
     * Measurements of the screen. (0, 0, screenWidth, screenHeight).
     *
     * Its safe to use as filterArea or hitArea for the whole stage.
     */
    screen: Rectangle;
    /** The render target that the view is drawn to. */
    renderTarget: RenderTarget;
    /** The resolution / device pixel ratio of the renderer. */
    get resolution(): number;
    set resolution(value: number);
    /**
     * initiates the view system
     * @param options - the options for the view
     */
    init(options: ViewSystemOptions): void;
    /**
     * Resizes the screen and canvas to the specified dimensions.
     * @param desiredScreenWidth - The new width of the screen.
     * @param desiredScreenHeight - The new height of the screen.
     * @param resolution
     */
    resize(desiredScreenWidth: number, desiredScreenHeight: number, resolution: number): void;
    /**
     * Destroys this System and optionally removes the canvas from the dom.
     * @param {options | false} options - The options for destroying the view, or "false".
     * @param options.removeView - Whether to remove the view element from the DOM. Defaults to \`false\`.
     */
    destroy(options?: TypeOrBool<ViewSystemDestroyOptions>): void;
}
`,wd=`import type { ICanvas } from '../../environment/canvas/ICanvas';
import type { WebGLOptions, WebGLPipes, WebGLRenderer } from './gl/WebGLRenderer';
import type { WebGPUOptions, WebGPUPipes, WebGPURenderer } from './gpu/WebGPURenderer';
/** A generic renderer. */
/**
 * @memberof rendering
 * @extends rendering.WebGLRenderer
 * @extends rendering.WebGPURenderer
 */
export type Renderer<T extends ICanvas = HTMLCanvasElement> = WebGLRenderer<T> | WebGPURenderer<T>;
export type RenderPipes = WebGLPipes | WebGPUPipes;
/**
 * @extends rendering.WebGLOptions
 * @extends rendering.WebGPUOptions
 */
export interface RendererOptions extends WebGLOptions, WebGPUOptions {
}
/**
 * Ids for the different render types.
 * The idea is that you can use bitwise operations to filter whether or not you want to do something
 * in a certain render type.
 * Filters for example can be compatible for both webGL or WebGPU but not compatible with canvas.
 * So internally if it works with both we set filter.compatibleRenderers = RendererType.WEBGL | RendererType.WEBGPU
 * if it only works with webgl we set filter.compatibleRenderers = RendererType.WEBGL
 *
 */
export declare enum RendererType {
    WEBGL = 1,
    WEBGPU = 2,
    BOTH = 3
}
export type GpuPowerPreference = 'low-power' | 'high-performance';
`,_d=`/* eslint-disable @typescript-eslint/no-empty-object-type */
import { type CollectRenderablesMixin } from './container/container-mixins/collectRenderablesMixin';
import { type GetFastGlobalBoundsMixin } from './container/container-mixins/getFastGlobalBoundsMixin';

import type { ContainerChild } from './container/Container';
import type { CacheAsTextureMixin, CacheAsTextureMixinConstructor } from './container/container-mixins/cacheAsTextureMixin';
import type { ChildrenHelperMixin } from './container/container-mixins/childrenHelperMixin';
import type { EffectsMixin, EffectsMixinConstructor } from './container/container-mixins/effectsMixin';
import type { FindMixin, FindMixinConstructor } from './container/container-mixins/findMixin';
import type { GetGlobalMixin } from './container/container-mixins/getGlobalMixin';
import type { MeasureMixin, MeasureMixinConstructor } from './container/container-mixins/measureMixin';
import type { OnRenderMixin, OnRenderMixinConstructor } from './container/container-mixins/onRenderMixin';
import type { SortMixin, SortMixinConstructor } from './container/container-mixins/sortMixin';
import type { ToLocalGlobalMixin } from './container/container-mixins/toLocalGlobalMixin';

declare global
{
    namespace PixiMixins
    {

        interface Container<C extends ContainerChild = ContainerChild>
            extends ChildrenHelperMixin<C>,
            ToLocalGlobalMixin,
            OnRenderMixin,
            MeasureMixin,
            EffectsMixin,
            FindMixin,
            SortMixin,
            GetGlobalMixin,
            CollectRenderablesMixin,
            GetFastGlobalBoundsMixin,
            CacheAsTextureMixin {}

        interface ContainerOptions
            extends OnRenderMixinConstructor,
            MeasureMixinConstructor,
            EffectsMixinConstructor,
            FindMixinConstructor,
            SortMixinConstructor,
            CacheAsTextureMixinConstructor {}

        interface ViewContainer {}
        interface ViewContainerOptions {}

        interface Graphics {}
        interface GraphicsOptions {}

        interface Mesh {}
        interface MeshOptions {}

        interface ParticleContainer {}
        interface ParticleContainerOptions {}

        interface Sprite {}
        interface SpriteOptions {}

        interface AnimatedSprite {}
        interface AnimatedSpriteOptions {}

        interface NineSliceSprite {}
        interface NineSliceSpriteOptions {}

        interface TilingSprite {}
        interface TilingSpriteOptions {}

        interface Text {}
        interface BitmapText {}
        interface TextOptions {}

        interface HTMLText {}
        interface HTMLTextOptions {}

    }
}

export { };

`,Ed=`import EventEmitter from 'eventemitter3';
import { type ColorSource } from '../../color/Color';
import { Matrix } from '../../maths/matrix/Matrix';
import { ObservablePoint } from '../../maths/point/ObservablePoint';
import { type IRenderLayer } from '../layers/RenderLayer';
import { RenderGroup } from './RenderGroup';
import type { Size } from '../../maths/misc/Size';
import type { PointData } from '../../maths/point/PointData';
import type { Rectangle } from '../../maths/shapes/Rectangle';
import type { BLEND_MODES } from '../../rendering/renderers/shared/state/const';
import type { Dict } from '../../utils/types';
import type { Optional } from './container-mixins/measureMixin';
import type { DestroyOptions } from './destroyTypes';
export type ContainerChild = Container;
export interface ContainerEvents<C extends ContainerChild> extends PixiMixins.ContainerEvents {
    added: [container: Container];
    childAdded: [child: C, container: Container, index: number];
    removed: [container: Container];
    childRemoved: [child: C, container: Container, index: number];
    destroyed: [container: Container];
}
type AnyEvent = {
    [K: ({} & string) | ({} & symbol)]: any;
};
export declare const UPDATE_COLOR = 1;
export declare const UPDATE_BLEND = 2;
export declare const UPDATE_VISIBLE = 4;
export declare const UPDATE_TRANSFORM = 8;
export interface UpdateTransformOptions {
    x: number;
    y: number;
    scaleX: number;
    scaleY: number;
    rotation: number;
    skewX: number;
    skewY: number;
    pivotX: number;
    pivotY: number;
}
/**
 * Constructor options used for \`Container\` instances.
 * \`\`\`js
 * const container = new Container({
 *    position: new Point(100, 200),
 *    scale: new Point(2, 2),
 *    rotation: Math.PI / 2,
 * });
 * \`\`\`
 * @memberof scene
 * @see scene.Container
 */
export interface ContainerOptions<C extends ContainerChild = ContainerChild> extends PixiMixins.ContainerOptions {
    /** @see scene.Container#isRenderGroup */
    isRenderGroup?: boolean;
    /** @see scene.Container#blendMode */
    blendMode?: BLEND_MODES;
    /** @see scene.Container#tint */
    tint?: ColorSource;
    /** @see scene.Container#alpha */
    alpha?: number;
    /** @see scene.Container#angle */
    angle?: number;
    /** @see scene.Container#children */
    children?: C[];
    /** @see scene.Container#parent */
    parent?: Container;
    /** @see scene.Container#renderable */
    renderable?: boolean;
    /** @see scene.Container#rotation */
    rotation?: number;
    /** @see scene.Container#scale */
    scale?: PointData | number;
    /** @see scene.Container#pivot */
    pivot?: PointData | number;
    /** @see scene.Container#position */
    position?: PointData;
    /** @see scene.Container#skew */
    skew?: PointData;
    /** @see scene.Container#visible */
    visible?: boolean;
    /** @see scene.Container#x */
    x?: number;
    /** @see scene.Container#y */
    y?: number;
    /** @see scene.Container#boundArea */
    boundsArea?: Rectangle;
}
export interface Container<C extends ContainerChild> extends PixiMixins.Container<C>, EventEmitter<ContainerEvents<C> & AnyEvent> {
}
/**
 * Container is a general-purpose display object that holds children. It also adds built-in support for advanced
 * rendering features like masking and filtering.
 *
 * It is the base class of all display objects that act as a container for other objects, including Graphics
 * and Sprite.
 *
 * <details id="transforms">
 *
 * <summary>Transforms</summary>
 *
 * The [transform]{@link scene.Container#transform} of a display object describes the projection from its
 * local coordinate space to its parent's local coordinate space. The following properties are derived
 * from the transform:
 *
 * <table>
 *   <thead>
 *     <tr>
 *       <th>Property</th>
 *       <th>Description</th>
 *     </tr>
 *   </thead>
 *   <tbody>
 *     <tr>
 *       <td>[pivot]{@link scene.Container#pivot}</td>
 *       <td>
 *         Invariant under rotation, scaling, and skewing. The projection of into the parent's space of the pivot
 *         is equal to position, regardless of the other three transformations. In other words, It is the center of
 *         rotation, scaling, and skewing.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[position]{@link scene.Container#position}</td>
 *       <td>
 *         Translation. This is the position of the [pivot]{@link scene.Container#pivot} in the parent's local
 *         space. The default value of the pivot is the origin (0,0). If the top-left corner of your display object
 *         is (0,0) in its local space, then the position will be its top-left corner in the parent's local space.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[scale]{@link scene.Container#scale}</td>
 *       <td>
 *         Scaling. This will stretch (or compress) the display object's projection. The scale factors are along the
 *         local coordinate axes. In other words, the display object is scaled before rotated or skewed. The center
 *         of scaling is the [pivot]{@link scene.Container#pivot}.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[rotation]{@link scene.Container#rotation}</td>
 *       <td>
 *          Rotation. This will rotate the display object's projection by this angle (in radians).
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[skew]{@link scene.Container#skew}</td>
 *       <td>
 *         <p>Skewing. This can be used to deform a rectangular display object into a parallelogram.</p>
 *         <p>
 *         In PixiJS, skew has a slightly different behaviour than the conventional meaning. It can be
 *         thought of the net rotation applied to the coordinate axes (separately). For example, if "skew.x" is
 *         ⍺ and "skew.y" is β, then the line x = 0 will be rotated by ⍺ (y = -x*cot⍺) and the line y = 0 will be
 *         rotated by β (y = x*tanβ). A line y = x*tanϴ (i.e. a line at angle ϴ to the x-axis in local-space) will
 *         be rotated by an angle between ⍺ and β.
 *         </p>
 *         <p>
 *         It can be observed that if skew is applied equally to both axes, then it will be equivalent to applying
 *         a rotation. Indeed, if "skew.x" = -ϴ and "skew.y" = ϴ, it will produce an equivalent of "rotation" = ϴ.
 *         </p>
 *         <p>
 *         Another quite interesting observation is that "skew.x", "skew.y", rotation are commutative operations. Indeed,
 *         because rotation is essentially a careful combination of the two.
 *         </p>
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[angle]{@link scene.Container#angle}</td>
 *       <td>Rotation. This is an alias for [rotation]{@link scene.Container#rotation}, but in degrees.</td>
 *     </tr>
 *     <tr>
 *       <td>[x]{@link scene.Container#x}</td>
 *       <td>Translation. This is an alias for position.x!</td>
 *     </tr>
 *     <tr>
 *       <td>[y]{@link scene.Container#y}</td>
 *       <td>Translation. This is an alias for position.y!</td>
 *     </tr>
 *     <tr>
 *       <td>[width]{@link scene.Container#width}</td>
 *       <td>
 *         Implemented in [Container]{@link scene.Container}. Scaling. The width property calculates scale.x by dividing
 *         the "requested" width by the local bounding box width. It is indirectly an abstraction over scale.x, and there
 *         is no concept of user-defined width.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[height]{@link scene.Container#height}</td>
 *       <td>
 *         Implemented in [Container]{@link scene.Container}. Scaling. The height property calculates scale.y by dividing
 *         the "requested" height by the local bounding box height. It is indirectly an abstraction over scale.y, and there
 *         is no concept of user-defined height.
 *       </td>
 *     </tr>
 *   </tbody>
 * </table>
 * </details>
 *
 * <details id="alpha">
 * <summary>Alpha</summary>
 *
 * This alpha sets a display object's **relative opacity** w.r.t its parent. For example, if the alpha of a display
 * object is 0.5 and its parent's alpha is 0.5, then it will be rendered with 25% opacity (assuming alpha is not
 * applied on any ancestor further up the chain).
 * </details>
 *
 * <details id="visible">
 * <summary>Renderable vs Visible</summary>
 *
 * The \`renderable\` and \`visible\` properties can be used to prevent a display object from being rendered to the
 * screen. However, there is a subtle difference between the two. When using \`renderable\`, the transforms  of the display
 * object (and its children subtree) will continue to be calculated. When using \`visible\`, the transforms will not
 * be calculated.
 * \`\`\`ts
 * import { BlurFilter, Container, Graphics, Sprite } from 'pixi.js';
 *
 * const container = new Container();
 * const sprite = Sprite.from('https://s3-us-west-2.amazonaws.com/s.cdpn.io/693612/IaUrttj.png');
 *
 * sprite.width = 512;
 * sprite.height = 512;
 *
 * // Adds a sprite as a child to this container. As a result, the sprite will be rendered whenever the container
 * // is rendered.
 * container.addChild(sprite);
 *
 * // Blurs whatever is rendered by the container
 * container.filters = [new BlurFilter()];
 *
 * // Only the contents within a circle at the center should be rendered onto the screen.
 * container.mask = new Graphics()
 *     .beginFill(0xffffff)
 *     .drawCircle(sprite.width / 2, sprite.height / 2, Math.min(sprite.width, sprite.height) / 2)
 *     .endFill();
 * \`\`\`
 *
 * </details>
 *
 * <details id="renderGroup">
 * <summary>RenderGroup</summary>
 *
 * In PixiJS v8, containers can be set to operate in 'render group mode',
 * transforming them into entities akin to a stage in traditional rendering paradigms.
 * A render group is a root renderable entity, similar to a container,
 * but it's rendered in a separate pass with its own unique set of rendering instructions.
 * This approach enhances rendering efficiency and organization, particularly in complex scenes.
 *
 * You can enable render group mode on any container using container.enableRenderGroup()
 * or by initializing a new container with the render group property set to true (new Container({isRenderGroup: true})).
 *  The method you choose depends on your specific use case and setup requirements.
 *
 * An important aspect of PixiJS’s rendering process is the automatic treatment of rendered scenes as render groups.
 * This conversion streamlines the rendering process, but understanding when and how this happens is crucial
 * to fully leverage its benefits.
 *
 * One of the key advantages of using render groups is the performance efficiency in moving them. Since transformations
 *  are applied at the GPU level, moving a render group, even one with complex and numerous children,
 * doesn't require recalculating the rendering instructions or performing transformations on each child.
 * This makes operations like panning a large game world incredibly efficient.
 *
 * However, it's crucial to note that render groups do not batch together.
 * This means that turning every container into a render group could actually slow things down,
 * as each render group is processed separately. It's best to use render groups judiciously, at a broader level,
 * rather than on a per-child basis.
 * This approach ensures you get the performance benefits without overburdening the rendering process.
 *
 * RenderGroups maintain their own set of rendering instructions,
 * ensuring that changes or updates within a render group don't affect the rendering
 * instructions of its parent or other render groups.
 *  This isolation ensures more stable and predictable rendering behavior.
 *
 * Additionally, renderGroups can be nested, allowing for powerful options in organizing different aspects of your scene.
 * This feature is particularly beneficial for separating complex game graphics from UI elements,
 * enabling intricate and efficient scene management in complex applications.
 *
 * This means that Containers have 3 levels of matrix to be mindful of:
 *
 * 1. localTransform, this is the transform of the container based on its own properties
 * 2. groupTransform, this it the transform of the container relative to the renderGroup it belongs too
 * 3. worldTransform, this is the transform of the container relative to the Scene being rendered
 * </details>
 * @memberof scene
 */
export declare class Container<C extends ContainerChild = ContainerChild> extends EventEmitter<ContainerEvents<C> & AnyEvent> {
    /**
     * Mixes all enumerable properties and methods from a source object to Container.
     * @param source - The source of properties and methods to mix in.
     * @deprecated since 8.8.0
     */
    static mixin(source: Dict<any>): void;
    /** unique id for this container */
    readonly uid: number;
    /** @private */
    _updateFlags: number;
    /** @private */
    renderGroup: RenderGroup;
    /** @private */
    parentRenderGroup: RenderGroup;
    /** @private */
    parentRenderGroupIndex: number;
    /** @private */
    didChange: boolean;
    /** @private */
    didViewUpdate: boolean;
    /** @private */
    relativeRenderGroupDepth: number;
    /**
     * The array of children of this container.
     * @readonly
     */
    children: C[];
    /** The display object container that contains this display object. */
    parent: Container;
    /** @private */
    includeInBuild: boolean;
    /** @private */
    measurable: boolean;
    /** @private */
    isSimple: boolean;
    /**
     * The RenderLayer this container belongs to, if any.
     * If it belongs to a RenderLayer, it will be rendered from the RenderLayer's position in the scene.
     * @readonly
     */
    parentRenderLayer: IRenderLayer;
    /**
     * @internal
     * @ignore
     */
    updateTick: number;
    /**
     * Current transform of the object based on local factors: position, scale, other stuff.
     * @readonly
     */
    localTransform: Matrix;
    /**
     * The relative group transform is a transform relative to the render group it belongs too. It will include all parent
     * transforms and up to the render group (think of it as kind of like a stage - but the stage can be nested).
     * If this container is is self a render group matrix will be relative to its parent render group
     * @readonly
     */
    relativeGroupTransform: Matrix;
    /**
     * The group transform is a transform relative to the render group it belongs too.
     * If this container is render group then this will be an identity matrix. other wise it
     * will be the same as the relativeGroupTransform.
     * Use this value when actually rendering things to the screen
     * @readonly
     */
    groupTransform: Matrix;
    private _worldTransform;
    /** If the object has been destroyed via destroy(). If true, it should not be used. */
    destroyed: boolean;
    /**
     * The coordinate of the object relative to the local coordinates of the parent.
     * @internal
     * @ignore
     */
    _position: ObservablePoint;
    /**
     * The scale factor of the object.
     * @internal
     * @ignore
     */
    _scale: ObservablePoint;
    /**
     * The pivot point of the container that it rotates around.
     * @internal
     * @ignore
     */
    _pivot: ObservablePoint;
    /**
     * The skew amount, on the x and y axis.
     * @internal
     * @ignore
     */
    _skew: ObservablePoint;
    /**
     * The X-coordinate value of the normalized local X axis,
     * the first column of the local transformation matrix without a scale.
     * @internal
     * @ignore
     */
    _cx: number;
    /**
     * The Y-coordinate value of the normalized local X axis,
     * the first column of the local transformation matrix without a scale.
     * @internal
     * @ignore
     */
    _sx: number;
    /**
     * The X-coordinate value of the normalized local Y axis,
     * the second column of the local transformation matrix without a scale.
     * @internal
     * @ignore
     */
    _cy: number;
    /**
     * The Y-coordinate value of the normalized local Y axis,
     * the second column of the local transformation matrix without a scale.
     * @internal
     * @ignore
     */
    _sy: number;
    /**
     * The rotation amount.
     * @internal
     * @ignore
     */
    private _rotation;
    localColor: number;
    localAlpha: number;
    groupAlpha: number;
    groupColor: number;
    groupColorAlpha: number;
    /**
     * @internal
     * @ignore
     */
    localBlendMode: BLEND_MODES;
    /**
     * @internal
     * @ignore
     */
    groupBlendMode: BLEND_MODES;
    /**
     * This property holds three bits: culled, visible, renderable
     * the third bit represents culling (0 = culled, 1 = not culled) 0b100
     * the second bit represents visibility (0 = not visible, 1 = visible) 0b010
     * the first bit represents renderable (0 = not renderable, 1 = renderable) 0b001
     * @internal
     * @ignore
     */
    localDisplayStatus: number;
    /**
     * @internal
     * @ignore
     */
    globalDisplayStatus: number;
    readonly renderPipeId: string;
    /**
     * An optional bounds area for this container. Setting this rectangle will stop the renderer
     * from recursively measuring the bounds of each children and instead use this single boundArea.
     * This is great for optimisation! If for example you have a 1000 spinning particles and you know they all sit
     * within a specific bounds, then setting it will mean the renderer will not need to measure the
     * 1000 children to find the bounds. Instead it will just use the bounds you set.
     */
    boundsArea: Rectangle;
    /**
     * A value that increments each time the containe is modified
     * eg children added, removed etc
     * @ignore
     */
    _didContainerChangeTick: number;
    /**
     * A value that increments each time the container view is modified
     * eg texture swap, geometry change etc
     * @ignore
     */
    _didViewChangeTick: number;
    layerParentId: string;
    /**
     * We now use the _didContainerChangeTick and _didViewChangeTick to track changes
     * @deprecated since 8.2.6
     * @ignore
     */
    set _didChangeId(value: number);
    get _didChangeId(): number;
    /**
     * property that tracks if the container transform has changed
     * @ignore
     */
    private _didLocalTransformChangeId;
    constructor(options?: ContainerOptions<C>);
    /**
     * Adds one or more children to the container.
     *
     * Multiple items can be added like so: \`myContainer.addChild(thingOne, thingTwo, thingThree)\`
     * @param {...Container} children - The Container(s) to add to the container
     * @returns {Container} - The first child that was added.
     */
    addChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
    /**
     * Removes one or more children from the container.
     * @param {...Container} children - The Container(s) to remove
     * @returns {Container} The first child that was removed.
     */
    removeChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
    /** @ignore */
    _onUpdate(point?: ObservablePoint): void;
    set isRenderGroup(value: boolean);
    /**
     * Returns true if this container is a render group.
     * This means that it will be rendered as a separate pass, with its own set of instructions
     */
    get isRenderGroup(): boolean;
    /**
     * Calling this enables a render group for this container.
     * This means it will be rendered as a separate set of instructions.
     * The transform of the container will also be handled on the GPU rather than the CPU.
     */
    enableRenderGroup(): void;
    /** This will disable the render group for this container. */
    disableRenderGroup(): void;
    /** @ignore */
    _updateIsSimple(): void;
    /**
     * Current transform of the object based on world (parent) factors.
     * @readonly
     */
    get worldTransform(): Matrix;
    /**
     * The position of the container on the x axis relative to the local coordinates of the parent.
     * An alias to position.x
     */
    get x(): number;
    set x(value: number);
    /**
     * The position of the container on the y axis relative to the local coordinates of the parent.
     * An alias to position.y
     */
    get y(): number;
    set y(value: number);
    /**
     * The coordinate of the object relative to the local coordinates of the parent.
     * @since 4.0.0
     */
    get position(): ObservablePoint;
    set position(value: PointData);
    /**
     * The rotation of the object in radians.
     * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
     */
    get rotation(): number;
    set rotation(value: number);
    /**
     * The angle of the object in degrees.
     * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
     */
    get angle(): number;
    set angle(value: number);
    /**
     * The center of rotation, scaling, and skewing for this display object in its local space. The \`position\`
     * is the projection of \`pivot\` in the parent's local space.
     *
     * By default, the pivot is the origin (0, 0).
     * @since 4.0.0
     */
    get pivot(): ObservablePoint;
    set pivot(value: PointData | number);
    /**
     * The skew factor for the object in radians.
     * @since 4.0.0
     */
    get skew(): ObservablePoint;
    set skew(value: PointData);
    /**
     * The scale factors of this object along the local coordinate axes.
     *
     * The default scale is (1, 1).
     * @since 4.0.0
     */
    get scale(): ObservablePoint;
    set scale(value: PointData | number);
    /**
     * The width of the Container, setting this will actually modify the scale to achieve the value set.
     * @memberof scene.Container#
     */
    get width(): number;
    set width(value: number);
    /**
     * The height of the Container, setting this will actually modify the scale to achieve the value set.
     * @memberof scene.Container#
     */
    get height(): number;
    set height(value: number);
    /**
     * Retrieves the size of the container as a [Size]{@link Size} object.
     * This is faster than get the width and height separately.
     * @param out - Optional object to store the size in.
     * @returns - The size of the container.
     * @memberof scene.Container#
     */
    getSize(out?: Size): Size;
    /**
     * Sets the size of the container to the specified width and height.
     * This is faster than setting the width and height separately.
     * @param value - This can be either a number or a [Size]{@link Size} object.
     * @param height - The height to set. Defaults to the value of \`width\` if not provided.
     * @memberof scene.Container#
     */
    setSize(value: number | Optional<Size, 'height'>, height?: number): void;
    /** Called when the skew or the rotation changes. */
    private _updateSkew;
    /**
     * Updates the transform properties of the container (accepts partial values).
     * @param {object} opts - The options for updating the transform.
     * @param {number} opts.x - The x position of the container.
     * @param {number} opts.y - The y position of the container.
     * @param {number} opts.scaleX - The scale factor on the x-axis.
     * @param {number} opts.scaleY - The scale factor on the y-axis.
     * @param {number} opts.rotation - The rotation of the container, in radians.
     * @param {number} opts.skewX - The skew factor on the x-axis.
     * @param {number} opts.skewY - The skew factor on the y-axis.
     * @param {number} opts.pivotX - The x coordinate of the pivot point.
     * @param {number} opts.pivotY - The y coordinate of the pivot point.
     */
    updateTransform(opts: Partial<UpdateTransformOptions>): this;
    /**
     * Updates the local transform using the given matrix.
     * @param matrix - The matrix to use for updating the transform.
     */
    setFromMatrix(matrix: Matrix): void;
    /** Updates the local transform. */
    updateLocalTransform(): void;
    set alpha(value: number);
    /** The opacity of the object. */
    get alpha(): number;
    set tint(value: ColorSource);
    /**
     * The tint applied to the sprite. This is a hex value.
     *
     * A value of 0xFFFFFF will remove any tint effect.
     * @default 0xFFFFFF
     */
    get tint(): number;
    set blendMode(value: BLEND_MODES);
    /**
     * The blend mode to be applied to the sprite. Apply a value of \`'normal'\` to reset the blend mode.
     * @default 'normal'
     */
    get blendMode(): BLEND_MODES;
    /** The visibility of the object. If false the object will not be drawn, and the transform will not be updated. */
    get visible(): boolean;
    set visible(value: boolean);
    /** @ignore */
    get culled(): boolean;
    /** @ignore */
    set culled(value: boolean);
    /** Can this object be rendered, if false the object will not be drawn but the transform will still be updated. */
    get renderable(): boolean;
    set renderable(value: boolean);
    /** Whether or not the object should be rendered. */
    get isRenderable(): boolean;
    /**
     * Removes all internal references and listeners as well as removes children from the display list.
     * Do not use a Container after calling \`destroy\`.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their destroy
     *  method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Only used for children with textures e.g. Sprites. If options.children
     * is set to true it should destroy the texture of the child sprite
     * @param {boolean} [options.textureSource=false] - Only used for children with textures e.g. Sprites.
     * If options.children is set to true it should destroy the texture source of the child sprite
     * @param {boolean} [options.context=false] - Only used for children with graphicsContexts e.g. Graphics.
     * If options.children is set to true it should destroy the context of the child graphics
     */
    destroy(options?: DestroyOptions): void;
}
export {};
`,Pd=`import { ExtensionType } from '../../extensions/Extensions';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { InstructionPipe, RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { RenderContainer } from './RenderContainer';
/**
 * The CustomRenderPipe is a render pipe that allows for custom rendering logic for your renderable objects.
 * @example
 * import { RenderContainer } from 'pixi.js';
 *
 * const renderContainer = new RenderContainer(
 * (renderer) =>  {
 *     renderer.clear({
 *       clearColor: 'green', // clear the screen to green when rendering this item
 *     });
 * })
 * @memberof rendering
 */
export declare class CustomRenderPipe implements InstructionPipe<RenderContainer>, RenderPipe<RenderContainer> {
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "customRender";
    };
    private _renderer;
    constructor(renderer: Renderer);
    updateRenderable(): void;
    destroyRenderable(): void;
    validateRenderable(): boolean;
    addRenderable(container: RenderContainer, instructionSet: InstructionSet): void;
    execute(container: RenderContainer): void;
    destroy(): void;
}
`,Ad=`import type { Point } from '../../maths/point/Point';
import type { PointData } from '../../maths/point/PointData';
import type { Bounds } from './bounds/Bounds';
import type { Container } from './Container';
/**
 * An effect that can be applied to a container. This is used to create effects such as filters/masks etc.
 * @memberof rendering
 */
export interface Effect {
    pipe: string;
    priority: number;
    addBounds?(bounds: Bounds, skipUpdateTransform?: boolean): void;
    addLocalBounds?(bounds: Bounds, localRoot: Container): void;
    containsPoint?(point: PointData, hitTestFn: (container: Container, point: Point) => boolean): boolean;
    destroy(): void;
}
export interface EffectConstructor {
    new (options?: any): Effect;
    test?(options: any): boolean;
}
`,Cd=`import { ViewContainer } from '../view/ViewContainer';
import type { Point } from '../../maths/point/Point';
import type { Instruction } from '../../rendering/renderers/shared/instructions/Instruction';
import type { Renderer } from '../../rendering/renderers/types';
import type { Bounds, BoundsData } from './bounds/Bounds';
import type { ContainerOptions } from './Container';
type RenderFunction = (renderer: Renderer) => void;
/**
 * Options for the {@link scene.RenderContainer} constructor.
 * @memberof scene
 */
export interface RenderContainerOptions extends ContainerOptions {
    /** the optional custom render function if you want to inject the function via the constructor */
    render?: RenderFunction;
    /** how to know if the custom render logic contains a point or not, used for interaction */
    containsPoint?: (point: Point) => boolean;
    /** how to add the bounds of this object when measuring */
    addBounds?: (bounds: BoundsData) => void;
}
/**
 * A container that allows for custom rendering logic. Its essentially calls the render function each frame
 * and allows for custom rendering logic - the render could be a WebGL renderer or WebGPU render or even a canvas render.
 * Its up to you to define the logic.
 *
 * This can be used in two ways, either by extending the class and overriding the render method,
 * or by passing a custom render function
 * @example
 * \`\`\`js
 * import { RenderContainer } from 'pixi.js';
 *
 * // extend the class
 * class MyRenderContainer extends RenderContainer
 * {
 *    render(renderer)
 *    {
 *      renderer.clear({
 *         clearColor: 'green', // clear the screen to green when rendering this item
 *      });
 *   }
 * }
 *
 * // override the render method
 * const renderContainer = new RenderContainer(
 * (renderer) =>  {
 *     renderer.clear({
 *       clearColor: 'green', // clear the screen to green when rendering this item
 *     });
 * })
 * \`\`\`
 * @memberof scene
 * @extends scene.Container
 */
export declare class RenderContainer extends ViewContainer implements Instruction {
    readonly renderPipeId: string;
    batched: boolean;
    /**
     * Adds the bounds of this text to the bounds object.
     * @param bounds - The output bounds object.
     */
    addBounds: (bounds: Bounds) => void;
    /**
     * @param options - The options for the container.
     */
    constructor(options: RenderContainerOptions | RenderFunction);
    /** @private */
    protected updateBounds(): void;
    /**
     * An overridable function that can be used to render the object using the current renderer.
     * @param _renderer - The current renderer
     */
    render(_renderer: Renderer): void;
}
export {};
`,Rd=`import { Matrix } from '../../maths/matrix/Matrix';
import { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import { type Renderer } from '../../rendering/renderers/types';
import type { Instruction } from '../../rendering/renderers/shared/instructions/Instruction';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { BatchableSprite } from '../sprite/BatchableSprite';
import type { ViewContainer } from '../view/ViewContainer';
import type { Bounds } from './bounds/Bounds';
import type { Container } from './Container';
/**
 * Options for caching a container as a texture.
 * @memberof rendering
 * @see {@link RenderGroup#textureOptions}
 */
export interface CacheAsTextureOptions {
    /**
     * If true, the texture will be antialiased. This smooths out the edges of the texture.
     * @default false
     */
    antialias?: boolean;
    /**
     * The resolution of the texture. A higher resolution means a sharper texture but uses more memory.
     * By default the resolution is 1 which is the same as the rendererers resolution.
     */
    resolution?: number;
}
/**
 * A RenderGroup is a class that is responsible for I generating a set of instructions that are used to render the
 * root container and its children. It also watches for any changes in that container or its children,
 * these changes are analysed and either the instruction set is rebuild or the instructions data is updated.
 * @memberof rendering
 */
export declare class RenderGroup implements Instruction {
    renderPipeId: string;
    root: Container;
    canBundle: boolean;
    renderGroupParent: RenderGroup;
    renderGroupChildren: RenderGroup[];
    worldTransform: Matrix;
    worldColorAlpha: number;
    worldColor: number;
    worldAlpha: number;
    readonly childrenToUpdate: Record<number, {
        list: Container[];
        index: number;
    }>;
    updateTick: number;
    gcTick: number;
    readonly childrenRenderablesToUpdate: {
        list: Container[];
        index: number;
    };
    structureDidChange: boolean;
    instructionSet: InstructionSet;
    private readonly _onRenderContainers;
    /**
     * Indicates if the cached texture needs to be updated.
     * @default true
     */
    textureNeedsUpdate: boolean;
    /**
     * Indicates if the container should be cached as a texture.
     * @default false
     */
    isCachedAsTexture: boolean;
    /**
     * The texture used for caching the container. this is only set if isCachedAsTexture is true.
     * It can only be accessed after a render pass.
     * @type {Texture | undefined}
     */
    texture?: Texture;
    /**
     * The bounds of the cached texture.
     * @type {Bounds | undefined}
     * @ignore
     */
    _textureBounds?: Bounds;
    /**
     * The options for caching the container as a texture.
     * @type {CacheAsTextureOptions}
     */
    textureOptions: CacheAsTextureOptions;
    /**
     *  holds a reference to the batchable render sprite
     *  @ignore
     */
    _batchableRenderGroup: BatchableSprite;
    /**
     * Holds a reference to the closest parent RenderGroup that has isCachedAsTexture enabled.
     * This is used to properly transform coordinates when rendering into cached textures.
     * @type {RenderGroup | null}
     * @ignore
     */
    _parentCacheAsTextureRenderGroup: RenderGroup;
    private _inverseWorldTransform;
    private _textureOffsetInverseTransform;
    private _inverseParentTextureTransform;
    private _matrixDirty;
    init(root: Container): void;
    enableCacheAsTexture(options?: CacheAsTextureOptions): void;
    disableCacheAsTexture(): void;
    updateCacheTexture(): void;
    reset(): void;
    get localTransform(): Matrix;
    addRenderGroupChild(renderGroupChild: RenderGroup): void;
    private _removeRenderGroupChild;
    addChild(child: Container): void;
    removeChild(child: Container): void;
    removeChildren(children: Container[]): void;
    onChildUpdate(child: Container): void;
    updateRenderable(renderable: ViewContainer): void;
    onChildViewUpdate(child: Container): void;
    get isRenderable(): boolean;
    /**
     * adding a container to the onRender list will make sure the user function
     * passed in to the user defined 'onRender\` callBack
     * @param container - the container to add to the onRender list
     */
    addOnRender(container: Container): void;
    removeOnRender(container: Container): void;
    runOnRender(renderer: Renderer): void;
    destroy(): void;
    getChildren(out?: Container[]): Container[];
    private _getChildren;
    invalidateMatrices(): void;
    /**
     * Returns the inverse of the world transform matrix.
     * @returns {Matrix} The inverse of the world transform matrix.
     */
    get inverseWorldTransform(): Matrix;
    /**
     * Returns the inverse of the texture offset transform matrix.
     * @returns {Matrix} The inverse of the texture offset transform matrix.
     */
    get textureOffsetInverseTransform(): Matrix;
    /**
     * Returns the inverse of the parent texture transform matrix.
     * This is used to properly transform coordinates when rendering into cached textures.
     * @returns {Matrix} The inverse of the parent texture transform matrix.
     */
    get inverseParentTextureTransform(): Matrix;
    /**
     * Returns a matrix that transforms coordinates to the correct coordinate space of the texture being rendered to.
     * This is the texture offset inverse transform of the closest parent RenderGroup that is cached as a texture.
     * @returns {Matrix | null} The transform matrix for the cached texture coordinate space,
     * or null if no parent is cached as texture.
     */
    get cacheToLocalTransform(): Matrix;
}
`,Gd=`import { ExtensionType } from '../../extensions/Extensions';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { InstructionPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { RenderGroup } from './RenderGroup';
export declare class RenderGroupPipe implements InstructionPipe<RenderGroup> {
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "renderGroup";
    };
    private _renderer;
    constructor(renderer: Renderer);
    addRenderGroup(renderGroup: RenderGroup, instructionSet: InstructionSet): void;
    execute(renderGroup: RenderGroup): void;
    destroy(): void;
    private _addRenderableDirect;
    private _addRenderableCacheAsTexture;
    private _executeCacheAsTexture;
    private _executeDirect;
}
`,Md=`import { ExtensionType } from '../../extensions/Extensions';
import { Matrix } from '../../maths/matrix/Matrix';
import type { System } from '../../rendering/renderers/shared/system/System';
import type { Renderer } from '../../rendering/renderers/types';
import type { Container } from './Container';
/**
 * The view system manages the main canvas that is attached to the DOM.
 * This main role is to deal with how the holding the view reference and dealing with how it is resized.
 * @memberof rendering
 */
export declare class RenderGroupSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "renderGroup";
    };
    private readonly _renderer;
    constructor(renderer: Renderer);
    protected render({ container, transform }: {
        container: Container;
        transform: Matrix;
    }): void;
    destroy(): void;
    private _updateCachedRenderGroups;
    private _updateRenderGroups;
    private _updateRenderables;
    /**
     * @param renderGroup
     * @param renderPipes
     * @deprecated since 8.3.0
     */
    private _buildInstructions;
}
`,kd=`import { Matrix } from '../../../maths/matrix/Matrix';
import { Rectangle } from '../../../maths/shapes/Rectangle';
/**
 * Simple bounds implementation instead of more ambiguous [number, number, number, number]
 * @memberof rendering
 */
export interface BoundsData {
    minX: number;
    minY: number;
    maxX: number;
    maxY: number;
}
/**
 * A representation of an AABB bounding box.
 * @memberof rendering
 */
export declare class Bounds {
    /** @default Infinity */
    minX: number;
    /** @default Infinity */
    minY: number;
    /** @default -Infinity */
    maxX: number;
    /** @default -Infinity */
    maxY: number;
    matrix: Matrix;
    private _rectangle;
    constructor(minX?: number, minY?: number, maxX?: number, maxY?: number);
    /**
     * Checks if bounds are empty.
     * @returns - True if empty.
     */
    isEmpty(): boolean;
    /** The bounding rectangle of the bounds. */
    get rectangle(): Rectangle;
    /** Clears the bounds and resets. */
    clear(): this;
    /**
     * Sets the bounds.
     * @param x0 - left X of frame
     * @param y0 - top Y of frame
     * @param x1 - right X of frame
     * @param y1 - bottom Y of frame
     */
    set(x0: number, y0: number, x1: number, y1: number): void;
    /**
     * Adds sprite frame
     * @param x0 - left X of frame
     * @param y0 - top Y of frame
     * @param x1 - right X of frame
     * @param y1 - bottom Y of frame
     * @param matrix
     */
    addFrame(x0: number, y0: number, x1: number, y1: number, matrix?: Matrix): void;
    /**
     * Adds a rectangle to the bounds.
     * @param rect - The rectangle to be added.
     * @param matrix - The matrix to apply to the bounds.
     */
    addRect(rect: Rectangle, matrix?: Matrix): void;
    /**
     * Adds other {@link Bounds}.
     * @param bounds - The Bounds to be added
     * @param matrix
     */
    addBounds(bounds: BoundsData, matrix?: Matrix): void;
    /**
     * Adds other Bounds, masked with Bounds.
     * @param mask - The Bounds to be added.
     */
    addBoundsMask(mask: Bounds): void;
    /**
     * Adds other Bounds, multiplied with matrix.
     * @param matrix - The matrix to apply to the bounds.
     */
    applyMatrix(matrix: Matrix): void;
    /**
     * Resizes the bounds object to include the given rectangle.
     * @param rect - The rectangle to be included.
     */
    fit(rect: Rectangle): this;
    /**
     * Resizes the bounds object to include the given bounds.
     * @param left - The left value of the bounds.
     * @param right - The right value of the bounds.
     * @param top - The top value of the bounds.
     * @param bottom - The bottom value of the bounds.
     */
    fitBounds(left: number, right: number, top: number, bottom: number): this;
    /**
     * Pads bounds object, making it grow in all directions.
     * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
     * @param paddingX - The horizontal padding amount.
     * @param paddingY - The vertical padding amount.
     */
    pad(paddingX: number, paddingY?: number): this;
    /** Ceils the bounds. */
    ceil(): this;
    /** Clones the bounds. */
    clone(): Bounds;
    /**
     * Scales the bounds by the given values
     * @param x - The X value to scale by.
     * @param y - The Y value to scale by.
     */
    scale(x: number, y?: number): this;
    /** the x value of the bounds. */
    get x(): number;
    set x(value: number);
    /** the y value of the bounds. */
    get y(): number;
    set y(value: number);
    /** the width value of the bounds. */
    get width(): number;
    set width(value: number);
    /** the height value of the bounds. */
    get height(): number;
    set height(value: number);
    /** the left value of the bounds. */
    get left(): number;
    /** the right value of the bounds. */
    get right(): number;
    /** the top value of the bounds. */
    get top(): number;
    /** the bottom value of the bounds. */
    get bottom(): number;
    /** Is the bounds positive. */
    get isPositive(): boolean;
    get isValid(): boolean;
    /**
     * Adds screen vertices from array
     * @param vertexData - calculated vertices
     * @param beginOffset - begin offset
     * @param endOffset - end offset, excluded
     * @param matrix
     */
    addVertexData(vertexData: Float32Array, beginOffset: number, endOffset: number, matrix?: Matrix): void;
    /**
     * Checks if the point is contained within the bounds.
     * @param x - x coordinate
     * @param y - y coordinate
     */
    containsPoint(x: number, y: number): boolean;
    toString(): string;
    /**
     * Copies the bounds from another bounds object.
     * @param bounds - The bounds to copy from.
     * @returns - This bounds object.
     */
    copyFrom(bounds: Bounds): this;
}
`,Fd=`import type { Container } from '../Container';
import type { Bounds } from './Bounds';
/**
 * Does exactly the same as getGlobalBounds, but does instead makes use of transforming AABBs
 * of the various children within the scene graph. This is much faster, but less accurate.
 *
 * Deprecated, use container.getFastGlobalBounds() instead.
 *
 * the result will never be smaller - only ever slightly larger (in most cases, it will be the same).
 * @param target - The target container to get the bounds from
 * @param bounds - The output bounds object.
 * @returns The bounds.
 * @deprecated since 8.7.0
 * @see container.getFastGlobalBounds
 */
export declare function getFastGlobalBounds(target: Container, bounds: Bounds): Bounds;
`,Od=`import { Matrix } from '../../../maths/matrix/Matrix';
import type { Container } from '../Container';
import type { Bounds } from './Bounds';
export declare function getGlobalBounds(target: Container, skipUpdateTransform: boolean, bounds: Bounds): Bounds;
export declare function _getGlobalBounds(target: Container, bounds: Bounds, parentTransform: Matrix, skipUpdateTransform: boolean): void;
export declare function updateTransformBackwards(target: Container, parentTransform: Matrix): Matrix;
`,Id=`import { Matrix } from '../../../maths/matrix/Matrix';
import type { Container } from '../Container';
import type { Bounds } from './Bounds';
export declare function getLocalBounds(target: Container, bounds: Bounds, relativeMatrix?: Matrix): Bounds;
export declare function getParent(target: Container, root: Container, matrix: Matrix): void;
`,Ld=`import type { Renderable } from '../../../rendering/renderers/shared/Renderable';
import type { Bounds } from './Bounds';
export declare function getGlobalRenderableBounds(renderables: Renderable[], bounds: Bounds): Bounds;
`,Bd=`import { Matrix } from '../../../../maths/matrix/Matrix';
import { Pool } from '../../../../utils/pool/Pool';
import { Bounds } from '../Bounds';
import type { PoolItem } from '../../../../utils/pool/Pool';
type MatrixPoolItem = Matrix & PoolItem;
type BoundsPoolItem = Bounds & PoolItem;
export declare const matrixPool: Pool<MatrixPoolItem>;
export declare const boundsPool: Pool<BoundsPoolItem>;
export {};
`,Dd=`import type { Container } from '../Container';
import type { CacheAsTextureOptions } from '../RenderGroup';
export interface CacheAsTextureMixinConstructor {
    cacheAsTexture?: (val: boolean | CacheAsTextureOptions) => void;
}
export interface CacheAsTextureMixin extends Required<CacheAsTextureMixinConstructor> {
    /**
     * Caches this container as a texture. This allows the container to be rendered as a single texture,
     * which can improve performance for complex static containers.
     * @param val - If true, enables caching with default options. If false, disables caching.
     * Can also pass options object to configure caching behavior.
     * @memberof scene.Container#
     */
    cacheAsTexture: (val: boolean | CacheAsTextureOptions) => void;
    /**
     * Updates the cached texture of this container. This will flag the container's cached texture
     * to be redrawn on the next render.
     * @memberof scene.Container#
     */
    updateCacheTexture: () => void;
    /**
     * Legacy property for backwards compatibility with PixiJS v7 and below.
     * Use \`cacheAsTexture\` instead.
     * @deprecated Since PixiJS v8
     * @memberof scene.Container#
     */
    cacheAsBitmap: boolean;
    /**
     * Whether this container is currently cached as a texture.
     * @readonly
     * @memberof scene.Container#
     */
    readonly isCachedAsTexture: boolean;
}
export declare const cacheAsTextureMixin: Partial<Container>;
`,Ud=`import type { IRenderLayer } from '../../layers/RenderLayer';
import type { ContainerChild } from '../Container';
export interface ChildrenHelperMixin<C = ContainerChild> {
    allowChildren: boolean;
    addChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
    removeChild<U extends (C | IRenderLayer)[]>(...children: U): U[0];
    removeChildren(beginIndex?: number, endIndex?: number): C[];
    removeChildAt<U extends (C | IRenderLayer)>(index: number): U;
    getChildAt<U extends (C | IRenderLayer)>(index: number): U;
    setChildIndex(child: C | IRenderLayer, index: number): void;
    getChildIndex(child: C | IRenderLayer): number;
    addChildAt<U extends (C | IRenderLayer)>(child: U, index: number): U;
    swapChildren<U extends (C | IRenderLayer)>(child: U, child2: U): void;
    removeFromParent(): void;
    reparentChild<U extends C[]>(...child: U): U[0];
    reparentChildAt<U extends C>(child: U, index: number): U;
}
export declare const childrenHelperMixin: ChildrenHelperMixin<ContainerChild>;
`,jd=`import { type InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import { type Renderer } from '../../../rendering/renderers/types';
import { type IRenderLayer } from '../../layers/RenderLayer';
import type { Container } from '../Container';
/**
 * The CollectRenderablesMixin interface defines methods for collecting renderable objects
 * from a container and its children. These methods add the renderables to an instruction set,
 * which is used by the renderer to process and display the scene.
 */
export interface CollectRenderablesMixin {
    /**
     * Collects all renderables from the container and its children, adding them to the instruction set.
     * This method decides whether to use a simple or advanced collection method based on the container's properties.
     * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
     * @param {Renderer} renderer - The renderer responsible for rendering the scene.
     * @param {IRenderLayer} currentLayer - The current render layer being processed.
     * @memberof scene.Container#
     */
    collectRenderables(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
    /**
     * Collects renderables using a simple method, suitable for containers marked as simple.
     * This method iterates over the container's children and adds their renderables to the instruction set.
     * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
     * @param {Renderer} renderer - The renderer responsible for rendering the scene.
     * @param {IRenderLayer} currentLayer - The current render layer being processed.
     * @memberof scene.Container#
     */
    collectRenderablesSimple(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
    /**
     * Collects renderables using an advanced method, suitable for containers with complex processing needs.
     * This method handles additional effects and transformations that may be applied to the renderables.
     * @param {InstructionSet} instructionSet - The set of instructions to which the renderables will be added.
     * @param {Renderer} renderer - The renderer responsible for rendering the scene.
     * @param {IRenderLayer} currentLayer - The current render layer being processed.
     * @memberof scene.Container#
     */
    collectRenderablesWithEffects(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
}
/**
 * The collectRenderablesMixin provides implementations for the methods defined in the CollectRenderablesMixin interface.
 * It includes logic to determine the appropriate method for collecting renderables based on the container's properties.
 */
export declare const collectRenderablesMixin: Partial<Container>;
`,Wd=`import { FilterEffect } from '../../../filters/FilterEffect';
import type { Filter } from '../../../filters/Filter';
import type { Rectangle } from '../../../maths/shapes/Rectangle';
import type { MaskEffect } from '../../../rendering/mask/MaskEffectManager';
import type { Container } from '../Container';
import type { Effect } from '../Effect';
export interface EffectsMixinConstructor {
    mask?: Mask;
    setMask?: (options: Partial<MaskOptionsAndMask>) => void;
    filters?: Filter | Filter[];
}
export type Mask = number | Container | null;
export interface MaskOptions {
    inverse: boolean;
}
export interface MaskOptionsAndMask extends MaskOptions {
    mask: Mask;
}
export interface EffectsMixin extends Required<EffectsMixinConstructor> {
    _maskEffect?: MaskEffect;
    _maskOptions?: MaskOptions;
    _filterEffect?: FilterEffect;
    filterArea?: Rectangle;
    effects?: Effect[];
    _markStructureAsChanged(): void;
    addEffect(effect: Effect): void;
    removeEffect(effect: Effect): void;
}
export declare const effectsMixin: Partial<Container>;
`,Hd=`import type { Container } from '../Container';
export interface FindMixinConstructor {
    label?: string;
}
export interface FindMixin extends Required<FindMixinConstructor> {
    /**
     * @deprecated since 8.0.0
     * @see Container#label
     */
    name: string;
    getChildByName(label: RegExp | string, deep?: boolean): Container | null;
    getChildByLabel(label: RegExp | string, deep?: boolean): Container | null;
    getChildrenByLabel(label: RegExp | string, deep?: boolean, out?: Container[]): Container[];
}
export declare const findMixin: Partial<Container>;
`,Vd=`import { type IRenderLayer } from '../../layers/RenderLayer';
import { Bounds } from '../bounds/Bounds';
import type { Container } from '../Container';
/**
 * Interface for the GetFastGlobalBoundsMixin, which provides methods to compute
 * an approximate global bounding box for a container and its children.
 */
export interface GetFastGlobalBoundsMixin {
    /**
     * Computes an approximate global bounding box for the container and its children.
     * This method is optimized for speed by using axis-aligned bounding boxes (AABBs),
     * and uses the last render results from when it updated the transforms. This function does not update them.
     * which may result in slightly larger bounds but never smaller than the actual bounds.
     *
     * for accurate (but less performant) results use \`container.getGlobalBounds\`
     * @param {boolean} [factorRenderLayers] - A flag indicating whether to consider render layers in the calculation.
     * @param {Bounds} [bounds] - The output bounds object to store the result. If not provided, a new one is created.
     * @returns {Bounds} The computed bounds.
     * @memberof scene.Container#
     */
    getFastGlobalBounds(factorRenderLayers?: boolean, bounds?: Bounds): Bounds;
    /**
     * Recursively calculates the global bounds for the container and its children.
     * This method is used internally by getFastGlobalBounds to traverse the scene graph.
     * @param {boolean} factorRenderLayers - A flag indicating whether to consider render layers in the calculation.
     * @param {Bounds} bounds - The bounds object to update with the calculated values.
     * @param {IRenderLayer} currentLayer - The current render layer being processed.
     * @memberof scene.Container#
     */
    _getGlobalBoundsRecursive(factorRenderLayers: boolean, bounds: Bounds, currentLayer: IRenderLayer): void;
}
/**
 * Mixin providing the implementation of the GetFastGlobalBoundsMixin interface.
 * It includes methods to compute and recursively calculate global bounds for containers.
 */
export declare const getFastGlobalBoundsMixin: Partial<Container>;
`,Nd=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Container } from '../Container';
export declare function bgr2rgb(color: number): number;
export interface GetGlobalMixin {
    getGlobalAlpha(skipUpdate: boolean): number;
    getGlobalTransform(matrix: Matrix, skipUpdate: boolean): Matrix;
    getGlobalTint(skipUpdate?: boolean): number;
}
export declare const getGlobalMixin: Partial<Container>;
`,zd=`import { Bounds } from '../bounds/Bounds';
import type { Size } from '../../../maths/misc/Size';
import type { Container } from '../Container';
export type Optional<T, K extends keyof T> = Omit<T, K> & Partial<Pick<T, K>>;
export interface MeasureMixinConstructor {
    width?: number;
    height?: number;
}
export interface MeasureMixin extends Required<MeasureMixinConstructor> {
    getSize(out?: Size): Size;
    setSize(width: number, height?: number): void;
    setSize(value: Optional<Size, 'height'>): void;
    getLocalBounds(bounds?: Bounds): Bounds;
    getBounds(skipUpdate?: boolean, bounds?: Bounds): Bounds;
    _localBoundsCacheData: LocalBoundsCacheData;
    _localBoundsCacheId: number;
    _setWidth(width: number, localWidth: number): void;
    _setHeight(height: number, localHeight: number): void;
}
interface LocalBoundsCacheData {
    data: number[];
    index: number;
    didChange: boolean;
    localBounds: Bounds;
}
export declare const measureMixin: Partial<Container>;
export {};
`,Xd=`import type { Renderer } from '../../../rendering/renderers/types';
import type { Container } from '../Container';
export interface OnRenderMixinConstructor {
    onRender?: ((renderer: Renderer) => void | null);
}
export interface OnRenderMixin extends Required<OnRenderMixinConstructor> {
    _onRender: ((renderer: Renderer) => void) | null;
}
export declare const onRenderMixin: Partial<Container>;
`,Kd=`import type { Container } from '../Container';
export interface SortMixinConstructor {
    zIndex?: number;
    sortDirty?: boolean;
    sortableChildren?: boolean;
}
export interface SortMixin extends Required<SortMixinConstructor> {
    _zIndex: number;
    sortChildren: () => void;
    depthOfChildModified: () => void;
}
export declare const sortMixin: Partial<Container>;
`,qd=`import { Point } from '../../../maths/point/Point';
import type { PointData } from '../../../maths/point/PointData';
import type { Container } from '../Container';
export interface ToLocalGlobalMixin {
    getGlobalPosition(point?: Point, skipUpdate?: boolean): Point;
    toGlobal<P extends PointData = Point>(position: PointData, point?: P, skipUpdate?: boolean): P;
    toLocal<P extends PointData = Point>(position: PointData, from?: Container, point?: P, skipUpdate?: boolean): P;
}
export declare const toLocalGlobalMixin: Partial<Container>;
`,Yd=`/**
 * Base destroy options.
 * @example
 * // Destroy the sprite and all its children.
 * sprite.destroy({ children: true });
 * @memberof scene
 */
export interface BaseDestroyOptions {
    /** Destroy children recursively. */
    children?: boolean;
}
/**
 * Options when destroying textures. Most of these use cases are internal.
 * \`\`\`js
 * // destroy the graphics context and its texture
 * graphicsContext.destroy({ texture: true });
 * \`\`\`
 * @memberof scene
 */
export interface TextureDestroyOptions {
    /** Destroy the texture as well. */
    texture?: boolean;
    /** Destroy the texture source as well. */
    textureSource?: boolean;
}
/**
 * Options when destroying a graphics context.
 * \`\`\`js
 * // destroy the graphics context and its texture
 * graphicsContext.destroy({ context: true, texture: true });
 * \`\`\`
 * @memberof scene
 */
export interface ContextDestroyOptions {
    /** Destroy the graphics context as well. */
    context?: boolean;
}
/**
 * Options when destroying a text.
 * \`\`\`js
 * // destroy the text and its style
 * text.destroy({ style: true });
 * \`\`\`
 * @memberof scene
 */
export interface TextDestroyOptions {
    /** Destroy the text style as well. */
    style?: boolean;
}
export type TypeOrBool<T> = T | boolean;
/**
 * Options for destroying a container.
 * @property {boolean} [children=false] - Destroy the children of the container as well.
 * @property {boolean} [texture=false] - Destroy the texture of the container's children.
 * @property {boolean} [textureSource=false] - Destroy the texture source of the container's children.
 * @property {boolean} [context=false] - Destroy the context of the container's children.
 * @property {boolean} [style=false] - Destroy the style of the container's children.
 * @memberof scene
 */
export type DestroyOptions = TypeOrBool<BaseDestroyOptions & ContextDestroyOptions & TextureDestroyOptions & TextDestroyOptions>;
`,Jd=`/**
 * Assigns properties from one object to another, using an optional array of property names to ignore.
 * @param target - The target object to assign properties to.
 * @param options - The object to assign properties from.
 * @param ignore - An object of property names to ignore ({ propToIgnore: true }).
 */
export declare function assignWithIgnore<T extends Record<string, any>>(target: T, options: T, ignore?: Record<string, boolean>): void;
`,$d=`import type { Container } from '../Container';
/**
 * This function will crawl through the container essentially check if the children have changed.
 *
 * This function checkChildrenDidChange recursively checks if any child in a Container
 * or its children has changed. It does this by comparing a generated changeId for each
 * child against a stored value in previousData.
 * The changeId is a combination of the child's uid and _didChangeId, bitwise manipulated for uniqueness.
 * If a change is detected, it updates previousData and sets didChange to true.
 * The function returns a boolean indicating if any change was detected in the entire hierarchy of children.
 * @param container - the container to check for changes
 * @param previousData - the previous data from the last check made
 * @param previousData.data - the data array
 * @param previousData.index - the index of the data array
 * @param previousData.didChange - did the data change
 */
export declare function checkChildrenDidChange(container: Container, previousData: {
    data: number[];
    index: number;
    didChange: boolean;
}): boolean;
`,Qd=`/**
 * nulls all slots in an array from a certain index.
 * assume that when a null item is hit, the rest are also null.
 * Which will be the case for where this is used!
 * @param list - the array to clean
 * @param index - the index to start from
 */
export declare function clearList(list: Array<unknown>, index?: number): void;
`,Zd=`import { type InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import { type Renderer, type RenderPipes } from '../../../rendering/renderers/types';
import { type Container } from '../Container';
/**
 * Deprecated, please use container.collectRenderables instead.
 * @param container - The container to collect renderables from.
 * @param instructionSet - The instruction set to add the renderables to.
 * @param rendererOrPipes - The renderer to collect the renderables from.
 * @deprecated since version 8.7.0
 * @see container.collectRenderables
 */
export declare function collectAllRenderables(container: Container, instructionSet: InstructionSet, rendererOrPipes: Renderer | RenderPipes): void;
`,ep=`/**
 * Returns a new object with all properties from the input object that have defined values.
 * @template T - The type of the input object.
 * @param {T} obj - The input object.
 * @returns {T} - A new object with only the defined properties from the input object.
 * @memberof utils
 * @ignore
 */
export declare function definedProps<T extends Record<string, any>>(obj: T): T;
`,np=`import type { RenderPipes } from '../../../rendering/renderers/types';
import type { RenderGroup } from '../RenderGroup';
export declare function executeInstructions(renderGroup: RenderGroup, renderer: RenderPipes): void;
`,tp=`export declare function mixHexColors(color1: number, color2: number, ratio: number): number;
`,rp=`export declare function multiplyColors(localBGRColor: number, parentBGRColor: number): number;
`,op=`export declare function multiplyHexColors(color1: number, color2: number): number;
`,ap=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Container } from '../Container';
export declare function updateLocalTransform(lt: Matrix, container: Container): void;
`,ip=`import { Container } from '../Container';
import type { RenderGroup } from '../RenderGroup';
export declare function updateRenderGroupTransforms(renderGroup: RenderGroup, updateChildRenderGroups?: boolean): void;
export declare function updateRenderGroupTransform(renderGroup: RenderGroup): void;
export declare function updateTransformAndChildren(container: Container, updateTick: number, updateFlags: number): void;
`,sp=`import type { Matrix } from '../../../maths/matrix/Matrix';
export declare function updateWorldTransform(local: Matrix, parent: Matrix, world: Matrix): void;
`,lp=`import type { RenderPipes } from '../../../rendering/renderers/types';
import type { RenderGroup } from '../RenderGroup';
export declare function validateRenderables(renderGroup: RenderGroup, renderPipes: RenderPipes): boolean;
`,dp=`declare global
{
    namespace PixiMixins
    {
        interface RendererSystems
        {
            graphicsContext: import('./shared/GraphicsContextSystem').GraphicsContextSystem;
        }

        interface RendererPipes
        {
            graphics: import('./shared/GraphicsPipe').GraphicsPipe;
        }

        interface RendererOptions
        {
        /**
         * A value from 0 to 1 that controls the smoothness of bezier curves (the higher the smoother)
         * @default 0.5
         */
            bezierSmoothness: number
        }
    }
}
export {};
`,pp=`import { ExtensionType } from '../../../extensions/Extensions';
import { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { Graphics } from '../shared/Graphics';
import type { GraphicsAdaptor, GraphicsPipe } from '../shared/GraphicsPipe';
/**
 * A GraphicsAdaptor that uses WebGL to render graphics.
 * @memberof rendering
 * @ignore
 */
export declare class GlGraphicsAdaptor implements GraphicsAdaptor {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipesAdaptor];
        readonly name: "graphics";
    };
    shader: Shader;
    init(): void;
    execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
    destroy(): void;
}
`,cp=`import { ExtensionType } from '../../../extensions/Extensions';
import { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { Graphics } from '../shared/Graphics';
import type { GraphicsAdaptor, GraphicsPipe } from '../shared/GraphicsPipe';
/**
 * A GraphicsAdaptor that uses the GPU to render graphics.
 * @memberof rendering
 * @ignore
 */
export declare class GpuGraphicsAdaptor implements GraphicsAdaptor {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUPipesAdaptor];
        readonly name: "graphics";
    };
    shader: Shader;
    init(): void;
    execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
    destroy(): void;
}
`,up=`export declare function colorToUniform(rgb: number, alpha: number, out: Float32Array, offset: number): void;
export declare function color32BitToUniform(abgr: number, out: Float32Array, offset: number): void;
`,mp=`export {};
`,hp=`import { Matrix } from '../../../maths/matrix/Matrix';
import type { Batch, Batcher } from '../../../rendering/batcher/shared/Batcher';
import type { DefaultBatchableMeshElement } from '../../../rendering/batcher/shared/DefaultBatcher';
import type { Topology } from '../../../rendering/renderers/shared/geometry/const';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { Graphics } from './Graphics';
/**
 * A batchable graphics object.
 * @ignore
 */
export declare class BatchableGraphics implements DefaultBatchableMeshElement {
    readonly packAsQuad = false;
    batcherName: string;
    texture: Texture;
    topology: Topology;
    renderable: Graphics;
    indexOffset: number;
    indexSize: number;
    attributeOffset: number;
    attributeSize: number;
    baseColor: number;
    alpha: number;
    applyTransform: boolean;
    roundPixels: 0 | 1;
    _indexStart: number;
    _textureId: number;
    _attributeStart: number;
    _batcher: Batcher;
    _batch: Batch;
    geometryData: {
        vertices: number[];
        uvs: number[];
        indices: number[];
    };
    get uvs(): number[];
    get positions(): number[];
    get indices(): number[];
    get blendMode(): import("../../..").BLEND_MODES;
    get color(): number;
    get transform(): Matrix;
    copyTo(gpuBuffer: BatchableGraphics): void;
    reset(): void;
}
`,fp=`import type { ColorSource } from '../../../color/Color';
import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { LineCap, LineJoin } from './const';
import type { FillGradient } from './fill/FillGradient';
import type { FillPattern } from './fill/FillPattern';
/**
 * Determines how texture coordinates are calculated
 * Local Space:              Global Space:
 * ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐
 * │ A   B   │  │ A   B   │  │ A...B   │  │ ...B... │
 * │         │  │         │  │         │  │         │
 * │ C   D   │  │ C   D   │  │ C...D   │  │ ...D... │
 * └─────────┘  └─────────┘  └─────────┘  └─────────┘
 * (Each shape   (Each shape  (Texture continues across
 * gets full     gets full    shapes as if they're texture)      texture)     windows to same texture)
 * @memberof scene
 */
export type TextureSpace = 
/**
 * 'local' - Texture coordinates are relative to the shape's bounds.
 * The texture will stretch/fit to each individual shape's boundaries.
 * Think of it like the shape having its own coordinate system.
 */
'local'
/**
 * 'global' - Texture coordinates are in world space.
 * The texture position is consistent across all shapes,
 * as if the texture was laid down first and shapes were cut out of it.
 * Think of it like wallpaper that shows through shaped holes.
 */
 | 'global';
/**
 * A fill style object.
 * @memberof scene
 */
export interface FillStyle {
    /** The color to use for the fill. */
    color?: ColorSource;
    /** The alpha value to use for the fill. */
    alpha?: number;
    /** The texture to use for the fill. */
    texture?: Texture | null;
    /** The matrix to apply. */
    matrix?: Matrix | null;
    /** The fill pattern to use. */
    fill?: FillPattern | FillGradient | null;
    /** The fill units to use. */
    textureSpace?: TextureSpace;
}
/**
 * A stroke attribute object, used to define properties for a stroke.
 * @memberof scene
 */
export interface StrokeAttributes {
    /** The width of the stroke. */
    width?: number;
    /** The alignment of the stroke. */
    alignment?: number;
    /** The line cap style to use. */
    cap?: LineCap;
    /** The line join style to use. */
    join?: LineJoin;
    /** The miter limit to use. */
    miterLimit?: number;
    /** If the stroke is a pixel line. NOTE: this is only available for Graphic fills */
    pixelLine?: boolean;
}
/**
 * A stroke style object.
 * @memberof scene
 */
export interface StrokeStyle extends FillStyle, StrokeAttributes {
}
/**
 * These can be directly used as a fill or a stroke
 * \`\`\`ts
 * graphics.fill(0xff0000);
 * graphics.fill(new FillPattern(texture));
 * graphics.fill(new FillGradient(0, 0, 200, 0));
 * graphics.fill({
 *   color: 0xff0000,
 *   alpha: 0.5,
 *   texture?: null,
 *   matrix?: null,
 * });
 * graphics.fill({
 *   fill: new FillPattern(texture),
 * });
 * graphics.fill({
 *   fill: new FillGradient(0, 0, 200, 0),
 * });
 * \`\`\`
 * @memberof scene
 */
export type FillInput = ColorSource | FillGradient | FillPattern | FillStyle | Texture;
/**
 * These can be directly used as a stroke
 * \`\`\`ts
 * graphics.stroke(0xff0000);
 * graphics.stroke(new FillPattern(texture));
 * graphics.stroke(new FillGradient(0, 0, 200, 0));
 * graphics.stroke({
 *   color: 0xff0000,
 *   width?: 1,
 *   alignment?: 0.5,
 * });
 * graphics.stroke({
 *   fill: new FillPattern(texture),
 *   width: 1,
 *   alignment: 0.5,
 * });
 * graphics.stroke({
 *   fill: new FillGradient(0, 0, 200, 0),
 *   width: 1,
 *   alignment: 0.5,
 * });
 * \`\`\`
 * @memberof scene
 */
export type StrokeInput = ColorSource | FillGradient | FillPattern | StrokeStyle;
export type ConvertedFillStyle = Omit<Required<FillStyle>, 'color'> & {
    color: number;
};
export type ConvertedStrokeStyle = ConvertedFillStyle & Required<StrokeAttributes>;
/**
 * @deprecated since v8.1.6
 * @see scene.FillInput
 */
export type FillStyleInputs = ColorSource | FillGradient | FillPattern | FillStyle | ConvertedFillStyle | StrokeStyle | ConvertedStrokeStyle;
`,bp=`import { ViewContainer, type ViewContainerOptions } from '../../view/ViewContainer';
import { GraphicsContext } from './GraphicsContext';
import type { ColorSource } from '../../../color/Color';
import type { Matrix } from '../../../maths/matrix/Matrix';
import type { PointData } from '../../../maths/point/PointData';
import type { Instruction } from '../../../rendering/renderers/shared/instructions/Instruction';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { Bounds } from '../../container/bounds/Bounds';
import type { DestroyOptions } from '../../container/destroyTypes';
import type { FillInput, StrokeStyle } from './FillTypes';
import type { GraphicsPath } from './path/GraphicsPath';
import type { RoundedPoint } from './path/roundShape';
/**
 * Constructor options used for \`Graphics\` instances.
 * \`\`\`js
 * const graphics = new Graphics({
 *    fillStyle: { color: 0xff0000, alpha: 0.5 },
 *    strokeStyle: { color: 0x00ff00, width: 2 },
 * });
 * \`\`\`
 * @see {@link scene.Graphics}
 * @memberof scene
 */
export interface GraphicsOptions extends PixiMixins.GraphicsOptions, ViewContainerOptions {
    /** The GraphicsContext to use, useful for reuse and optimisation */
    context?: GraphicsContext;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
}
export interface Graphics extends PixiMixins.Graphics, ViewContainer {
}
/**
 * The Graphics class is primarily used to render primitive shapes such as lines, circles and
 * rectangles to the display, and to color and fill them.  However, you can also use a Graphics
 * object to build a list of primitives to use as a mask, or as a complex hitArea.
 * @memberof scene
 * @extends scene.Container
 */
export declare class Graphics extends ViewContainer implements Instruction {
    readonly renderPipeId: string;
    batched: boolean;
    private _context;
    private readonly _ownedContext;
    /**
     * @param options - Options for the Graphics.
     */
    constructor(options?: GraphicsOptions | GraphicsContext);
    set context(context: GraphicsContext);
    get context(): GraphicsContext;
    /**
     * The local bounds of the graphic.
     * @type {rendering.Bounds}
     */
    get bounds(): Bounds;
    /**
     * Graphics objects do not need to update their bounds as the context handles this.
     * @private
     */
    protected updateBounds(): void;
    /**
     * Checks if the object contains the given point.
     * @param point - The point to check
     */
    containsPoint(point: PointData): boolean;
    /**
     * Destroys this graphics renderable and optionally its context.
     * @param options - Options parameter. A boolean will act as if all options
     *
     * If the context was created by this graphics and \`destroy(false)\` or \`destroy()\` is called
     * then the context will still be destroyed.
     *
     * If you want to explicitly not destroy this context that this graphics created,
     * then you should pass destroy({ context: false })
     *
     * If the context was passed in as an argument to the constructor then it will not be destroyed
     * @param {boolean} [options.texture=false] - Should destroy the texture of the graphics context
     * @param {boolean} [options.textureSource=false] - Should destroy the texture source of the graphics context
     * @param {boolean} [options.context=false] - Should destroy the context
     */
    destroy(options?: DestroyOptions): void;
    private _callContextMethod;
    /**
     * Sets the current fill style of the graphics context. The fill style can be a color, gradient,
     * pattern, or a more complex style defined by a FillStyle object.
     * @param {FillInput} args - The fill style to apply. This can be a simple color, a gradient or
     * pattern object, or a FillStyle or ConvertedFillStyle object.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setFillStyle(...args: Parameters<GraphicsContext['setFillStyle']>): this;
    /**
     * Sets the current stroke style of the graphics context. Similar to fill styles, stroke styles can
     * encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
     * @param {StrokeInput} args - The stroke style to apply. Can be defined as a color, a gradient or pattern,
     * or a StrokeStyle or ConvertedStrokeStyle object.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setStrokeStyle(...args: Parameters<GraphicsContext['setStrokeStyle']>): this;
    /**
     * Fills the current or given path with the current fill style. This method can optionally take
     * a color and alpha for a simple fill, or a more complex FillStyle object for advanced fills.
     * @param {FillInput} style - (Optional) The style to fill the path with. Can be a color, gradient, pattern, or a
     * complex style object. If omitted, uses the current fill style.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    fill(style?: FillInput): this;
    /** @deprecated 8.0.0 */
    fill(color: ColorSource, alpha?: number): this;
    /**
     * Strokes the current path with the current stroke style. This method can take an optional
     * FillStyle parameter to define the stroke's appearance, including its color, width, and other properties.
     * @param {FillStyle} args - (Optional) The stroke style to apply. Can be defined as a simple color or a more
     * complex style object. If omitted, uses the current stroke style.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    stroke(...args: Parameters<GraphicsContext['stroke']>): this;
    /**
     * Adds a texture to the graphics context. This method supports multiple overloads for specifying the texture,
     * tint, and dimensions. If only a texture is provided, it uses the texture's width and height for drawing.
     * Additional parameters allow for specifying a tint color, and custom dimensions for the texture drawing area.
     * @param texture - The Texture object to use.
     * @param tint - (Optional) A ColorSource to tint the texture. If not provided, defaults to white (0xFFFFFF).
     * @param dx - (Optional) The x-coordinate in the destination canvas at which to place the top-left corner of
     * the source image.
     * @param dy - (Optional) The y-coordinate in the destination canvas at which to place the top-left corner of
     * the source image.
     * @param dw - (Optional) The width of the rectangle within the source image to draw onto the destination canvas.
     * If not provided, uses the texture's frame width.
     * @param dh - (Optional) The height of the rectangle within the source image to draw onto the destination canvas.
     * If not provided, uses the texture's frame height.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    texture(texture: Texture, tint?: ColorSource, dx?: number, dy?: number, dw?: number, dh?: number): this;
    texture(texture: Texture): this;
    /**
     * Resets the current path. Any previous path and its commands are discarded and a new path is
     * started. This is typically called before beginning a new shape or series of drawing commands.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    beginPath(): this;
    /**
     * Applies a cutout to the last drawn shape. This is used to create holes or complex shapes by
     * subtracting a path from the previously drawn path. If a hole is not completely in a shape, it will
     * fail to cut correctly!
     */
    cut(): this;
    /**
     * Adds an arc to the current path, which is centered at (x, y) with the specified radius,
     * starting and ending angles, and direction.
     * @param x - The x-coordinate of the arc's center.
     * @param y - The y-coordinate of the arc's center.
     * @param radius - The arc's radius.
     * @param startAngle - The starting angle, in radians.
     * @param endAngle - The ending angle, in radians.
     * @param counterclockwise - (Optional) Specifies whether the arc is drawn counterclockwise (true) or clockwise
     * (false). Defaults to false.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
    /**
     * Adds an arc to the current path with the given control points and radius, connected to the previous point
     * by a straight line if necessary.
     * @param x1 - The x-coordinate of the first control point.
     * @param y1 - The y-coordinate of the first control point.
     * @param x2 - The x-coordinate of the second control point.
     * @param y2 - The y-coordinate of the second control point.
     * @param radius - The arc's radius.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
    /**
     * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
     * @param rx - The x-radius of the ellipse.
     * @param ry - The y-radius of the ellipse.
     * @param xAxisRotation - The rotation of the ellipse's x-axis relative
     * to the x-axis of the coordinate system, in degrees.
     * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
     * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
     * @param x - The x-coordinate of the arc's end point.
     * @param y - The y-coordinate of the arc's end point.
     * @returns The instance of the current object for chaining.
     */
    arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
    /**
     * Adds a cubic Bezier curve to the path.
     * It requires three points: the first two are control points and the third one is the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the first control point.
     * @param cp1y - The y-coordinate of the first control point.
     * @param cp2x - The x-coordinate of the second control point.
     * @param cp2y - The y-coordinate of the second control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
    /**
     * Closes the current path by drawing a straight line back to the start.
     * If the shape is already closed or there are no points in the path, this method does nothing.
     * @returns The instance of the current object for chaining.
     */
    closePath(): this;
    /**
     * Draws an ellipse at the specified location and with the given x and y radii.
     * An optional transformation can be applied, allowing for rotation, scaling, and translation.
     * @param x - The x-coordinate of the center of the ellipse.
     * @param y - The y-coordinate of the center of the ellipse.
     * @param radiusX - The horizontal radius of the ellipse.
     * @param radiusY - The vertical radius of the ellipse.
     * @returns The instance of the current object for chaining.
     */
    ellipse(x: number, y: number, radiusX: number, radiusY: number): this;
    /**
     * Draws a circle shape. This method adds a new circle path to the current drawing.
     * @param x - The x-coordinate of the center of the circle.
     * @param y - The y-coordinate of the center of the circle.
     * @param radius - The radius of the circle.
     * @returns The instance of the current object for chaining.
     */
    circle(x: number, y: number, radius: number): this;
    /**
     * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
     * @param path - The \`GraphicsPath\` to add.
     * @returns The instance of the current object for chaining.
     */
    path(path: GraphicsPath): this;
    /**
     * Connects the current point to a new point with a straight line. This method updates the current path.
     * @param x - The x-coordinate of the new point to connect to.
     * @param y - The y-coordinate of the new point to connect to.
     * @returns The instance of the current object for chaining.
     */
    lineTo(x: number, y: number): this;
    /**
     * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
     * @param x - The x-coordinate for the starting point.
     * @param y - The y-coordinate for the starting point.
     * @returns The instance of the current object for chaining.
     */
    moveTo(x: number, y: number): this;
    /**
     * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
     * The starting point is the last point in the current path.
     * @param cpx - The x-coordinate of the control point.
     * @param cpy - The y-coordinate of the control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
    /**
     * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @returns The instance of the current object for chaining.
     */
    rect(x: number, y: number, w: number, h: number): this;
    /**
     * Draws a rectangle with rounded corners.
     * The corner radius can be specified to determine how rounded the corners should be.
     * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
     * @returns The instance of the current object for chaining.
     */
    roundRect(x: number, y: number, w: number, h: number, radius?: number): this;
    /**
     * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
     * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
     * rotated, or translated as needed.
     * @param points - An array of numbers, or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
     * representing the x and y coordinates, of the polygon's vertices, in sequence.
     * @param close - A boolean indicating whether to close the polygon path. True by default.
     * @returns The instance of the current object for chaining further drawing commands.
     */
    poly(points: number[] | PointData[], close?: boolean): this;
    /**
     * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining.
     */
    regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
    /**
     * Draws a polygon with rounded corners.
     * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param corner - The radius of the rounding of the corners.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @returns The instance of the current object for chaining.
     */
    roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
    /**
     * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
     * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
     * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
     * A minimum of 3 points is required.
     * @param radius - The default radius for the corners.
     * This radius is applied to all corners unless overridden in \`points\`.
     * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
     *  method instead of an arc method. Defaults to false.
     * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
     * Higher values make the curve smoother.
     * @returns The instance of the current object for chaining.
     */
    roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
    /**
     * Draw Rectangle with fillet corners. This is much like rounded rectangle
     * however it support negative numbers as well for the corner radius.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param fillet - accept negative or positive values
     */
    filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
    /**
     * Draw Rectangle with chamfer corners. These are angled corners.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param chamfer - non-zero real number, size of corner cutout
     * @param transform
     */
    chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
    /**
     * Draws a star shape centered at a specified location. This method allows for the creation
     *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
     * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
     * An optional transformation can be applied to scale, rotate, or translate the star as needed.
     * @param x - The x-coordinate of the center of the star.
     * @param y - The y-coordinate of the center of the star.
     * @param points - The number of points of the star.
     * @param radius - The outer radius of the star (distance from the center to the outer points).
     * @param innerRadius - Optional. The inner radius of the star
     * (distance from the center to the inner points between the outer points).
     * If not provided, defaults to half of the \`radius\`.
     * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
     * Defaults to 0, meaning one point is directly upward.
     * @returns The instance of the current object for chaining further drawing commands.
     */
    star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number): this;
    /**
     * Parses and renders an SVG string into the graphics context. This allows for complex shapes and paths
     * defined in SVG format to be drawn within the graphics context.
     * @param svg - The SVG string to be parsed and rendered.
     */
    svg(svg: string): this;
    /**
     * Restores the most recently saved graphics state by popping the top of the graphics state stack.
     * This includes transformations, fill styles, and stroke styles.
     */
    restore(): this;
    /** Saves the current graphics state, including transformations, fill styles, and stroke styles, onto a stack. */
    save(): this;
    /**
     * Returns the current transformation matrix of the graphics context.
     * @returns The current transformation matrix.
     */
    getTransform(): Matrix;
    /**
     * Resets the current transformation matrix to the identity matrix, effectively removing
     * any transformations (rotation, scaling, translation) previously applied.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    resetTransform(): this;
    /**
     * Applies a rotation transformation to the graphics context around the current origin.
     * @param angle - The angle of rotation in radians.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    rotateTransform(angle: number): this;
    /**
     * Applies a scaling transformation to the graphics context, scaling drawings by x horizontally and by y vertically.
     * @param x - The scale factor in the horizontal direction.
     * @param y - (Optional) The scale factor in the vertical direction.
     * If not specified, the x value is used for both directions.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    scaleTransform(x: number, y?: number): this;
    /**
     * Sets the current transformation matrix of the graphics context to the specified matrix or values.
     * This replaces the current transformation matrix.
     * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
     * @param b - The value for the b property of the matrix.
     * @param c - The value for the c property of the matrix.
     * @param d - The value for the d property of the matrix.
     * @param dx - The value for the tx (translate x) property of the matrix.
     * @param dy - The value for the ty (translate y) property of the matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setTransform(transform: Matrix): this;
    setTransform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
    setTransform(a: number | Matrix, b?: number, c?: number, d?: number, dx?: number, dy?: number): this;
    /**
     * Applies the specified transformation matrix to the current graphics context by multiplying
     * the current matrix with the specified matrix.
     * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
     * @param b - The value for the b property of the matrix.
     * @param c - The value for the c property of the matrix.
     * @param d - The value for the d property of the matrix.
     * @param dx - The value for the tx (translate x) property of the matrix.
     * @param dy - The value for the ty (translate y) property of the matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    transform(transform: Matrix): this;
    transform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
    transform(a: number | Matrix, b?: number, c?: number, d?: number, dx?: number, dy?: number): this;
    /**
     * Applies a translation transformation to the graphics context, moving the origin by the specified amounts.
     * @param x - The amount to translate in the horizontal direction.
     * @param y - (Optional) The amount to translate in the vertical direction. If not specified,
     * the x value is used for both directions.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    translateTransform(x: number, y?: number): this;
    /**
     * Clears all drawing commands from the graphics context, effectively resetting it. This includes clearing the path,
     * and optionally resetting transformations to the identity matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    clear(): this;
    /**
     * The fill style to use.
     * @type {ConvertedFillStyle}
     */
    get fillStyle(): GraphicsContext['fillStyle'];
    set fillStyle(value: FillInput);
    /**
     * The stroke style to use.
     * @type {ConvertedStrokeStyle}
     */
    get strokeStyle(): GraphicsContext['strokeStyle'];
    set strokeStyle(value: StrokeStyle);
    /**
     * Creates a new Graphics object.
     * Note that only the context of the object is cloned, not its transform (position,scale,etc)
     * @param deep - Whether to create a deep clone of the graphics object. If false, the context
     * will be shared between the two objects (default false). If true, the context will be
     * cloned (recommended if you need to modify the context in any way).
     * @returns - A clone of the graphics object
     */
    clone(deep?: boolean): Graphics;
    /**
     * @param width
     * @param color
     * @param alpha
     * @deprecated since 8.0.0 Use {@link Graphics#setStrokeStyle} instead
     */
    lineStyle(width?: number, color?: ColorSource, alpha?: number): this;
    /**
     * @param color
     * @param alpha
     * @deprecated since 8.0.0 Use {@link Graphics#fill} instead
     */
    beginFill(color: ColorSource, alpha?: number): this;
    /**
     * @deprecated since 8.0.0 Use {@link Graphics#fill} instead
     */
    endFill(): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#circle} instead
     */
    drawCircle(...args: Parameters<GraphicsContext['circle']>): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#ellipse} instead
     */
    drawEllipse(...args: Parameters<GraphicsContext['ellipse']>): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#poly} instead
     */
    drawPolygon(...args: Parameters<GraphicsContext['poly']>): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#rect} instead
     */
    drawRect(...args: Parameters<GraphicsContext['rect']>): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#roundRect} instead
     */
    drawRoundedRect(...args: Parameters<GraphicsContext['roundRect']>): this;
    /**
     * @param {...any} args
     * @deprecated since 8.0.0 Use {@link Graphics#star} instead
     */
    drawStar(...args: Parameters<GraphicsContext['star']>): this;
}
`,gp=`import EventEmitter from 'eventemitter3';
import { type ColorSource } from '../../../color/Color';
import { Matrix } from '../../../maths/matrix/Matrix';
import { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import { Bounds } from '../../container/bounds/Bounds';
import { GraphicsPath } from './path/GraphicsPath';
import type { PointData } from '../../../maths/point/PointData';
import type { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { TextureDestroyOptions, TypeOrBool } from '../../container/destroyTypes';
import type { ConvertedFillStyle, ConvertedStrokeStyle, FillInput, StrokeInput } from './FillTypes';
import type { RoundedPoint } from './path/roundShape';
export type BatchMode = 'auto' | 'batch' | 'no-batch';
export interface FillInstruction {
    action: 'fill' | 'cut';
    data: {
        style: ConvertedFillStyle;
        path: GraphicsPath;
        hole?: GraphicsPath;
    };
}
export interface StrokeInstruction {
    action: 'stroke';
    data: {
        style: ConvertedStrokeStyle;
        path: GraphicsPath;
        hole?: GraphicsPath;
    };
}
export interface TextureInstruction {
    action: 'texture';
    data: {
        image: Texture;
        dx: number;
        dy: number;
        dw: number;
        dh: number;
        transform: Matrix;
        alpha: number;
        style: number;
    };
}
export type GraphicsInstructions = FillInstruction | StrokeInstruction | TextureInstruction;
/**
 * The GraphicsContext class allows for the creation of lightweight objects that contain instructions for drawing shapes and paths.
 * It is used internally by the Graphics class to draw shapes and paths, and can be used directly and shared between Graphics objects,
 *
 * This sharing of a \`GraphicsContext\` means that the intensive task of converting graphics instructions into GPU-ready geometry is done once, and the results are reused,
 * much like sprites reusing textures.
 * @memberof scene
 */
export declare class GraphicsContext extends EventEmitter<{
    update: GraphicsContext;
    destroy: GraphicsContext;
}> {
    /** The default fill style to use when none is provided. */
    static defaultFillStyle: ConvertedFillStyle;
    /** The default stroke style to use when none is provided. */
    static defaultStrokeStyle: ConvertedStrokeStyle;
    /** unique id for this graphics context */
    readonly uid: number;
    dirty: boolean;
    batchMode: BatchMode;
    instructions: GraphicsInstructions[];
    customShader?: Shader;
    private _activePath;
    private _transform;
    private _fillStyle;
    private _strokeStyle;
    private _stateStack;
    private _tick;
    private _bounds;
    private _boundsDirty;
    /**
     * Creates a new GraphicsContext object that is a clone of this instance, copying all properties,
     * including the current drawing state, transformations, styles, and instructions.
     * @returns A new GraphicsContext instance with the same properties and state as this one.
     */
    clone(): GraphicsContext;
    /**
     * The current fill style of the graphics context. This can be a color, gradient, pattern, or a more complex style defined by a FillStyle object.
     */
    get fillStyle(): ConvertedFillStyle;
    set fillStyle(value: FillInput);
    /**
     * The current stroke style of the graphics context. Similar to fill styles, stroke styles can encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
     */
    get strokeStyle(): ConvertedStrokeStyle;
    set strokeStyle(value: FillInput);
    /**
     * Sets the current fill style of the graphics context. The fill style can be a color, gradient,
     * pattern, or a more complex style defined by a FillStyle object.
     * @param style - The fill style to apply. This can be a simple color, a gradient or pattern object,
     *                or a FillStyle or ConvertedFillStyle object.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setFillStyle(style: FillInput): this;
    /**
     * Sets the current stroke style of the graphics context. Similar to fill styles, stroke styles can
     * encompass colors, gradients, patterns, or more detailed configurations via a StrokeStyle object.
     * @param style - The stroke style to apply. Can be defined as a color, a gradient or pattern,
     *                or a StrokeStyle or ConvertedStrokeStyle object.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setStrokeStyle(style: StrokeInput): this;
    /**
     * Adds a texture to the graphics context. This method supports multiple overloads for specifying the texture, tint, and dimensions.
     * If only a texture is provided, it uses the texture's width and height for drawing. Additional parameters allow for specifying
     * a tint color, and custom dimensions for the texture drawing area.
     * @param texture - The Texture object to use.
     * @param tint - (Optional) A ColorSource to tint the texture. If not provided, defaults to white (0xFFFFFF).
     * @param dx - (Optional) The x-coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dy - (Optional) The y-coordinate in the destination canvas at which to place the top-left corner of the source image.
     * @param dw - (Optional) The width of the rectangle within the source image to draw onto the destination canvas. If not provided, uses the texture's frame width.
     * @param dh - (Optional) The height of the rectangle within the source image to draw onto the destination canvas. If not provided, uses the texture's frame height.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    texture(texture: Texture): this;
    texture(texture: Texture, tint: ColorSource): this;
    texture(texture: Texture, tint: ColorSource, dx: number, dy: number): this;
    texture(texture: Texture, tint: ColorSource, dx: number, dy: number, dw: number, dh: number): this;
    /**
     * Resets the current path. Any previous path and its commands are discarded and a new path is
     * started. This is typically called before beginning a new shape or series of drawing commands.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    beginPath(): this;
    /**
     * Fills the current or given path with the current fill style. This method can optionally take
     * a color and alpha for a simple fill, or a more complex FillInput object for advanced fills.
     * @param style - (Optional) The style to fill the path with. Can be a color, gradient, pattern, or a complex style object. If omitted, uses the current fill style.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    fill(style?: FillInput): this;
    /** @deprecated 8.0.0 */
    fill(color: ColorSource, alpha: number): this;
    private _initNextPathLocation;
    /**
     * Strokes the current path with the current stroke style. This method can take an optional
     * FillInput parameter to define the stroke's appearance, including its color, width, and other properties.
     * @param style - (Optional) The stroke style to apply. Can be defined as a simple color or a more complex style object. If omitted, uses the current stroke style.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    stroke(style?: StrokeInput): this;
    /**
     * Applies a cutout to the last drawn shape. This is used to create holes or complex shapes by
     * subtracting a path from the previously drawn path. If a hole is not completely in a shape, it will
     * fail to cut correctly!
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    cut(): this;
    /**
     * Adds an arc to the current path, which is centered at (x, y) with the specified radius,
     * starting and ending angles, and direction.
     * @param x - The x-coordinate of the arc's center.
     * @param y - The y-coordinate of the arc's center.
     * @param radius - The arc's radius.
     * @param startAngle - The starting angle, in radians.
     * @param endAngle - The ending angle, in radians.
     * @param counterclockwise - (Optional) Specifies whether the arc is drawn counterclockwise (true) or clockwise (false). Defaults to false.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
    /**
     * Adds an arc to the current path with the given control points and radius, connected to the previous point
     * by a straight line if necessary.
     * @param x1 - The x-coordinate of the first control point.
     * @param y1 - The y-coordinate of the first control point.
     * @param x2 - The x-coordinate of the second control point.
     * @param y2 - The y-coordinate of the second control point.
     * @param radius - The arc's radius.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
    /**
     * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
     * @param rx - The x-radius of the ellipse.
     * @param ry - The y-radius of the ellipse.
     * @param xAxisRotation - The rotation of the ellipse's x-axis relative
     * to the x-axis of the coordinate system, in degrees.
     * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
     * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
     * @param x - The x-coordinate of the arc's end point.
     * @param y - The y-coordinate of the arc's end point.
     * @returns The instance of the current object for chaining.
     */
    arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
    /**
     * Adds a cubic Bezier curve to the path.
     * It requires three points: the first two are control points and the third one is the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the first control point.
     * @param cp1y - The y-coordinate of the first control point.
     * @param cp2x - The x-coordinate of the second control point.
     * @param cp2y - The y-coordinate of the second control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
    /**
     * Closes the current path by drawing a straight line back to the start.
     * If the shape is already closed or there are no points in the path, this method does nothing.
     * @returns The instance of the current object for chaining.
     */
    closePath(): this;
    /**
     * Draws an ellipse at the specified location and with the given x and y radii.
     * An optional transformation can be applied, allowing for rotation, scaling, and translation.
     * @param x - The x-coordinate of the center of the ellipse.
     * @param y - The y-coordinate of the center of the ellipse.
     * @param radiusX - The horizontal radius of the ellipse.
     * @param radiusY - The vertical radius of the ellipse.
     * @returns The instance of the current object for chaining.
     */
    ellipse(x: number, y: number, radiusX: number, radiusY: number): this;
    /**
     * Draws a circle shape. This method adds a new circle path to the current drawing.
     * @param x - The x-coordinate of the center of the circle.
     * @param y - The y-coordinate of the center of the circle.
     * @param radius - The radius of the circle.
     * @returns The instance of the current object for chaining.
     */
    circle(x: number, y: number, radius: number): this;
    /**
     * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
     * @param path - The \`GraphicsPath\` to add.
     * @returns The instance of the current object for chaining.
     */
    path(path: GraphicsPath): this;
    /**
     * Connects the current point to a new point with a straight line. This method updates the current path.
     * @param x - The x-coordinate of the new point to connect to.
     * @param y - The y-coordinate of the new point to connect to.
     * @returns The instance of the current object for chaining.
     */
    lineTo(x: number, y: number): this;
    /**
     * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
     * @param x - The x-coordinate for the starting point.
     * @param y - The y-coordinate for the starting point.
     * @returns The instance of the current object for chaining.
     */
    moveTo(x: number, y: number): this;
    /**
     * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
     * The starting point is the last point in the current path.
     * @param cpx - The x-coordinate of the control point.
     * @param cpy - The y-coordinate of the control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
    /**
     * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @returns The instance of the current object for chaining.
     */
    rect(x: number, y: number, w: number, h: number): this;
    /**
     * Draws a rectangle with rounded corners.
     * The corner radius can be specified to determine how rounded the corners should be.
     * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
     * @returns The instance of the current object for chaining.
     */
    roundRect(x: number, y: number, w: number, h: number, radius?: number): this;
    /**
     * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
     * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
     * rotated, or translated as needed.
     * @param points - An array of numbers, or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
     * representing the x and y coordinates, of the polygon's vertices, in sequence.
     * @param close - A boolean indicating whether to close the polygon path. True by default.
     */
    poly(points: number[] | PointData[], close?: boolean): this;
    /**
     * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining.
     */
    regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
    /**
     * Draws a polygon with rounded corners.
     * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param corner - The radius of the rounding of the corners.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @returns The instance of the current object for chaining.
     */
    roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
    /**
     * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
     * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
     * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
     * A minimum of 3 points is required.
     * @param radius - The default radius for the corners.
     * This radius is applied to all corners unless overridden in \`points\`.
     * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
     *  method instead of an arc method. Defaults to false.
     * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
     * Higher values make the curve smoother.
     * @returns The instance of the current object for chaining.
     */
    roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
    /**
     * Draw Rectangle with fillet corners. This is much like rounded rectangle
     * however it support negative numbers as well for the corner radius.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param fillet - accept negative or positive values
     */
    filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
    /**
     * Draw Rectangle with chamfer corners. These are angled corners.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param chamfer - non-zero real number, size of corner cutout
     * @param transform
     */
    chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
    /**
     * Draws a star shape centered at a specified location. This method allows for the creation
     *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
     * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
     * An optional transformation can be applied to scale, rotate, or translate the star as needed.
     * @param x - The x-coordinate of the center of the star.
     * @param y - The y-coordinate of the center of the star.
     * @param points - The number of points of the star.
     * @param radius - The outer radius of the star (distance from the center to the outer points).
     * @param innerRadius - Optional. The inner radius of the star
     * (distance from the center to the inner points between the outer points).
     * If not provided, defaults to half of the \`radius\`.
     * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
     * Defaults to 0, meaning one point is directly upward.
     * @returns The instance of the current object for chaining further drawing commands.
     */
    star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number): this;
    /**
     * Parses and renders an SVG string into the graphics context. This allows for complex shapes and paths
     * defined in SVG format to be drawn within the graphics context.
     * @param svg - The SVG string to be parsed and rendered.
     */
    svg(svg: string): this;
    /**
     * Restores the most recently saved graphics state by popping the top of the graphics state stack.
     * This includes transformations, fill styles, and stroke styles.
     */
    restore(): this;
    /** Saves the current graphics state, including transformations, fill styles, and stroke styles, onto a stack. */
    save(): this;
    /**
     * Returns the current transformation matrix of the graphics context.
     * @returns The current transformation matrix.
     */
    getTransform(): Matrix;
    /**
     * Resets the current transformation matrix to the identity matrix, effectively removing any transformations (rotation, scaling, translation) previously applied.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    resetTransform(): this;
    /**
     * Applies a rotation transformation to the graphics context around the current origin.
     * @param angle - The angle of rotation in radians.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    rotate(angle: number): this;
    /**
     * Applies a scaling transformation to the graphics context, scaling drawings by x horizontally and by y vertically.
     * @param x - The scale factor in the horizontal direction.
     * @param y - (Optional) The scale factor in the vertical direction. If not specified, the x value is used for both directions.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    scale(x: number, y?: number): this;
    /**
     * Sets the current transformation matrix of the graphics context to the specified matrix or values.
     * This replaces the current transformation matrix.
     * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
     * @param b - The value for the b property of the matrix.
     * @param c - The value for the c property of the matrix.
     * @param d - The value for the d property of the matrix.
     * @param dx - The value for the tx (translate x) property of the matrix.
     * @param dy - The value for the ty (translate y) property of the matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    setTransform(transform: Matrix): this;
    setTransform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
    /**
     * Applies the specified transformation matrix to the current graphics context by multiplying the current matrix with the specified matrix.
     * @param a - The value for the a property of the matrix, or a Matrix object to use directly.
     * @param b - The value for the b property of the matrix.
     * @param c - The value for the c property of the matrix.
     * @param d - The value for the d property of the matrix.
     * @param dx - The value for the tx (translate x) property of the matrix.
     * @param dy - The value for the ty (translate y) property of the matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    transform(transform: Matrix): this;
    transform(a: number, b: number, c: number, d: number, dx: number, dy: number): this;
    /**
     * Applies a translation transformation to the graphics context, moving the origin by the specified amounts.
     * @param x - The amount to translate in the horizontal direction.
     * @param y - (Optional) The amount to translate in the vertical direction. If not specified, the x value is used for both directions.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    translate(x: number, y?: number): this;
    /**
     * Clears all drawing commands from the graphics context, effectively resetting it. This includes clearing the path,
     * and optionally resetting transformations to the identity matrix.
     * @returns The instance of the current GraphicsContext for method chaining.
     */
    clear(): this;
    protected onUpdate(): void;
    /** The bounds of the graphic shape. */
    get bounds(): Bounds;
    /**
     * Check to see if a point is contained within this geometry.
     * @param point - Point to check if it's contained.
     * @returns {boolean} \`true\` if the point is contained within geometry.
     */
    containsPoint(point: PointData): boolean;
    /**
     * Destroys the GraphicsData object.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the fill/stroke style?
     * @param {boolean} [options.textureSource=false] - Should it destroy the texture source of the fill/stroke style?
     */
    destroy(options?: TypeOrBool<TextureDestroyOptions>): void;
}
`,yp=`import { ExtensionType } from '../../../extensions/Extensions';
import { InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import type { Batcher } from '../../../rendering/batcher/shared/Batcher';
import type { System } from '../../../rendering/renderers/shared/system/System';
import type { Renderer } from '../../../rendering/renderers/types';
import type { BatchableGraphics } from './BatchableGraphics';
import type { GraphicsContext } from './GraphicsContext';
interface GeometryData {
    vertices: number[];
    uvs: number[];
    indices: number[];
}
/**
 * A class that holds batchable graphics data for a GraphicsContext.
 * @memberof rendering
 * @ignore
 */
export declare class GpuGraphicsContext {
    isBatchable: boolean;
    context: GraphicsContext;
    batches: BatchableGraphics[];
    geometryData: GeometryData;
    graphicsData: GraphicsContextRenderData;
}
/**
 * A class that holds the render data for a GraphicsContext.
 * @memberof rendering
 * @ignore
 */
export declare class GraphicsContextRenderData {
    batcher: Batcher;
    instructions: InstructionSet;
    init(): void;
    /**
     * @deprecated since version 8.0.0
     * Use \`batcher.geometry\` instead.
     * @see {Batcher#geometry}
     */
    get geometry(): import("../../..").Geometry;
}
/**
 * Options for the GraphicsContextSystem.
 * @memberof rendering
 */
export interface GraphicsContextSystemOptions {
    /** A value from 0 to 1 that controls the smoothness of bezier curves (the higher the smoother) */
    bezierSmoothness?: number;
}
/**
 * A system that manages the rendering of GraphicsContexts.
 * @memberof rendering
 */
export declare class GraphicsContextSystem implements System<GraphicsContextSystemOptions> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "graphicsContext";
    };
    /** The default options for the GraphicsContextSystem. */
    static readonly defaultOptions: GraphicsContextSystemOptions;
    private _gpuContextHash;
    private _graphicsDataContextHash;
    constructor(renderer: Renderer);
    /**
     * Runner init called, update the default options
     * @ignore
     */
    init(options?: GraphicsContextSystemOptions): void;
    getContextRenderData(context: GraphicsContext): GraphicsContextRenderData;
    updateGpuContext(context: GraphicsContext): GpuGraphicsContext;
    getGpuContext(context: GraphicsContext): GpuGraphicsContext;
    private _initContextRenderData;
    private _initContext;
    protected onGraphicsContextDestroy(context: GraphicsContext): void;
    private _cleanGraphicsContextData;
    destroy(): void;
}
export {};
`,xp=`import { ExtensionType } from '../../../extensions/Extensions';
import { State } from '../../../rendering/renderers/shared/state/State';
import type { InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import type { BatchPipe, RenderPipe } from '../../../rendering/renderers/shared/instructions/RenderPipe';
import type { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { RenderableGCSystem } from '../../../rendering/renderers/shared/texture/RenderableGCSystem';
import type { Graphics } from './Graphics';
import type { GraphicsContextSystem } from './GraphicsContextSystem';
export interface GraphicsAdaptor {
    shader: Shader;
    init(): void;
    execute(graphicsPipe: GraphicsPipe, renderable: Graphics): void;
    destroy(): void;
}
export interface GraphicsSystem {
    graphicsContext: GraphicsContextSystem;
    renderableGC: RenderableGCSystem;
    renderPipes: {
        batch: BatchPipe;
    };
    _roundPixels: 0 | 1;
}
export declare class GraphicsPipe implements RenderPipe<Graphics> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "graphics";
    };
    renderer: GraphicsSystem;
    state: State;
    private _graphicsBatchesHash;
    private _adaptor;
    private readonly _destroyRenderableBound;
    constructor(renderer: GraphicsSystem, adaptor: GraphicsAdaptor);
    validateRenderable(graphics: Graphics): boolean;
    addRenderable(graphics: Graphics, instructionSet: InstructionSet): void;
    updateRenderable(graphics: Graphics): void;
    destroyRenderable(graphics: Graphics): void;
    execute(graphics: Graphics): void;
    private _rebuild;
    private _addToBatcher;
    private _getBatchesForRenderable;
    private _initBatchesForRenderable;
    private _removeBatchForRenderable;
    destroy(): void;
}
`,vp=`import type { ExtensionMetadataDetails } from '../../../../extensions/Extensions';
import type { ShapePrimitive } from '../../../../maths/shapes/ShapePrimitive';
export interface ShapeBuildCommand<T extends ShapePrimitive = ShapePrimitive> {
    extension: ExtensionMetadataDetails;
    build(shape: T, points: number[]): void;
    triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
}
`,Tp=`export declare function buildAdaptiveBezier(points: number[], sX: number, sY: number, cp1x: number, cp1y: number, cp2x: number, cp2y: number, eX: number, eY: number, smoothness?: number): number[];
`,Sp=`export declare function buildAdaptiveQuadratic(points: number[], sX: number, sY: number, cp1x: number, cp1y: number, eX: number, eY: number, smoothness?: number): number[];
`,wp=`export declare function buildArc(points: number[], x: number, y: number, radius: number, start: number, end: number, clockwise: boolean, steps?: number): void;
`,_p=`/**
 * The arcTo() method creates an arc/curve between two tangents on the canvas.
 *
 * "borrowed" from https://code.google.com/p/fxcanvas/ - thanks google!
 * @param points
 * @param x1
 * @param y1
 * @param x2
 * @param y2
 * @param radius
 */
export declare function buildArcTo(points: number[], x1: number, y1: number, x2: number, y2: number, radius: number): void;
`,Ep=`export declare function buildArcToSvg(points: number[], px: number, py: number, cx: number, cy: number, rx: number, ry: number, xAxisRotation?: number, largeArcFlag?: number, sweepFlag?: number): void;
`,Pp=`import { ExtensionType } from '../../../../extensions/Extensions';
import type { Circle } from '../../../../maths/shapes/Circle';
import type { Ellipse } from '../../../../maths/shapes/Ellipse';
import type { RoundedRectangle } from '../../../../maths/shapes/RoundedRectangle';
import type { ShapeBuildCommand } from './ShapeBuildCommand';
type RoundedShape = Circle | Ellipse | RoundedRectangle;
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildCircle: ShapeBuildCommand<RoundedShape>;
export declare const buildEllipse: {
    extension: {
        name: string;
        type: ExtensionType | ExtensionType[];
        priority?: number;
    };
    build(shape: RoundedShape, points: number[]): void;
    triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
};
export declare const buildRoundedRectangle: {
    extension: {
        name: string;
        type: ExtensionType | ExtensionType[];
        priority?: number;
    };
    build(shape: RoundedShape, points: number[]): void;
    triangulate(points: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
};
export {};
`,Ap=`import type { StrokeAttributes } from '../FillTypes';
/**
 * Builds a line to draw using the polygon method.
 * @param points
 * @param lineStyle
 * @param flipAlignment
 * @param closed
 * @param vertices
 * @param indices
 */
export declare function buildLine(points: number[], lineStyle: StrokeAttributes, flipAlignment: boolean, closed: boolean, vertices: number[], indices: number[]): void;
`,Cp=`/**
 * Builds a line to draw using the polygon method.
 * @param points
 * @param closed
 * @param vertices
 * @param indices
 */
export declare function buildPixelLine(points: number[], closed: boolean, vertices: number[], indices: number[]): void;
`,Rp=`import type { Polygon } from '../../../../maths/shapes/Polygon';
import type { ShapeBuildCommand } from './ShapeBuildCommand';
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildPolygon: ShapeBuildCommand<Polygon>;
`,Gp=`import type { Rectangle } from '../../../../maths/shapes/Rectangle';
import type { ShapeBuildCommand } from './ShapeBuildCommand';
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildRectangle: ShapeBuildCommand<Rectangle>;
`,Mp=`import type { Triangle } from '../../../../maths/shapes/Triangle';
import type { ShapeBuildCommand } from './ShapeBuildCommand';
/**
 * Builds a triangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 * @ignore
 * @private
 */
export declare const buildTriangle: ShapeBuildCommand<Triangle>;
`,kp=`export type LineCap = 'butt' | 'round' | 'square';
export type LineJoin = 'round' | 'bevel' | 'miter';
export declare const closePointEps = 0.0001;
export declare const curveEps = 0.0001;
`,Fp=`import { Matrix } from '../../../../maths/matrix/Matrix';
import { Texture } from '../../../../rendering/renderers/shared/texture/Texture';
import type { ColorSource } from '../../../../color/Color';
import type { PointData } from '../../../../maths/point/PointData';
import type { TextureSpace } from '../FillTypes';
export type GradientType = 'linear' | 'radial';
/**
 * Represents the style options for a linear gradient fill.
 * @memberof scene
 */
export interface BaseGradientOptions {
    /** The type of gradient */
    type?: GradientType;
    /** Array of colors stops to use in the gradient */
    colorStops?: {
        offset: number;
        color: ColorSource;
    }[];
    /** Whether coordinates are 'global' or 'local' */
    textureSpace?: TextureSpace;
    /**
     * The size of the texture to use for the gradient - this is for advanced usage.
     * The texture size does not need to match the size of the object being drawn.
     * Due to GPU interpolation, gradient textures can be relatively small!
     * Consider using a larger texture size if your gradient has a lot of very tight color steps
     */
    textureSize?: number;
}
/**
 * Options specific to linear gradients.
 * A linear gradient creates a smooth transition between colors along a straight line defined by start and end points.
 * @memberof scene
 */
export interface LinearGradientOptions extends BaseGradientOptions {
    /** The type of gradient. Must be 'linear' for linear gradients. */
    type?: 'linear';
    /**
     * The start point of the gradient.
     * This point defines where the gradient begins.
     * It is represented as a PointData object containing x and y coordinates.
     * The coordinates are in local space by default (0-1), but can be in global space if specified.
     */
    start?: PointData;
    /**
     * The end point of the gradient.
     * This point defines where the gradient ends.
     * It is represented as a PointData object containing x and y coordinates.
     * The coordinates are in local space by default (0-1), but can be in global space if specified.
     */
    end?: PointData;
}
/**
 * Options specific to radial gradients.
 * A radial gradient creates a smooth transition between colors that radiates outward in a circular pattern.
 * The gradient is defined by inner and outer circles, each with their own radius.
 * @memberof scene
 */
export interface RadialGradientOptions extends BaseGradientOptions {
    /** The type of gradient. Must be 'radial' for radial gradients. */
    type?: 'radial';
    /** The center point of the inner circle where the gradient begins. In local coordinates by default (0-1). */
    center?: PointData;
    /** The radius of the inner circle where the gradient begins. */
    innerRadius?: number;
    /** The center point of the outer circle where the gradient ends. In local coordinates by default (0-1). */
    outerCenter?: PointData;
    /** The radius of the outer circle where the gradient ends. */
    outerRadius?: number;
    /**
     * The y scale of the gradient, use this to make the gradient elliptical.
     * NOTE: Only applied to radial gradients used with Graphics.
     */
    scale?: number;
    /**
     * The rotation of the gradient in radians, useful for making the gradient elliptical.
     * NOTE: Only applied to radial gradients used with Graphics.
     */
    rotation?: number;
}
/**
 * Options for creating a gradient fill.
 * @memberof scene
 */
export type GradientOptions = LinearGradientOptions | RadialGradientOptions;
/**
 * Class representing a gradient fill that can be used to fill shapes and text.
 * Supports both linear and radial gradients with multiple color stops.
 *
 * For linear gradients, color stops define colors and positions (0 to 1) along a line from start point (x0,y0)
 * to end point (x1,y1).
 *
 * For radial gradients, color stops define colors between two circles - an inner circle centered at (x0,y0) with radius r0,
 * and an outer circle centered at (x1,y1) with radius r1.
 * @example
 * \`\`\`ts
 * // Create a vertical linear gradient from red to blue
 * const linearGradient = new FillGradient({
 *     type: 'linear',
 *     start: { x: 0, y: 0 },  // Start at top
 *     end: { x: 0, y: 1 },    // End at bottom
 *     colorStops: [
 *         { offset: 0, color: 'red' },   // Red at start
 *         { offset: 1, color: 'blue' }   // Blue at end
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 *
 * // Create a radial gradient from yellow center to green edge
 * const radialGradient = new FillGradient({
 *     type: 'radial',
 *     center: { x: 0.5, y: 0.5 },
 *     innerRadius: 0,
 *     outerCenter: { x: 0.5, y: 0.5 },
 *     outerRadius: 0.5,
 *     colorStops: [
 *         { offset: 0, color: 'yellow' }, // Center color
 *         { offset: 1, color: 'green' }   // Edge color
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 *
 * // Create a rainbow linear gradient in global coordinates
 * const globalGradient = new FillGradient({
 *     type: 'linear',
 *     start: { x: 0, y: 0 },
 *     end: { x: 100, y: 0 },
 *     colorStops: [
 *         { offset: 0, color: 0xff0000 },    // Red
 *         { offset: 0.33, color: 0x00ff00 }, // Green
 *         { offset: 0.66, color: 0x0000ff }, // Blue
 *         { offset: 1, color: 0xff00ff }     // Purple
 *     ],
 *     textureSpace: 'global'  // Use world coordinates
 * });
 *
 * // Create an offset radial gradient
 * const offsetRadial = new FillGradient({
 *     type: 'radial',
 *     center: { x: 0.3, y: 0.3 },
 *     innerRadius: 0.1,
 *     outerCenter: { x: 0.5, y: 0.5 },
 *     outerRadius: 0.5,
 *     colorStops: [
 *         { offset: 0, color: 'white' },
 *         { offset: 1, color: 'black' }
 *     ],
 *     // Use normalized coordinate system where (0,0) is the top-left and (1,1) is the bottom-right of the shape
 *     textureSpace: 'local'
 * });
 * \`\`\`
 *
 * Internally this creates a  texture of the gradient then applies a
 * transform to it to give it the correct size and angle.
 *
 * This means that it's important to destroy a gradient when it is no longer needed
 * to avoid memory leaks.
 *
 * If you want to animate a gradient then it's best to modify and update an existing one
 * rather than creating a whole new one each time. That or use a custom shader.
 * @memberof scene
 * @implements {CanvasGradient}
 */
export declare class FillGradient implements CanvasGradient {
    /**
     * Default options for creating a gradient fill
     * @property {PointData} start - Start point of the gradient (default: { x: 0, y: 0 })
     * @property {PointData} end - End point of the gradient (default: { x: 0, y: 1 })
     * @property {TextureSpace} textureSpace - Whether coordinates are 'global' or 'local' (default: 'local')
     * @property {number} textureSize - The size of the texture to use for the gradient (default: 256)
     * @property {Array<{offset: number, color: ColorSource}>} colorStops - Array of color stops (default: empty array)
     * @property {GradientType} type - Type of gradient (default: 'linear')
     */
    static readonly defaultLinearOptions: LinearGradientOptions;
    /**
     * Default options for creating a radial gradient fill
     * @property {PointData} innerCenter - Center of the inner circle (default: { x: 0.5, y: 0.5 })
     * @property {number} innerRadius - Radius of the inner circle (default: 0)
     * @property {PointData} outerCenter - Center of the outer circle (default: { x: 0.5, y: 0.5 })
     * @property {number} outerRadius - Radius of the outer circle (default: 0.5)
     * @property {TextureSpace} textureSpace - Whether coordinates are 'global' or 'local' (default: 'local')
     * @property {number} textureSize - The size of the texture to use for the gradient (default: 256)
     * @property {Array<{offset: number, color: ColorSource}>} colorStops - Array of color stops (default: empty array)
     * @property {GradientType} type - Type of gradient (default: 'radial')
     */
    static readonly defaultRadialOptions: RadialGradientOptions;
    /** Unique identifier for this gradient instance */
    readonly uid: number;
    /** Type of gradient - currently only supports 'linear' */
    readonly type: GradientType;
    /** Internal texture used to render the gradient */
    texture: Texture;
    /** Transform matrix for positioning the gradient */
    transform: Matrix;
    /** Array of color stops defining the gradient */
    colorStops: Array<{
        offset: number;
        color: string;
    }>;
    /** Whether gradient coordinates are in local or global space */
    textureSpace: TextureSpace;
    private readonly _textureSize;
    /** The start point of the linear gradient */
    start: PointData;
    /** The end point of the linear gradient */
    end: PointData;
    /** The center point of the inner circle of the radial gradient */
    center: PointData;
    /** The center point of the outer circle of the radial gradient */
    outerCenter: PointData;
    /** The radius of the inner circle of the radial gradient */
    innerRadius: number;
    /** The radius of the outer circle of the radial gradient */
    outerRadius: number;
    /** The scale of the radial gradient */
    scale: number;
    /** The rotation of the radial gradient */
    rotation: number;
    /**
     * Creates a new gradient fill. The constructor behavior changes based on the gradient type.
     *
     * For linear gradients:
     * @param {GradientOptions} options - The options for the gradient
     * @param {PointData} [options.start] - The start point of the linear gradient
     * @param {PointData} [options.end] - The end point of the linear gradient
     *
     * For radial gradients:
     * @param {PointData} [options.innerCenter] - The center point of the inner circle of the radial gradient
     * @param {number} [options.innerRadius] - The radius of the inner circle of the radial gradient
     * @param {PointData} [options.outerCenter] - The center point of the outer circle of the radial gradient
     * @param {number} [options.outerRadius] - The radius of the outer circle of the radial gradient
     *
     * Common options for both gradient types:
     * @param {TextureSpace} [options.textureSpace='local'] - Whether coordinates are 'global' or 'local'
     * @param {number} [options.textureSize=256] - The size of the texture to use for the gradient
     * @param {Array<{offset: number, color: ColorSource}>} [options.colorStops=[]] - Array of color stops
     * @param {GradientType} [options.type='linear'] - Type of gradient
     */
    constructor(options: GradientOptions);
    /** @deprecated since 8.5.2 */
    constructor(x0?: number, y0?: number, x1?: number, y1?: number, textureSpace?: TextureSpace, textureSize?: number);
    /**
     * Adds a color stop to the gradient
     * @param offset - Position of the stop (0-1)
     * @param color - Color of the stop
     * @returns This gradient instance for chaining
     */
    addColorStop(offset: number, color: ColorSource): this;
    /**
     * Builds the internal texture and transform for the gradient.
     * Called automatically when the gradient is first used.
     * @internal
     */
    buildLinearGradient(): void;
    buildGradient(): void;
    buildRadialGradient(): void;
    /**
     * Gets a unique key representing the current state of the gradient.
     * Used internally for caching.
     * @returns Unique string key
     */
    get styleKey(): number;
    destroy(): void;
}
`,Op=`import { Matrix } from '../../../../maths/matrix/Matrix';
import type { Texture } from '../../../../rendering/renderers/shared/texture/Texture';
export type PatternRepetition = 'repeat' | 'repeat-x' | 'repeat-y' | 'no-repeat';
export declare class FillPattern implements CanvasPattern {
    /** unique id for this fill pattern */
    readonly uid: number;
    texture: Texture;
    transform: Matrix;
    private _styleKey;
    constructor(texture: Texture, repetition?: PatternRepetition);
    setTransform(transform?: Matrix): void;
    get styleKey(): string;
}
`,Ip=`import { Point } from '../../../../maths/point/Point';
import { ShapePath } from './ShapePath';
import type { Matrix } from '../../../../maths/matrix/Matrix';
import type { PointData } from '../../../../maths/point/PointData';
import type { Bounds } from '../../../container/bounds/Bounds';
import type { RoundedPoint } from './roundShape';
export interface PathInstruction {
    action: 'moveTo' | 'lineTo' | 'quadraticCurveTo' | 'bezierCurveTo' | 'arc' | 'closePath' | 'addPath' | 'arcTo' | 'ellipse' | 'rect' | 'roundRect' | 'arcToSvg' | 'poly' | 'circle' | 'regularPoly' | 'roundPoly' | 'roundShape' | 'filletRect' | 'chamferRect';
    data: any[];
}
/**
 * The \`GraphicsPath\` class is designed to represent a graphical path consisting of multiple drawing instructions.
 * This class serves as a collection of drawing commands that can be executed to render shapes and paths on a canvas or
 * similar graphical context. It supports high-level drawing operations like lines, arcs, curves, and more, enabling
 * complex graphic constructions with relative ease.
 * @memberof scene
 */
export declare class GraphicsPath {
    instructions: PathInstruction[];
    /** unique id for this graphics path */
    readonly uid: number;
    private _dirty;
    private _shapePath;
    /**
     * Controls whether shapes in this path should be checked for holes using the non-zero fill rule.
     * When true, any closed shape that is fully contained within another shape will become
     * a hole in that shape during filling operations.
     *
     * This follows SVG's non-zero fill rule where:
     * 1. Shapes are analyzed to find containment relationships
     * 2. If Shape B is fully contained within Shape A, Shape B becomes a hole in Shape A
     * 3. Multiple nested holes are supported
     *
     * Mainly used internally by the SVG parser to correctly handle holes in complex paths.
     * When false, all shapes are filled independently without checking for holes.
     */
    checkForHoles: boolean;
    /**
     * Provides access to the internal shape path, ensuring it is up-to-date with the current instructions.
     * @returns The \`ShapePath\` instance associated with this \`GraphicsPath\`.
     */
    get shapePath(): ShapePath;
    /**
     * Creates a \`GraphicsPath\` instance optionally from an SVG path string or an array of \`PathInstruction\`.
     * @param instructions - An SVG path string or an array of \`PathInstruction\` objects.
     * @param signed
     */
    constructor(instructions?: string | PathInstruction[], signed?: boolean);
    /**
     * Adds another \`GraphicsPath\` to this path, optionally applying a transformation.
     * @param path - The \`GraphicsPath\` to add.
     * @param transform - An optional transformation to apply to the added path.
     * @returns The instance of the current object for chaining.
     */
    addPath(path: GraphicsPath, transform?: Matrix): this;
    /**
     * Adds an arc to the path. The arc is centered at (x, y)
     *  position with radius \`radius\` starting at \`startAngle\` and ending at \`endAngle\`.
     * @param x - The x-coordinate of the arc's center.
     * @param y - The y-coordinate of the arc's center.
     * @param radius - The radius of the arc.
     * @param startAngle - The starting angle of the arc, in radians.
     * @param endAngle - The ending angle of the arc, in radians.
     * @param counterclockwise - Specifies whether the arc should be drawn in the anticlockwise direction. False by default.
     * @returns The instance of the current object for chaining.
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise?: boolean): this;
    /**
     * Adds an arc to the path with the arc tangent to the line joining two specified points.
     * The arc radius is specified by \`radius\`.
     * @param x1 - The x-coordinate of the first point.
     * @param y1 - The y-coordinate of the first point.
     * @param x2 - The x-coordinate of the second point.
     * @param y2 - The y-coordinate of the second point.
     * @param radius - The radius of the arc.
     * @returns The instance of the current object for chaining.
     */
    arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
    /**
     * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
     * @param rx - The x-radius of the ellipse.
     * @param ry - The y-radius of the ellipse.
     * @param xAxisRotation - The rotation of the ellipse's x-axis relative
     * to the x-axis of the coordinate system, in degrees.
     * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
     * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
     * @param x - The x-coordinate of the arc's end point.
     * @param y - The y-coordinate of the arc's end point.
     * @returns The instance of the current object for chaining.
     */
    arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
    /**
     * Adds a cubic Bezier curve to the path.
     * It requires three points: the first two are control points and the third one is the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the first control point.
     * @param cp1y - The y-coordinate of the first control point.
     * @param cp2x - The x-coordinate of the second control point.
     * @param cp2y - The y-coordinate of the second control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
    /**
     * Adds a cubic Bezier curve to the path.
     * It requires two points: the second control point and the end point. The first control point is assumed to be
     * The starting point is the last point in the current path.
     * @param cp2x - The x-coordinate of the second control point.
     * @param cp2y - The y-coordinate of the second control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    bezierCurveToShort(cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
    /**
     * Closes the current path by drawing a straight line back to the start.
     * If the shape is already closed or there are no points in the path, this method does nothing.
     * @returns The instance of the current object for chaining.
     */
    closePath(): this;
    /**
     * Draws an ellipse at the specified location and with the given x and y radii.
     * An optional transformation can be applied, allowing for rotation, scaling, and translation.
     * @param x - The x-coordinate of the center of the ellipse.
     * @param y - The y-coordinate of the center of the ellipse.
     * @param radiusX - The horizontal radius of the ellipse.
     * @param radiusY - The vertical radius of the ellipse.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the ellipse. This can include rotations.
     * @returns The instance of the current object for chaining.
     */
    ellipse(x: number, y: number, radiusX: number, radiusY: number, matrix?: Matrix): this;
    /**
     * Connects the current point to a new point with a straight line. This method updates the current path.
     * @param x - The x-coordinate of the new point to connect to.
     * @param y - The y-coordinate of the new point to connect to.
     * @returns The instance of the current object for chaining.
     */
    lineTo(x: number, y: number): this;
    /**
     * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
     * @param x - The x-coordinate for the starting point.
     * @param y - The y-coordinate for the starting point.
     * @returns The instance of the current object for chaining.
     */
    moveTo(x: number, y: number): this;
    /**
     * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the control point.
     * @param cp1y - The y-coordinate of the control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    quadraticCurveTo(cpx: number, cpy: number, x: number, y: number, smoothness?: number): this;
    /**
     * Adds a quadratic curve to the path. It uses the previous point as the control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    quadraticCurveToShort(x: number, y: number, smoothness?: number): this;
    /**
     * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
     * @returns The instance of the current object for chaining.
     */
    rect(x: number, y: number, w: number, h: number, transform?: Matrix): this;
    /**
     * Draws a circle shape. This method adds a new circle path to the current drawing.
     * @param x - The x-coordinate of the center of the circle.
     * @param y - The y-coordinate of the center of the circle.
     * @param radius - The radius of the circle.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the circle.
     * @returns The instance of the current object for chaining.
     */
    circle(x: number, y: number, radius: number, transform?: Matrix): this;
    /**
     * Draws a rectangle with rounded corners.
     * The corner radius can be specified to determine how rounded the corners should be.
     * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
     * @returns The instance of the current object for chaining.
     */
    roundRect(x: number, y: number, w: number, h: number, radius?: number, transform?: Matrix): this;
    /**
     * Draws a polygon shape by specifying a sequence of points. This method allows for the creation of complex polygons,
     * which can be both open and closed. An optional transformation can be applied, enabling the polygon to be scaled,
     * rotated, or translated as needed.
     * @param points - An array of numbers representing the x and y coordinates of the polygon's vertices, in sequence.
     * @param close - A boolean indicating whether to close the polygon path. True by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining further drawing commands.
     */
    poly(points: number[] | PointData[], close?: boolean, transform?: Matrix): this;
    /**
     * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining.
     */
    regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
    /**
     * Draws a polygon with rounded corners.
     * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param corner - The radius of the rounding of the corners.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @returns The instance of the current object for chaining.
     */
    roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number): this;
    /**
     * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
     * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
     * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
     * A minimum of 3 points is required.
     * @param radius - The default radius for the corners.
     * This radius is applied to all corners unless overridden in \`points\`.
     * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
     *  method instead of an arc method. Defaults to false.
     * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
     * Higher values make the curve smoother.
     * @returns The instance of the current object for chaining.
     */
    roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
    /**
     * Draw Rectangle with fillet corners. This is much like rounded rectangle
     * however it support negative numbers as well for the corner radius.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param fillet - accept negative or positive values
     */
    filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
    /**
     * Draw Rectangle with chamfer corners. These are angled corners.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param chamfer - non-zero real number, size of corner cutout
     * @param transform
     */
    chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
    /**
     * Draws a star shape centered at a specified location. This method allows for the creation
     *  of stars with a variable number of points, outer radius, optional inner radius, and rotation.
     * The star is drawn as a closed polygon with alternating outer and inner vertices to create the star's points.
     * An optional transformation can be applied to scale, rotate, or translate the star as needed.
     * @param x - The x-coordinate of the center of the star.
     * @param y - The y-coordinate of the center of the star.
     * @param points - The number of points of the star.
     * @param radius - The outer radius of the star (distance from the center to the outer points).
     * @param innerRadius - Optional. The inner radius of the star
     * (distance from the center to the inner points between the outer points).
     * If not provided, defaults to half of the \`radius\`.
     * @param rotation - Optional. The rotation of the star in radians, where 0 is aligned with the y-axis.
     * Defaults to 0, meaning one point is directly upward.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the star.
     * This can include rotations, scaling, and translations.
     * @returns The instance of the current object for chaining further drawing commands.
     */
    star(x: number, y: number, points: number, radius: number, innerRadius?: number, rotation?: number, transform?: Matrix): this;
    /**
     * Creates a copy of the current \`GraphicsPath\` instance. This method supports both shallow and deep cloning.
     * A shallow clone copies the reference of the instructions array, while a deep clone creates a new array and
     * copies each instruction individually, ensuring that modifications to the instructions of the cloned \`GraphicsPath\`
     * do not affect the original \`GraphicsPath\` and vice versa.
     * @param deep - A boolean flag indicating whether the clone should be deep.
     * @returns A new \`GraphicsPath\` instance that is a clone of the current instance.
     */
    clone(deep?: boolean): GraphicsPath;
    clear(): this;
    /**
     * Applies a transformation matrix to all drawing instructions within the \`GraphicsPath\`.
     * This method enables the modification of the path's geometry according to the provided
     * transformation matrix, which can include translations, rotations, scaling, and skewing.
     *
     * Each drawing instruction in the path is updated to reflect the transformation,
     * ensuring the visual representation of the path is consistent with the applied matrix.
     *
     * Note: The transformation is applied directly to the coordinates and control points of the drawing instructions,
     * not to the path as a whole. This means the transformation's effects are baked into the individual instructions,
     * allowing for fine-grained control over the path's appearance.
     * @param matrix - A \`Matrix\` object representing the transformation to apply.
     * @returns The instance of the current object for chaining further operations.
     */
    transform(matrix: Matrix): this;
    get bounds(): Bounds;
    /**
     * Retrieves the last point from the current drawing instructions in the \`GraphicsPath\`.
     * This method is useful for operations that depend on the path's current endpoint,
     * such as connecting subsequent shapes or paths. It supports various drawing instructions,
     * ensuring the last point's position is accurately determined regardless of the path's complexity.
     *
     * If the last instruction is a \`closePath\`, the method iterates backward through the instructions
     *  until it finds an actionable instruction that defines a point (e.g., \`moveTo\`, \`lineTo\`,
     * \`quadraticCurveTo\`, etc.). For compound paths added via \`addPath\`, it recursively retrieves
     * the last point from the nested path.
     * @param out - A \`Point\` object where the last point's coordinates will be stored.
     * This object is modified directly to contain the result.
     * @returns The \`Point\` object containing the last point's coordinates.
     */
    getLastPoint(out: Point): Point;
}
`,Lp=`import { Bounds } from '../../../container/bounds/Bounds';
import type { Matrix } from '../../../../maths/matrix/Matrix';
import type { PointData } from '../../../../maths/point/PointData';
import type { ShapePrimitive } from '../../../../maths/shapes/ShapePrimitive';
import type { GraphicsPath } from './GraphicsPath';
import type { RoundedPoint } from './roundShape';
export type ShapePrimitiveWithHoles = {
    shape: ShapePrimitive;
    transform?: Matrix;
    holes?: ShapePrimitiveWithHoles[];
};
/**
 * The \`ShapePath\` class acts as a bridge between high-level drawing commands
 * and the lower-level \`GraphicsContext\` rendering engine.
 * It translates drawing commands, such as those for creating lines, arcs, ellipses, rectangles, and complex polygons, into a
 * format that can be efficiently processed by a \`GraphicsContext\`. This includes handling path starts,
 * ends, and transformations for shapes.
 *
 * It is used internally by \`GraphicsPath\` to build up the path.
 * @memberof scene
 */
export declare class ShapePath {
    /** The list of shape primitives that make up the path. */
    shapePrimitives: ShapePrimitiveWithHoles[];
    private _currentPoly;
    private readonly _graphicsPath2D;
    private readonly _bounds;
    readonly signed: boolean;
    constructor(graphicsPath2D: GraphicsPath);
    /**
     * Sets the starting point for a new sub-path. Any subsequent drawing commands are considered part of this path.
     * @param x - The x-coordinate for the starting point.
     * @param y - The y-coordinate for the starting point.
     * @returns The instance of the current object for chaining.
     */
    moveTo(x: number, y: number): this;
    /**
     * Connects the current point to a new point with a straight line. This method updates the current path.
     * @param x - The x-coordinate of the new point to connect to.
     * @param y - The y-coordinate of the new point to connect to.
     * @returns The instance of the current object for chaining.
     */
    lineTo(x: number, y: number): this;
    /**
     * Adds an arc to the path. The arc is centered at (x, y)
     *  position with radius \`radius\` starting at \`startAngle\` and ending at \`endAngle\`.
     * @param x - The x-coordinate of the arc's center.
     * @param y - The y-coordinate of the arc's center.
     * @param radius - The radius of the arc.
     * @param startAngle - The starting angle of the arc, in radians.
     * @param endAngle - The ending angle of the arc, in radians.
     * @param counterclockwise - Specifies whether the arc should be drawn in the anticlockwise direction. False by default.
     * @returns The instance of the current object for chaining.
     */
    arc(x: number, y: number, radius: number, startAngle: number, endAngle: number, counterclockwise: boolean): this;
    /**
     * Adds an arc to the path with the arc tangent to the line joining two specified points.
     * The arc radius is specified by \`radius\`.
     * @param x1 - The x-coordinate of the first point.
     * @param y1 - The y-coordinate of the first point.
     * @param x2 - The x-coordinate of the second point.
     * @param y2 - The y-coordinate of the second point.
     * @param radius - The radius of the arc.
     * @returns The instance of the current object for chaining.
     */
    arcTo(x1: number, y1: number, x2: number, y2: number, radius: number): this;
    /**
     * Adds an SVG-style arc to the path, allowing for elliptical arcs based on the SVG spec.
     * @param rx - The x-radius of the ellipse.
     * @param ry - The y-radius of the ellipse.
     * @param xAxisRotation - The rotation of the ellipse's x-axis relative
     * to the x-axis of the coordinate system, in degrees.
     * @param largeArcFlag - Determines if the arc should be greater than or less than 180 degrees.
     * @param sweepFlag - Determines if the arc should be swept in a positive angle direction.
     * @param x - The x-coordinate of the arc's end point.
     * @param y - The y-coordinate of the arc's end point.
     * @returns The instance of the current object for chaining.
     */
    arcToSvg(rx: number, ry: number, xAxisRotation: number, largeArcFlag: number, sweepFlag: number, x: number, y: number): this;
    /**
     * Adds a cubic Bezier curve to the path.
     * It requires three points: the first two are control points and the third one is the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the first control point.
     * @param cp1y - The y-coordinate of the first control point.
     * @param cp2x - The x-coordinate of the second control point.
     * @param cp2y - The y-coordinate of the second control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothness - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    bezierCurveTo(cp1x: number, cp1y: number, cp2x: number, cp2y: number, x: number, y: number, smoothness?: number): this;
    /**
     * Adds a quadratic curve to the path. It requires two points: the control point and the end point.
     * The starting point is the last point in the current path.
     * @param cp1x - The x-coordinate of the control point.
     * @param cp1y - The y-coordinate of the control point.
     * @param x - The x-coordinate of the end point.
     * @param y - The y-coordinate of the end point.
     * @param smoothing - Optional parameter to adjust the smoothness of the curve.
     * @returns The instance of the current object for chaining.
     */
    quadraticCurveTo(cp1x: number, cp1y: number, x: number, y: number, smoothing?: number): this;
    /**
     * Closes the current path by drawing a straight line back to the start.
     * If the shape is already closed or there are no points in the path, this method does nothing.
     * @returns The instance of the current object for chaining.
     */
    closePath(): this;
    /**
     * Adds another path to the current path. This method allows for the combination of multiple paths into one.
     * @param path - The \`GraphicsPath\` object representing the path to add.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the path before adding it.
     * @returns The instance of the current object for chaining.
     */
    addPath(path: GraphicsPath, transform?: Matrix): this;
    /**
     * Finalizes the drawing of the current path. Optionally, it can close the path.
     * @param closePath - A boolean indicating whether to close the path after finishing. False by default.
     */
    finish(closePath?: boolean): void;
    /**
     * Draws a rectangle shape. This method adds a new rectangle path to the current drawing.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
     * @returns The instance of the current object for chaining.
     */
    rect(x: number, y: number, w: number, h: number, transform?: Matrix): this;
    /**
     * Draws a circle shape. This method adds a new circle path to the current drawing.
     * @param x - The x-coordinate of the center of the circle.
     * @param y - The y-coordinate of the center of the circle.
     * @param radius - The radius of the circle.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the circle.
     * @returns The instance of the current object for chaining.
     */
    circle(x: number, y: number, radius: number, transform?: Matrix): this;
    /**
     * Draws a polygon shape. This method allows for the creation of complex polygons by specifying a sequence of points.
     * @param points - An array of numbers, or or an array of PointData objects eg [{x,y}, {x,y}, {x,y}]
     * representing the x and y coordinates of the polygon's vertices, in sequence.
     * @param close - A boolean indicating whether to close the polygon path. True by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining.
     */
    poly(points: number[] | PointData[], close?: boolean, transform?: Matrix): this;
    /**
     * Draws a regular polygon with a specified number of sides. All sides and angles are equal.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the polygon.
     * @returns The instance of the current object for chaining.
     */
    regularPoly(x: number, y: number, radius: number, sides: number, rotation?: number, transform?: Matrix): this;
    /**
     * Draws a polygon with rounded corners.
     * Similar to \`regularPoly\` but with the ability to round the corners of the polygon.
     * @param x - The x-coordinate of the center of the polygon.
     * @param y - The y-coordinate of the center of the polygon.
     * @param radius - The radius of the circumscribed circle of the polygon.
     * @param sides - The number of sides of the polygon. Must be 3 or more.
     * @param corner - The radius of the rounding of the corners.
     * @param rotation - The rotation angle of the polygon, in radians. Zero by default.
     * @param smoothness - Optional parameter to adjust the smoothness of the rounding.
     * @returns The instance of the current object for chaining.
     */
    roundPoly(x: number, y: number, radius: number, sides: number, corner: number, rotation?: number, smoothness?: number): this;
    /**
     * Draws a shape with rounded corners. This function supports custom radius for each corner of the shape.
     * Optionally, corners can be rounded using a quadratic curve instead of an arc, providing a different aesthetic.
     * @param points - An array of \`RoundedPoint\` representing the corners of the shape to draw.
     * A minimum of 3 points is required.
     * @param radius - The default radius for the corners.
     * This radius is applied to all corners unless overridden in \`points\`.
     * @param useQuadratic - If set to true, rounded corners are drawn using a quadraticCurve
     *  method instead of an arc method. Defaults to false.
     * @param smoothness - Specifies the smoothness of the curve when \`useQuadratic\` is true.
     * Higher values make the curve smoother.
     * @returns The instance of the current object for chaining.
     */
    roundShape(points: RoundedPoint[], radius: number, useQuadratic?: boolean, smoothness?: number): this;
    /**
     * Draw Rectangle with fillet corners. This is much like rounded rectangle
     * however it support negative numbers as well for the corner radius.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param fillet - accept negative or positive values
     */
    filletRect(x: number, y: number, width: number, height: number, fillet: number): this;
    /**
     * Draw Rectangle with chamfer corners. These are angled corners.
     * @param x - Upper left corner of rect
     * @param y - Upper right corner of rect
     * @param width - Width of rect
     * @param height - Height of rect
     * @param chamfer - non-zero real number, size of corner cutout
     * @param transform
     */
    chamferRect(x: number, y: number, width: number, height: number, chamfer: number, transform?: Matrix): this;
    /**
     * Draws an ellipse at the specified location and with the given x and y radii.
     * An optional transformation can be applied, allowing for rotation, scaling, and translation.
     * @param x - The x-coordinate of the center of the ellipse.
     * @param y - The y-coordinate of the center of the ellipse.
     * @param radiusX - The horizontal radius of the ellipse.
     * @param radiusY - The vertical radius of the ellipse.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the ellipse. This can include rotations.
     * @returns The instance of the current object for chaining.
     */
    ellipse(x: number, y: number, radiusX: number, radiusY: number, transform?: Matrix): this;
    /**
     * Draws a rectangle with rounded corners.
     * The corner radius can be specified to determine how rounded the corners should be.
     * An optional transformation can be applied, which allows for rotation, scaling, and translation of the rectangle.
     * @param x - The x-coordinate of the top-left corner of the rectangle.
     * @param y - The y-coordinate of the top-left corner of the rectangle.
     * @param w - The width of the rectangle.
     * @param h - The height of the rectangle.
     * @param radius - The radius of the rectangle's corners. If not specified, corners will be sharp.
     * @param transform - An optional \`Matrix\` object to apply a transformation to the rectangle.
     * @returns The instance of the current object for chaining.
     */
    roundRect(x: number, y: number, w: number, h: number, radius?: number, transform?: Matrix): this;
    /**
     * Draws a given shape on the canvas.
     * This is a generic method that can draw any type of shape specified by the \`ShapePrimitive\` parameter.
     * An optional transformation matrix can be applied to the shape, allowing for complex transformations.
     * @param shape - The shape to draw, defined as a \`ShapePrimitive\` object.
     * @param matrix - An optional \`Matrix\` for transforming the shape. This can include rotations,
     * scaling, and translations.
     * @returns The instance of the current object for chaining.
     */
    drawShape(shape: ShapePrimitive, matrix?: Matrix): this;
    /**
     * Starts a new polygon path from the specified starting point.
     * This method initializes a new polygon or ends the current one if it exists.
     * @param x - The x-coordinate of the starting point of the new polygon.
     * @param y - The y-coordinate of the starting point of the new polygon.
     * @returns The instance of the current object for chaining.
     */
    startPoly(x: number, y: number): this;
    /**
     * Ends the current polygon path. If \`closePath\` is set to true,
     * the path is closed by connecting the last point to the first one.
     * This method finalizes the current polygon and prepares it for drawing or adding to the shape primitives.
     * @param closePath - A boolean indicating whether to close the polygon by connecting the last point
     *  back to the starting point. False by default.
     * @returns The instance of the current object for chaining.
     */
    endPoly(closePath?: boolean): this;
    private _ensurePoly;
    /** Builds the path. */
    buildPath(): void;
    /** Gets the bounds of the path. */
    get bounds(): Bounds;
}
`,Bp=`import type { PointData } from '../../../../maths/point/PointData';
import type { ShapePath } from './ShapePath';
/**
 * Typed and cleaned up version of:
 * https://stackoverflow.com/questions/44855794/html5-canvas-triangle-with-rounded-corners/44856925#44856925
 * @param g - Graphics to be drawn on.
 * @param points - Corners of the shape to draw. Minimum length is 3.
 * @param radius - Corners default radius.
 * @ignore
 */
export declare function roundedShapeArc(g: ShapePath, points: RoundedPoint[], radius: number): void;
export type RoundedPoint = PointData & {
    radius?: number;
};
/**
 * Typed and cleaned up version of:
 * https://stackoverflow.com/questions/44855794/html5-canvas-triangle-with-rounded-corners/56214413#56214413
 * @param g - Graphics to be drawn on.
 * @param points - Corners of the shape to draw. Minimum length is 3.
 * @param radius - Corners default radius.
 * @ignore
 */
export declare function roundedShapeQuadraticCurve(g: ShapePath, points: RoundedPoint[], radius: number, smoothness?: number): void;
`,Dp=`import { GraphicsPath } from '../path/GraphicsPath';
import type { FillGradient } from '../fill/FillGradient';
import type { GraphicsContext } from '../GraphicsContext';
/** Represents a session for SVG parsing. Contains the current state and resources needed during parsing. */
export interface Session {
    /** The graphics context to render to */
    context: GraphicsContext;
    /** The current path being constructed */
    path: GraphicsPath;
    /** Map of definitions by id */
    defs: Record<string, FillGradient>;
}
/**
 * Parses an SVG element or string and renders it to a graphics context.
 * Handles both SVG strings and SVG DOM elements as input.
 * @param svg - The SVG content to parse, either as a string or element
 * @param graphicsContext - Optional graphics context to render to
 * @returns The graphics context with the SVG rendered into it
 */
export declare function SVGParser(svg: string | SVGElement | SVGSVGElement, graphicsContext?: GraphicsContext): GraphicsContext;
`,Up=`import type { Session } from './SVGParser';
/**
 * Parses SVG gradient definitions and stores them in the session for later use.
 * Currently supports linear gradients and has placeholder support for radial gradients.
 * @param svg - The root SVG element to parse definitions from
 * @param session - The parsing session to store definitions in
 */
export declare function parseSVGDefinitions(svg: SVGElement, session: Session): void;
`,jp=`/**
 * Parses a float value from an SVG element's attribute.
 * This is commonly used for parsing numeric attributes like coordinates, dimensions,
 * and other measurements from SVG elements.
 * @param svg - The SVG element to get the attribute from
 * @param id - The name of the attribute to parse (e.g. 'x', 'y', 'width', etc)
 * @param defaultValue - The value to return if the attribute doesn't exist or can't be parsed
 * @returns The parsed float value, or the default value if parsing fails
 * @example
 * // For SVG: <rect x="10.5" width="20"/>
 * parseSVGFloatAttribute(rectElement, 'x', 0) // Returns 10.5
 * parseSVGFloatAttribute(rectElement, 'y', 0) // Returns 0 since y is not specified
 */
export declare function parseSVGFloatAttribute(svg: SVGElement, id: string, defaultValue: number): number;
`,Wp=`import type { GraphicsPath } from '../path/GraphicsPath';
/**
 * Parses an SVG path data string and builds a GraphicsPath object from the commands.
 * This function handles all standard SVG path commands including moves, lines, curves and arcs.
 * It maintains state for the current position and subpaths to properly handle relative commands
 * and path closures.
 *
 * Supported SVG commands:
 * - M/m: Move to absolute/relative
 * - L/l: Line to absolute/relative
 * - H/h: Horizontal line absolute/relative
 * - V/v: Vertical line absolute/relative
 * - C/c: Cubic bezier curve absolute/relative
 * - S/s: Smooth cubic bezier curve absolute/relative
 * - Q/q: Quadratic bezier curve absolute/relative
 * - T/t: Smooth quadratic bezier curve absolute/relative
 * - A/a: Arc absolute/relative
 * - Z/z: Close path
 * @param svgPath - The SVG path data string to parse (e.g. "M0,0 L100,100")
 * @param path - The GraphicsPath object to build the path into
 * @returns The input path object with the SVG commands applied
 */
export declare function parseSVGPath(svgPath: string, path: GraphicsPath): GraphicsPath;
`,Hp=`import type { FillStyle, StrokeStyle } from '../FillTypes';
import type { Session } from './SVGParser';
/**
 * A map of SVG style attributes and their default values.
 * Each attribute has a type and default value used for SVG parsing.
 * - 'paint' type can be a color or gradient
 * - 'number' type is a numeric value
 * - 'string' type is a text value
 */
export declare const styleAttributes: {
    fill: {
        type: string;
        default: number;
    };
    'fill-opacity': {
        type: string;
        default: number;
    };
    stroke: {
        type: string;
        default: number;
    };
    'stroke-width': {
        type: string;
        default: number;
    };
    'stroke-opacity': {
        type: string;
        default: number;
    };
    'stroke-linecap': {
        type: string;
        default: string;
    };
    'stroke-linejoin': {
        type: string;
        default: string;
    };
    'stroke-miterlimit': {
        type: string;
        default: number;
    };
    'stroke-dasharray': {
        type: string;
        default: string;
    };
    'stroke-dashoffset': {
        type: string;
        default: number;
    };
    opacity: {
        type: string;
        default: number;
    };
};
/** Represents the result of parsing SVG style attributes */
export type StyleResult = {
    /** The stroke style properties */
    strokeStyle: StrokeStyle;
    /** The fill style properties */
    fillStyle: FillStyle;
    /** Whether fill should be applied */
    useFill: boolean;
    /** Whether stroke should be applied */
    useStroke: boolean;
};
/**
 * Parses SVG style attributes and inline styles to determine fill and stroke properties.
 * Handles both direct attributes and CSS-style declarations in the style attribute.
 * @param svg - The SVG element to parse styles from
 * @param session - The current SVG parsing session containing definitions
 * @returns An object containing the parsed fill and stroke styles
 */
export declare function parseSVGStyle(svg: SVGElement, session: Session): StyleResult;
/**
 * Parses a single SVG style attribute and updates the style result accordingly.
 * Handles color values, gradients, opacities and other style properties.
 * @param session - The current SVG parsing session containing definitions
 * @param result - The style result object to update
 * @param id - The attribute name/id to parse
 * @param value - The attribute value to parse
 */
export declare function parseAttribute(session: Session, result: StyleResult, id: string, value: string): void;
`,Vp=`/**
 * Extracts the ID from an SVG url() reference.
 *
 * This function handles all valid SVG url() formats including:
 * - url(#id)
 * - url('#id')
 * - url("#id")
 * - url( #id )
 * - url( '#id' )
 * - url( "#id" )
 *
 * The regex pattern matches:
 * - url followed by optional whitespace
 * - opening parenthesis followed by optional whitespace
 * - optional single or double quotes with optional whitespace
 * - # followed by the ID (any chars except quotes, whitespace, or closing paren)
 * - optional single or double quotes with optional whitespace
 * - closing parenthesis
 * @param url - The SVG url() string to parse
 * @returns The extracted ID string, or empty string if no valid ID found
 */
export declare function extractSvgUrlId(url: string): string;
`,Np=`/** Type definitions for parse-svg-path module This module parses SVG path data strings into an array of commands */

declare module 'parse-svg-path'
{
    /**
     * Represents a single SVG path command
     * First element is the command letter (e.g. 'M' for moveto, 'L' for lineto, etc)
     * Remaining elements are the numeric parameters for that command
     * @example ['M', 10, 20] // Move to x=10, y=20
     * @example ['L', 30, 40] // Line to x=30, y=40
     */
    export type Command = [string, ...number[]];

    /**
     * Parses an SVG path data string into an array of commands
     * @param path - The SVG path data string to parse
     * @returns Array of parsed commands, each containing a command letter and parameters
     * @example
     * parse('M10 20L30 40')
     * // Returns: [['M', 10, 20], ['L', 30, 40]]
     */
    export default function parse(path: string): Command[];
}
`,zp=`import type { ShapeBuildCommand } from '../buildCommands/ShapeBuildCommand';
import type { GraphicsContext } from '../GraphicsContext';
import type { GpuGraphicsContext } from '../GraphicsContextSystem';
export declare const shapeBuilders: Record<string, ShapeBuildCommand>;
export declare function buildContextBatches(context: GraphicsContext, gpuContext: GpuGraphicsContext): void;
`,Xp=`import { MeshGeometry } from '../../../mesh/shared/MeshGeometry';
import { GraphicsPath } from '../path/GraphicsPath';
import type { Matrix } from '../../../../maths/matrix/Matrix';
export interface GeometryPathOptions {
    /** the path to build the geometry from */
    path: GraphicsPath;
    /** a \`Matrix\` that can be used to modify the the texture UVs of the the path being built */
    textureMatrix?: Matrix;
    /** an optional \`MeshGeometry\` to write too instead of creating a new one*/
    out?: MeshGeometry;
}
/**
 * When building a mesh, it helps to leverage the simple API we have in \`GraphicsPath\` as it can often be easier to
 * to define the geometry in a more human readable way. This function takes a \`GraphicsPath\` and returns a \`MeshGeometry\`.
 * @example
 * \`\`\`ts
 *
 * const path = new GraphicsPath()
 *    .drawRect(0, 0, 100, 100)
 *
 * const geometry:MeshGeometry = buildGeometryFromPath(path);
 *
 * const mesh = new Mesh({geometry});
 *
 * \`\`\`
 * You can also pass in a Matrix to transform the uvs as by default you may want to control how they are set up.
 * @param options - either a \`GraphicsPath\` or \`GeometryPathOptions\`
 * @returns a new \`MeshGeometry\` instance build from the path
 */
export declare function buildGeometryFromPath(options: GraphicsPath | GeometryPathOptions): MeshGeometry;
`,Kp=`import type { ConvertedFillStyle, ConvertedStrokeStyle, FillInput, StrokeInput } from '../FillTypes';
/**
 * Converts a value to a fill style, we do this as PixiJS has a number of ways to define a fill style
 * They can be a direct color, a texture, a gradient, or an object with these values in them
 * This function will take any of these input types and convert them into a single object
 * that PixiJS can understand and use internally.
 * @param value - The value to convert to a fill style
 * @param defaultStyle - The default fill style to use
 * @private
 */
export declare function toFillStyle<T extends FillInput>(value: T, defaultStyle: ConvertedFillStyle): ConvertedFillStyle;
/**
 * Converts a value to a stroke style, similar to \`toFillStyle\` but for strokes
 * @param value - The value to convert to a stroke style
 * @param defaultStyle - The default stroke style to use
 * @private
 */
export declare function toStrokeStyle(value: StrokeInput, defaultStyle: ConvertedStrokeStyle): ConvertedStrokeStyle;
`,qp=`import { Matrix } from '../../../../maths/matrix/Matrix';
import type { ShapePrimitive } from '../../../../maths/shapes/ShapePrimitive';
import type { FillStyle } from '../FillTypes';
/**
 * Generates a texture matrix for mapping textures onto shapes.
 * This function handles both local and global texture space mapping.
 *
 * In local space, the texture is mapped to fit exactly within the bounds of the shape.
 * In global space, the texture is mapped using its own dimensions and position.
 * @param out - The matrix to store the result in
 * @param style - The fill style containing texture and mapping properties
 * @param shape - The shape to map the texture onto
 * @param matrix - Optional transform matrix to apply
 * @returns The generated texture matrix for UV mapping
 * @example
 * \`\`\`ts
 * const matrix = new Matrix();
 * const textureMatrix = generateTextureMatrix(matrix, fillStyle, shape);
 * // textureMatrix now contains the proper UV mapping for the texture
 * \`\`\`
 */
export declare function generateTextureMatrix(out: Matrix, style: FillStyle, shape: ShapePrimitive, matrix?: Matrix): Matrix;
`,Yp=`export declare function getOrientationOfPoints(points: number[]): number;
`,Jp=`export declare function triangulateWithHoles(points: number[], holes: number[], vertices: number[], verticesStride: number, verticesOffset: number, indices: number[], indicesOffset: number): void;
`,$p=`export * from './container/bounds/Bounds';
export * from './container/bounds/getFastGlobalBounds';
export * from './container/bounds/getGlobalBounds';
export * from './container/bounds/getLocalBounds';
export * from './container/bounds/getRenderableBounds';
export * from './container/bounds/utils/matrixAndBoundsPool';
export * from './container/container-mixins/cacheAsTextureMixin';
export * from './container/container-mixins/childrenHelperMixin';
export * from './container/container-mixins/collectRenderablesMixin';
export * from './container/container-mixins/effectsMixin';
export * from './container/container-mixins/findMixin';
export * from './container/container-mixins/getFastGlobalBoundsMixin';
export * from './container/container-mixins/getGlobalMixin';
export * from './container/container-mixins/measureMixin';
export * from './container/container-mixins/onRenderMixin';
export * from './container/container-mixins/sortMixin';
export * from './container/container-mixins/toLocalGlobalMixin';
export * from './container/Container';
export * from './container/CustomRenderPipe';
export * from './container/destroyTypes';
export * from './container/Effect';
export * from './container/RenderContainer';
export * from './container/RenderGroup';
export * from './container/RenderGroupPipe';
export * from './container/RenderGroupSystem';
export * from './container/utils/assignWithIgnore';
export * from './container/utils/checkChildrenDidChange';
export * from './container/utils/clearList';
export * from './container/utils/collectAllRenderables';
export * from './container/utils/definedProps';
export * from './container/utils/executeInstructions';
export * from './container/utils/mixHexColors';
export * from './container/utils/multiplyColors';
export * from './container/utils/multiplyHexColors';
export * from './container/utils/updateLocalTransform';
export * from './container/utils/updateRenderGroupTransforms';
export * from './container/utils/updateWorldTransform';
export * from './container/utils/validateRenderables';
export * from './graphics/gl/GlGraphicsAdaptor';
export * from './graphics/gpu/colorToUniform';
export * from './graphics/gpu/GpuGraphicsAdaptor';
export * from './graphics/shared/BatchableGraphics';
export * from './graphics/shared/buildCommands/buildAdaptiveBezier';
export * from './graphics/shared/buildCommands/buildAdaptiveQuadratic';
export * from './graphics/shared/buildCommands/buildArc';
export * from './graphics/shared/buildCommands/buildArcTo';
export * from './graphics/shared/buildCommands/buildArcToSvg';
export * from './graphics/shared/buildCommands/buildCircle';
export * from './graphics/shared/buildCommands/buildLine';
export * from './graphics/shared/buildCommands/buildPixelLine';
export * from './graphics/shared/buildCommands/buildPolygon';
export * from './graphics/shared/buildCommands/buildRectangle';
export * from './graphics/shared/buildCommands/buildTriangle';
export * from './graphics/shared/buildCommands/ShapeBuildCommand';
export * from './graphics/shared/const';
export * from './graphics/shared/fill/FillGradient';
export * from './graphics/shared/fill/FillPattern';
export * from './graphics/shared/FillTypes';
export * from './graphics/shared/Graphics';
export * from './graphics/shared/GraphicsContext';
export * from './graphics/shared/GraphicsContextSystem';
export * from './graphics/shared/GraphicsPipe';
export * from './graphics/shared/path/GraphicsPath';
export * from './graphics/shared/path/roundShape';
export * from './graphics/shared/path/ShapePath';
export * from './graphics/shared/svg/parseSVGDefinitions';
export * from './graphics/shared/svg/parseSVGFloatAttribute';
export * from './graphics/shared/svg/parseSVGPath';
export * from './graphics/shared/svg/parseSVGStyle';
export * from './graphics/shared/svg/SVGParser';
export * from './graphics/shared/svg/utils/extractSvgUrlId';
export * from './graphics/shared/utils/buildContextBatches';
export * from './graphics/shared/utils/buildGeometryFromPath';
export * from './graphics/shared/utils/convertFillInputToFillStyle';
export * from './graphics/shared/utils/generateTextureFillMatrix';
export * from './graphics/shared/utils/getOrientationOfPoints';
export * from './graphics/shared/utils/triangulateWithHoles';
export * from './layers/RenderLayer';
export * from './mesh-perspective/PerspectiveMesh';
export * from './mesh-perspective/PerspectivePlaneGeometry';
export * from './mesh-perspective/utils/applyProjectiveTransformationToPlane';
export * from './mesh-perspective/utils/compute2DProjections';
export * from './mesh-plane/MeshPlane';
export * from './mesh-plane/PlaneGeometry';
export * from './mesh-simple/MeshRope';
export * from './mesh-simple/MeshSimple';
export * from './mesh-simple/RopeGeometry';
export * from './mesh/gl/GlMeshAdaptor';
export * from './mesh/gpu/GpuMeshAdapter';
export * from './mesh/shared/BatchableMesh';
export * from './mesh/shared/getTextureDefaultMatrix';
export * from './mesh/shared/Mesh';
export * from './mesh/shared/MeshGeometry';
export * from './mesh/shared/MeshPipe';
export * from './particle-container/gl/GlParticleContainerAdaptor';
export * from './particle-container/gpu/GpuParticleContainerAdaptor';
export * from './particle-container/shared/GlParticleContainerPipe';
export * from './particle-container/shared/GpuParticleContainerPipe';
export * from './particle-container/shared/Particle';
export * from './particle-container/shared/ParticleBuffer';
export * from './particle-container/shared/ParticleContainer';
export * from './particle-container/shared/ParticleContainerPipe';
export * from './particle-container/shared/particleData';
export * from './particle-container/shared/shader/ParticleShader';
export * from './particle-container/shared/utils/createIndicesForQuads';
export * from './particle-container/shared/utils/generateParticleUpdateFunction';
export * from './sprite-animated/AnimatedSprite';
export * from './sprite-nine-slice/NineSliceGeometry';
export * from './sprite-nine-slice/NineSliceSprite';
export * from './sprite-nine-slice/NineSliceSpritePipe';
export * from './sprite-tiling/shader/tilingBit';
export * from './sprite-tiling/shader/TilingSpriteShader';
export * from './sprite-tiling/TilingSprite';
export * from './sprite-tiling/TilingSpritePipe';
export * from './sprite-tiling/utils/applyMatrix';
export * from './sprite-tiling/utils/QuadGeometry';
export * from './sprite-tiling/utils/setPositions';
export * from './sprite-tiling/utils/setUvs';
export * from './sprite/BatchableSprite';
export * from './sprite/Sprite';
export * from './sprite/SpritePipe';
export * from './text-bitmap/AbstractBitmapFont';
export * from './text-bitmap/asset/bitmapFontTextParser';
export * from './text-bitmap/asset/bitmapFontXMLParser';
export * from './text-bitmap/asset/bitmapFontXMLStringParser';
export * from './text-bitmap/asset/loadBitmapFont';
export * from './text-bitmap/BitmapFont';
export * from './text-bitmap/BitmapFontManager';
export * from './text-bitmap/BitmapText';
export * from './text-bitmap/BitmapTextPipe';
export * from './text-bitmap/DynamicBitmapFont';
export * from './text-bitmap/utils/getBitmapTextLayout';
export * from './text-bitmap/utils/resolveCharacters';
export * from './text-html/HTMLText';
export * from './text-html/HTMLTextPipe';
export * from './text-html/HTMLTextRenderData';
export * from './text-html/HTMLTextStyle';
export * from './text-html/HTMLTextSystem';
export * from './text-html/utils/extractFontFamilies';
export * from './text-html/utils/getFontCss';
export * from './text-html/utils/getSVGUrl';
export * from './text-html/utils/getTemporaryCanvasFromImage';
export * from './text-html/utils/loadFontAsBase64';
export * from './text-html/utils/loadFontCSS';
export * from './text-html/utils/loadSVGImage';
export * from './text-html/utils/measureHtmlText';
export * from './text-html/utils/textStyleToCSS';
export * from './text/AbstractText';
export * from './text/canvas/CanvasTextMetrics';
export * from './text/canvas/CanvasTextPipe';
export * from './text/canvas/CanvasTextSystem';
export * from './text/canvas/utils/fontStringFromTextStyle';
export * from './text/canvas/utils/getCanvasFillStyle';
export * from './text/sdfShader/SdfShader';
export * from './text/sdfShader/shader-bits/localUniformMSDFBit';
export * from './text/sdfShader/shader-bits/mSDFBit';
export * from './text/Text';
export * from './text/TextStyle';
export * from './text/utils/ensureTextStyle';
export * from './text/utils/generateTextStyleKey';
export * from './text/utils/getPo2TextureFromSource';
export * from './text/utils/updateTextBounds';
export * from './view/ViewContainer';
export { default as particlesFrag } from './particle-container/shared/shader/particles.frag';
export { default as particlesVert } from './particle-container/shared/shader/particles.vert';
export { default as particlesWgsl } from './particle-container/shared/shader/particles.wgsl';
`,Qp=`import { type InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import { type Renderer } from '../../rendering/renderers/types';
import { type Bounds } from '../container/bounds/Bounds';
import { Container } from '../container/Container';
import type EventEmitter from 'eventemitter3';
/**
 * Options for configuring a RenderLayer.
 * @memberof scene
 */
export interface RenderLayerOptions {
    /**
     * If true, the layer's children will be sorted by zIndex before rendering
     * If false, you can manually sort the children using sortRenderLayerChildren when ever you need!
     * @default false
     */
    sortableChildren?: boolean;
    /**
     * Custom sort function to sort layer children. Default sorts by zIndex.
     * @param a - First container to compare
     * @param b - Second container to compare
     * @returns Negative if a should render before b, positive if b should render before a
     */
    sortFunction?: (a: Container, b: Container) => number;
}
type ContainerKeys = keyof Container;
type PartialContainerKeys = Exclude<ContainerKeys, 'parent' | 'didChange' | '_updateFlags' | keyof EventEmitter | 'parentRenderLayer' | 'destroyed' | 'layerParentId' | 'sortableChildren' | 'getFastGlobalBounds'>;
export type IRenderLayer = Omit<RenderLayerClass, PartialContainerKeys>;
/**
 * The RenderLayer API provides a way to control the rendering order of objects independently
 * of their logical parent-child relationships in the scene graph.
 * This allows developers to decouple how objects are transformed
 * (via their logical parent) from how they are rendered on the screen.
 *
 * ### Key Concepts
 *
 * #### RenderLayers Control Rendering Order:
 * - RenderLayers define where in the render stack objects are drawn,
 * but they do not affect an object's transformations (e.g., position, scale, rotation) or logical hierarchy.
 * - RenderLayers can be added anywhere in the scene graph.
 *
 * #### Logical Parenting Remains Unchanged:
 * - Objects still have a logical parent for transformations via addChild.
 * - Assigning an object to a layer does not reparent it.
 *
 * #### Explicit Control:
 * - Developers assign objects to layers using renderLayer.add and remove them using renderLayer.remove.
 * ---
 * ### API Details
 *
 * #### 1. Creating a RenderLayer
 * A RenderLayer is a lightweight object responsible for controlling render order.
 * It has no children or transformations of its own
 * but can be inserted anywhere in the scene graph to define its render position.
 * \`\`\`js
 * const layer = new RenderLayer();
 * app.stage.addChild(layer); // Insert the layer into the scene graph
 * \`\`\`
 *
 * #### 2. Adding Objects to a Layer
 * Use renderLayer.add to assign an object to a layer.
 * This overrides the object's default render order defined by its logical parent.
 * \`\`\`js
 * const rect = new PIXI.Graphics();
 * container.addChild(rect);    // Add to logical parent
 * layer.attach(rect);      // Control render order via the layer
 * \`\`\`
 *
 * #### 3. Removing Objects from a Layer
 * To stop an object from being rendered in the layer, use remove.
 * \`\`\`js
 * layer.remove(rect); // Stop rendering rect via the layer
 * \`\`\`
 * When an object is removed from its logical parent (removeChild), it is automatically removed from the layer.
 *
 * #### 4. Re-Adding Objects to Layers
 * If an object is re-added to a logical parent, it does not automatically reassign itself to the layer.
 * Developers must explicitly reassign it.
 * \`\`\`js
 * container.addChild(rect);    // Logical parent
 * layer.attach(rect);      // Explicitly reassign to the layer
 * \`\`\`
 *
 * #### 5. Layer Position in Scene Graph
 * A layer's position in the scene graph determines its render priority relative to other layers and objects.
 * Layers can be inserted anywhere in the scene graph.
 * \`\`\`js
 * const backgroundLayer = new RenderLayer();
 * const uiLayer = new RenderLayer();
 *
 * app.stage.addChild(backgroundLayer);
 * app.stage.addChild(world);
 * app.stage.addChild(uiLayer);
 * \`\`\`
 * This is a new API and therefore considered experimental at this stage.
 * While the core is pretty robust, there are still a few tricky issues we need to tackle.
 * However, even with the known issues below, we believe this API is incredibly useful!
 *
 * Known issues:
 *  - Interaction may not work as expected since hit testing does not account for the visual render order created by layers.
 *    For example, if an object is visually moved to the front via a layer, hit testing will still use its original position.
 *  - RenderLayers and their children must all belong to the same renderGroup to work correctly
 * @memberof scene
 * @class RenderLayer
 * @extends null
 */
export declare class RenderLayerClass extends Container {
    /**
     * Default options for RenderLayer instances
     * @property {boolean} sortableChildren - If true, layer children will be automatically sorted each render.
     * Default false.
     * @property {Function} sortFunction - Function used to sort layer children. Default sorts by zIndex.
     */
    static defaultOptions: RenderLayerOptions;
    /** Function used to sort layer children if sortableChildren is true */
    sortFunction: (a: Container, b: Container) => number;
    /** List of objects to be rendered by this layer */
    renderLayerChildren: Container[];
    /**
     * Creates a new RenderLayer instance
     * @param options - Configuration options for the RenderLayer
     * @param {boolean} [options.sortableChildren=false] - If true, layer children will be automatically sorted each render
     * @param {Function} [options.sortFunction] - Custom function to sort layer children. Default sorts by zIndex
     */
    constructor(options?: RenderLayerOptions);
    /**
     * Add an Container to this render layer. The Container will be rendered as part of this layer
     * while maintaining its original parent in the scene graph.
     * If the Container already belongs to a layer, it will be removed from the old layer before being added to this one.
     * @param children - The Container(s) to add to this layer
     */
    attach<U extends Container[]>(...children: U): U[0];
    /**
     * Remove an Container from this render layer. The Container will no longer be rendered
     * as part of this layer but maintains its original parent.
     * @param children - The Container(s) to remove from this layer
     */
    detach<U extends Container[]>(...children: U): U[0];
    /** Remove all objects from this render layer. */
    detachAll(): void;
    collectRenderables(instructionSet: InstructionSet, renderer: Renderer, _currentLayer: RenderLayerClass): void;
    /**
     * Sort the layer's children using the defined sort function.
     * Will be called each render if sortableChildren is true.
     * Otherwise can call this manually.
     */
    sortRenderLayerChildren(): void;
    _getGlobalBoundsRecursive(factorRenderLayers: boolean, bounds: Bounds, _currentLayer: RenderLayerClass): void;
}
export declare const RenderLayer: new (options?: RenderLayerOptions) => IRenderLayer;
export {};
`,Zp=`import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { Mesh } from '../mesh/shared/Mesh';
import { PerspectivePlaneGeometry } from './PerspectivePlaneGeometry';
import type { MeshPlaneOptions } from '../mesh-plane/MeshPlane';
/**
 *
 * Constructor options used for \`PerspectiveMesh\` instances.
 * \`\`\`js
 * const meshPlane = new PerspectiveMesh({
 *  texture: Texture.from('snake.png'),
 *  verticesX: 20,
 *  verticesY: 20,
 *  x0: 0,
 *  y0: 0,
 *  x1: 100,
 *  y1: 0,
 *  x2: 100,
 *  y2: 100,
 *  x3: 0,
 *  y3: 100
 * });
 * @see {@link scene.PerspectiveMesh}
 * @memberof scene
 */
export interface PerspectivePlaneOptions extends MeshPlaneOptions {
    /** top left corner x value */
    x0?: number;
    /** top left corner y value */
    y0?: number;
    /** top right corner x value */
    x1?: number;
    /** top right corner y value */
    y1?: number;
    /** bottom right corner x value */
    x2?: number;
    /** bottom right corner y value */
    y2?: number;
    /** bottom left corner x value */
    x3?: number;
    /** bottom left corner y value */
    y3?: number;
}
/**
 * A perspective mesh that allows you to draw a 2d plane with perspective. Where ever you move the corners
 * the texture will be projected to look like it is in 3d space. Great for mapping a 2D mesh into a 3D scene.
 *
 * The calculations is done at the uv level. This means that the more vertices you have the more smooth
 * the perspective will be. If you have a low amount of vertices you may see the texture stretch. Too many vertices
 * could be slower. It is a balance between performance and quality! We leave that to you to decide.
 *
 * IMPORTANT: This is not a full 3D mesh, it is a 2D mesh with a perspective projection applied to it :)
 * @example
 * \`\`\`js
 * const meshPlane = new PerspectiveMesh({
 *  texture: Texture.from('snake.png'),
 *  verticesX: 20,
 *  verticesY: 20,
 *  x0: 0,
 *  y0: 0,
 *  x1: 100,
 *  y1: 0,
 *  x2: 100,
 *  y2: 100,
 *  x3: 0,
 *  y3: 100
 * });
 * @see {@link scene.PerspectiveMesh}
 * @memberof scene
 */
export declare class PerspectiveMesh extends Mesh<PerspectivePlaneGeometry> {
    /** default options for the mesh */
    static defaultOptions: PerspectivePlaneOptions;
    /**
     * @param options - Options to be applied to PerspectiveMesh
     */
    constructor(options: PerspectivePlaneOptions);
    /** Update the geometry when the texture is updated */
    protected textureUpdated(): void;
    set texture(value: Texture);
    /** The texture that the mesh uses */
    get texture(): Texture;
    /**
     * Set the corners of the quad to the given coordinates
     * The mesh will then calculate the perspective so it looks correct!
     * @param x0 - x coordinate of the first corner
     * @param y0 - y coordinate of the first corner
     * @param x1 - x coordinate of the second corner
     * @param y1 - y coordinate of the second corner
     * @param x2 - x coordinate of the third corner
     * @param y2 - y coordinate of the third corner
     * @param x3 - x coordinate of the fourth corner
     * @param y3 - y coordinate of the fourth corner
     */
    setCorners(x0: number, y0: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): void;
}
`,ec=`import { PlaneGeometry } from '../mesh-plane/PlaneGeometry';
import type { PlaneGeometryOptions } from '../mesh-plane/PlaneGeometry';
/**
 * Constructor options used for \`PerspectivePlaneGeometry\` instances.
 * @memberof scene
 */
export interface PerspectivePlaneGeometryOptions extends PlaneGeometryOptions {
    /** The width of the plane */
    width: number;
    /** The height of the plane */
    height: number;
}
/**
 * A PerspectivePlaneGeometry allows you to draw a 2d plane with perspective. Where ever you move the corners
 * the texture will be projected to look like it is in 3d space. Great for mapping a 2D mesh into a 3D scene.
 *
 * IMPORTANT: This is not a full 3D mesh, it is a 2D mesh with a perspective projection applied to it :)
 *
 * \`\`\`js
 * const perspectivePlaneGeometry = new PerspectivePlaneGeometry({
 *  width: 100,
 *  height: 100,
 *  verticesX: 10,
 *  verticesY: 10,
 * });
 * \`\`\`
 * @see {@link scene.PerspectivePlaneGeometry}
 * @memberof scene
 */
export declare class PerspectivePlaneGeometry extends PlaneGeometry {
    /** The corner points of the quad you can modify these directly, if you do make sure to call \`updateProjection\` */
    corners: [number, number, number, number, number, number, number, number];
    private readonly _projectionMatrix;
    /**
     * @param options - Options to be applied to MeshPlane
     * @param options.width - The width of the plane
     * @param options.height - The height of the plane
     * @param options.verticesX - The amount of vertices on the x axis
     * @param options.verticesY - The amount of vertices on the y axis
     */
    constructor(options: PerspectivePlaneGeometryOptions);
    /**
     * Will set the corners of the quad to the given coordinates
     * Calculating the perspective so it looks correct!
     * @param x0 - x coordinate of the first corner
     * @param y0 - y coordinate of the first corner
     * @param x1 - x coordinate of the second corner
     * @param y1 - y coordinate of the second corner
     * @param x2 - x coordinate of the third corner
     * @param y2 - y coordinate of the third corner
     * @param x3 - x coordinate of the fourth corner
     * @param y3 - y coordinate of the fourth corner
     */
    setCorners(x0: number, y0: number, x1: number, y1: number, x2: number, y2: number, x3: number, y3: number): void;
    /** Update the projection matrix based on the corners */
    updateProjection(): void;
}
`,nc=`import type { ArrayFixed } from '../../../utils/types';
import type { PlaneGeometry } from '../../mesh-plane/PlaneGeometry';
/**
 * Apply a projective transformation to a plane geometry
 * @param width - The width of the plane
 * @param height - The height of the plane
 * @param geometry - The plane geometry to apply the transformation to
 * @param transformationMatrix - The transformation matrix to apply
 */
export declare function applyProjectiveTransformationToPlane(width: number, height: number, geometry: PlaneGeometry, transformationMatrix: ArrayFixed<number, 9>): void;
`,tc=`import type { ArrayFixed } from '../../../utils/types';
type Matrix3x3 = ArrayFixed<number, 9>;
/**
 * Compute a 2D projection matrix
 * @param out - The matrix to store the result in
 * @param x1s - The x coordinate of the first source point
 * @param y1s - The y coordinate of the first source point
 * @param x1d - The x coordinate of the first destination point
 * @param y1d - The y coordinate of the first destination point
 * @param x2s - The x coordinate of the second source point
 * @param y2s - The y coordinate of the second source point
 * @param x2d - The x coordinate of the second destination point
 * @param y2d - The y coordinate of the second destination point
 * @param x3s - The x coordinate of the third source point
 * @param y3s - The y coordinate of the third source point
 * @param x3d - The x coordinate of the third destination point
 * @param y3d - The y coordinate of the third destination point
 * @param x4s - The x coordinate of the fourth source point
 * @param y4s - The y coordinate of the fourth source point
 * @param x4d - The x coordinate of the fourth destination point
 * @param y4d - The y coordinate of the fourth destination point
 * @returns - The computed 2D projection matrix
 * @private
 */
export declare function compute2DProjection(out: Matrix3x3, x1s: number, y1s: number, x1d: number, y1d: number, x2s: number, y2s: number, x2d: number, y2d: number, x3s: number, y3s: number, x3d: number, y3d: number, x4s: number, y4s: number, x4d: number, y4d: number): Matrix3x3;
export {};
`,rc=`import { Mesh } from '../mesh/shared/Mesh';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { DestroyOptions } from '../container/destroyTypes';
import type { MeshOptions } from '../mesh/shared/Mesh';
/**
 * Constructor options used for \`MeshPlane\` instances.
 * \`\`\`js
 * const meshPlane = new MeshPlane({
 *    texture: Texture.from('snake.png'),
 *    verticesX: 20,
 *    verticesY: 20,
 * });
 * \`\`\`
 * @see {@link scene.MeshPlane}
 * @memberof scene
 */
export interface MeshPlaneOptions extends Omit<MeshOptions, 'geometry'> {
    /** The texture to use on the plane. */
    texture: Texture;
    /** The number of vertices in the x-axis */
    verticesX?: number;
    /** The number of vertices in the y-axis */
    verticesY?: number;
}
/**
 * The MeshPlane allows you to draw a texture across several points and then manipulate these points
 * @example
 * import { Point, MeshPlane, Texture } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * }
 * const MeshPlane = new MeshPlane({ texture: Texture.from('snake.png'), verticesX: points });
 * @memberof scene
 */
export declare class MeshPlane extends Mesh {
    /** The geometry is automatically updated when the texture size changes. */
    autoResize: boolean;
    protected _textureID: number;
    /**
     * @param options - Options to be applied to MeshPlane
     */
    constructor(options: MeshPlaneOptions);
    /**
     * Method used for overrides, to do something in case texture frame was changed.
     * Meshes based on plane can override it and change more details based on texture.
     */
    textureUpdated(): void;
    set texture(value: Texture);
    /** The texture of the MeshPlane */
    get texture(): Texture;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
}
`,oc=`import { MeshGeometry } from '../mesh/shared/MeshGeometry';
import type { MeshGeometryOptions } from '../mesh/shared/MeshGeometry';
/**
 * Constructor options used for \`PlaneGeometry\` instances.
 * \`\`\`js
 * const planeGeometry = new PlaneGeometry({
 *    width: 100,
 *    height: 100,
 *    verticesX: 10,
 *    verticesY: 10,
 * });
 * \`\`\`
 * @see {@link scene.PlaneGeometry}
 * @memberof scene
 */
export interface PlaneGeometryOptions {
    /** Width of plane */
    width?: number;
    /** Height of plane */
    height?: number;
    /** Number of vertices on x-axis */
    verticesX?: number;
    /** Number of vertices on y-axis */
    verticesY?: number;
}
/**
 * The PlaneGeometry allows you to draw a 2d plane
 * @memberof scene
 */
export declare class PlaneGeometry extends MeshGeometry {
    static defaultOptions: PlaneGeometryOptions & MeshGeometryOptions;
    /** The number of vertices on x-axis */
    verticesX: number;
    /** The number of vertices on y-axis */
    verticesY: number;
    /** The width of plane */
    width: number;
    /** The height of plane */
    height: number;
    /**
     * @param {PlaneGeometryOptions} options - Options to be applied to plane geometry
     */
    constructor(options: PlaneGeometryOptions);
    /** @deprecated since 8.0.0 */
    constructor(width?: number, height?: number, verticesX?: number, verticesY?: number);
    /**
     * Refreshes plane coordinates
     * @param options - Options to be applied to plane geometry
     */
    build(options: PlaneGeometryOptions): void;
}
`,ac=`import { Mesh } from '../mesh/shared/Mesh';
import type { PointData } from '../../maths/point/PointData';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { MeshOptions } from '../mesh/shared/Mesh';
/**
 * Constructor options used for \`MeshRope\` instances.
 * \`\`\`js
 * const meshRope = new MeshRope({
 *    texture: Texture.from('snake.png'),
 *    points: [new Point(0, 0), new Point(100, 0)],
 *    textureScale: 0,
 * });
 * \`\`\`
 * @see {@link scene.MeshRope}
 * @memberof scene
 */
export interface MeshRopeOptions extends Omit<MeshOptions, 'geometry'> {
    /** The texture to use on the rope. */
    texture: Texture;
    /** An array of points that determine the rope. */
    points: PointData[];
    /**
     * Rope texture scale, if zero then the rope texture is stretched.
     * Positive values scale rope texture
     * keeping its aspect ratio. You can reduce alpha channel artifacts by providing a larger texture
     * and downsampling here. If set to zero, texture will be stretched instead.
     */
    textureScale?: number;
}
/**
 * The rope allows you to draw a texture across several points and then manipulate these points
 * @example
 * import { Point, MeshRope, Texture } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * };
 * const rope = new MeshRope(Texture.from('snake.png'), points);
 * @memberof scene
 */
export declare class MeshRope extends Mesh {
    static defaultOptions: Partial<MeshRopeOptions>;
    /** re-calculate vertices by rope points each frame */
    autoUpdate: boolean;
    /**
     * Note: The wrap mode of the texture is set to REPEAT if \`textureScale\` is positive.
     * @param options
     * @param options.texture - The texture to use on the rope.
     * @param options.points - An array of {@link math.Point} objects to construct this rope.
     * @param {number} options.textureScale - Optional. Positive values scale rope texture
     * keeping its aspect ratio. You can reduce alpha channel artifacts by providing a larger texture
     * and downsampling here. If set to zero, texture will be stretched instead.
     */
    constructor(options: MeshRopeOptions);
    private _render;
}
`,ic=`import { Mesh } from '../mesh/shared/Mesh';
import type { TypedArray } from '../../rendering/renderers/shared/buffer/Buffer';
import type { Topology } from '../../rendering/renderers/shared/geometry/const';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { MeshOptions } from '../mesh/shared/Mesh';
/**
 * Options for the simple mesh.
 * @memberof scene
 */
export interface SimpleMeshOptions extends Omit<MeshOptions, 'geometry'> {
    /** The texture to use */
    texture: Texture;
    /** if you want to specify the vertices */
    vertices?: Float32Array;
    /** if you want to specify the uvs */
    uvs?: Float32Array;
    /** if you want to specify the indices */
    indices?: Uint32Array;
    /** the topology, can be any of the Topology values */
    topology?: Topology;
}
/**
 * The Simple Mesh class mimics Mesh in PixiJS, providing easy-to-use constructor arguments.
 * For more robust customization, use {@link scene.Mesh}.
 * @memberof scene
 */
export declare class MeshSimple extends Mesh {
    /** Upload vertices buffer each frame. */
    autoUpdate: boolean;
    /**
     * @param options - Options to be used for construction
     */
    constructor(options: SimpleMeshOptions);
    /**
     * Collection of vertices data.
     * @type {Float32Array}
     */
    get vertices(): TypedArray;
    set vertices(value: TypedArray);
    private _render;
}
`,sc=`import { MeshGeometry } from '../mesh/shared/MeshGeometry';
import type { PointData } from '../../maths/point/PointData';
import type { MeshGeometryOptions } from '../mesh/shared/MeshGeometry';
/**
 * Constructor options used for \`RopeGeometry\` instances.
 * \`\`\`js
 * const ropeGeometry = new RopeGeometry({
 *    points: [new Point(0, 0), new Point(100, 0)],
 *    width: 10,
 *    textureScale: 0,
 * });
 * \`\`\`
 * @see {@link scene.RopeGeometry}
 * @memberof scene
 */
export interface RopeGeometryOptions {
    /** The width (i.e., thickness) of the rope. */
    width?: number;
    /** An array of points that determine the rope. */
    points?: PointData[];
    /**
     * Rope texture scale, if zero then the rope texture is stretched.
     * By default the rope texture will be stretched to match
     * rope length. If textureScale is positive this value will be treated as a scaling
     * factor and the texture will preserve its aspect ratio instead. To create a tiling rope
     * set baseTexture.wrapMode to 'repeat' and use a power of two texture,
     * then set textureScale=1 to keep the original texture pixel size.
     * In order to reduce alpha channel artifacts provide a larger texture and downsample -
     * i.e. set textureScale=0.5 to scale it down twice.
     */
    textureScale?: number;
}
/**
 * RopeGeometry allows you to draw a geometry across several points and then manipulate these points.
 * @example
 * import { Point, RopeGeometry } from 'pixi.js';
 *
 * for (let i = 0; i < 20; i++) {
 *     points.push(new Point(i * 50, 0));
 * };
 * const rope = new RopeGeometry(100, points);
 * @memberof scene
 */
export declare class RopeGeometry extends MeshGeometry {
    /** Default options for RopeGeometry constructor. */
    static defaultOptions: RopeGeometryOptions & MeshGeometryOptions;
    /** An array of points that determine the rope. */
    points: PointData[];
    /** Rope texture scale, if zero then the rope texture is stretched. */
    readonly textureScale: number;
    /**
     * The width (i.e., thickness) of the rope.
     * @readonly
     */
    _width: number;
    /**
     * @param options - Options to be applied to rope geometry
     */
    constructor(options: RopeGeometryOptions);
    /**
     * The width (i.e., thickness) of the rope.
     * @readonly
     */
    get width(): number;
    /** Refreshes Rope indices and uvs */
    private _build;
    /** refreshes vertices of Rope mesh */
    updateVertices(): void;
    /** Refreshes Rope indices and uvs */
    update(): void;
}
`,lc=`declare global
{
    namespace PixiMixins
    {
        interface RendererPipes
        {
            mesh: import('./shared/MeshPipe').MeshPipe;
        }
    }
}
export {};
`,dc=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Mesh } from '../shared/Mesh';
import type { MeshAdaptor, MeshPipe } from '../shared/MeshPipe';
/**
 * A MeshAdaptor that uses the WebGL to render meshes.
 * @memberof rendering
 * @ignore
 */
export declare class GlMeshAdaptor implements MeshAdaptor {
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipesAdaptor];
        readonly name: "mesh";
    };
    private _shader;
    init(): void;
    execute(meshPipe: MeshPipe, mesh: Mesh): void;
    destroy(): void;
}
`,pc=`import { ExtensionType } from '../../../extensions/Extensions';
import type { Mesh } from '../shared/Mesh';
import type { MeshAdaptor, MeshPipe } from '../shared/MeshPipe';
/**
 * The WebGL adaptor for the mesh system. Allows the Mesh System to be used with the WebGl renderer
 * @memberof rendering
 * @ignore
 */
export declare class GpuMeshAdapter implements MeshAdaptor {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUPipesAdaptor];
        readonly name: "mesh";
    };
    private _shader;
    init(): void;
    execute(meshPipe: MeshPipe, mesh: Mesh): void;
    destroy(): void;
}
`,cc=`export {};
`,uc=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Batch, Batcher } from '../../../rendering/batcher/shared/Batcher';
import type { DefaultBatchableMeshElement } from '../../../rendering/batcher/shared/DefaultBatcher';
import type { Topology } from '../../../rendering/renderers/shared/geometry/const';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { ViewContainer } from '../../view/ViewContainer';
import type { MeshGeometry } from './MeshGeometry';
/**
 * A batchable mesh object.
 * @ignore
 */
export declare class BatchableMesh implements DefaultBatchableMeshElement {
    batcherName: string;
    _topology: Topology;
    readonly packAsQuad = false;
    location: number;
    renderable: ViewContainer;
    indexOffset: number;
    attributeOffset: number;
    texture: Texture;
    geometry: MeshGeometry;
    transform: Matrix;
    roundPixels: 0 | 1;
    _attributeStart: number;
    _batcher: Batcher;
    _batch: Batch;
    _indexStart: number;
    _textureId: number;
    _textureMatrixUpdateId: number;
    private _transformedUvs;
    private _uvUpdateId;
    get blendMode(): import("../../..").BLEND_MODES;
    get topology(): Topology;
    set topology(value: Topology);
    reset(): void;
    /**
     * Sets the texture for the batchable mesh.
     * As it does so, it resets the texture matrix update ID.
     * this is to ensure that the texture matrix is recalculated when the uvs are referenced
     * @param value - The texture to set.
     */
    setTexture(value: Texture): void;
    get uvs(): Float32Array;
    get positions(): Float32Array;
    get indices(): Uint32Array;
    get color(): number;
    get groupTransform(): Matrix;
    get attributeSize(): number;
    get indexSize(): number;
}
`,mc=`import { Geometry } from '../../../rendering/renderers/shared/geometry/Geometry';
import { State } from '../../../rendering/renderers/shared/state/State';
import { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import { ViewContainer } from '../../view/ViewContainer';
import { MeshGeometry } from './MeshGeometry';
import type { PointData } from '../../../maths/point/PointData';
import type { Topology } from '../../../rendering/renderers/shared/geometry/const';
import type { Instruction } from '../../../rendering/renderers/shared/instructions/Instruction';
import type { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { View } from '../../../rendering/renderers/shared/view/View';
import type { ContainerOptions } from '../../container/Container';
import type { DestroyOptions } from '../../container/destroyTypes';
export interface TextureShader extends Shader {
    texture: Texture;
}
/**
 * Constructor options used for \`Mesh\` instances. Extends {@link scene.MeshViewOptions}
 * \`\`\`js
 * const mesh = new Mesh({
 *    texture: Texture.from('assets/image.png'),
 *    geometry: new PlaneGeometry(),
 *    shader: Shader.from(VERTEX, FRAGMENT),
 * });
 * \`\`\`
 * @see {@link scene.Mesh}
 * @see {@link scene.MeshViewOptions}
 * @memberof scene
 */
/**
 * @memberof scene
 */
export interface MeshOptions<GEOMETRY extends Geometry = MeshGeometry, SHADER extends Shader = TextureShader> extends PixiMixins.MeshOptions, ContainerOptions {
    /**
     * Includes vertex positions, face indices, colors, UVs, and
     * custom attributes within buffers, reducing the cost of passing all
     * this data to the GPU. Can be shared between multiple Mesh objects.
     */
    geometry: GEOMETRY;
    /**
     * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
     * Can be shared between multiple Mesh objects.
     */
    shader?: SHADER | null;
    /** The state of WebGL required to render the mesh. */
    state?: State;
    /** The texture that the Mesh uses. Null for non-MeshMaterial shaders */
    texture?: Texture;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
}
export interface Mesh extends PixiMixins.Mesh, ViewContainer {
}
/**
 * Base mesh class.
 *
 * This class empowers you to have maximum flexibility to render any kind of WebGL/WebGPU visuals you can think of.
 * This class assumes a certain level of WebGL/WebGPU knowledge.
 * If you know a bit this should abstract enough away to make your life easier!
 *
 * Pretty much ALL WebGL/WebGPU can be broken down into the following:
 * - Geometry - The structure and data for the mesh. This can include anything from positions, uvs, normals, colors etc..
 * - Shader - This is the shader that PixiJS will render the geometry with (attributes in the shader must match the geometry)
 * - State - This is the state of WebGL required to render the mesh.
 *
 * Through a combination of the above elements you can render anything you want, 2D or 3D!
 * @memberof scene
 */
export declare class Mesh<GEOMETRY extends Geometry = MeshGeometry, SHADER extends Shader = TextureShader> extends ViewContainer implements View, Instruction {
    readonly renderPipeId: string;
    state: State;
    /** @ignore */
    _texture: Texture;
    /** @ignore */
    _geometry: GEOMETRY;
    /** @ignore */
    _shader: SHADER | null;
    /**
     * @param {scene.MeshOptions} options - options for the mesh instance
     */
    constructor(options: MeshOptions<GEOMETRY, SHADER>);
    /** @deprecated since 8.0.0 */
    constructor(geometry: GEOMETRY, shader: SHADER, state?: State, drawMode?: Topology);
    /** Alias for {@link scene.Mesh#shader}. */
    get material(): SHADER;
    /**
     * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
     * Can be shared between multiple Mesh objects.
     */
    set shader(value: SHADER | null);
    get shader(): SHADER | null;
    /**
     * Includes vertex positions, face indices, colors, UVs, and
     * custom attributes within buffers, reducing the cost of passing all
     * this data to the GPU. Can be shared between multiple Mesh objects.
     */
    set geometry(value: GEOMETRY);
    get geometry(): GEOMETRY;
    /** The texture that the Mesh uses. Null for non-MeshMaterial shaders */
    set texture(value: Texture);
    get texture(): Texture;
    get batched(): boolean;
    /**
     * The local bounds of the mesh.
     * @type {rendering.Bounds}
     */
    get bounds(): import("../..").Bounds;
    /**
     * Update local bounds of the mesh.
     * @private
     */
    protected updateBounds(): void;
    /**
     * Checks if the object contains the given point.
     * @param point - The point to check
     */
    containsPoint(point: PointData): boolean;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
}
`,hc=`import { Geometry } from '../../../rendering/renderers/shared/geometry/Geometry';
import type { Topology } from '../../../rendering/renderers/shared/geometry/const';
import type { BatchMode } from '../../graphics/shared/GraphicsContext';
/**
 * Options for the mesh geometry.
 * @memberof scene
 */
export interface MeshGeometryOptions {
    /** The positions of the mesh. */
    positions?: Float32Array;
    /** The UVs of the mesh. If not provided, they will be filled with 0 and match the size of the positions. */
    uvs?: Float32Array;
    /** The indices of the mesh. */
    indices?: Uint32Array;
    /** The topology of the mesh. */
    topology?: Topology;
    /** Whether to shrink the buffers to fit the data. */
    shrinkBuffersToFit?: boolean;
}
/**
 * A geometry used to batch multiple meshes with the same texture.
 * @memberof scene
 */
export declare class MeshGeometry extends Geometry {
    static defaultOptions: MeshGeometryOptions;
    batchMode: BatchMode;
    /**
     * @param {scene.MeshGeometryOptions} options - The options of the mesh geometry.
     */
    constructor(options: MeshGeometryOptions);
    /** @deprecated since 8.0.0 */
    constructor(positions: Float32Array, uvs: Float32Array, indices: Uint32Array);
    /** The positions of the mesh. */
    get positions(): Float32Array;
    /**
     * Set the positions of the mesh.
     * When setting the positions, its important that the uvs array is at least as long as the positions array.
     * otherwise the geometry will not be valid.
     * @param {Float32Array} value - The positions of the mesh.
     */
    set positions(value: Float32Array);
    /** The UVs of the mesh. */
    get uvs(): Float32Array;
    /**
     * Set the UVs of the mesh.
     * Its important that the uvs array you set is at least as long as the positions array.
     * otherwise the geometry will not be valid.
     * @param {Float32Array} value - The UVs of the mesh.
     */
    set uvs(value: Float32Array);
    /** The indices of the mesh. */
    get indices(): Uint32Array;
    set indices(value: Uint32Array);
}
`,fc=`import { ExtensionType } from '../../../extensions/Extensions';
import { Matrix } from '../../../maths/matrix/Matrix';
import { BindGroup } from '../../../rendering/renderers/gpu/shader/BindGroup';
import { UniformGroup } from '../../../rendering/renderers/shared/shader/UniformGroup';
import type { InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import type { InstructionPipe, RenderPipe } from '../../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../../rendering/renderers/types';
import type { Mesh } from './Mesh';
export interface MeshAdaptor {
    init(): void;
    execute(meshPipe: MeshPipe, mesh: Mesh): void;
    destroy(): void;
}
export declare class MeshPipe implements RenderPipe<Mesh>, InstructionPipe<Mesh> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "mesh";
    };
    localUniforms: UniformGroup<{
        uTransformMatrix: {
            value: Matrix;
            type: "mat3x3<f32>";
        };
        uColor: {
            value: Float32Array;
            type: "vec4<f32>";
        };
        uRound: {
            value: number;
            type: "f32";
        };
    }>;
    localUniformsBindGroup: BindGroup;
    renderer: Renderer;
    private _meshDataHash;
    private _gpuBatchableMeshHash;
    private _adaptor;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer, adaptor: MeshAdaptor);
    validateRenderable(mesh: Mesh): boolean;
    addRenderable(mesh: Mesh, instructionSet: InstructionSet): void;
    updateRenderable(mesh: Mesh): void;
    destroyRenderable(mesh: Mesh): void;
    execute(mesh: Mesh): void;
    private _getMeshData;
    private _initMeshData;
    private _getBatchableMesh;
    private _initBatchableMesh;
    destroy(): void;
}
`,bc=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
export declare function getTextureDefaultMatrix(texture: Texture, out: Matrix): Matrix;
`,gc=`declare global
{
    namespace PixiMixins
    {
        interface RendererPipes
        {
            particle: import('./shared/ParticleContainerPipe').ParticleContainerPipe;
        }
    }
}
export {};
`,yc=`import type { ParticleContainer } from '../shared/ParticleContainer';
import type { ParticleContainerAdaptor, ParticleContainerPipe } from '../shared/ParticleContainerPipe';
export declare class GlParticleContainerAdaptor implements ParticleContainerAdaptor {
    execute(particleContainerPipe: ParticleContainerPipe, container: ParticleContainer): void;
}
`,xc=`import type { ParticleContainer } from '../shared/ParticleContainer';
import type { ParticleContainerAdaptor, ParticleContainerPipe } from '../shared/ParticleContainerPipe';
export declare class GpuParticleContainerAdaptor implements ParticleContainerAdaptor {
    execute(particleContainerPipe: ParticleContainerPipe, container: ParticleContainer): void;
}
`,vc=`export {};
`,Tc=`import { ExtensionType } from '../../../extensions/Extensions';
import { ParticleContainerPipe } from './ParticleContainerPipe';
import type { WebGLRenderer } from '../../../rendering/renderers/gl/WebGLRenderer';
export declare class GlParticleContainerPipe extends ParticleContainerPipe {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes];
        readonly name: "particle";
    };
    constructor(renderer: WebGLRenderer);
}
`,Sc=`import { ExtensionType } from '../../../extensions/Extensions';
import { ParticleContainerPipe } from './ParticleContainerPipe';
import type { WebGPURenderer } from '../../../rendering/renderers/gpu/WebGPURenderer';
export declare class GpuParticleContainerPipe extends ParticleContainerPipe {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGPUPipes];
        readonly name: "particle";
    };
    constructor(renderer: WebGPURenderer);
}
`,wc=`import { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { ColorSource } from '../../../color/Color';
/**
 * Represents a particle with properties for position, scale, rotation, color, and texture.
 * @property {number} x - The x-coordinate of the particle.
 * @property {number} y - The y-coordinate of the particle.
 * @property {number} scaleX - The scale factor in the x-axis.
 * @property {number} scaleY - The scale factor in the y-axis.
 * @property {number} anchorX - The x-coordinate of the anchor point.
 * @property {number} anchorY - The y-coordinate of the anchor point.
 * @property {number} rotation - The rotation of the particle in radians.
 * @property {number} color - The color of the particle as a hexadecimal number.
 * @property {Texture} texture - The texture of the particle.
 * @memberof scene
 */
export interface IParticle {
    x: number;
    y: number;
    scaleX: number;
    scaleY: number;
    anchorX: number;
    anchorY: number;
    rotation: number;
    color: number;
    texture: Texture;
}
/**
 * Represents the options for creating a new particle.
 * @property {number} x - The x-coordinate of the particle.
 * @property {number} y - The y-coordinate of the particle.
 * @property {number} scaleX - The scale factor in the x-axis.
 * @property {number} scaleY - The scale factor in the y-axis.
 * @property {number} anchorX - The x-coordinate of the anchor point.
 * @property {number} anchorY - The y-coordinate of the anchor point.
 * @property {number} rotation - The rotation of the particle in radians.
 * @property {Texture} texture - The texture of the particle.
 * @property {ColorSource} tint - The tint color of the particle as a hexadecimal number.
 * @property {number} alpha - The alpha value of the particle.
 * @memberof scene
 */
export type ParticleOptions = Omit<Partial<IParticle>, 'color'> & {
    texture: Texture;
    tint?: ColorSource;
    alpha?: number;
};
/**
 * Represents a single particle within a particle container. This class implements the IParticle interface,
 * providing properties and methods to manage the particle's position, scale, rotation, color, and texture.
 *
 * The reason we use a particle over a sprite is that these are much lighter weight and we can create a lot of them
 * without taking on the overhead of a full sprite.
 *
 * Here is an example of how to create a new particle:
 *
 * \`\`\`javascript
 * const particle = new Particle({
 *   texture,
 *   x: 100,
 *   y: 100,
 *   scaleX: 0.5,
 *   scaleY: 0.5,
 *   rotation: Math.PI / 2,
 *   color: 0xff0000,
 * });
 * \`\`\`
 * @implements {IParticle}
 * @memberof scene
 */
export declare class Particle implements IParticle {
    /** Default options for constructing with options */
    static defaultOptions: Partial<ParticleOptions>;
    /** The x-coordinate of the anchor point. */
    anchorX: number;
    /** The y-coordinate of the anchor point. */
    anchorY: number;
    /** The x-coordinate of the particle. */
    x: number;
    /** The y-coordinate of the particle. */
    y: number;
    /** The scale factor in the x-axis. */
    scaleX: number;
    /** The scale factor in the y-axis. */
    scaleY: number;
    /** The rotation of the particle in radians. */
    rotation: number;
    /** The color of the particle as a hexadecimal number. */
    color: number;
    /** The texture of the particle. */
    texture: Texture;
    private _alpha;
    private _tint;
    constructor(options: Texture | ParticleOptions);
    /** Gets or sets the alpha value of the particle. */
    get alpha(): number;
    set alpha(value: number);
    /** Gets or sets the tint color of the particle. */
    get tint(): number;
    set tint(value: ColorSource);
    private _updateColor;
}
`,_c=`import { Geometry } from '../../../rendering/renderers/shared/geometry/Geometry';
import { ViewableBuffer } from '../../../utils/data/ViewableBuffer';
import type { IndexBufferArray } from '../../../rendering/renderers/shared/geometry/Geometry';
import type { IParticle } from './Particle';
import type { ParticleRendererProperty } from './particleData';
import type { ParticleUpdateFunction } from './utils/generateParticleUpdateFunction';
/**
 * Options for creating a ParticleBuffer.
 * @property {number} size - The size of the particle buffer.
 * @property {Record<string, ParticleRendererProperty>} properties - A record of attributes that the particle container uses.
 */
export interface ParticleBufferOptions {
    size: number;
    properties: Record<string, ParticleRendererProperty>;
}
/**
 * The ParticleBuffer holds the buffers and geometry for a particle container.
 * It also contains the upload functions for the static and dynamic properties.
 * @internal
 */
export declare class ParticleBuffer {
    /** The buffer containing static attribute data for all elements in the batch. */
    staticAttributeBuffer: ViewableBuffer;
    /** The buffer containing dynamic attribute data for all elements in the batch. */
    dynamicAttributeBuffer: ViewableBuffer;
    private readonly _staticBuffer;
    private readonly _dynamicBuffer;
    /** The buffer containing index data for all elements in the batch. */
    indexBuffer: IndexBufferArray;
    private readonly _dynamicStride;
    private readonly _staticStride;
    /** The geometry of the particle buffer. */
    readonly geometry: Geometry;
    private _size;
    private readonly _dynamicUpload;
    private readonly _staticUpload;
    private readonly _generateParticleUpdateCache;
    constructor(options: ParticleBufferOptions);
    getParticleUpdate(properties: Record<string, ParticleRendererProperty>): {
        dynamicUpdate: ParticleUpdateFunction;
        staticUpdate: ParticleUpdateFunction;
    };
    generateParticleUpdate(properties: Record<string, ParticleRendererProperty>): {
        dynamicUpdate: ParticleUpdateFunction;
        staticUpdate: ParticleUpdateFunction;
    };
    update(particles: IParticle[], uploadStatic: boolean): void;
    destroy(): void;
}
`,Ec=`import { Bounds } from '../../container/bounds/Bounds';
import { type IRenderLayer } from '../../layers/RenderLayer';
import { ViewContainer, type ViewContainerOptions } from '../../view/ViewContainer';
import type { Instruction } from '../../../rendering/renderers/shared/instructions/Instruction';
import type { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { ContainerChild } from '../../container/Container';
import type { DestroyOptions } from '../../container/destroyTypes';
import type { IParticle } from './Particle';
import type { ParticleRendererProperty } from './particleData';
/**
 * Represents the properties of a particle that can be dynamically updated.
 * @property {boolean} [vertices] - Indicates if vertices are dynamic.
 * @property {boolean} [position] - Indicates if position is dynamic.
 * @property {boolean} [rotation] - Indicates if rotation is dynamic.
 * @property {boolean} [uvs] - Indicates if UVs are dynamic.
 * @property {boolean} [color] - Indicates if color is dynamic.
 * @memberof scene
 */
export interface ParticleProperties {
    vertex?: boolean;
    position?: boolean;
    rotation?: boolean;
    uvs?: boolean;
    color?: boolean;
}
/**
 * Options for the ParticleContainer constructor.
 * @extends ContainerOptions
 * @property {Record<string, boolean>} dynamicProperties - Specifies which properties are dynamic.
 * @property {Shader} shader - The shader to use for rendering.
 * @property {boolean} roundPixels - Indicates if pixels should be rounded.
 * @property {Texture} texture - The texture to use for rendering - if not provided the texture of the first child is used.
 * @property {IParticle[]} particles - An array of particles to add to the container.
 * @memberof scene
 */
export interface ParticleContainerOptions extends PixiMixins.ParticleContainerOptions, Omit<ViewContainerOptions, 'children'> {
    dynamicProperties?: Record<string, boolean>;
    shader?: Shader;
    roundPixels?: boolean;
    texture?: Texture;
    particles?: IParticle[];
}
export interface ParticleContainer extends PixiMixins.ParticleContainer, ViewContainer {
}
/**
 * The ParticleContainer class is a highly optimized container that can render 1000s or particles at great speed.
 *
 * A ParticleContainer is specialized in that it can only contain and render particles. Particles are
 * lightweight objects that use minimal memory, which helps boost performance.
 *
 * It can render particles EXTREMELY fast!
 *
 * The tradeoff of using a ParticleContainer is that most advanced functionality is unavailable. Particles are simple
 * and cannot have children, filters, masks, etc. They possess only the basic properties: position, scale, rotation,
 * and color.
 *
 * All particles must share the same texture source (using something like a sprite sheet works well here).
 *
 * When creating a ParticleContainer, a developer can specify which of these properties are static and which are dynamic.
 * - Static properties are only updated when you add or remove a child, or when the \`update\` function is called.
 * - Dynamic properties are updated every frame.
 *
 * It is up to the developer to specify which properties are static and which are dynamic. Generally, the more static
 * properties you have (i.e., those that do not change per frame), the faster the rendering.
 *
 * If the developer modifies the children order or any static properties of the particle, they must call the \`update\` method.
 *
 * By default, only the \`position\` property is set to dynamic, which makes rendering very fast!
 *
 * Developers can also provide a custom shader to the particle container, allowing them to render particles in a custom way.
 *
 * To help with performance, the particle containers bounds are not calculated.
 * It's up to the developer to set the boundsArea property.
 *
 * It's extremely easy to use. Below is an example of rendering thousands of sprites at lightning speed.
 *
 * --------- EXPERIMENTAL ---------
 *
 * This is a new API, things may change and it may not work as expected.
 * We want to hear your feedback as we go!
 *
 * --------------------------------
 * @example
 * import { ParticleContainer, Particle } from 'pixi.js';
 *
 * const container = new ParticleContainer();
 *
 * for (let i = 0; i < 100; ++i)
 * {
 *     let particle = new Particle(texture);
 *     container.addParticle(particle);
 * }
 * @memberof scene
 */
export declare class ParticleContainer extends ViewContainer implements Instruction {
    /**
     * Defines the default options for creating a ParticleContainer.
     * @property {Record<string, boolean>} dynamicProperties - Specifies which properties are dynamic.
     * @property {boolean} roundPixels - Indicates if pixels should be  rounded.
     */
    static defaultOptions: ParticleContainerOptions;
    /** The unique identifier for the render pipe of this ParticleContainer. */
    readonly renderPipeId: string;
    batched: boolean;
    /**
     * A record of properties and their corresponding ParticleRendererProperty.
     * @internal
     */
    _properties: Record<string, ParticleRendererProperty>;
    /** Indicates if the children of this ParticleContainer have changed and need to be updated. */
    _childrenDirty: boolean;
    /**
     * An array of particles that are children of this ParticleContainer.
     * it can be modified directly, after which the 'update' method must be called.
     * to ensure the container is rendered correctly.
     */
    particleChildren: IParticle[];
    /** The shader used for rendering particles in this ParticleContainer. */
    shader: Shader;
    /**
     * The texture used for rendering particles in this ParticleContainer.
     * Defaults to the first childs texture if not set
     */
    texture: Texture;
    /**
     * @param options - The options for creating the sprite.
     */
    constructor(options?: ParticleContainerOptions);
    /**
     * Adds one or more particles to the container.
     *
     * Multiple items can be added like so: \`myContainer.addParticle(thingOne, thingTwo, thingThree)\`
     * @param {...IParticle} children - The Particle(s) to add to the container
     * @returns {IParticle} - The first child that was added.
     */
    addParticle(...children: IParticle[]): IParticle;
    /**
     * Removes one or more particles from the container.
     * @param {...IParticle} children - The Particle(s) to remove
     * @returns {IParticle} The first child that was removed.
     */
    removeParticle(...children: IParticle[]): IParticle;
    /**
     * Updates the particle container.
     * Please call this when you modify the particleChildren array.
     * or any static properties of the particles.
     */
    update(): void;
    protected onViewUpdate(): void;
    /**
     * ParticleContainer does not calculated bounds as it would slow things down,
     * its up to you to set this via the boundsArea property
     */
    get bounds(): Bounds;
    /** @private */
    protected updateBounds(): void;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
    /**
     * Removes all particles from this container that are within the begin and end indexes.
     * @param beginIndex - The beginning position.
     * @param endIndex - The ending position. Default value is size of the container.
     * @returns - List of removed particles
     */
    removeParticles(beginIndex?: number, endIndex?: number): IParticle[];
    /**
     * Removes a particle from the specified index position.
     * @param index - The index to get the particle from
     * @returns The particle that was removed.
     */
    removeParticleAt<U extends IParticle>(index: number): U;
    /**
     * Adds a particle to the container at a specified index. If the index is out of bounds an error will be thrown.
     * If the particle is already in this container, it will be moved to the specified index.
     * @param {Container} child - The particle to add.
     * @param {number} index - The absolute index where the particle will be positioned at the end of the operation.
     * @returns {Container} The particle that was added.
     */
    addParticleAt<U extends IParticle>(child: U, index: number): U;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.addParticle()\` instead.
     * @param {...any} _children
     * @throws {Error} Always throws an error as this method is not available.
     */
    addChild<U extends (ContainerChild | IRenderLayer)[]>(..._children: U): U[0];
    /**
     * This method is not available in ParticleContainer.
     * Calling this method will throw an error. Please use \`ParticleContainer.removeParticle()\` instead.
     * @param {...any} _children
     * @throws {Error} Always throws an error as this method is not available.
     */
    removeChild<U extends (ContainerChild | IRenderLayer)[]>(..._children: U): U[0];
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.removeParticles()\` instead.
     * @param {number} [_beginIndex]
     * @param {number} [_endIndex]
     * @throws {Error} Always throws an error as this method is not available.
     */
    removeChildren(_beginIndex?: number, _endIndex?: number): ContainerChild[];
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.removeParticleAt()\` instead.
     * @param {number} _index
     * @throws {Error} Always throws an error as this method is not available.
     */
    removeChildAt<U extends (ContainerChild | IRenderLayer)>(_index: number): U;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.getParticleAt()\` instead.
     * @param {number} _index
     * @throws {Error} Always throws an error as this method is not available.
     */
    getChildAt<U extends (ContainerChild | IRenderLayer)>(_index: number): U;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.setParticleIndex()\` instead.
     * @param {ContainerChild} _child
     * @param {number} _index
     * @throws {Error} Always throws an error as this method is not available.
     */
    setChildIndex(_child: ContainerChild, _index: number): void;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.getParticleIndex()\` instead.
     * @param {ContainerChild} _child
     * @throws {Error} Always throws an error as this method is not available.
     */
    getChildIndex(_child: ContainerChild): number;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.addParticleAt()\` instead.
     * @param {ContainerChild} _child
     * @param {number} _index
     * @throws {Error} Always throws an error as this method is not available.
     */
    addChildAt<U extends (ContainerChild | IRenderLayer)>(_child: U, _index: number): U;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error. Please use \`ParticleContainer.swapParticles()\` instead.
     * @param {ContainerChild} _child
     * @param {ContainerChild} _child2
     */
    swapChildren<U extends (ContainerChild | IRenderLayer)>(_child: U, _child2: U): void;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error.
     * @param _child - The child to reparent
     * @throws {Error} Always throws an error as this method is not available.
     */
    reparentChild(..._child: ContainerChild[]): any;
    /**
     * This method is not available in ParticleContainer.
     *
     * Calling this method will throw an error.
     * @param _child - The child to reparent
     * @param _index - The index to reparent the child to
     * @throws {Error} Always throws an error as this method is not available.
     */
    reparentChildAt(_child: ContainerChild, _index: number): any;
}
`,Pc=`import { Matrix } from '../../../maths/matrix/Matrix';
import { UniformGroup } from '../../../rendering/renderers/shared/shader/UniformGroup';
import { State } from '../../../rendering/renderers/shared/state/State';
import { ParticleBuffer } from './ParticleBuffer';
import type { InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../../rendering/renderers/shared/instructions/RenderPipe';
import type { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import type { Renderer } from '../../../rendering/renderers/types';
import type { ParticleContainer } from './ParticleContainer';
export interface ParticleContainerAdaptor {
    execute(particleContainerPop: ParticleContainerPipe, container: ParticleContainer): void;
}
/**
 * Renderer for Particles that is designer for speed over feature set.
 * @memberof scene
 */
export declare class ParticleContainerPipe implements RenderPipe<ParticleContainer> {
    /** The default shader that is used if a sprite doesn't have a more specific one. */
    defaultShader: Shader;
    adaptor: ParticleContainerAdaptor;
    readonly state: State;
    readonly renderer: Renderer;
    private _gpuBufferHash;
    private readonly _destroyRenderableBound;
    readonly localUniforms: UniformGroup<{
        uTranslationMatrix: {
            value: Matrix;
            type: "mat3x3<f32>";
        };
        uColor: {
            value: Float32Array;
            type: "vec4<f32>";
        };
        uRound: {
            value: number;
            type: "f32";
        };
        uResolution: {
            value: number[];
            type: "vec2<f32>";
        };
    }>;
    /**
     * @param renderer - The renderer this sprite batch works for.
     * @param adaptor
     */
    constructor(renderer: Renderer, adaptor: ParticleContainerAdaptor);
    validateRenderable(_renderable: ParticleContainer): boolean;
    addRenderable(renderable: ParticleContainer, instructionSet: InstructionSet): void;
    getBuffers(renderable: ParticleContainer): ParticleBuffer;
    private _initBuffer;
    updateRenderable(_renderable: ParticleContainer): void;
    destroyRenderable(renderable: ParticleContainer): void;
    execute(container: ParticleContainer): void;
    /** Destroys the ParticleRenderer. */
    destroy(): void;
}
`,Ac=`import type { VertexFormat } from '../../../rendering/renderers/shared/geometry/const';
import type { IParticle } from './Particle';
export interface ParticleRendererProperty {
    attributeName: string;
    format: VertexFormat;
    code: string;
    dynamic: boolean;
    updateFunction?: (ps: IParticle[], f32v: Float32Array, u32v: Uint32Array, offset: number, stride: number) => void;
}
export declare const particleData: Record<string, ParticleRendererProperty>;
`,Cc=`import { Shader } from '../../../../rendering/renderers/shared/shader/Shader';
export declare class ParticleShader extends Shader {
    constructor();
}
`,Rc=`/**
 * Generic Mask Stack data structure
 * @function createIndicesForQuads
 * @param {number} size - Number of quads
 * @param {Uint16Array|Uint32Array} [outBuffer] - Buffer for output, length has to be \`6 * size\`
 * @returns {Uint16Array|Uint32Array} - Resulting index buffer
 */
export declare function createIndicesForQuads(size: number, outBuffer?: Uint16Array | Uint32Array | null): Uint16Array | Uint32Array;
`,Gc=`import type { IParticle } from '../Particle';
import type { ParticleRendererProperty } from '../particleData';
export type ParticleUpdateFunction = (ps: IParticle[], f32v: Float32Array, u32v: Uint32Array) => void;
export declare function generateParticleUpdateFunction(properties: Record<string, ParticleRendererProperty>): {
    dynamicUpdate: ParticleUpdateFunction;
    staticUpdate: ParticleUpdateFunction;
};
`,Mc=`import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { Ticker } from '../../ticker/Ticker';
import { Sprite } from '../sprite/Sprite';
import type { SpriteOptions } from '../sprite/Sprite';
export type AnimatedSpriteFrames = Texture[] | FrameObject[];
/**
 * Constructor options used for \`AnimatedSprite\` instances.
 * @see {@link scene.AnimatedSprite}
 * @memberof scene
 */
export interface AnimatedSpriteOptions extends PixiMixins.AnimatedSpriteOptions, Omit<SpriteOptions, 'texture'> {
    /** The speed that the AnimatedSprite will play at. Higher is faster, lower is slower. */
    animationSpeed?: number;
    /** Whether to start the animation immediately on creation. */
    autoPlay?: boolean;
    /** Whether to use Ticker.shared to auto update animation time. */
    autoUpdate?: boolean;
    /** Whether or not the animate sprite repeats after playing. */
    loop?: boolean;
    /** User-assigned function to call when an AnimatedSprite finishes playing. */
    onComplete?: () => void;
    /** User-assigned function to call when an AnimatedSprite changes which texture is being rendered. */
    onFrameChange?: (currentFrame: number) => void;
    /**
     * User-assigned function to call when \`loop\` is true, and an AnimatedSprite is played and loops around to start again.
     */
    onLoop?: () => void;
    /** An array of {@link Texture} or frame objects that make up the animation. */
    textures: AnimatedSpriteFrames;
    /** Update anchor to [Texture's defaultAnchor]{@link Texture#defaultAnchor} when frame changes. */
    updateAnchor?: boolean;
}
export interface AnimatedSprite extends PixiMixins.AnimatedSprite, Sprite {
}
/**
 * An AnimatedSprite is a simple way to display an animation depicted by a list of textures.
 *
 * \`\`\`js
 * import { AnimatedSprite, Texture } from 'pixi.js';
 *
 * const alienImages = [
 *     'image_sequence_01.png',
 *     'image_sequence_02.png',
 *     'image_sequence_03.png',
 *     'image_sequence_04.png',
 * ];
 * const textureArray = [];
 *
 * for (let i = 0; i < 4; i++)
 * {
 *     const texture = Texture.from(alienImages[i]);
 *     textureArray.push(texture);
 * }
 *
 * const animatedSprite = new AnimatedSprite(textureArray);
 * \`\`\`
 *
 * The more efficient and simpler way to create an animated sprite is using a {@link Spritesheet}
 * containing the animation definitions:
 * @example
 * import { AnimatedSprite, Assets } from 'pixi.js';
 *
 * const sheet = await Assets.load('assets/spritesheet.json');
 * animatedSprite = new AnimatedSprite(sheet.animations['image_sequence']);
 * @memberof scene
 */
export declare class AnimatedSprite extends Sprite {
    /**
     * The speed that the AnimatedSprite will play at. Higher is faster, lower is slower.
     * @default 1
     */
    animationSpeed: number;
    /**
     * Whether or not the animate sprite repeats after playing.
     * @default true
     */
    loop: boolean;
    /**
     * Update anchor to [Texture's defaultAnchor]{@link Texture#defaultAnchor} when frame changes.
     *
     * Useful with [sprite sheet animations]{@link Spritesheet#animations} created with tools.
     * Changing anchor for each frame allows to pin sprite origin to certain moving feature
     * of the frame (e.g. left foot).
     *
     * Note: Enabling this will override any previously set \`anchor\` on each frame change.
     * @default false
     */
    updateAnchor: boolean;
    /**
     * User-assigned function to call when an AnimatedSprite finishes playing.
     * @example
     * animation.onComplete = () => {
     *     // Finished!
     * };
     */
    onComplete?: () => void;
    /**
     * User-assigned function to call when an AnimatedSprite changes which texture is being rendered.
     * @example
     * animation.onFrameChange = () => {
     *     // Updated!
     * };
     */
    onFrameChange?: (currentFrame: number) => void;
    /**
     * User-assigned function to call when \`loop\` is true, and an AnimatedSprite is played and
     * loops around to start again.
     * @example
     * animation.onLoop = () => {
     *     // Looped!
     * };
     */
    onLoop?: () => void;
    private _playing;
    private _textures;
    private _durations;
    /**
     * \`true\` uses Ticker.shared to auto update animation time.
     * @default true
     */
    private _autoUpdate;
    /**
     * \`true\` if the instance is currently connected to Ticker.shared to auto update animation time.
     * @default false
     */
    private _isConnectedToTicker;
    /** Elapsed time since animation has been started, used internally to display current texture. */
    private _currentTime;
    /** The texture index that was displayed last time. */
    private _previousFrame;
    /**
     * @param frames - Collection of textures or frames to use.
     * @param autoUpdate - Whether to use Ticker.shared to auto update animation time.
     */
    constructor(frames: AnimatedSpriteFrames, autoUpdate?: boolean);
    /**
     * @param options - The options for the AnimatedSprite.
     */
    constructor(options: AnimatedSpriteOptions);
    /** Stops the AnimatedSprite. */
    stop(): void;
    /** Plays the AnimatedSprite. */
    play(): void;
    /**
     * Stops the AnimatedSprite and goes to a specific frame.
     * @param frameNumber - Frame index to stop at.
     */
    gotoAndStop(frameNumber: number): void;
    /**
     * Goes to a specific frame and begins playing the AnimatedSprite.
     * @param frameNumber - Frame index to start at.
     */
    gotoAndPlay(frameNumber: number): void;
    /**
     * Updates the object transform for rendering.
     * @param ticker - the ticker to use to update the object.
     */
    update(ticker: Ticker): void;
    /** Updates the displayed texture to match the current frame index. */
    private _updateTexture;
    /** Stops the AnimatedSprite and destroys it. */
    destroy(): void;
    /**
     * A short hand way of creating an AnimatedSprite from an array of frame ids.
     * @param frames - The array of frames ids the AnimatedSprite will use as its texture frames.
     * @returns - The new animated sprite with the specified frames.
     */
    static fromFrames(frames: string[]): AnimatedSprite;
    /**
     * A short hand way of creating an AnimatedSprite from an array of image ids.
     * @param images - The array of image urls the AnimatedSprite will use as its texture frames.
     * @returns The new animate sprite with the specified images as frames.
     */
    static fromImages(images: string[]): AnimatedSprite;
    /**
     * The total number of frames in the AnimatedSprite. This is the same as number of textures
     * assigned to the AnimatedSprite.
     * @readonly
     * @default 0
     */
    get totalFrames(): number;
    /** The array of textures used for this AnimatedSprite. */
    get textures(): AnimatedSpriteFrames;
    set textures(value: AnimatedSpriteFrames);
    /** The AnimatedSprite's current frame index. */
    get currentFrame(): number;
    set currentFrame(value: number);
    /**
     * Indicates if the AnimatedSprite is currently playing.
     * @readonly
     */
    get playing(): boolean;
    /** Whether to use Ticker.shared to auto update animation time. */
    get autoUpdate(): boolean;
    set autoUpdate(value: boolean);
}
/**
 * A reference to a frame in an {@link scene.AnimatedSprite}
 * @memberof scene
 */
export interface FrameObject {
    /** The {@link Texture} of the frame. */
    texture: Texture;
    /** The duration of the frame, in milliseconds. */
    time: number;
}
`,kc=`import { type PointData } from '../../maths/point/PointData';
import { PlaneGeometry } from '../mesh-plane/PlaneGeometry';
/**
 * Options for the NineSliceGeometry.
 * @memberof scene
 */
export interface NineSliceGeometryOptions {
    /** The width of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane. */
    width?: number;
    /** The height of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane. */
    height?: number;
    /** The original width of the texture */
    originalWidth?: number;
    /** The original height of the texture */
    originalHeight?: number;
    /** The width of the left column. */
    leftWidth?: number;
    /** The height of the top row. */
    topHeight?: number;
    /** The width of the right column. */
    rightWidth?: number;
    /** The height of the bottom row. */
    bottomHeight?: number;
    /** The anchor point of the NineSliceSprite. */
    anchor?: PointData;
}
/**
 * The NineSliceGeometry class allows you to create a NineSlicePlane object.
 * @memberof scene
 */
export declare class NineSliceGeometry extends PlaneGeometry {
    /** The default options for the NineSliceGeometry. */
    static defaultOptions: NineSliceGeometryOptions;
    _leftWidth: number;
    _rightWidth: number;
    _topHeight: number;
    _bottomHeight: number;
    private _originalWidth;
    private _originalHeight;
    private _anchorX;
    private _anchorY;
    constructor(options?: NineSliceGeometryOptions);
    /**
     * Updates the NineSliceGeometry with the options.
     * @param options - The options of the NineSliceGeometry.
     */
    update(options: NineSliceGeometryOptions): void;
    /** Updates the positions of the vertices. */
    updatePositions(): void;
    /** Updates the UVs of the vertices. */
    updateUvs(): void;
}
`,Fc=`import { ObservablePoint } from '../../maths/point/ObservablePoint';
import { type PointData } from '../../maths/point/PointData';
import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { ViewContainer, type ViewContainerOptions } from '../view/ViewContainer';
import type { Size } from '../../maths/misc/Size';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { Optional } from '../container/container-mixins/measureMixin';
import type { DestroyOptions } from '../container/destroyTypes';
/**
 * Constructor options used for \`NineSliceSprite\` instances.
 * \`\`\`js
 * const nineSliceSprite = new NineSliceSprite({
 *    texture: Texture.from('button.png'),
 *    leftWidth: 20,
 *    topHeight: 20,
 *    rightWidth: 20,
 *    bottomHeight: 20,
 * });
 * \`\`\`
 * @see {@link scene.NineSliceSprite}
 * @memberof scene
 */
export interface NineSliceSpriteOptions extends PixiMixins.NineSliceSpriteOptions, ViewContainerOptions {
    /** The texture to use on the NineSliceSprite. */
    texture: Texture;
    /** Width of the left vertical bar (A) */
    leftWidth?: number;
    /** Height of the top horizontal bar (C) */
    topHeight?: number;
    /** Width of the right vertical bar (B) */
    rightWidth?: number;
    /** Height of the bottom horizontal bar (D) */
    bottomHeight?: number;
    /** Width of the NineSliceSprite, setting this will actually modify the vertices and not the UV's of this plane. */
    width?: number;
    /** Height of the NineSliceSprite, setting this will actually modify the vertices and not UV's of this plane. */
    height?: number;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
    /** The anchor point of the NineSliceSprite. */
    anchor?: PointData | number;
}
export interface NineSliceSprite extends PixiMixins.NineSliceSprite, ViewContainer {
}
/**
 * The NineSliceSprite allows you to stretch a texture using 9-slice scaling. The corners will remain unscaled (useful
 * for buttons with rounded corners for example) and the other areas will be scaled horizontally and or vertically
 *
 * <pre>
 *      A                          B
 *    +---+----------------------+---+
 *  C | 1 |          2           | 3 |
 *    +---+----------------------+---+
 *    |   |                      |   |
 *    | 4 |          5           | 6 |
 *    |   |                      |   |
 *    +---+----------------------+---+
 *  D | 7 |          8           | 9 |
 *    +---+----------------------+---+
 *  When changing this objects width and/or height:
 *     areas 1 3 7 and 9 will remain unscaled.
 *     areas 2 and 8 will be stretched horizontally
 *     areas 4 and 6 will be stretched vertically
 *     area 5 will be stretched both horizontally and vertically
 * </pre>
 * @example
 * import { NineSliceSprite, Texture } from 'pixi.js';
 *
 * const plane9 = new NineSliceSprite(Texture.from('BoxWithRoundedCorners.png'), 15, 15, 15, 15);
 * @memberof scene
 */
export declare class NineSliceSprite extends ViewContainer implements View {
    /** The default options, used to override the initial values of any options passed in the constructor. */
    static defaultOptions: NineSliceSpriteOptions;
    readonly renderPipeId: string;
    _texture: Texture;
    batched: boolean;
    _anchor: ObservablePoint;
    private _leftWidth;
    private _topHeight;
    private _rightWidth;
    private _bottomHeight;
    private _width;
    private _height;
    /**
     * @param {scene.NineSliceSpriteOptions|Texture} options - Options to use
     * @param options.texture - The texture to use on the NineSliceSprite.
     * @param options.leftWidth - Width of the left vertical bar (A)
     * @param options.topHeight - Height of the top horizontal bar (C)
     * @param options.rightWidth - Width of the right vertical bar (B)
     * @param options.bottomHeight - Height of the bottom horizontal bar (D)
     * @param options.width - Width of the NineSliceSprite,
     * setting this will actually modify the vertices and not the UV's of this plane.
     * @param options.height - Height of the NineSliceSprite,
     * setting this will actually modify the vertices and not UV's of this plane.
     */
    constructor(options: NineSliceSpriteOptions | Texture);
    get anchor(): ObservablePoint;
    set anchor(value: PointData | number);
    /** The width of the NineSliceSprite, setting this will actually modify the vertices and UV's of this plane. */
    get width(): number;
    set width(value: number);
    /** The height of the NineSliceSprite, setting this will actually modify the vertices and UV's of this plane. */
    get height(): number;
    set height(value: number);
    /**
     * Sets the size of the NiceSliceSprite to the specified width and height.
     * setting this will actually modify the vertices and UV's of this plane
     * This is faster than setting the width and height separately.
     * @param value - This can be either a number or a [Size]{@link Size} object.
     * @param height - The height to set. Defaults to the value of \`width\` if not provided.
     */
    setSize(value: number | Optional<Size, 'height'>, height?: number): void;
    /**
     * Retrieves the size of the NineSliceSprite as a [Size]{@link Size} object.
     * This is faster than get the width and height separately.
     * @param out - Optional object to store the size in.
     * @returns - The size of the NineSliceSprite.
     */
    getSize(out?: Size): Size;
    /** The width of the left column (a) of the NineSliceSprite. */
    get leftWidth(): number;
    set leftWidth(value: number);
    /** The width of the right column (b) of the NineSliceSprite. */
    get topHeight(): number;
    set topHeight(value: number);
    /** The width of the right column (b) of the NineSliceSprite. */
    get rightWidth(): number;
    set rightWidth(value: number);
    /** The width of the right column (b) of the NineSliceSprite. */
    get bottomHeight(): number;
    set bottomHeight(value: number);
    /** The texture that the NineSliceSprite is using. */
    get texture(): Texture;
    set texture(value: Texture);
    /** The original width of the texture */
    get originalWidth(): number;
    /** The original height of the texture */
    get originalHeight(): number;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
    /**
     * @private
     */
    protected updateBounds(): void;
}
/**
 * Please use the \`NineSliceSprite\` class instead.
 * @deprecated since 8.0.0
 * @memberof scene
 */
export declare class NineSlicePlane extends NineSliceSprite {
    constructor(options: NineSliceSpriteOptions | Texture);
    /** @deprecated since 8.0.0 */
    constructor(texture: Texture, leftWidth: number, topHeight: number, rightWidth: number, bottomHeight: number);
}
`,Oc=`declare global
{
    namespace PixiMixins
    {
        interface RendererPipes
        {
            nineSliceSprite: import('./NineSliceSpritePipe').NineSliceSpritePipe;
        }
    }
}

export {};
`,Ic=`import { ExtensionType } from '../../extensions/Extensions';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { NineSliceSprite } from './NineSliceSprite';
export declare class NineSliceSpritePipe implements RenderPipe<NineSliceSprite> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "nineSliceSprite";
    };
    private readonly _renderer;
    private readonly _gpuSpriteHash;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    addRenderable(sprite: NineSliceSprite, instructionSet: InstructionSet): void;
    updateRenderable(sprite: NineSliceSprite): void;
    validateRenderable(sprite: NineSliceSprite): boolean;
    destroyRenderable(sprite: NineSliceSprite): void;
    private _updateBatchableSprite;
    private _getGpuSprite;
    private _initGPUSprite;
    destroy(): void;
}
`,Lc=`export {};
`,Bc=`import { ObservablePoint } from '../../maths/point/ObservablePoint';
import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { Transform } from '../../utils/misc/Transform';
import { ViewContainer, type ViewContainerOptions } from '../view/ViewContainer';
import type { Size } from '../../maths/misc/Size';
import type { PointData } from '../../maths/point/PointData';
import type { Instruction } from '../../rendering/renderers/shared/instructions/Instruction';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { Optional } from '../container/container-mixins/measureMixin';
import type { DestroyOptions } from '../container/destroyTypes';
/**
 * Constructor options used for \`TilingSprite\` instances. Extends {@link scene.TilingSpriteViewOptions}
 * \`\`\`js
 * const tilingSprite = new TilingSprite({
 *    texture: Texture.from('assets/image.png'),
 *    width: 100,
 *    height: 100,
 *    tilePosition: { x: 100, y: 100 },
 *    tileScale: { x: 2, y: 2 },
 * });
 * \`\`\`
 * @see {@link scene.TilingSprite}
 * @see {@link scene.TilingSpriteViewOptions}
 * @memberof scene
 */
export interface TilingSpriteOptions extends PixiMixins.TilingSpriteOptions, ViewContainerOptions {
    /**
     * The anchor point of the sprite
     * @default {x: 0, y: 0}
     */
    anchor?: PointData | number;
    /**
     * The offset of the image that is being tiled.
     * @default {x: 0, y: 0}
     */
    tilePosition?: PointData;
    /**
     * Scaling of the image that is being tiled.
     * @default {x: 1, y: 1}
     */
    tileScale?: PointData;
    /**
     * The rotation of the image that is being tiled.
     * @default 0
     */
    tileRotation?: number;
    /**
     * The texture to use for the sprite.
     * @default Texture.WHITE
     */
    texture?: Texture;
    /**
     * The width of the tiling sprite. #
     * @default 256
     */
    width?: number;
    /**
     * The height of the tiling sprite.
     * @default 256
     */
    height?: number;
    /**
     * @todo
     * @default false
     */
    applyAnchorToTexture?: boolean;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
}
export interface TilingSprite extends PixiMixins.TilingSprite, ViewContainer {
}
/**
 * A tiling sprite is a fast way of rendering a tiling image.
 * @example
 * const tilingSprite = new TilingSprite({
 *    texture: Texture.from('assets/image.png'),
 *    width: 100,
 *    height: 100,
 * });
 *
 * tilingSprite.tilePosition.x = 100;
 * tilingSprite.tilePosition.y = 100;
 *
 * app.stage.addChild(tilingSprite);
 * @memberof scene
 * @extends scene.Container
 */
export declare class TilingSprite extends ViewContainer implements View, Instruction {
    /**
     * Creates a new tiling sprite.
     * @param source - The source to create the texture from.
     * @param options - The options for creating the tiling sprite.
     * @returns A new tiling sprite.
     */
    static from(source: Texture | string, options?: TilingSpriteOptions): TilingSprite;
    /** default options for the TilingSprite */
    static defaultOptions: TilingSpriteOptions;
    readonly renderPipeId: string;
    readonly batched = true;
    /**
     * Flags whether the tiling pattern should originate from the origin instead of the top-left corner in
     * local space.
     *
     * This will make the texture coordinates assigned to each vertex dependent on the value of the anchor. Without
     * this, the top-left corner always gets the (0, 0) texture coordinate.
     * @default false
     */
    applyAnchorToTexture: boolean;
    /**
     * @see {@link scene.TilingSpriteOptions.applyAnchorToTexture}
     * @deprecated since 8.0.0
     */
    get uvRespectAnchor(): boolean;
    set uvRespectAnchor(value: boolean);
    _anchor: ObservablePoint;
    _tileTransform: Transform;
    _texture: Texture;
    private _width;
    private _height;
    /**
     * @param {rendering.Texture | scene.TilingSpriteOptions} options - The options for creating the tiling sprite.
     */
    constructor(options?: Texture | TilingSpriteOptions);
    /** @deprecated since 8.0.0 */
    constructor(texture: Texture, width: number, height: number);
    /**
     * Changes frame clamping in corresponding textureMatrix
     * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
     * @default 0.5
     * @member {number}
     */
    get clampMargin(): number;
    set clampMargin(value: number);
    /**
     * The anchor sets the origin point of the sprite. The default value is taken from the {@link Texture}
     * and passed to the constructor.
     *
     * The default is \`(0,0)\`, this means the sprite's origin is the top left.
     *
     * Setting the anchor to \`(0.5,0.5)\` means the sprite's origin is centered.
     *
     * Setting the anchor to \`(1,1)\` would mean the sprite's origin point will be the bottom right corner.
     *
     * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
     * @example
     * import { TilingSprite } from 'pixi.js';
     *
     * const sprite = new TilingSprite({texture: Texture.WHITE});
     * sprite.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
     */
    get anchor(): ObservablePoint;
    set anchor(value: PointData | number);
    /** The offset of the image that is being tiled. */
    get tilePosition(): ObservablePoint;
    set tilePosition(value: PointData);
    /** The scaling of the image that is being tiled. */
    get tileScale(): ObservablePoint;
    set tileScale(value: PointData | number);
    set tileRotation(value: number);
    /** The rotation of the image that is being tiled. */
    get tileRotation(): number;
    /** The transform of the image that is being tiled. */
    get tileTransform(): Transform;
    set texture(value: Texture);
    /** The texture that the sprite is using. */
    get texture(): Texture;
    /** The width of the tiling area. */
    set width(value: number);
    get width(): number;
    set height(value: number);
    /** The height of the tiling area. */
    get height(): number;
    /**
     * Sets the size of the TilingSprite to the specified width and height.
     * This is faster than setting the width and height separately.
     * @param value - This can be either a number or a [Size]{@link Size} object.
     * @param height - The height to set. Defaults to the value of \`width\` if not provided.
     */
    setSize(value: number | Optional<Size, 'height'>, height?: number): void;
    /**
     * Retrieves the size of the TilingSprite as a [Size]{@link Size} object.
     * This is faster than get the width and height separately.
     * @param out - Optional object to store the size in.
     * @returns - The size of the TilingSprite.
     */
    getSize(out?: Size): Size;
    /**
     * @private
     */
    protected updateBounds(): void;
    /**
     * Checks if the object contains the given point.
     * @param point - The point to check
     */
    containsPoint(point: PointData): boolean;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
}
`,Dc=`declare global
{
    namespace PixiMixins
    {
        interface RendererPipes
        {
            tilingSprite: import('./TilingSpritePipe').TilingSpritePipe;
        }
    }
}

export {};
`,Uc=`import { ExtensionType } from '../../extensions/Extensions';
import { type Renderer } from '../../rendering/renderers/types';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { TilingSprite } from './TilingSprite';
export declare class TilingSpritePipe implements RenderPipe<TilingSprite> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "tilingSprite";
    };
    private _renderer;
    private readonly _state;
    private readonly _tilingSpriteDataHash;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    validateRenderable(renderable: TilingSprite): boolean;
    addRenderable(tilingSprite: TilingSprite, instructionSet: InstructionSet): void;
    execute(tilingSprite: TilingSprite): void;
    updateRenderable(tilingSprite: TilingSprite): void;
    destroyRenderable(tilingSprite: TilingSprite): void;
    private _getTilingSpriteData;
    private _initTilingSpriteData;
    private _updateBatchableMesh;
    destroy(): void;
    private _updateCanBatch;
}
`,jc=`export {};
`,Wc=`import { Matrix } from '../../../maths/matrix/Matrix';
import { Shader } from '../../../rendering/renderers/shared/shader/Shader';
import { Texture } from '../../../rendering/renderers/shared/texture/Texture';
export declare class TilingSpriteShader extends Shader {
    constructor();
    updateUniforms(width: number, height: number, matrix: Matrix, anchorX: number, anchorY: number, texture: Texture): void;
}
`,Hc=`export declare const tilingBit: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
export declare const tilingBitGl: {
    name: string;
    vertex: {
        header: string;
        main: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
`,Vc=`import { MeshGeometry } from '../../mesh/shared/MeshGeometry';
export declare class QuadGeometry extends MeshGeometry {
    constructor();
}
`,Nc=`import type { Matrix } from '../../../maths/matrix/Matrix';
import type { TypedArray } from '../../../rendering/renderers/shared/buffer/Buffer';
export declare function applyMatrix(array: TypedArray, stride: number, offset: number, matrix: Matrix): void;
`,zc=`import type { TilingSprite } from '../TilingSprite';
export declare function setPositions(tilingSprite: TilingSprite, positions: Float32Array): void;
`,Xc=`import type { TilingSprite } from '../TilingSprite';
export declare function setUvs(tilingSprite: TilingSprite, uvs: Float32Array): void;
`,Kc=`import type { Matrix } from '../../maths/matrix/Matrix';
import type { Batch, Batcher } from '../../rendering/batcher/shared/Batcher';
import type { DefaultBatchableQuadElement } from '../../rendering/batcher/shared/DefaultBatcher';
import type { Topology } from '../../rendering/renderers/shared/geometry/const';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { BoundsData } from '../container/bounds/Bounds';
import type { Container } from '../container/Container';
/**
 * A batchable sprite object.
 * @ignore
 */
export declare class BatchableSprite implements DefaultBatchableQuadElement {
    batcherName: string;
    topology: Topology;
    readonly attributeSize = 4;
    readonly indexSize = 6;
    readonly packAsQuad = true;
    transform: Matrix;
    renderable: Container;
    texture: Texture;
    bounds: BoundsData;
    roundPixels: 0 | 1;
    _indexStart: number;
    _textureId: number;
    _attributeStart: number;
    _batcher: Batcher;
    _batch: Batch;
    get blendMode(): import("../..").BLEND_MODES;
    get color(): number;
    reset(): void;
}
`,qc=`import { ObservablePoint } from '../../maths/point/ObservablePoint';
import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { ViewContainer, type ViewContainerOptions } from '../view/ViewContainer';
import type { Size } from '../../maths/misc/Size';
import type { PointData } from '../../maths/point/PointData';
import type { TextureSourceLike } from '../../rendering/renderers/shared/texture/Texture';
import type { BoundsData } from '../container/bounds/Bounds';
import type { Optional } from '../container/container-mixins/measureMixin';
import type { DestroyOptions } from '../container/destroyTypes';
/**
 * Options for the {@link scene.Sprite} constructor.
 * @memberof scene
 */
export interface SpriteOptions extends PixiMixins.SpriteOptions, ViewContainerOptions {
    /** The texture to use for the sprite. */
    texture?: Texture;
    /** The anchor point of the sprite. */
    anchor?: PointData | number;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
}
export interface Sprite extends PixiMixins.Sprite, ViewContainer {
}
/**
 * The Sprite object is one of the most important objects in PixiJS. It is a
 * drawing item that can be added to a scene and rendered to the screen.
 *
 * A sprite can be created directly from an image like this:
 *
 * \`\`\`js
 * import { Sprite } from 'pixi.js';
 *
 * const sprite = Sprite.from('assets/image.png');
 * \`\`\`
 *
 * The more efficient way to create sprites is using a {@link assets.Spritesheet},
 * as swapping base textures when rendering to the screen is inefficient.
 *
 * \`\`\`js
 * import { Assets, Sprite } from 'pixi.js';
 *
 * const sheet = await Assets.load('assets/spritesheet.json');
 * const sprite = new Sprite(sheet.textures['image.png']);
 * \`\`\`
 * @memberof scene
 * @extends scene.Container
 */
export declare class Sprite extends ViewContainer {
    /**
     * Helper function that creates a new sprite based on the source you provide.
     * The source can be - frame id, image, video, canvas element, video element, texture
     * @param source - Source to create texture from
     * @param [skipCache] - Whether to skip the cache or not
     * @returns The newly created sprite
     */
    static from(source: Texture | TextureSourceLike, skipCache?: boolean): Sprite;
    readonly renderPipeId: string;
    batched: boolean;
    readonly _anchor: ObservablePoint;
    _texture: Texture;
    private readonly _visualBounds;
    private _width;
    private _height;
    /**
     * @param options - The options for creating the sprite.
     */
    constructor(options?: SpriteOptions | Texture);
    set texture(value: Texture);
    /** The texture that the sprite is using. */
    get texture(): Texture;
    /**
     * The bounds of the sprite, taking the texture's trim into account.
     * @type {rendering.Bounds}
     */
    get visualBounds(): BoundsData;
    /**
     * @deprecated
     */
    get sourceBounds(): BoundsData;
    /** @private */
    protected updateBounds(): void;
    /**
     * Destroys this sprite renderable and optionally its texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the renderable as well
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the renderable as well
     */
    destroy(options?: DestroyOptions): void;
    /**
     * The anchor sets the origin point of the sprite. The default value is taken from the {@link Texture}
     * and passed to the constructor.
     *
     * The default is \`(0,0)\`, this means the sprite's origin is the top left.
     *
     * Setting the anchor to \`(0.5,0.5)\` means the sprite's origin is centered.
     *
     * Setting the anchor to \`(1,1)\` would mean the sprite's origin point will be the bottom right corner.
     *
     * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
     * @example
     * import { Sprite } from 'pixi.js';
     *
     * const sprite = new Sprite({texture: Texture.WHITE});
     * sprite.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
     */
    get anchor(): ObservablePoint;
    set anchor(value: PointData | number);
    /** The width of the sprite, setting this will actually modify the scale to achieve the value set. */
    get width(): number;
    set width(value: number);
    /** The height of the sprite, setting this will actually modify the scale to achieve the value set. */
    get height(): number;
    set height(value: number);
    /**
     * Retrieves the size of the Sprite as a [Size]{@link Size} object.
     * This is faster than get the width and height separately.
     * @param out - Optional object to store the size in.
     * @returns - The size of the Sprite.
     */
    getSize(out?: Size): Size;
    /**
     * Sets the size of the Sprite to the specified width and height.
     * This is faster than setting the width and height separately.
     * @param value - This can be either a number or a [Size]{@link Size} object.
     * @param height - The height to set. Defaults to the value of \`width\` if not provided.
     */
    setSize(value: number | Optional<Size, 'height'>, height?: number): void;
}
`,Yc=`import { ExtensionType } from '../../extensions/Extensions';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { Sprite } from './Sprite';
export declare class SpritePipe implements RenderPipe<Sprite> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "sprite";
    };
    private _renderer;
    private _gpuSpriteHash;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    addRenderable(sprite: Sprite, instructionSet: InstructionSet): void;
    updateRenderable(sprite: Sprite): void;
    validateRenderable(sprite: Sprite): boolean;
    destroyRenderable(sprite: Sprite): void;
    private _updateBatchableSprite;
    private _getGpuSprite;
    private _initGPUSprite;
    destroy(): void;
}
`,Jc=`import EventEmitter from 'eventemitter3';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { FontMetrics } from '../text/canvas/CanvasTextMetrics';
/** @memberof text */
export interface CharData {
    /** Unique id of character */
    id: number;
    /** x-offset to apply when rendering character */
    xOffset: number;
    /** y-offset to apply when rendering character. */
    yOffset: number;
    /** Advancement to apply to next character. */
    xAdvance: number;
    /** The kerning values for this character. */
    kerning: Record<string, number>;
    /** The texture of the character. */
    texture?: Texture;
}
/**
 * The raw data of a character in a bitmap font.
 * @memberof text
 */
export interface RawCharData extends Omit<CharData, 'texture'> {
    /** The page of the font texture that the character is on. */
    page: number;
    /** The x position of the character in the page. */
    x: number;
    /** The y position of the character in the page. */
    y: number;
    /** The width of the character in the page. */
    width: number;
    /** The height of the character in the page. */
    height: number;
    /** The letter of the character. */
    letter: string;
}
/**
 * The raw data of a bitmap font.
 * @memberof text
 */
export interface BitmapFontData {
    /** The offset of the font face from the baseline. */
    baseLineOffset: number;
    /** The map of characters by character code. */
    chars: Record<string, RawCharData>;
    /** The map of base page textures (i.e., sheets of glyphs). */
    pages: {
        /** Unique id for bitmap texture */
        id: number;
        /** File name */
        file: string;
    }[];
    /** The line-height of the font face in pixels. */
    lineHeight: number;
    /** The size of the font face in pixels. */
    fontSize: number;
    /** The name of the font face. */
    fontFamily: string;
    /** The range and type of the distance field for this font. */
    distanceField?: {
        /** Type of distance field */
        type: 'sdf' | 'msdf' | 'none';
        /** Range of the distance field in pixels */
        range: number;
    };
}
interface BitmapFontEvents<Type> {
    destroy: [Type];
}
/**
 * An abstract representation of a bitmap font.
 * @memberof text
 */
export declare abstract class AbstractBitmapFont<FontType> extends EventEmitter<BitmapFontEvents<FontType>> implements Omit<BitmapFontData, 'chars' | 'pages' | 'fontSize'> {
    /** The map of characters by character code. */
    readonly chars: Record<string, CharData>;
    /**
     * The line-height of the font face in pixels.
     * @type {number}
     */
    readonly lineHeight: BitmapFontData['lineHeight'];
    /**
     * The name of the font face
     * @type {string}
     */
    readonly fontFamily: BitmapFontData['fontFamily'];
    /** The metrics of the font face. */
    readonly fontMetrics: FontMetrics;
    /**
     * The offset of the font face from the baseline.
     * @type {number}
     */
    readonly baseLineOffset: BitmapFontData['baseLineOffset'];
    /** The range and type of the distance field for this font. */
    readonly distanceField: BitmapFontData['distanceField'];
    /** The map of base page textures (i.e., sheets of glyphs). */
    readonly pages: {
        texture: Texture;
    }[];
    /** should the fill for this font be applied as a tint to the text. */
    applyFillAsTint: boolean;
    /** The size of the font face in pixels. */
    readonly baseMeasurementFontSize: number;
    protected baseRenderedFontSize: number;
    /**
     * The name of the font face.
     * @deprecated since 8.0.0 Use \`fontFamily\` instead.
     */
    get font(): BitmapFontData['fontFamily'];
    /**
     * The map of base page textures (i.e., sheets of glyphs).
     * @deprecated since 8.0.0 Use \`pages\` instead.
     */
    get pageTextures(): AbstractBitmapFont<FontType>['pages'];
    /**
     * The size of the font face in pixels.
     * @deprecated since 8.0.0 Use \`fontMetrics.fontSize\` instead.
     */
    get size(): BitmapFontData['fontSize'];
    /**
     * The kind of distance field for this font or "none".
     * @deprecated since 8.0.0 Use \`distanceField.type\` instead.
     */
    get distanceFieldRange(): NonNullable<BitmapFontData['distanceField']>['range'];
    /**
     * The range of the distance field in pixels.
     * @deprecated since 8.0.0 Use \`distanceField.range\` instead.
     */
    get distanceFieldType(): NonNullable<BitmapFontData['distanceField']>['type'];
    destroy(destroyTextures?: boolean): void;
}
export {};
`,$c=`import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { AbstractBitmapFont } from './AbstractBitmapFont';
import type { BitmapFontData } from './AbstractBitmapFont';
import type { BitmapFontInstallOptions } from './BitmapFontManager';
/**
 * Options for creating a BitmapFont.
 * @memberof text
 */
export interface BitmapFontOptions {
    data: BitmapFontData;
    textures: Texture[];
}
/**
 * A BitmapFont object represents a particular font face, size, and style.
 * @memberof text
 */
export declare class BitmapFont extends AbstractBitmapFont<BitmapFont> {
    /** the url of the font */
    url?: string;
    constructor(options: BitmapFontOptions, url?: string);
    /** Destroys the BitmapFont object. */
    destroy(): void;
    /**
     * Generates a bitmap-font for the given style and character set
     * @param options - Setup options for font generation.
     * @returns Font generated by style options.
     * @example
     * import { BitmapFont, BitmapText } from 'pixi.js';
     *
     * BitmapFont.install('TitleFont', {
     *     fontFamily: 'Arial',
     *     fontSize: 12,
     *     strokeThickness: 2,
     *     fill: 'purple',
     * });
     *
     * const title = new BitmapText({ text: 'This is the title', fontFamily: 'TitleFont' });
     */
    static install(options: BitmapFontInstallOptions): void;
    /**
     * Uninstalls a bitmap font from the cache.
     * @param {string} name - The name of the bitmap font to uninstall.
     */
    static uninstall(name: string): void;
}
`,Qc=`import { TextStyle } from '../text/TextStyle';
import type { TextStyleOptions } from '../text/TextStyle';
import type { BitmapFont } from './BitmapFont';
import type { BitmapTextLayoutData } from './utils/getBitmapTextLayout';
/**
 *
 * The options for installing a new BitmapFont. Once installed the font will be available for use in the BitmapText.
 * It can be accessed by the \`fontFamily\` property of the TextStyle.
 *
 * Install a new BitmapFont will create the characters provided for the font and store them in the cache.
 * But don't worry, if a character is requested that hasn't been generated yet, it will be created on the fly.
 * @memberof text
 */
export interface BitmapFontInstallOptions {
    /** the name of the font, this will be the name you use in the fontFamily of text style to access this font */
    name?: string;
    /**
     * Characters included in the font set. You can also use ranges.
     * For example, \`[['a', 'z'], ['A', 'Z'], "!@#$%^&*()~{}[] "]\`.
     * Don't forget to include spaces ' ' in your character set!
     * @default BitmapFont.ALPHANUMERIC
     */
    chars?: string | (string | string[])[];
    /**
     * Render resolution for glyphs.
     * @default 1
     */
    resolution?: number;
    /**
     * Padding between glyphs on texture atlas. Lower values could mean more visual artifacts
     * and bleeding from other glyphs, larger values increase the space required on the texture.
     * @default 4
     */
    padding?: number;
    /**
     * Skip generation of kerning information for the BitmapFont.
     * If true, this could potentially increase the performance, but may impact the rendered text appearance.
     * @default false
     */
    skipKerning?: boolean;
    /** Style options to render with BitmapFont. */
    style?: TextStyle | TextStyleOptions;
}
/**
 * The BitmapFontManager is a helper that exists to install and uninstall fonts
 * into the cache for BitmapText objects.
 * @memberof text
 * @name BitmapFontManager
 * @example
 * import { BitmapFontManager, BitmapText } from 'pixi.js';
 *
 * BitmapFontManager.install({
 *   name: 'TitleFont',
 *   style: {}
 * });
 *
 * const title = new BitmapText({ text: 'This is the title', style: { fontFamily: 'TitleFont' }});
 */
declare class BitmapFontManagerClass {
    /**
     * This character set includes all the letters in the alphabet (both lower- and upper- case).
     * @type {string[][]}
     * @example
     * BitmapFont.from('ExampleFont', style, { chars: BitmapFont.ALPHA })
     */
    readonly ALPHA: (string | string[])[];
    /**
     * This character set includes all decimal digits (from 0 to 9).
     * @type {string[][]}
     * @example
     * BitmapFont.from('ExampleFont', style, { chars: BitmapFont.NUMERIC })
     */
    readonly NUMERIC: string[][];
    /**
     * This character set is the union of \`BitmapFont.ALPHA\` and \`BitmapFont.NUMERIC\`.
     * @type {string[][]}
     */
    readonly ALPHANUMERIC: (string | string[])[];
    /**
     * This character set consists of all the ASCII table.
     * @member {string[][]}
     * @see http://www.asciitable.com/
     */
    readonly ASCII: string[][];
    /** Default options for installing a new BitmapFont. */
    defaultOptions: Omit<BitmapFontInstallOptions, 'style'>;
    /**
     * Get a font for the specified text and style.
     * @param text - The text to get the font for
     * @param style - The style to use
     */
    getFont(text: string, style: TextStyle): BitmapFont;
    /**
     * Get the layout of a text for the specified style.
     * @param text - The text to get the layout for
     * @param style - The style to use
     * @param trimEnd - Whether to ignore whitespaces at the end of each line
     */
    getLayout(text: string, style: TextStyle, trimEnd?: boolean): BitmapTextLayoutData;
    /**
     * Measure the text using the specified style.
     * @param text - The text to measure
     * @param style - The style to use
     * @param trimEnd - Whether to ignore whitespaces at the end of each line
     */
    measureText(text: string, style: TextStyle, trimEnd?: boolean): {
        width: number;
        height: number;
        scale: number;
        offsetY: number;
    };
    /**
     * Generates a bitmap-font for the given style and character set
     * @param options - Setup options for font generation.
     * @returns Font generated by style options.
     * @example
     * import { BitmapFontManager, BitmapText } from 'pixi.js';
     *
     * BitmapFontManager.install('TitleFont', {
     *     fontFamily: 'Arial',
     *     fontSize: 12,
     *     strokeThickness: 2,
     *     fill: 'purple',
     * });
     *
     * const title = new BitmapText({ text: 'This is the title', fontFamily: 'TitleFont' });
     */
    install(options: BitmapFontInstallOptions): BitmapFont;
    /** @deprecated since 7.0.0 */
    install(name: string, style?: TextStyle | TextStyleOptions, options?: BitmapFontInstallOptions): BitmapFont;
    /**
     * Uninstalls a bitmap font from the cache.
     * @param {string} name - The name of the bitmap font to uninstall.
     */
    uninstall(name: string): void;
}
export declare const BitmapFontManager: BitmapFontManagerClass;
export {};
`,Zc=`import { AbstractText } from '../text/AbstractText';
import { TextStyle } from '../text/TextStyle';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { TextOptions, TextString } from '../text/AbstractText';
import type { TextStyleOptions } from '../text/TextStyle';
export interface BitmapText extends PixiMixins.BitmapText, AbstractText<TextStyle, TextStyleOptions> {
}
/**
 * A BitmapText Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and give the \`wordWrapWidth\` property a value.
 *
 * The text is created using a bitmap font (a sprite sheet of characters).
 *
 * The primary advantage of this render mode over \`text\` is that all of your textures are pre-generated and loaded,
 * meaning that rendering is fast, and changing text is much faster than Text.
 *
 * The primary disadvantage is that supporting character sets other than latin, such as CJK languages,
 * may be impractical due to the number of characters.
 *
 * <b>Pre-loaded BitmapFonts:</b>
 *
 *
 * PixiJS enables the loading of BitmapFonts through its Asset Manager, supporting both XML and FNT formats.
 * Additionally, PixiJS is compatible with MSDF (Multi-channel Signed Distance Field) and SDF (Signed Distance Field) fonts.
 * These advanced font types allow for scaling without quality degradation and must be created with specific tools,
 * such as the one available at https://msdf-bmfont.donmccurdy.com/.
 *
 * <b>Dynamically Generated BitmapFonts:</b>
 *
 *
 * PixiJS also offers the capability to generate BitmapFonts dynamically. This means that fonts are created in real-time
 * based on specified styles, eliminating the need for pre-loading. This process is initiated simply by assigning a style
 * to a BitmapText object, which then automatically generates the required font.
 *
 * However, dynamically generating a large number of fonts may lead to significant memory use. To prevent this,
 * PixiJS smartly attempts to reuse fonts that closely match the desired style parameters. For instance, if a text style
 * requires a font size of 80 but a similar font of size 100 has already been generated, PixiJS will scale the existing
 * font to fit the new requirement, rather than creating a new font from scratch.
 *
 * For those who prefer to manage BitmapFonts manually, PixiJS provides the BitmapFont.install method. This method
 * allows for the pre-generation and preparation of fonts, making them readily available for use by specifying the
 * fontFamily in your text styling.
 *
 * This approach ensures efficient font management within PixiJS, balancing between dynamic generation for flexibility
 * and manual management for optimized performance.
 * @example
 * import { BitmapText, BitmapFont } from 'pixi.js';
 *
 * // generate a dynamic font behind the scenes:
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 *
 * // pre install
 * BitmapFont.install({
 *    name: 'myFont',
 *    style:{
 *        fontFamily: 'Arial',
 *    }
 * })
 *
 * // new bitmap text with preinstalled font
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *        fontFamily: 'myFont',
 *        fontSize: 24,
 *        fill: 0xff1010,
 *        align: 'center',
 *     }
 * }
 *
 * // load a font from an xml file
 * const font = await Assets.load('path/to/myLoadedFont.fnt');
 *
 * // new bitmap text with loaded font
 * const text = new BitmapText({
 *     text: 'Hello Pixi!',
 *     style: {
 *        fontFamily: 'myLoadedFont', // the name of the font in the fnt file
 *        fontSize: 24,
 *        fill: 0xff1010,
 *        align: 'center',
 *     }
 * }
 * @memberof scene
 */
export declare class BitmapText extends AbstractText<TextStyle, TextStyleOptions> implements View {
    readonly renderPipeId: string;
    /**
     * **Note:** Our docs parser struggles to properly understand the constructor signature.
     * This is the correct signature.
     * \`\`\`ts
     * new BitmapText(options?: TextOptions);
     * \`\`\`
     * @param { text.TextOptions } options - The options of the bitmap text.
     */
    constructor(options?: TextOptions);
    /** @deprecated since 8.0.0 */
    constructor(text?: TextString, options?: Partial<TextStyle>);
    /** @private */
    protected updateBounds(): void;
    /**
     * The resolution / device pixel ratio of the canvas.
     * @default 1
     */
    set resolution(value: number);
    get resolution(): number;
}
`,eu=`import { ExtensionType } from '../../extensions/Extensions';
import { Graphics } from '../graphics/shared/Graphics';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { BitmapText } from './BitmapText';
export declare class BitmapTextPipe implements RenderPipe<BitmapText> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "bitmapText";
    };
    private _renderer;
    private _gpuBitmapText;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    validateRenderable(bitmapText: BitmapText): boolean;
    addRenderable(bitmapText: BitmapText, instructionSet: InstructionSet): void;
    destroyRenderable(bitmapText: BitmapText): void;
    private _destroyRenderableByUid;
    updateRenderable(bitmapText: BitmapText): void;
    private _updateContext;
    private _getGpuBitmapText;
    initGpuText(bitmapText: BitmapText): Graphics;
    private _updateDistanceField;
    destroy(): void;
}
`,nu=`import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { TextStyle } from '../text/TextStyle';
import { AbstractBitmapFont } from './AbstractBitmapFont';
import type { CanvasAndContext } from '../../rendering/renderers/shared/texture/CanvasPool';
export interface DynamicBitmapFontOptions {
    style: TextStyle;
    skipKerning?: boolean;
    resolution?: number;
    padding?: number;
    overrideFill?: boolean;
    overrideSize?: boolean;
    textureSize?: number;
    mipmap?: boolean;
}
/**
 * A BitmapFont that generates its glyphs dynamically.
 * @memberof text
 * @ignore
 */
export declare class DynamicBitmapFont extends AbstractBitmapFont<DynamicBitmapFont> {
    static defaultOptions: DynamicBitmapFontOptions;
    /**
     * this is a resolution modifier for the font size..
     * texture resolution will also be used to scale texture according to its font size also
     */
    resolution: number;
    /** The pages of the font. */
    readonly pages: {
        canvasAndContext?: CanvasAndContext;
        texture: Texture;
    }[];
    private readonly _padding;
    private readonly _measureCache;
    private _currentChars;
    private _currentX;
    private _currentY;
    private _currentPageIndex;
    private readonly _style;
    private readonly _skipKerning;
    private readonly _textureSize;
    private readonly _mipmap;
    /**
     * @param options - The options for the dynamic bitmap font.
     */
    constructor(options: DynamicBitmapFontOptions);
    ensureCharacters(chars: string): void;
    /**
     * @deprecated since 8.0.0
     * The map of base page textures (i.e., sheets of glyphs).
     */
    get pageTextures(): DynamicBitmapFont['pages'];
    private _applyKerning;
    private _nextPage;
    private _setupContext;
    private _drawGlyph;
    destroy(): void;
}
`,tu=`declare global
{
    namespace PixiMixins
    {
        interface RendererPipes
        {
            bitmapText: import('./BitmapTextPipe').BitmapTextPipe;
        }
    }
}
export {};
`,ru=`import type { BitmapFontData } from '../AbstractBitmapFont';
/**
 * Internal data format used to convert to BitmapFontData.
 * @private
 */
export interface BitmapFontRawData {
    info: {
        face: string;
        size: string;
    }[];
    common: {
        lineHeight: string;
        base: string;
    }[];
    page: {
        id: string;
        file: string;
    }[];
    chars: {
        count: number;
    }[];
    char: {
        id: string;
        page: string;
        xoffset: string;
        yoffset: string;
        xadvance: string;
        x: string;
        y: string;
        width: string;
        height: string;
        letter?: string;
        char?: string;
    }[];
    kernings?: {
        count: number;
    }[];
    kerning?: {
        first: string;
        second: string;
        amount: string;
    }[];
    distanceField?: {
        fieldType: 'sdf' | 'msdf' | 'none';
        distanceRange: string;
    }[];
}
export declare const bitmapFontTextParser: {
    test(data: string | XMLDocument | BitmapFontData): boolean;
    parse(txt: string): BitmapFontData;
};
`,ou=`import type { BitmapFontData } from '../AbstractBitmapFont';
export declare const bitmapFontXMLParser: {
    test(data: string | XMLDocument | BitmapFontData): boolean;
    parse(xml: Document): BitmapFontData;
};
`,au=`import type { BitmapFontData } from '../AbstractBitmapFont';
export declare const bitmapFontXMLStringParser: {
    test(data: string | XMLDocument | BitmapFontData): boolean;
    parse(data: string): BitmapFontData;
};
`,iu=`import { LoaderParserPriority } from '../../../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../../../extensions/Extensions';
import { BitmapFont } from '../BitmapFont';
import type { Loader } from '../../../assets/loader/Loader';
import type { ResolvedAsset } from '../../../assets/types';
/** simple loader plugin for loading in bitmap fonts! */
export declare const bitmapFontCachePlugin: {
    extension: {
        type: ExtensionType.CacheParser;
        name: string;
    };
    test: (asset: BitmapFont) => boolean;
    getCacheableAssets(keys: string[], asset: BitmapFont): Record<string, BitmapFont>;
};
export declare const loadBitmapFont: {
    extension: {
        type: ExtensionType.LoadParser;
        priority: LoaderParserPriority;
    };
    name: string;
    test(url: string): boolean;
    testParse(data: string): Promise<boolean>;
    parse<T>(asset: string, data: ResolvedAsset, loader: Loader): Promise<BitmapFont>;
    load<T_1>(url: string, _options: ResolvedAsset): Promise<string>;
    unload(bitmapFont: BitmapFont, _resolvedAsset: ResolvedAsset<any>, loader: Loader): Promise<void>;
};
`,su=`export {};
`,lu=`import type { TextStyle } from '../../text/TextStyle';
import type { AbstractBitmapFont } from '../AbstractBitmapFont';
export interface BitmapTextLayoutData {
    width: number;
    height: number;
    scale: number;
    offsetY: number;
    lines: {
        width: number;
        charPositions: number[];
        chars: string[];
        spaceWidth: number;
        spacesIndex: number[];
    }[];
}
export declare function getBitmapTextLayout(chars: string[], style: TextStyle, font: AbstractBitmapFont<any>, trimEnd: boolean): BitmapTextLayoutData;
`,du=`/**
 * Processes the passed character set data and returns a flattened array of all the characters.
 *
 * Ignored because not directly exposed.
 * @ignore
 * @param {string | string[] | string[][] } chars
 * @returns {string[]} the flattened array of characters
 */
export declare function resolveCharacters(chars: string | (string | string[])[]): string[];
`,pu=`import { AbstractText } from '../text/AbstractText';
import { HTMLTextStyle } from './HTMLTextStyle';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { TextOptions, TextString } from '../text/AbstractText';
import type { HTMLTextStyleOptions } from './HTMLTextStyle';
/**
 * Constructor options used for \`HTMLText\` instances.
 * @property {string} [text=''] - The string that you would like the text to display.
 * @property {text.HTMLTextStyle | text.HTMLTextStyleOptions} [style] - The style of the text.
 * @memberof text
 */
export type HTMLTextOptions = TextOptions<HTMLTextStyle, HTMLTextStyleOptions> & PixiMixins.HTMLTextOptions;
export interface HTMLText extends PixiMixins.HTMLText, AbstractText<HTMLTextStyle, HTMLTextStyleOptions> {
}
/**
 * A HTMLText Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and give the \`wordWrapWidth\` property a value.
 *
 * HTMLText uses an svg foreignObject to render HTML text.
 *
 *
 * The primary advantages of this render mode are:
 *
 *  - Supports [HTML tags](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/HTML_text_fundamentals)
 * for styling such as \`<strong>\`, or \`<em>\`, as well as \`<span style="">\`
 *
 *       - Better support for emojis and other HTML layout features, better compatibility with CSS
 *     line-height and letter-spacing.
 *
 *
 * The primary disadvantages are:
 *   - Unlike \`text\`, \`html\` rendering will vary slightly between platforms and browsers.
 * \`html\` uses SVG/DOM to render text and not Context2D's fillText like \`text\`.
 *
 *   - Performance and memory usage is on-par with \`text\` (that is to say, slow and heavy)
 *
 *   - Only works with browsers that support <foreignObject>.
 * @example
 * import { HTMLText } from 'pixi.js';
 *
 * const text = new HTMLText({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 * @memberof scene
 */
export declare class HTMLText extends AbstractText<HTMLTextStyle, HTMLTextStyleOptions> implements View {
    readonly renderPipeId: string;
    /**
     * @param {text.HTMLTextOptions} options - The options of the html text.
     */
    constructor(options?: HTMLTextOptions);
    /** @deprecated since 8.0.0 */
    constructor(text?: TextString, options?: Partial<HTMLTextStyle>);
    /** @private */
    protected updateBounds(): void;
}
`,cu=`import { ExtensionType } from '../../extensions/Extensions';
import { Texture } from '../../rendering/renderers/shared/texture/Texture';
import { BatchableSprite } from '../sprite/BatchableSprite';
import type { InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../rendering/renderers/shared/instructions/RenderPipe';
import type { Renderer } from '../../rendering/renderers/types';
import type { HTMLText } from './HTMLText';
export declare class HTMLTextPipe implements RenderPipe<HTMLText> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "htmlText";
    };
    private _renderer;
    private _gpuText;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    resolutionChange(): void;
    validateRenderable(htmlText: HTMLText): boolean;
    addRenderable(htmlText: HTMLText, instructionSet: InstructionSet): void;
    updateRenderable(htmlText: HTMLText): void;
    destroyRenderable(htmlText: HTMLText): void;
    private _destroyRenderableById;
    private _updateText;
    private _updateGpuText;
    private _getGpuText;
    initGpuText(htmlText: HTMLText): {
        textureNeedsUploading: boolean;
        generatingTexture: boolean;
        texture: Texture<import("../..").TextureSource<any>>;
        currentKey: string;
        batchableSprite: BatchableSprite;
    };
    destroy(): void;
}
`,uu=`import type { CanvasAndContext } from '../../rendering/renderers/shared/texture/CanvasPool';
export declare const nssvg = "http://www.w3.org/2000/svg";
export declare const nsxhtml = "http://www.w3.org/1999/xhtml";
export declare class HTMLTextRenderData {
    svgRoot: SVGSVGElement;
    foreignObject: SVGForeignObjectElement;
    domElement: HTMLElement;
    styleElement: HTMLElement;
    image: HTMLImageElement;
    canvasAndContext?: CanvasAndContext;
    constructor();
}
`,mu=`import { TextStyle } from '../text/TextStyle';
import type { FillInput, StrokeInput } from '../graphics/shared/FillTypes';
import type { TextStyleOptions } from '../text/TextStyle';
/**
 * Options for HTML text style, extends {@link TextStyle}.
 * @memberof text
 * @extends text.TextStyleOptions
 * @property {string[]} [cssOverrides] - CSS style(s) to add.
 * @property {Record<string, text.HTMLTextStyleOptions>} [tagStyles] - Tag styles.
 */
export interface HTMLTextStyleOptions extends Omit<TextStyleOptions, 'leading' | 'textBaseline' | 'trim'> {
    cssOverrides?: string[];
    tagStyles?: Record<string, HTMLTextStyleOptions>;
}
/**
 * A TextStyle object rendered by the HTMLTextSystem.
 * @memberof text
 */
export declare class HTMLTextStyle extends TextStyle {
    private _cssOverrides;
    private _cssStyle;
    /**
     * List of styles per tag.
     * @example
     * new HTMLText({
     *   text:'<red>Red</red>,<blue>Blue</blue>,<green>Green</green>',
     *   style:{
     *       fontFamily: 'DM Sans',
     *       fill: 'white',
     *       fontSize:100,
     *       tagStyles:{
     *           red:{
     *               fill:'red',
     *           },
     *           blue:{
     *               fill:'blue',
     *           },
     *           green:{
     *               fill:'green',
     *           }
     *       }
     *   }
     * );
     */
    tagStyles: Record<string, HTMLTextStyleOptions>;
    constructor(options?: HTMLTextStyleOptions);
    /** List of style overrides that will be applied to the HTML text. */
    set cssOverrides(value: string | string[]);
    get cssOverrides(): string[];
    protected _generateKey(): string;
    update(): void;
    /**
     * Creates a new HTMLTextStyle object with the same values as this one.
     * @returns New cloned HTMLTextStyle object
     */
    clone(): HTMLTextStyle;
    get cssStyle(): string;
    /**
     * Add a style override, this can be any CSS property
     * it will override any built-in style. This is the
     * property and the value as a string (e.g., \`color: red\`).
     * This will override any other internal style.
     * @param {string} value - CSS style(s) to add.
     * @example
     * style.addOverride('background-color: red');
     */
    addOverride(...value: string[]): void;
    /**
     * Remove any overrides that match the value.
     * @param {string} value - CSS style to remove.
     * @example
     * style.removeOverride('background-color: red');
     */
    removeOverride(...value: string[]): void;
    set fill(value: FillInput);
    set stroke(value: StrokeInput);
}
`,hu=`import { ExtensionType } from '../../extensions/Extensions';
import { type Renderer } from '../../rendering/renderers/types';
import { HTMLTextStyle } from './HTMLTextStyle';
import type { System } from '../../rendering/renderers/shared/system/System';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { HTMLTextOptions } from './HTMLText';
import type { FontCSSStyleOptions } from './utils/loadFontCSS';
/**
 * System plugin to the renderer to manage HTMLText
 * @memberof rendering
 */
export declare class HTMLTextSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "htmlText";
    };
    static defaultFontOptions: FontCSSStyleOptions;
    private _activeTextures;
    /**
     * WebGPU has a cors issue when uploading an image that is an SVGImage
     * To get around this we need to create a canvas draw the image to it and upload that instead.
     * Bit of a shame.. but no other work around just yet!
     */
    private readonly _createCanvas;
    private readonly _renderer;
    constructor(renderer: Renderer);
    getTexture(options: HTMLTextOptions): Promise<Texture>;
    getManagedTexture(text: string, resolution: number, style: HTMLTextStyle, textKey: string): Promise<Texture>;
    private _buildTexturePromise;
    private _increaseReferenceCount;
    decreaseReferenceCount(textKey: string): void;
    private _cleanUp;
    getReferenceCount(textKey: string): number;
    destroy(): void;
}
`,fu=`declare global
{
    namespace PixiMixins
    {
        interface RendererSystems
        {
            htmlText: import('./HTMLTextSystem').HTMLTextSystem;
        }

        interface RendererPipes
        {
            htmlText: import('./HTMLTextPipe').HTMLTextPipe;
        }
    }
}
export {};
`,bu=`export {};
`,gu=`import type { HTMLTextStyle } from '../HTMLTextStyle';
/**
 * Extracts font families from text. It will extract font families from the style, tagStyles and any font families
 * embedded in the text. It should also strip out duplicates as it goes.
 * @param  text - The text to extract font families from
 * @param style - The style to extract font families from
 * @returns {string[]} - The font families as an array of strings
 */
export declare function extractFontFamilies(text: string, style: HTMLTextStyle): string[];
`,yu=`import type { FontCSSStyleOptions } from './loadFontCSS';
export declare const FontStylePromiseCache: Map<string, Promise<string>>;
/**
 * takes the font families and returns a css string that can be injected into a style tag
 * It will contain the font families and the font urls encoded as base64
 * @param fontFamilies - The font families to load
 * @param style - The FontCSSStyleOptions to load the font with (used for the first font family)
 * @param defaultOptions - The default options to load the font with (used for the rest of the font families)
 * @param defaultOptions.fontWeight - The default font weight
 * @param defaultOptions.fontStyle - The default font style
 * @returns - The css string
 */
export declare function getFontCss(fontFamilies: string[], style: FontCSSStyleOptions, defaultOptions: {
    fontWeight: string;
    fontStyle: string;
}): Promise<string>;
`,xu=`import type { HTMLTextRenderData } from '../HTMLTextRenderData';
import type { HTMLTextStyle } from '../HTMLTextStyle';
/**
 * takes all the data and returns a svg url string can be loaded by an image element
 * @param text - The text to measure
 * @param style - The style to use
 * @param resolution - The resolution to use
 * @param fontCSS - The font css to use
 * @param htmlTextData - The HTMLTextRenderData to write the SVG to
 * @returns - The SVG as a url string
 */
export declare function getSVGUrl(text: string, style: HTMLTextStyle, resolution: number, fontCSS: string, htmlTextData: HTMLTextRenderData): string;
`,vu=`import type { CanvasAndContext } from '../../../rendering/renderers/shared/texture/CanvasPool';
/**
 * This function converts an image to a canvas, and returns the canvas.
 * It is used to convert images to canvases to work around a CORS issue where WebGPU cannot
 * upload an SVGImage to a texture.
 *
 * It uses the CanvasPool to get an optimal canvas and context, and then draws the image onto it.
 * Remember to return this canvas is immediately to the CanvasPool for reuse when you are done with it.
 * (eg upload it to the GPU!)
 * @param image - The image to convert to a canvas.
 * @param resolution - The resolution of the canvas.
 */
export declare function getTemporaryCanvasFromImage(image: HTMLImageElement, resolution: number): CanvasAndContext;
`,Tu=`/**
 * Resolves a font url to a base64 string
 * @param url - The url to load the font from
 * @returns - The font as a base64 string
 */
export declare function loadFontAsBase64(url: string): Promise<string>;
`,Su=`export interface FontCSSStyleOptions {
    fontFamily: string | string[];
    fontWeight: string;
    fontStyle: string;
}
/**
 * This will take a font url and a style and return a css string that can be injected into a style tag
 * This will contain inlined base64 font and the font family information
 * @param style - the style to generate the css for
 * @param url - The url to load the font from
 * @returns - The css string
 */
export declare function loadFontCSS(style: FontCSSStyleOptions, url: string): Promise<string>;
`,wu=`/**
 * This function loads an SVG image into an HTMLImageElement.
 * The image can then be uploaded as texture to the GPU.
 * iOS has a bug where embedded fonts are not available immediately after the image loads,
 * so we wait an arbitrary amount of time before resolving the promise.
 * @param image - The image to load the SVG into
 * @param url - The url to load the SVG from
 * @param delay - Whether to delay the load
 * @returns - A promise that resolves when the image has loaded
 */
export declare function loadSVGImage(image: HTMLImageElement, url: string, delay: boolean): Promise<void>;
`,_u=`import { HTMLTextRenderData } from '../HTMLTextRenderData';
import type { Size } from '../../../maths/misc/Size';
import type { HTMLTextStyle } from '../HTMLTextStyle';
/**
 * Measures the HTML text without actually generating an image.
 * This is used to calculate the size of the text.
 * @param text - The text to measure
 * @param style - The style to use
 * @param fontStyleCSS - The font css to use
 * @param htmlTextRenderData - The HTMLTextRenderData to write the SVG to
 * @returns - The size of the text
 */
export declare function measureHtmlText(text: string, style: HTMLTextStyle, fontStyleCSS?: string, htmlTextRenderData?: HTMLTextRenderData): Size;
`,Eu=`import type { HTMLTextStyle } from '../HTMLTextStyle';
/**
 * Internally converts all of the style properties into CSS equivalents.
 * @param style
 * @returns The CSS style string, for setting \`style\` property of root HTMLElement.
 */
export declare function textStyleToCSS(style: HTMLTextStyle): string;
`,Pu=`import { ObservablePoint } from '../../maths/point/ObservablePoint';
import { ViewContainer, type ViewContainerOptions } from '../view/ViewContainer';
import type { Size } from '../../maths/misc/Size';
import type { PointData } from '../../maths/point/PointData';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { Optional } from '../container/container-mixins/measureMixin';
import type { DestroyOptions } from '../container/destroyTypes';
import type { HTMLTextStyle, HTMLTextStyleOptions } from '../text-html/HTMLTextStyle';
import type { TextStyle, TextStyleOptions } from './TextStyle';
/**
 * A string or number that can be used as text.
 * @memberof text
 */
export type TextString = string | number | {
    toString: () => string;
};
/**
 * A union of all text styles, including HTML, Bitmap and Canvas text styles.
 * @memberof text
 * @see text.TextStyle
 * @see text.HTMLTextStyle
 */
export type AnyTextStyle = TextStyle | HTMLTextStyle;
/**
 * A union of all text style options, including HTML, Bitmap and Canvas text style options.
 * @memberof text
 * @see text.TextStyleOptions
 * @see text.HTMLTextStyleOptions
 */
export type AnyTextStyleOptions = TextStyleOptions | HTMLTextStyleOptions;
/**
 * Options for the {@link scene.Text} class.
 * @example
 * const text = new Text({
 *    text: 'Hello Pixi!',
 *    style: {
 *       fontFamily: 'Arial',
 *       fontSize: 24,
 *    fill: 0xff1010,
 *    align: 'center',
 *  }
 * });
 * @memberof text
 */
export interface TextOptions<TEXT_STYLE extends TextStyle = TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions = TextStyleOptions> extends PixiMixins.TextOptions, ViewContainerOptions {
    /** The anchor point of the text. */
    anchor?: PointData | number;
    /** The copy for the text object. To split a line you can use '\\n'. */
    text?: TextString;
    /** The resolution of the text. */
    resolution?: number;
    /**
     * The text style
     * @type {
     * text.TextStyle |
     * Partial<text.TextStyle> |
     * text.TextStyleOptions |
     * text.HTMLTextStyle |
     * Partial<text.HTMLTextStyle> |
     * text.HTMLTextStyleOptions
     * }
     */
    style?: TEXT_STYLE | TEXT_STYLE_OPTIONS;
    /** Whether or not to round the x/y position. */
    roundPixels?: boolean;
}
/**
 * An abstract Text class, used by all text type in Pixi. This includes Canvas, HTML, and Bitmap Text.
 * @see scene.Text
 * @see scene.BitmapText
 * @see scene.HTMLText
 * @memberof scene
 */
export declare abstract class AbstractText<TEXT_STYLE extends TextStyle = TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions = TextStyleOptions> extends ViewContainer implements View {
    batched: boolean;
    _anchor: ObservablePoint;
    _resolution: number;
    _autoResolution: boolean;
    _style: TEXT_STYLE;
    _didTextUpdate: boolean;
    protected _text: string;
    private readonly _styleClass;
    constructor(options: TextOptions<TEXT_STYLE, TEXT_STYLE_OPTIONS>, styleClass: new (options: TEXT_STYLE_OPTIONS) => TEXT_STYLE);
    /**
     * The anchor sets the origin point of the text.
     * The default is \`(0,0)\`, this means the text's origin is the top left.
     *
     * Setting the anchor to \`(0.5,0.5)\` means the text's origin is centered.
     *
     * Setting the anchor to \`(1,1)\` would mean the text's origin point will be the bottom right corner.
     *
     * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
     * @example
     * import { Text } from 'pixi.js';
     *
     * const text = new Text('hello world');
     * text.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
     */
    get anchor(): ObservablePoint;
    set anchor(value: PointData | number);
    /** Set the copy for the text object. To split a line you can use '\\n'. */
    set text(value: TextString);
    get text(): string;
    /**
     * The resolution / device pixel ratio of the canvas.
     * @default 1
     */
    set resolution(value: number);
    get resolution(): number;
    get style(): TEXT_STYLE;
    /**
     * Set the style of the text.
     *
     * Set up an event listener to listen for changes on the style object and mark the text as dirty.
     *
     * If setting the \`style\` can also be partial {@link AnyTextStyleOptions}.
     * @type {
     * text.TextStyle |
     * Partial<text.TextStyle> |
     * text.TextStyleOptions |
     * text.HTMLTextStyle |
     * Partial<text.HTMLTextStyle> |
     * text.HTMLTextStyleOptions
     * }
     */
    set style(style: TEXT_STYLE | Partial<TEXT_STYLE> | TEXT_STYLE_OPTIONS);
    /** The width of the sprite, setting this will actually modify the scale to achieve the value set. */
    get width(): number;
    set width(value: number);
    /** The height of the sprite, setting this will actually modify the scale to achieve the value set. */
    get height(): number;
    set height(value: number);
    /**
     * Retrieves the size of the Text as a [Size]{@link Size} object.
     * This is faster than get the width and height separately.
     * @param out - Optional object to store the size in.
     * @returns - The size of the Text.
     */
    getSize(out?: Size): Size;
    /**
     * Sets the size of the Text to the specified width and height.
     * This is faster than setting the width and height separately.
     * @param value - This can be either a number or a [Size]{@link Size} object.
     * @param height - The height to set. Defaults to the value of \`width\` if not provided.
     */
    setSize(value: number | Optional<Size, 'height'>, height?: number): void;
    /**
     * Checks if the text contains the given point.
     * @param point - The point to check
     */
    containsPoint(point: PointData): boolean;
    onViewUpdate(): void;
    _getKey(): string;
    /**
     * Destroys this text renderable and optionally its style texture.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the texture of the text style
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the text style
     * @param {boolean} [options.style=false] - Should it destroy the style of the text
     */
    destroy(options?: DestroyOptions): void;
}
/**
 * Helper function to ensure consistent handling of text options across different text classes.
 * This function handles both the new options object format and the deprecated parameter format.
 * @example
 * // New recommended way:
 * const options = ensureTextOptions([{
 *     text: "Hello",
 *     style: { fontSize: 20 }
 * }], "Text");
 *
 * // Deprecated way (will show warning in debug):
 * const options = ensureTextOptions(["Hello", { fontSize: 20 }], "Text");
 * @param args - Arguments passed to text constructor
 * @param name - Name of the text class (used in deprecation warning)
 * @returns Normalized text options object
 * @template TEXT_STYLE - The specific TextStyle class being used
 * @template TEXT_STYLE_OPTIONS - The options type for the TextStyle
 * @internal
 */
export declare function ensureTextOptions<TEXT_STYLE extends TextStyle, TEXT_STYLE_OPTIONS extends TextStyleOptions>(args: any[], name: string): TextOptions<TEXT_STYLE, TEXT_STYLE_OPTIONS>;
`,Au=`import { AbstractText } from './AbstractText';
import { TextStyle } from './TextStyle';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { TextOptions, TextString } from './AbstractText';
import type { TextStyleOptions } from './TextStyle';
export interface Text extends PixiMixins.Text, AbstractText<TextStyle, TextStyleOptions> {
}
/**
 * A Text Object will create a line or multiple lines of text.
 *
 * To split a line you can use '\\n' in your text string, or, on the \`style\` object,
 * change its \`wordWrap\` property to true and and givae the \`wordWrapWidth\` property a value.
 *
 * The primary advantage of this class over BitmapText is that you have great control over the style of the text,
 * which you can change at runtime.
 *
 * The primary disadvantages is that each piece of text has it's own texture, which can use more memory.
 * When text changes, this texture has to be re-generated and re-uploaded to the GPU, taking up time.
 * @example
 * import { Text } from 'pixi.js';
 *
 * const text = new Text({
 *     text: 'Hello Pixi!',
 *     style: {
 *         fontFamily: 'Arial',
 *         fontSize: 24,
 *         fill: 0xff1010,
 *         align: 'center',
 *     }
 * });
 * @memberof scene
 */
export declare class Text extends AbstractText<TextStyle, TextStyleOptions> implements View {
    readonly renderPipeId: string;
    /**
     * @param {text.TextOptions} options - The options of the text.
     */
    constructor(options?: TextOptions);
    /** @deprecated since 8.0.0 */
    constructor(text?: TextString, options?: Partial<TextStyle>);
    /** @private */
    protected updateBounds(): void;
}
`,Cu=`declare global
{
    namespace PixiMixins
    {
        interface RendererSystems
        {
            canvasText: import('./canvas/CanvasTextSystem').CanvasTextSystem;
        }

        interface RendererPipes
        {
            text: import('./canvas/CanvasTextPipe').CanvasTextPipe;
        }
    }
}
export {};
`,Ru=`import EventEmitter from 'eventemitter3';
import { type ColorSource } from '../../color/Color';
import type { TextureDestroyOptions, TypeOrBool } from '../container/destroyTypes';
import type { ConvertedFillStyle, ConvertedStrokeStyle, FillInput, StrokeInput } from '../graphics/shared/FillTypes';
export type TextStyleAlign = 'left' | 'center' | 'right' | 'justify';
export type TextStyleFill = string | string[] | number | number[] | CanvasGradient | CanvasPattern;
export type TextStyleFontStyle = 'normal' | 'italic' | 'oblique';
export type TextStyleFontVariant = 'normal' | 'small-caps';
export type TextStyleFontWeight = 'normal' | 'bold' | 'bolder' | 'lighter' | '100' | '200' | '300' | '400' | '500' | '600' | '700' | '800' | '900';
export type TextStyleLineJoin = 'miter' | 'round' | 'bevel';
export type TextStyleTextBaseline = 'alphabetic' | 'top' | 'hanging' | 'middle' | 'ideographic' | 'bottom';
export type TextStyleWhiteSpace = 'normal' | 'pre' | 'pre-line';
/**
 * A collection of text related classes.
 * @namespace text
 */
/**
 * A drop shadow effect.
 * @memberof text
 */
export type TextDropShadow = {
    /** Set alpha for the drop shadow  */
    alpha: number;
    /** Set a angle of the drop shadow */
    angle: number;
    /** Set a shadow blur radius */
    blur: number;
    /** A fill style to be used on the  e.g., 'red', '#00FF00' */
    color: ColorSource;
    /** Set a distance of the drop shadow */
    distance: number;
};
/**
 * Constructor options used for \`TextStyle\` instances.
 * \`\`\`js
 * const textStyle = new TextStyle({
 *    fontSize: 12,
 *    fill: 'black',
 * });
 * \`\`\`
 * @see {@link text.TextStyle}
 * @memberof text
 */
export interface TextStyleOptions {
    /**
     * Alignment for multiline text, does not affect single line text
     * @type {'left'|'center'|'right'|'justify'}
     */
    align?: TextStyleAlign;
    /** Indicates if lines can be wrapped within words, it needs \`wordWrap\` to be set to \`true\` */
    breakWords?: boolean;
    /** Set a drop shadow for the text */
    dropShadow?: boolean | Partial<TextDropShadow>;
    /**
     * A canvas fillstyle that will be used on the text e.g., 'red', '#00FF00'.
     * Can be an array to create a gradient, e.g., \`['#000000','#FFFFFF']\`
     * {@link https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/fillStyle|MDN}
     * @type {string|string[]|number|number[]|CanvasGradient|CanvasPattern}
     */
    fill?: FillInput;
    /** The font family, can be a single font name, or a list of names where the first is the preferred font. */
    fontFamily?: string | string[];
    /** The font size (as a number it converts to px, but as a string, equivalents are '26px','20pt','160%' or '1.6em') */
    fontSize?: number | string;
    /**
     * The font style.
     * @type {'normal'|'italic'|'oblique'}
     */
    fontStyle?: TextStyleFontStyle;
    /**
     * The font variant.
     * @type {'normal'|'small-caps'}
     */
    fontVariant?: TextStyleFontVariant;
    /**
     * The font weight.
     * @type {'normal'|'bold'|'bolder'|'lighter'|'100'|'200'|'300'|'400'|'500'|'600'|'700'|'800'|'900'}
     */
    fontWeight?: TextStyleFontWeight;
    /** The height of the line, a number that represents the vertical space that a letter uses. */
    leading?: number;
    /** The amount of spacing between letters, default is 0 */
    letterSpacing?: number;
    /** The line height, a number that represents the vertical space that a letter uses */
    lineHeight?: number;
    /**
     * Occasionally some fonts are cropped. Adding some padding will prevent this from
     * happening by adding padding to all sides of the text.
     */
    padding?: number;
    /** A canvas fillstyle that will be used on the text stroke, e.g., 'blue', '#FCFF00' */
    stroke?: StrokeInput;
    /**
     * The baseline of the text that is rendered.
     * @type {'alphabetic'|'top'|'hanging'|'middle'|'ideographic'|'bottom'}
     */
    textBaseline?: TextStyleTextBaseline;
    trim?: boolean;
    /**
     * Determines whether newlines & spaces are collapsed or preserved "normal"
     * (collapse, collapse), "pre" (preserve, preserve) | "pre-line" (preserve,
     * collapse). It needs wordWrap to be set to true.
     * @type {'normal'|'pre'|'pre-line'}
     */
    whiteSpace?: TextStyleWhiteSpace;
    /** Indicates if word wrap should be used */
    wordWrap?: boolean;
    /** The width at which text will wrap, it needs wordWrap to be set to true */
    wordWrapWidth?: number;
}
/**
 * A TextStyle Object contains information to decorate a Text objects.
 *
 * An instance can be shared between multiple Text objects; then changing the style will update all text objects using it.
 * @memberof text
 * @example
 * import { TextStyle } from 'pixi.js';
 * const style = new TextStyle({
 *   fontFamily: ['Helvetica', 'Arial', 'sans-serif'],
 *   fontSize: 36,
 * });
 */
export declare class TextStyle extends EventEmitter<{
    update: TextDropShadow;
}> {
    /** The default drop shadow settings */
    static defaultDropShadow: TextDropShadow;
    /** The default text style settings */
    static defaultTextStyle: TextStyleOptions;
    _fill: ConvertedFillStyle;
    private _originalFill;
    _stroke: ConvertedStrokeStyle;
    private _originalStroke;
    private _dropShadow;
    private _fontFamily;
    private _fontSize;
    private _fontStyle;
    private _fontVariant;
    private _fontWeight;
    private _breakWords;
    private _align;
    private _leading;
    private _letterSpacing;
    private _lineHeight;
    private _textBaseline;
    private _whiteSpace;
    private _wordWrap;
    private _wordWrapWidth;
    private _padding;
    protected _styleKey: string;
    private _trim;
    constructor(style?: Partial<TextStyleOptions>);
    /**
     * Alignment for multiline text, does not affect single line text.
     * @member {'left'|'center'|'right'|'justify'}
     */
    get align(): TextStyleAlign;
    set align(value: TextStyleAlign);
    /** Indicates if lines can be wrapped within words, it needs wordWrap to be set to true. */
    get breakWords(): boolean;
    set breakWords(value: boolean);
    /** Set a drop shadow for the text. */
    get dropShadow(): TextDropShadow;
    set dropShadow(value: boolean | TextDropShadow);
    /** The font family, can be a single font name, or a list of names where the first is the preferred font. */
    get fontFamily(): string | string[];
    set fontFamily(value: string | string[]);
    /** The font size (as a number it converts to px, but as a string, equivalents are '26px','20pt','160%' or '1.6em') */
    get fontSize(): number;
    set fontSize(value: string | number);
    /**
     * The font style.
     * @member {'normal'|'italic'|'oblique'}
     */
    get fontStyle(): TextStyleFontStyle;
    set fontStyle(value: TextStyleFontStyle);
    /**
     * The font variant.
     * @member {'normal'|'small-caps'}
     */
    get fontVariant(): TextStyleFontVariant;
    set fontVariant(value: TextStyleFontVariant);
    /**
     * The font weight.
     * @member {'normal'|'bold'|'bolder'|'lighter'|'100'|'200'|'300'|'400'|'500'|'600'|'700'|'800'|'900'}
     */
    get fontWeight(): TextStyleFontWeight;
    set fontWeight(value: TextStyleFontWeight);
    /** The space between lines. */
    get leading(): number;
    set leading(value: number);
    /** The amount of spacing between letters, default is 0. */
    get letterSpacing(): number;
    set letterSpacing(value: number);
    /** The line height, a number that represents the vertical space that a letter uses. */
    get lineHeight(): number;
    set lineHeight(value: number);
    /**
     * Occasionally some fonts are cropped. Adding some padding will prevent this from happening
     * by adding padding to all sides of the text.
     */
    get padding(): number;
    set padding(value: number);
    /** Trim transparent borders. This is an expensive operation so only use this if you have to! */
    get trim(): boolean;
    set trim(value: boolean);
    /**
     * The baseline of the text that is rendered.
     * @member {'alphabetic'|'top'|'hanging'|'middle'|'ideographic'|'bottom'}
     */
    get textBaseline(): TextStyleTextBaseline;
    set textBaseline(value: TextStyleTextBaseline);
    /**
     * How newlines and spaces should be handled.
     * Default is 'pre' (preserve, preserve).
     *
     *  value       | New lines     |   Spaces
     *  ---         | ---           |   ---
     * 'normal'     | Collapse      |   Collapse
     * 'pre'        | Preserve      |   Preserve
     * 'pre-line'   | Preserve      |   Collapse
     * @member {'normal'|'pre'|'pre-line'}
     */
    get whiteSpace(): TextStyleWhiteSpace;
    set whiteSpace(value: TextStyleWhiteSpace);
    /** Indicates if word wrap should be used. */
    get wordWrap(): boolean;
    set wordWrap(value: boolean);
    /** The width at which text will wrap, it needs wordWrap to be set to true. */
    get wordWrapWidth(): number;
    set wordWrapWidth(value: number);
    /**
     * The fill style that will be used to color the text.
     * This can be:
     * - A color string like 'red', '#00FF00', or 'rgba(255,0,0,0.5)'
     * - A hex number like 0xff0000 for red
     * - A FillStyle object with properties like { color: 0xff0000, alpha: 0.5 }
     * - A FillGradient for gradient fills
     * - A FillPattern for pattern/texture fills
     *
     * When using a FillGradient, vertical gradients (angle of 90 degrees) are applied per line of text,
     * while gradients at any other angle are spread across the entire text body as a whole.
     * @example
     * // Vertical gradient applied per line
     * const verticalGradient = new FillGradient(0, 0, 0, 1)
     *     .addColorStop(0, 0xff0000)
     *     .addColorStop(1, 0x0000ff);
     *
     * const text = new Text({
     *     text: 'Line 1\\nLine 2',
     *     style: { fill: verticalGradient }
     * });
     *
     * To manage the gradient in a global scope, set the textureSpace property of the FillGradient to 'global'.
     * @type {string|number|FillStyle|FillGradient|FillPattern}
     */
    get fill(): FillInput;
    set fill(value: FillInput);
    /** A fillstyle that will be used on the text stroke, e.g., 'blue', '#FCFF00'. */
    get stroke(): StrokeInput;
    set stroke(value: StrokeInput);
    protected _generateKey(): string;
    update(): void;
    /** Resets all properties to the default values */
    reset(): void;
    get styleKey(): string;
    /**
     * Creates a new TextStyle object with the same values as this one.
     * @returns New cloned TextStyle object
     */
    clone(): TextStyle;
    /**
     * Destroys this text style.
     * @param options - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.texture=false] - Should it destroy the texture of the this style
     * @param {boolean} [options.textureSource=false] - Should it destroy the textureSource of the this style
     */
    destroy(options?: TypeOrBool<TextureDestroyOptions>): void;
    private _createProxy;
    private _isFillStyle;
}
`,Gu=`import type { ICanvas } from '../../../environment/canvas/ICanvas';
import type { ICanvasRenderingContext2D } from '../../../environment/canvas/ICanvasRenderingContext2D';
import type { TextStyle } from '../TextStyle';
/**
 * A number, or a string containing a number.
 * @memberof text
 * @typedef {object} FontMetrics
 * @property {number} ascent - Font ascent
 * @property {number} descent - Font descent
 * @property {number} fontSize - Font size
 */
export interface FontMetrics {
    ascent: number;
    descent: number;
    fontSize: number;
}
/**
 * The TextMetrics object represents the measurement of a block of text with a specified style.
 * @example
 * import { CanvasTextMetrics, TextStyle } from 'pixi.js';
 *
 * const style = new TextStyle({
 *     fontFamily: 'Arial',
 *     fontSize: 24,
 *     fill: 0xff1010,
 *     align: 'center',
 * });
 * const textMetrics = CanvasTextMetrics.measureText('Your text', style);
 * @memberof text
 */
export declare class CanvasTextMetrics {
    /** The text that was measured. */
    text: string;
    /** The style that was measured. */
    style: TextStyle;
    /** The measured width of the text. */
    width: number;
    /** The measured height of the text. */
    height: number;
    /** An array of lines of the text broken by new lines and wrapping is specified in style. */
    lines: string[];
    /** An array of the line widths for each line matched to \`lines\`. */
    lineWidths: number[];
    /** The measured line height for this style. */
    lineHeight: number;
    /** The maximum line width for all measured lines. */
    maxLineWidth: number;
    /** The font properties object from TextMetrics.measureFont. */
    fontProperties: FontMetrics;
    /**
     * String used for calculate font metrics.
     * These characters are all tall to help calculate the height required for text.
     */
    static METRICS_STRING: string;
    /** Baseline symbol for calculate font metrics. */
    static BASELINE_SYMBOL: string;
    /** Baseline multiplier for calculate font metrics. */
    static BASELINE_MULTIPLIER: number;
    /** Height multiplier for setting height of canvas to calculate font metrics. */
    static HEIGHT_MULTIPLIER: number;
    /**
     * A Unicode "character", or "grapheme cluster", can be composed of multiple Unicode code points,
     * such as letters with diacritical marks (e.g. \`'\\u0065\\u0301'\`, letter e with acute)
     * or emojis with modifiers (e.g. \`'\\uD83E\\uDDD1\\u200D\\uD83D\\uDCBB'\`, technologist).
     * The new \`Intl.Segmenter\` API in ES2022 can split the string into grapheme clusters correctly. If it is not available,
     * PixiJS will fallback to use the iterator of String, which can only spilt the string into code points.
     * If you want to get full functionality in environments that don't support \`Intl.Segmenter\` (such as Firefox),
     * you can use other libraries such as [grapheme-splitter]{@link https://www.npmjs.com/package/grapheme-splitter}
     * or [graphemer]{@link https://www.npmjs.com/package/graphemer} to create a polyfill. Since these libraries can be
     * relatively large in size to handle various Unicode grapheme clusters properly, PixiJS won't use them directly.
     */
    static graphemeSegmenter: (s: string) => string[];
    static _experimentalLetterSpacingSupported?: boolean;
    /**
     * Checking that we can use modern canvas 2D API.
     *
     * Note: This is an unstable API, Chrome < 94 use \`textLetterSpacing\`, later versions use \`letterSpacing\`.
     * @see TextMetrics.experimentalLetterSpacing
     * @see https://developer.mozilla.org/en-US/docs/Web/API/ICanvasRenderingContext2D/letterSpacing
     * @see https://developer.chrome.com/origintrials/#/view_trial/3585991203293757441
     */
    static get experimentalLetterSpacingSupported(): boolean;
    /**
     * New rendering behavior for letter-spacing which uses Chrome's new native API. This will
     * lead to more accurate letter-spacing results because it does not try to manually draw
     * each character. However, this Chrome API is experimental and may not serve all cases yet.
     * @see TextMetrics.experimentalLetterSpacingSupported
     */
    static experimentalLetterSpacing: boolean;
    /** Cache of {@see TextMetrics.FontMetrics} objects. */
    private static _fonts;
    /** Cache of new line chars. */
    private static readonly _newlines;
    /** Cache of breaking spaces. */
    private static readonly _breakingSpaces;
    private static __canvas;
    private static __context;
    private static readonly _measurementCache;
    /**
     * @param text - the text that was measured
     * @param style - the style that was measured
     * @param width - the measured width of the text
     * @param height - the measured height of the text
     * @param lines - an array of the lines of text broken by new lines and wrapping if specified in style
     * @param lineWidths - an array of the line widths for each line matched to \`lines\`
     * @param lineHeight - the measured line height for this style
     * @param maxLineWidth - the maximum line width for all measured lines
     * @param {FontMetrics} fontProperties - the font properties object from TextMetrics.measureFont
     */
    constructor(text: string, style: TextStyle, width: number, height: number, lines: string[], lineWidths: number[], lineHeight: number, maxLineWidth: number, fontProperties: FontMetrics);
    /**
     * Measures the supplied string of text and returns a Rectangle.
     * @param text - The text to measure.
     * @param style - The text style to use for measuring
     * @param canvas - optional specification of the canvas to use for measuring.
     * @param wordWrap
     * @returns Measured width and height of the text.
     */
    static measureText(text: string, style: TextStyle, canvas?: ICanvas, wordWrap?: boolean): CanvasTextMetrics;
    private static _measureText;
    /**
     * Applies newlines to a string to have it optimally fit into the horizontal
     * bounds set by the Text object's wordWrapWidth property.
     * @param text - String to apply word wrapping to
     * @param style - the style to use when wrapping
     * @param canvas - optional specification of the canvas to use for measuring.
     * @returns New string with new lines applied where required
     */
    private static _wordWrap;
    /**
     * Convenience function for logging each line added during the wordWrap method.
     * @param line    - The line of text to add
     * @param newLine - Add new line character to end
     * @returns A formatted line
     */
    private static _addLine;
    /**
     * Gets & sets the widths of calculated characters in a cache object
     * @param key            - The key
     * @param letterSpacing  - The letter spacing
     * @param cache          - The cache
     * @param context        - The canvas context
     * @returns The from cache.
     */
    private static _getFromCache;
    /**
     * Determines whether we should collapse breaking spaces.
     * @param whiteSpace - The TextStyle property whiteSpace
     * @returns Should collapse
     */
    private static _collapseSpaces;
    /**
     * Determines whether we should collapse newLine chars.
     * @param whiteSpace - The white space
     * @returns should collapse
     */
    private static _collapseNewlines;
    /**
     * Trims breaking whitespaces from string.
     * @param text - The text
     * @returns Trimmed string
     */
    private static _trimRight;
    /**
     * Determines if char is a newline.
     * @param char - The character
     * @returns True if newline, False otherwise.
     */
    private static _isNewline;
    /**
     * Determines if char is a breaking whitespace.
     *
     * It allows one to determine whether char should be a breaking whitespace
     * For example certain characters in CJK langs or numbers.
     * It must return a boolean.
     * @param char - The character
     * @param [_nextChar] - The next character
     * @returns True if whitespace, False otherwise.
     */
    static isBreakingSpace(char: string, _nextChar?: string): boolean;
    /**
     * Splits a string into words, breaking-spaces and newLine characters
     * @param text - The text
     * @returns A tokenized array
     */
    private static _tokenize;
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It allows one to customise which words should break
     * Examples are if the token is CJK or numbers.
     * It must return a boolean.
     * @param _token - The token
     * @param breakWords - The style attr break words
     * @returns Whether to break word or not
     */
    static canBreakWords(_token: string, breakWords: boolean): boolean;
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It allows one to determine whether a pair of characters
     * should be broken by newlines
     * For example certain characters in CJK langs or numbers.
     * It must return a boolean.
     * @param _char - The character
     * @param _nextChar - The next character
     * @param _token - The token/word the characters are from
     * @param _index - The index in the token of the char
     * @param _breakWords - The style attr break words
     * @returns whether to break word or not
     */
    static canBreakChars(_char: string, _nextChar: string, _token: string, _index: number, _breakWords: boolean): boolean;
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It is called when a token (usually a word) has to be split into separate pieces
     * in order to determine the point to break a word.
     * It must return an array of characters.
     * @param token - The token to split
     * @returns The characters of the token
     * @see CanvasTextMetrics.graphemeSegmenter
     */
    static wordWrapSplit(token: string): string[];
    /**
     * Calculates the ascent, descent and fontSize of a given font-style
     * @param font - String representing the style of the font
     * @returns Font properties object
     */
    static measureFont(font: string): FontMetrics;
    /**
     * Clear font metrics in metrics cache.
     * @param {string} [font] - font name. If font name not set then clear cache for all fonts.
     */
    static clearMetrics(font?: string): void;
    /**
     * Cached canvas element for measuring text
     * TODO: this should be private, but isn't because of backward compat, will fix later.
     * @ignore
     */
    static get _canvas(): ICanvas;
    /**
     * TODO: this should be private, but isn't because of backward compat, will fix later.
     * @ignore
     */
    static get _context(): ICanvasRenderingContext2D;
}
`,Mu=`import { ExtensionType } from '../../../extensions/Extensions';
import { BatchableSprite } from '../../sprite/BatchableSprite';
import type { InstructionSet } from '../../../rendering/renderers/shared/instructions/InstructionSet';
import type { RenderPipe } from '../../../rendering/renderers/shared/instructions/RenderPipe';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { Renderer } from '../../../rendering/renderers/types';
import type { Text } from '../Text';
export declare class CanvasTextPipe implements RenderPipe<Text> {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLPipes, ExtensionType.WebGPUPipes, ExtensionType.CanvasPipes];
        readonly name: "text";
    };
    private _renderer;
    private _gpuText;
    private readonly _destroyRenderableBound;
    constructor(renderer: Renderer);
    resolutionChange(): void;
    validateRenderable(text: Text): boolean;
    addRenderable(text: Text, instructionSet: InstructionSet): void;
    updateRenderable(text: Text): void;
    destroyRenderable(text: Text): void;
    private _destroyRenderableById;
    private _updateText;
    private _updateGpuText;
    private _getGpuText;
    initGpuText(text: Text): {
        texture: Texture<import("../../..").TextureSource<any>>;
        currentKey: string;
        batchableSprite: BatchableSprite;
    };
    destroy(): void;
}
`,ku=`import { ExtensionType } from '../../../extensions/Extensions';
import { TextStyle } from '../TextStyle';
import type { ICanvas } from '../../../environment/canvas/ICanvas';
import type { ICanvasRenderingContext2D } from '../../../environment/canvas/ICanvasRenderingContext2D';
import type { System } from '../../../rendering/renderers/shared/system/System';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
import type { Renderer } from '../../../rendering/renderers/types';
import type { TextOptions } from '../AbstractText';
import type { Text } from '../Text';
interface CanvasAndContext {
    canvas: ICanvas;
    context: ICanvasRenderingContext2D;
}
/**
 * System plugin to the renderer to manage canvas text.
 * @memberof rendering
 */
export declare class CanvasTextSystem implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem, ExtensionType.CanvasSystem];
        readonly name: "canvasText";
    };
    private _activeTextures;
    private readonly _renderer;
    constructor(_renderer: Renderer);
    getTextureSize(text: string, resolution: number, style: TextStyle): {
        width: number;
        height: number;
    };
    /**
     * This is a function that will create a texture from a text string, style and resolution.
     * Useful if you want to make a texture of your text and use if for various other pixi things!
     * @param options - The options of the text that will be used to generate the texture.
     * @param options.text - the text to render
     * @param options.style - the style of the text
     * @param options.resolution - the resolution of the texture
     * @returns the newly created texture
     */
    /** @deprecated since 8.0.0 */
    getTexture(text: string, resolution: number, style: TextStyle, textKey: string): Texture;
    getTexture(options: TextOptions): Texture;
    createTextureAndCanvas(options: {
        text: string;
        style: TextStyle;
        resolution?: number;
    }): {
        texture: Texture<import("../../..").TextureSource<any>>;
        canvasAndContext: import("../../../rendering/renderers/shared/texture/CanvasPool").CanvasAndContext;
    };
    getManagedTexture(text: Text): Texture<import("../../..").TextureSource<any>>;
    private _increaseReferenceCount;
    /**
     * Returns a texture that was created wit the above \`getTexture\` function.
     * Handy if you are done with a texture and want to return it to the pool.
     * @param texture - The texture to be returned.
     */
    returnTexture(texture: Texture): void;
    decreaseReferenceCount(textKey: string): void;
    getReferenceCount(textKey: string): number;
    /**
     * Renders text to its canvas, and updates its texture.
     *
     * By default this is used internally to ensure the texture is correct before rendering,
     * but it can be used called externally, for example from this class to 'pre-generate' the texture from a piece of text,
     * and then shared across multiple Sprites.
     * @param text
     * @param style
     * @param resolution
     * @param canvasAndContext
     */
    renderTextToCanvas(text: string, style: TextStyle, resolution: number, canvasAndContext: CanvasAndContext): void;
    /**
     * Render the text with letter-spacing.
     * @param text - The text to draw
     * @param style
     * @param canvasAndContext
     * @param x - Horizontal position to draw the text
     * @param y - Vertical position to draw the text
     * @param isStroke - Is this drawing for the outside stroke of the
     *  text? If not, it's for the inside fill
     */
    private _drawLetterSpacing;
    destroy(): void;
}
export {};
`,Fu=`import type { TextStyle } from '../../TextStyle';
/**
 * Generates a font style string to use for \`TextMetrics.measureFont()\`.
 * @param style
 * @returns Font style string, for passing to \`TextMetrics.measureFont()\`
 */
export declare function fontStringFromTextStyle(style: TextStyle): string;
`,Ou=`import type { ICanvasRenderingContext2D } from '../../../../environment/canvas/ICanvasRenderingContext2D';
import type { ConvertedFillStyle } from '../../../graphics/shared/FillTypes';
import type { CanvasTextMetrics } from '../CanvasTextMetrics';
/**
 * Converts a PixiJS fill style into a Canvas-compatible fill style.
 * Handles solid colors, textures, patterns, and gradients.
 * @param fillStyle - The PixiJS fill style to convert
 * @param context - The canvas rendering context
 * @param textMetrics - Metrics about the text being rendered
 * @param padding - Padding to add to the text metrics (used to ensure that the gradient accommodates the stroke width)
 * @returns Canvas-compatible fill style (string, CanvasGradient, or CanvasPattern)
 */
export declare function getCanvasFillStyle(fillStyle: ConvertedFillStyle, context: ICanvasRenderingContext2D, textMetrics?: CanvasTextMetrics, padding?: number): string | CanvasGradient | CanvasPattern;
`,Iu=`export {};
`,Lu=`import { Shader } from '../../../rendering/renderers/shared/shader/Shader';
export declare class SdfShader extends Shader {
    constructor();
}
`,Bu=`export declare const localUniformMSDFBit: {
    name: string;
    vertex: {
        header: string;
        main: string;
        end: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
export declare const localUniformMSDFBitGl: {
    name: string;
    vertex: {
        header: string;
        main: string;
        end: string;
    };
    fragment: {
        header: string;
        main: string;
    };
};
`,Du=`export declare const mSDFBit: {
    name: string;
    fragment: {
        header: string;
    };
};
export declare const mSDFBitGl: {
    name: string;
    fragment: {
        header: string;
    };
};
`,Uu=`import { HTMLTextStyle } from '../../text-html/HTMLTextStyle';
import { TextStyle } from '../TextStyle';
import type { HTMLTextStyleOptions } from '../../text-html/HTMLTextStyle';
import type { TextStyleOptions } from '../TextStyle';
/**
 * converts the style input into the correct type of TextStyle
 * either HTMLTextStyle or TextStyle based on the renderMode.
 * @param renderMode - The render mode to use
 * @param style - The style to use
 * @returns - The style class
 */
export declare function ensureTextStyle(renderMode: string, style: TextStyle | HTMLTextStyle | TextStyleOptions | HTMLTextStyleOptions): TextStyle;
`,ju=`import type { TextStyle } from '../TextStyle';
/**
 * Generates a unique key for the text style.
 * @param style - The style to generate a key for.
 * @returns the key for the style.
 */
export declare function generateTextStyleKey(style: TextStyle): string;
`,Wu=`import type { ICanvas } from '../../../environment/canvas/ICanvas';
import type { Texture } from '../../../rendering/renderers/shared/texture/Texture';
/**
 * Takes an image and creates a texture from it, using a power of 2 texture from the texture pool.
 * Remember to return the texture when you don't need it any more!
 * @param image - The image to create a texture from
 * @param width - the frame width of the texture
 * @param height - the frame height of the texture
 * @param resolution - The resolution of the texture
 * @returns - The texture
 */
export declare function getPo2TextureFromSource(image: HTMLImageElement | HTMLCanvasElement | ICanvas, width: number, height: number, resolution: number): Texture;
`,Hu=`import { type BatchableSprite } from '../../sprite/BatchableSprite';
import { type AbstractText } from '../AbstractText';
/**
 * Updates the bounds of the given batchable sprite based on the provided text object.
 *
 * This function adjusts the bounds of the batchable sprite to match the dimensions
 * and anchor point of the text's texture. Additionally, it compensates for any padding
 * specified in the text's style to ensure the text is rendered correctly on screen.
 * @param {BatchableSprite} batchableSprite - The sprite whose bounds need to be updated.
 * @param {AbstractText} text - The text object containing the texture and style information.
 */
export declare function updateTextBounds(batchableSprite: BatchableSprite, text: AbstractText): void;
`,Vu=`import { type InstructionSet } from '../../rendering/renderers/shared/instructions/InstructionSet';
import { type Renderer } from '../../rendering/renderers/types';
import { Bounds } from '../container/bounds/Bounds';
import { Container, type ContainerOptions } from '../container/Container';
import { type IRenderLayer } from '../layers/RenderLayer';
import type { PointData } from '../../maths/point/PointData';
import type { View } from '../../rendering/renderers/shared/view/View';
import type { DestroyOptions } from '../container/destroyTypes';
export interface ViewContainerOptions extends ContainerOptions, PixiMixins.ViewContainerOptions {
}
export interface ViewContainer extends PixiMixins.ViewContainer, Container {
}
/**
 * A ViewContainer is a type of container that represents a view.
 * This view can be a Sprite, a Graphics object, or any other object that can be rendered.
 * This class is abstract and should not be used directly.
 * @memberof scene
 */
export declare abstract class ViewContainer extends Container implements View {
    /** @private */
    readonly renderPipeId: string;
    /** @private */
    readonly canBundle = true;
    /** @private */
    allowChildren: boolean;
    /** @private */
    _roundPixels: 0 | 1;
    /** @private */
    _lastUsed: number;
    protected _bounds: Bounds;
    protected _boundsDirty: boolean;
    /**
     * The local bounds of the view.
     * @type {rendering.Bounds}
     */
    get bounds(): Bounds;
    /** @private */
    protected abstract updateBounds(): void;
    /**
     * Whether or not to round the x/y position of the sprite.
     * @type {boolean}
     */
    get roundPixels(): boolean;
    set roundPixels(value: boolean);
    constructor(options: ViewContainerOptions);
    /**
     * Checks if the object contains the given point.
     * @param point - The point to check
     */
    containsPoint(point: PointData): boolean;
    /** @private */
    abstract batched: boolean;
    /** @private */
    protected onViewUpdate(): void;
    destroy(options?: DestroyOptions): void;
    collectRenderablesSimple(instructionSet: InstructionSet, renderer: Renderer, currentLayer: IRenderLayer): void;
}
`,Nu=`import { Texture } from '../rendering/renderers/shared/texture/Texture';
import type { PointData } from '../maths/point/PointData';
import type { TextureSource } from '../rendering/renderers/shared/texture/sources/TextureSource';
import type { BindableTexture, TextureBorders } from '../rendering/renderers/shared/texture/Texture';
import type { Dict } from '../utils/types';
/**
 * Represents the JSON data for a spritesheet atlas.
 * @memberof assets
 */
export interface SpritesheetFrameData {
    /** The frame rectangle of the texture. */
    frame: {
        x: number;
        y: number;
        w: number;
        h: number;
    };
    /** Whether the texture is trimmed. */
    trimmed?: boolean;
    /** Whether the texture is rotated. */
    rotated?: boolean;
    /** The source size of the texture. */
    sourceSize?: {
        w: number;
        h: number;
    };
    /** The sprite source size. */
    spriteSourceSize?: {
        h?: number;
        w?: number;
        x: number;
        y: number;
    };
    /** The anchor point of the texture. */
    anchor?: PointData;
    /** The 9-slice borders of the texture. */
    borders?: TextureBorders;
}
/**
 * Atlas format.
 * @memberof assets
 */
export interface SpritesheetData {
    /** The frames of the atlas. */
    frames: Dict<SpritesheetFrameData>;
    /** The animations of the atlas. */
    animations?: Dict<string[]>;
    /** The meta data of the atlas. */
    meta: {
        app?: string;
        format?: string;
        frameTags?: {
            from: number;
            name: string;
            to: number;
            direction: string;
        }[];
        image?: string;
        layers?: {
            blendMode: string;
            name: string;
            opacity: number;
        }[];
        scale: number | string;
        size?: {
            h: number;
            w: number;
        };
        slices?: {
            color: string;
            name: string;
            keys: {
                frame: number;
                bounds: {
                    x: number;
                    y: number;
                    w: number;
                    h: number;
                };
            }[];
        }[];
        related_multi_packs?: string[];
        version?: string;
    };
}
/**
 * Utility class for maintaining reference to a collection
 * of Textures on a single Spritesheet.
 *
 * To access a sprite sheet from your code you may pass its JSON data file to Pixi's loader:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * const sheet = await Assets.load('images/spritesheet.json');
 * \`\`\`
 *
 * Alternately, you may circumvent the loader by instantiating the Spritesheet directly:
 *
 * \`\`\`js
 * import { Spritesheet } from 'pixi.js';
 *
 * const sheet = new Spritesheet(texture, spritesheetData);
 * await sheet.parse();
 * console.log('Spritesheet ready to use!');
 * \`\`\`
 *
 * With the \`sheet.textures\` you can create Sprite objects, and \`sheet.animations\` can be used to create an AnimatedSprite.
 *
 * Here's an example of a sprite sheet JSON data file:
 * \`\`\`json
 * {
 *     "frames": {
 *         "enemy1.png":
 *         {
 *             "frame": {"x":103,"y":1,"w":32,"h":32},
 *             "spriteSourceSize": {"x":0,"y":0,"w":32,"h":32},
 *             "sourceSize": {"w":32,"h":32},
 *             "anchor": {"x":16,"y":16}
 *         },
 *         "enemy2.png":
 *         {
 *             "frame": {"x":103,"y":35,"w":32,"h":32},
 *             "spriteSourceSize": {"x":0,"y":0,"w":32,"h":32},
 *             "sourceSize": {"w":32,"h":32},
 *             "anchor": {"x":16,"y":16}
 *         },
 *         "button.png":
 *         {
 *             "frame": {"x":1,"y":1,"w":100,"h":100},
 *             "spriteSourceSize": {"x":0,"y":0,"w":100,"h":100},
 *             "sourceSize": {"w":100,"h":100},
 *             "anchor": {"x":0,"y":0},
 *             "borders": {"left":35,"top":35,"right":35,"bottom":35}
 *         }
 *     },
 *
 *     "animations": {
 *         "enemy": ["enemy1.png","enemy2.png"]
 *     },
 *
 *     "meta": {
 *         "image": "sheet.png",
 *         "format": "RGBA8888",
 *         "size": {"w":136,"h":102},
 *         "scale": "1"
 *     }
 * }
 * \`\`\`
 * Sprite sheets can be packed using tools like {@link https://codeandweb.com/texturepacker|TexturePacker},
 * {@link https://renderhjs.net/shoebox/|Shoebox} or {@link https://github.com/krzysztof-o/spritesheet.js|Spritesheet.js}.
 * Default anchor points (see {@link Texture#defaultAnchor}), default 9-slice borders
 * (see {@link Texture#defaultBorders}) and grouping of animation sprites are currently only
 * supported by TexturePacker.
 *
 * Alternative ways for loading spritesheet image if you need more control:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * const sheetTexture = await Assets.load('images/spritesheet.png');
 * Assets.add({
 *     alias: 'atlas',
 *     src: 'images/spritesheet.json',
 *     data: {texture: sheetTexture} // using of preloaded texture
 * });
 * const sheet = await Assets.load('atlas')
 * \`\`\`
 *
 * or:
 *
 * \`\`\`js
 * import { Assets } from 'pixi.js';
 *
 * Assets.add({
 *     alias: 'atlas',
 *     src: 'images/spritesheet.json',
 *     data: {imageFilename: 'my-spritesheet.2x.avif'} // using of custom filename located in "images/my-spritesheet.2x.avif"
 * });
 * const sheet = await Assets.load('atlas')
 * \`\`\`
 * @memberof assets
 */
export declare class Spritesheet<S extends SpritesheetData = SpritesheetData> {
    /** The maximum number of Textures to build per process. */
    static readonly BATCH_SIZE = 1000;
    /** For multi-packed spritesheets, this contains a reference to all the other spritesheets it depends on. */
    linkedSheets: Spritesheet<S>[];
    /** Reference to the source texture. */
    textureSource: TextureSource;
    /**
     * A map containing all textures of the sprite sheet.
     * Can be used to create a {@link Sprite|Sprite}:
     * @example
     * import { Sprite } from 'pixi.js';
     *
     * new Sprite(sheet.textures['image.png']);
     */
    textures: Record<keyof S['frames'], Texture>;
    /**
     * A map containing the textures for each animation.
     * Can be used to create an {@link AnimatedSprite|AnimatedSprite}:
     * @example
     * import { AnimatedSprite } from 'pixi.js';
     *
     * new AnimatedSprite(sheet.animations['anim_name']);
     */
    animations: Record<keyof NonNullable<S['animations']>, Texture[]>;
    /**
     * Reference to the original JSON data.
     * @type {object}
     */
    data: S;
    /** The resolution of the spritesheet. */
    resolution: number;
    /**
     * Reference to original source image from the Loader. This reference is retained so we
     * can destroy the Texture later on. It is never used internally.
     */
    private _texture;
    /**
     * Map of spritesheet frames.
     * @type {object}
     */
    private _frames;
    /** Collection of frame names. */
    private _frameKeys;
    /** Current batch index being processed. */
    private _batchIndex;
    /**
     * Callback when parse is completed.
     * @type {Function}
     */
    private _callback;
    /**
     * @param texture - Reference to the source BaseTexture object.
     * @param {object} data - Spritesheet image data.
     */
    constructor(texture: BindableTexture, data: S);
    /**
     * Parser spritesheet from loaded data. This is done asynchronously
     * to prevent creating too many Texture within a single process.
     */
    parse(): Promise<Record<string, Texture>>;
    /**
     * Process a batch of frames
     * @param initialFrameIndex - The index of frame to start.
     */
    private _processFrames;
    /** Parse animations config. */
    private _processAnimations;
    /** The parse has completed. */
    private _parseComplete;
    /** Begin the next batch of textures. */
    private _nextBatch;
    /**
     * Destroy Spritesheet and don't use after this.
     * @param {boolean} [destroyBase=false] - Whether to destroy the base texture as well
     */
    destroy(destroyBase?: boolean): void;
}
`,zu=`export * from './Spritesheet';
export * from './spritesheetAsset';
`,Xu=`export {};
`,Ku=`import { LoaderParserPriority } from '../assets/loader/parsers/LoaderParser';
import { ExtensionType } from '../extensions/Extensions';
import { Texture } from '../rendering/renderers/shared/texture/Texture';
import { Spritesheet } from './Spritesheet';
import type { Loader } from '../assets/loader/Loader';
import type { ResolvedAsset } from '../assets/types';
import type { TextureSourceOptions } from '../rendering/renderers/shared/texture/sources/TextureSource';
import type { SpritesheetData } from './Spritesheet';
export interface SpriteSheetJson extends SpritesheetData {
    meta: {
        image: string;
        scale: string;
        related_multi_packs?: string[];
    };
}
/**
 * Asset extension for loading spritesheets
 * @example
 * import { Assets } from 'pixi.js';
 *
 * Assets.load({
 *     alias: 'spritesheet',
 *     src: 'path/to/spritesheet.json',
 *     data: {
 *         ignoreMultiPack: true,
 *         textureOptions: {
 *             scaleMode: "nearest"
 *         }
 *     }
 * })
 * @type {AssetExtension}
 * @memberof assets
 */
export declare const spritesheetAsset: {
    extension: ExtensionType.Asset;
    /** Handle the caching of the related Spritesheet Textures */
    cache: {
        test: (asset: Spritesheet) => boolean;
        getCacheableAssets: (keys: string[], asset: Spritesheet) => Record<string, any>;
    };
    /** Resolve the resolution of the asset. */
    resolver: {
        extension: {
            type: ExtensionType.ResolveParser;
            name: string;
        };
        test: (value: string) => boolean;
        parse: (value: string) => {
            resolution: number;
            format: string;
            src: string;
        };
    };
    /**
     * Loader plugin that parses sprite sheets!
     * once the JSON has been loaded this checks to see if the JSON is spritesheet data.
     * If it is, we load the spritesheets image and parse the data into Spritesheet
     * All textures in the sprite sheet are then added to the cache
     */
    loader: {
        name: string;
        extension: {
            type: ExtensionType.LoadParser;
            priority: LoaderParserPriority;
            name: string;
        };
        testParse(asset: SpriteSheetJson, options: ResolvedAsset): Promise<boolean>;
        parse<T>(asset: SpriteSheetJson, options: ResolvedAsset<{
            texture?: Texture;
            imageFilename?: string;
            ignoreMultiPack?: boolean;
            textureOptions?: TextureSourceOptions;
        }>, loader?: Loader): Promise<Spritesheet>;
        unload(spritesheet: Spritesheet, _resolvedAsset: ResolvedAsset<any>, loader: Loader): Promise<void>;
    };
};
`,qu=`/**
 * A callback which can be added to a ticker.
 * \`\`\`js
 * ticker.add(() => {
 *    // do something every frame
 * });
 * \`\`\`
 * @memberof ticker
 */
export type TickerCallback<T> = (this: T, ticker: Ticker) => any;
/**
 * {@link ticker.Ticker|Tickers} provide periodic callbacks based on the system clock.
 * Your game update logic will generally be run in response to a tick once per frame.
 * You can have multiple tickers in use at one time.
 * \`\`\`js
 * import { Ticker } from 'pixi.js';
 *
 * const callback = (ticker: Ticker) => {
 *    // do something on the next animation frame
 * };
 *
 * // create a ticker
 * const ticker = new Ticker();
 *
 * // register the callback and start the ticker
 * ticker.add(callback);
 * ticker.start();
 * \`\`\`
 *
 * You can always use the {@link ticker.Ticker.shared|shared} ticker that Pixi renders with by default.
 * \`\`\`js
 * Ticker.shared.add(callback);
 * \`\`\`
 * @namespace ticker
 */
/**
 * A Ticker class that runs an update loop that other objects listen to.
 *
 * This class is composed around listeners meant for execution on the next requested animation frame.
 * Animation frames are requested only when necessary, e.g. When the ticker is started and the emitter has listeners.
 * @class
 * @memberof ticker
 */
export declare class Ticker {
    /**
     * Target frames per millisecond.
     * @static
     */
    static targetFPMS: number;
    /** The private shared ticker instance */
    private static _shared;
    /** The private system ticker instance  */
    private static _system;
    /**
     * Whether or not this ticker should invoke the method
     * {@link ticker.Ticker#start|start} automatically when a listener is added.
     */
    autoStart: boolean;
    /**
     * Scalar time value from last frame to this frame.
     * This value is capped by setting {@link ticker.Ticker#minFPS|minFPS}
     * and is scaled with {@link ticker.Ticker#speed|speed}.
     * **Note:** The cap may be exceeded by scaling.
     */
    deltaTime: number;
    /**
     * Scalar time elapsed in milliseconds from last frame to this frame.
     * This value is capped by setting {@link ticker.Ticker#minFPS|minFPS}
     * and is scaled with {@link ticker.Ticker#speed|speed}.
     * **Note:** The cap may be exceeded by scaling.
     * If the platform supports DOMHighResTimeStamp,
     * this value will have a precision of 1 µs.
     * Defaults to target frame time
     * @default 16.66
     */
    deltaMS: number;
    /**
     * Time elapsed in milliseconds from last frame to this frame.
     * Opposed to what the scalar {@link ticker.Ticker#deltaTime|deltaTime}
     * is based, this value is neither capped nor scaled.
     * If the platform supports DOMHighResTimeStamp,
     * this value will have a precision of 1 µs.
     * Defaults to target frame time
     * @default 16.66
     */
    elapsedMS: number;
    /**
     * The last time {@link ticker.Ticker#update|update} was invoked.
     * This value is also reset internally outside of invoking
     * update, but only when a new animation frame is requested.
     * If the platform supports DOMHighResTimeStamp,
     * this value will have a precision of 1 µs.
     */
    lastTime: number;
    /**
     * Factor of current {@link ticker.Ticker#deltaTime|deltaTime}.
     * @example
     * // Scales ticker.deltaTime to what would be
     * // the equivalent of approximately 120 FPS
     * ticker.speed = 2;
     */
    speed: number;
    /**
     * Whether or not this ticker has been started.
     * \`true\` if {@link ticker.Ticker#start|start} has been called.
     * \`false\` if {@link ticker.Ticker#stop|Stop} has been called.
     * While \`false\`, this value may change to \`true\` in the
     * event of {@link ticker.Ticker#autoStart|autoStart} being \`true\`
     * and a listener is added.
     */
    started: boolean;
    /** The first listener. All new listeners added are chained on this. */
    private _head;
    /** Internal current frame request ID */
    private _requestId;
    /**
     * Internal value managed by minFPS property setter and getter.
     * This is the maximum allowed milliseconds between updates.
     */
    private _maxElapsedMS;
    /**
     * Internal value managed by minFPS property setter and getter.
     * This is the minimum allowed milliseconds between updates.
     */
    private _minElapsedMS;
    /** If enabled, deleting is disabled.*/
    private _protected;
    /** The last time keyframe was executed. Maintains a relatively fixed interval with the previous value. */
    private _lastFrame;
    /**
     * Internal tick method bound to ticker instance.
     * This is because in early 2015, Function.bind
     * is still 60% slower in high performance scenarios.
     * Also separating frame requests from update method
     * so listeners may be called at any time and with
     * any animation API, just invoke ticker.update(time).
     * @param time - Time since last tick.
     */
    private readonly _tick;
    constructor();
    /**
     * Conditionally requests a new animation frame.
     * If a frame has not already been requested, and if the internal
     * emitter has listeners, a new frame is requested.
     * @private
     */
    private _requestIfNeeded;
    /**
     * Conditionally cancels a pending animation frame.
     * @private
     */
    private _cancelIfNeeded;
    /**
     * Conditionally requests a new animation frame.
     * If the ticker has been started it checks if a frame has not already
     * been requested, and if the internal emitter has listeners. If these
     * conditions are met, a new frame is requested. If the ticker has not
     * been started, but autoStart is \`true\`, then the ticker starts now,
     * and continues with the previous conditions to request a new frame.
     * @private
     */
    private _startIfPossible;
    /**
     * Register a handler for tick events. Calls continuously unless
     * it is removed or the ticker is stopped.
     * @param fn - The listener function to be added for updates
     * @param context - The listener context
     * @param {number} [priority=UPDATE_PRIORITY.NORMAL] - The priority for emitting
     * @returns This instance of a ticker
     */
    add<T = any>(fn: TickerCallback<T>, context?: T, priority?: number): this;
    /**
     * Add a handler for the tick event which is only execute once.
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @param {number} [priority=UPDATE_PRIORITY.NORMAL] - The priority for emitting
     * @returns This instance of a ticker
     */
    addOnce<T = any>(fn: TickerCallback<T>, context?: T, priority?: number): this;
    /**
     * Internally adds the event handler so that it can be sorted by priority.
     * Priority allows certain handler (user, AnimatedSprite, Interaction) to be run
     * before the rendering.
     * @private
     * @param listener - Current listener being added.
     * @returns This instance of a ticker
     */
    private _addListener;
    /**
     * Removes any handlers matching the function and context parameters.
     * If no handlers are left after removing, then it cancels the animation frame.
     * @param fn - The listener function to be removed
     * @param context - The listener context to be removed
     * @returns This instance of a ticker
     */
    remove<T = any>(fn: TickerCallback<T>, context?: T): this;
    /**
     * The number of listeners on this ticker, calculated by walking through linked list
     * @readonly
     * @member {number}
     */
    get count(): number;
    /** Starts the ticker. If the ticker has listeners a new animation frame is requested at this point. */
    start(): void;
    /** Stops the ticker. If the ticker has requested an animation frame it is canceled at this point. */
    stop(): void;
    /** Destroy the ticker and don't use after this. Calling this method removes all references to internal events. */
    destroy(): void;
    /**
     * Triggers an update. An update entails setting the
     * current {@link ticker.Ticker#elapsedMS|elapsedMS},
     * the current {@link ticker.Ticker#deltaTime|deltaTime},
     * invoking all listeners with current deltaTime,
     * and then finally setting {@link ticker.Ticker#lastTime|lastTime}
     * with the value of currentTime that was provided.
     * This method will be called automatically by animation
     * frame callbacks if the ticker instance has been started
     * and listeners are added.
     * @param {number} [currentTime=performance.now()] - the current time of execution
     */
    update(currentTime?: number): void;
    /**
     * The frames per second at which this ticker is running.
     * The default is approximately 60 in most modern browsers.
     * **Note:** This does not factor in the value of
     * {@link ticker.Ticker#speed|speed}, which is specific
     * to scaling {@link ticker.Ticker#deltaTime|deltaTime}.
     * @member {number}
     * @readonly
     */
    get FPS(): number;
    /**
     * Manages the maximum amount of milliseconds allowed to
     * elapse between invoking {@link ticker.Ticker#update|update}.
     * This value is used to cap {@link ticker.Ticker#deltaTime|deltaTime},
     * but does not effect the measured value of {@link ticker.Ticker#FPS|FPS}.
     * When setting this property it is clamped to a value between
     * \`0\` and \`Ticker.targetFPMS * 1000\`.
     * @member {number}
     * @default 10
     */
    get minFPS(): number;
    set minFPS(fps: number);
    /**
     * Manages the minimum amount of milliseconds required to
     * elapse between invoking {@link ticker.Ticker#update|update}.
     * This will effect the measured value of {@link ticker.Ticker#FPS|FPS}.
     * If it is set to \`0\`, then there is no limit; PixiJS will render as many frames as it can.
     * Otherwise it will be at least \`minFPS\`
     * @member {number}
     * @default 0
     */
    get maxFPS(): number;
    set maxFPS(fps: number);
    /**
     * The shared ticker instance used by {@link AnimatedSprite} and by
     * {@link VideoResource} to update animation frames / video textures.
     *
     * It may also be used by {@link Application} if created with the \`sharedTicker\` option property set to true.
     *
     * The property {@link ticker.Ticker#autoStart|autoStart} is set to \`true\` for this instance.
     * Please follow the examples for usage, including how to opt-out of auto-starting the shared ticker.
     * @example
     * import { Ticker } from 'pixi.js';
     *
     * const ticker = Ticker.shared;
     * // Set this to prevent starting this ticker when listeners are added.
     * // By default this is true only for the Ticker.shared instance.
     * ticker.autoStart = false;
     *
     * // FYI, call this to ensure the ticker is stopped. It should be stopped
     * // if you have not attempted to render anything yet.
     * ticker.stop();
     *
     * // Call this when you are ready for a running shared ticker.
     * ticker.start();
     * @example
     * import { autoDetectRenderer, Container } from 'pixi.js';
     *
     * // You may use the shared ticker to render...
     * const renderer = autoDetectRenderer();
     * const stage = new Container();
     * document.body.appendChild(renderer.view);
     * ticker.add((time) => renderer.render(stage));
     *
     * // Or you can just update it manually.
     * ticker.autoStart = false;
     * ticker.stop();
     * const animate = (time) => {
     *     ticker.update(time);
     *     renderer.render(stage);
     *     requestAnimationFrame(animate);
     * };
     * animate(performance.now());
     * @member {ticker.Ticker}
     * @readonly
     * @static
     */
    static get shared(): Ticker;
    /**
     * The system ticker instance used by {@link BasePrepare} for core timing
     * functionality that shouldn't usually need to be paused, unlike the \`shared\`
     * ticker which drives visual animations and rendering which may want to be paused.
     *
     * The property {@link ticker.Ticker#autoStart|autoStart} is set to \`true\` for this instance.
     * @member {ticker.Ticker}
     * @readonly
     * @static
     */
    static get system(): Ticker;
}
`,Yu=`import type { Ticker, TickerCallback } from './Ticker';
/**
 * Internal class for handling the priority sorting of ticker handlers.
 * @private
 * @class
 */
export declare class TickerListener<T = any> {
    /** The current priority. */
    priority: number;
    /** The next item in chain. */
    next: TickerListener;
    /** The previous item in chain. */
    previous: TickerListener;
    /** The handler function to execute. */
    private _fn;
    /** The calling to execute. */
    private _context;
    /** If this should only execute once. */
    private readonly _once;
    /** \`true\` if this listener has been destroyed already. */
    private _destroyed;
    /**
     * Constructor
     * @private
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @param priority - The priority for emitting
     * @param once - If the handler should fire once
     */
    constructor(fn: TickerCallback<T>, context?: T, priority?: number, once?: boolean);
    /**
     * Simple compare function to figure out if a function and context match.
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @returns \`true\` if the listener match the arguments
     */
    match(fn: TickerCallback<T>, context?: any): boolean;
    /**
     * Emit by calling the current function.
     * @param ticker - The ticker emitting.
     * @returns Next ticker
     */
    emit(ticker: Ticker): TickerListener;
    /**
     * Connect to the list.
     * @param previous - Input node, previous listener
     */
    connect(previous: TickerListener): void;
    /**
     * Destroy and don't use after this.
     * @param hard - \`true\` to remove the \`next\` reference, this
     *        is considered a hard destroy. Soft destroy maintains the next reference.
     * @returns The listener to redirect while emitting or removing.
     */
    destroy(hard?: boolean): TickerListener;
}
`,Ju=`/**
 * Represents the update priorities used by internal Pixi classes when registered with
 * the {@link ticker.Ticker} object. Higher priority items are updated first and lower
 * priority items, such as render, should go later.
 * @static
 * @enum {number}
 * @memberof ticker
 */
export declare enum UPDATE_PRIORITY {
    /**
     * Highest priority used for interaction events in {@link EventSystem}
     * @default 50
     */
    INTERACTION = 50,
    /**
     * High priority updating, used by {@link AnimatedSprite}
     * @default 25
     */
    HIGH = 25,
    /**
     * Default priority for ticker events, see {@link Ticker#add}.
     * @default 0
     */
    NORMAL = 0,
    /**
     * Low priority used for {@link Application} rendering.
     * @default -25
     */
    LOW = -25,
    /**
     * Lowest priority used for {@link BasePrepare} utility.
     * @default -50
     */
    UTILITY = -50
}
`,$u=`export * from './const';
export * from './Ticker';
export * from './TickerListener';
`,Qu=`export * from './particle/generateParticleUpdatePolyfill';
export * from './particle/particleUpdateFunctions';
export * from './shader/generateShaderSyncPolyfill';
export * from './ubo/generateUboSyncPolyfill';
export * from './ubo/uboSyncFunctions';
export * from './uniforms/generateUniformsSyncPolyfill';
export * from './uniforms/uniformSyncFunctions';
`,Zu=`export {};
`,em=`import type { IParticle } from '../../scene/particle-container/shared/Particle';
import type { ParticleRendererProperty } from '../../scene/particle-container/shared/particleData';
export type ParticleUpdateFunction = (ps: IParticle[], f32v: Float32Array, u32v: Uint32Array, offset: number, stride: number) => void;
export declare function generateParticleUpdatePolyfill(properties: ParticleRendererProperty[]): {
    dynamicUpdate: ParticleUpdateFunction;
    staticUpdate: ParticleUpdateFunction;
};
`,nm=`import type { IParticle } from '../../scene/particle-container/shared/Particle';
export declare const particleUpdateFunctions: {
    aVertex: (ps: IParticle[], f32v: Float32Array, _u32v: Uint32Array, offset: number, stride: number) => void;
    aPosition: (ps: IParticle[], f32v: Float32Array, _u32v: Uint32Array, offset: number, stride: number) => void;
    aRotation: (ps: IParticle[], f32v: Float32Array, _u32v: Uint32Array, offset: number, stride: number) => void;
    aUV: (ps: IParticle[], f32v: Float32Array, _u32v: Uint32Array, offset: number, stride: number) => void;
    aColor: (ps: IParticle[], _f32v: Float32Array, u32v: Uint32Array, offset: number, stride: number) => void;
};
`,tm=`import type { ShaderSyncFunction } from '../../rendering/renderers/gl/shader/GlShaderSystem';
export declare function generateShaderSyncPolyfill(): ShaderSyncFunction;
`,rm=`import type { UboElement, UniformsSyncCallback } from '../../rendering/renderers/shared/shader/types';
export declare function generateUboSyncPolyfillSTD40(uboElements: UboElement[]): UniformsSyncCallback;
export declare function generateUboSyncPolyfillWGSL(uboElements: UboElement[]): UniformsSyncCallback;
`,om=`/**
 * This file is auto generated by scripts/utils/autoGenerateUnsafeEvalFunctions.ts
 * Do not edit manually - or you will be sad.
 */
import type { UNIFORM_TYPES } from '../../rendering/renderers/shared/shader/types';
export type UboUploadFunction = (name: string, data: Float32Array, offset: number, uv: any, v: any) => void;
export declare const uboParserFunctions: UboUploadFunction[];
export declare const uboSingleFunctionsWGSL: Record<UNIFORM_TYPES | string, UboUploadFunction>;
export declare const uboSingleFunctionsSTD40: Record<UNIFORM_TYPES | string, UboUploadFunction>;
`,am=`import type { GlUniformData } from '../../rendering/renderers/gl/shader/GlProgram';
import type { UniformsSyncCallback } from '../../rendering/renderers/shared/shader/types';
import type { UniformGroup } from '../../rendering/renderers/shared/shader/UniformGroup';
export declare function generateUniformsSyncPolyfill(group: UniformGroup, uniformData: Record<string, GlUniformData>): UniformsSyncCallback;
`,im=`/**
 * This file is auto generated by scripts/utils/autoGenerateUnsafeEvalFunctions.ts
 * Do not edit manually - or you will be sad.
 */
import type { UNIFORM_TYPES } from '../../rendering/renderers/shared/shader/types';
export type UniformUploadFunction = (name: string, cu: any, cv: any, v: any, ud: any, uv: any, gl: any) => void;
export declare const uniformSingleParserFunctions: Record<UNIFORM_TYPES | string, UniformUploadFunction>;
export declare const uniformArrayParserFunctions: Record<UNIFORM_TYPES | string, UniformUploadFunction>;
export declare const uniformParserFunctions: UniformUploadFunction[];
`,sm=`import type { ALPHA_MODES } from '../../rendering/renderers/shared/texture/const';
/**
 * Helper for detecting the correct alpha mode for video textures.
 * For some reason, some browsers/devices/WebGL implementations premultiply the alpha
 * of a video before and then a second time if \`UNPACK_PREMULTIPLY_ALPHA_WEBGL\`
 * is true. So the video is premultiplied twice if the alpha mode is \`UNPACK\`.
 * In this case we need the alpha mode to be \`PMA\`. This function detects
 * the upload behavior by uploading a white 2x2 webm with 50% alpha
 * without \`UNPACK_PREMULTIPLY_ALPHA_WEBGL\` and then checking whether
 * the uploaded pixels are premultiplied.
 * @memberof utils
 * @function detectVideoAlphaMode
 * @returns {Promise<ALPHA_MODES>} The correct alpha mode for video textures.
 */
export declare function detectVideoAlphaMode(): Promise<ALPHA_MODES>;
`,lm=`/**
 * The result of the {@link utils.isMobile} function.
 * @ignore
 * @memberof utils
 */
export type isMobileResult = {
    /**
     * Whether the device is an Apple device.
     * @memberof utils.isMobile
     */
    apple: {
        phone: boolean;
        ipod: boolean;
        tablet: boolean;
        universal: boolean;
        device: boolean;
    };
    /**
     * Whether the device is an Amazon device.
     * @memberof utils.isMobile
     */
    amazon: {
        phone: boolean;
        tablet: boolean;
        device: boolean;
    };
    /**
     * Whether the device is an Android device.
     * @memberof utils.isMobile
     */
    android: {
        phone: boolean;
        tablet: boolean;
        device: boolean;
    };
    /**
     * Whether the device is a Windows device.
     * @memberof utils.isMobile
     */
    windows: {
        phone: boolean;
        tablet: boolean;
        device: boolean;
    };
    /**
     * Whether the device is a specific device.
     * @memberof utils.isMobile
     */
    other: {
        blackberry: boolean;
        blackberry10: boolean;
        opera: boolean;
        firefox: boolean;
        chrome: boolean;
        device: boolean;
    };
    /**
     * Whether the device is a phone device.
     * @memberof utils.isMobile
     */
    phone: boolean;
    /**
     * Whether the device is a tablet device.
     * @memberof utils.isMobile
     */
    tablet: boolean;
    /**
     * Whether the device is any kind of device.
     * @memberof utils.isMobile
     */
    any: boolean;
};
/**
 * Detects whether the device is mobile and what type of mobile device it is.
 * \`\`\`js
 * import { isMobile } from 'pixi.js';
 *
 * if (isMobile.apple.tablet) {
 *    // The device is an Apple tablet device.
 * }
 * \`\`\`
 * @memberof utils
 */
export declare const isMobile: isMobileResult;
`,dm=`export declare function isSafari(): boolean;
`,pm=`/**
 * Helper for checking for WebGL support.
 * @param failIfMajorPerformanceCaveat - whether to fail if there is a major performance caveat, defaults to false
 * @memberof utils
 * @function isWebGLSupported
 * @returns {boolean} Is WebGL supported.
 */
export declare function isWebGLSupported(failIfMajorPerformanceCaveat?: boolean): boolean;
`,cm=`/// <reference types="@webgpu/types" />
/**
 * Helper for checking for WebGPU support.
 * @param options - The options for requesting a GPU adapter.
 * @memberof utils
 * @function isWebGPUSupported
 * @returns Is WebGPU supported.
 */
export declare function isWebGPUSupported(options?: GPURequestAdapterOptions): Promise<boolean>;
`,um=`/**
 * Not all platforms allow to generate function code (e.g., \`new Function\`).
 * this provides the platform-level detection.
 * @private
 * @returns {boolean} \`true\` if \`new Function\` is supported.
 */
export declare function unsafeEvalSupported(): boolean;
`,mm=`import { Rectangle } from '../../maths/shapes/Rectangle';
import type { ICanvas } from '../../environment/canvas/ICanvas';
/**
 * Measuring the bounds of a canvas' visible (non-transparent) pixels.
 * @param canvas - The canvas to measure.
 * @param resolution - The resolution of the canvas.
 * @returns The bounding box of the canvas' visible pixels.
 * @since 7.1.0
 * @memberof utils
 */
export declare function getCanvasBoundingBox(canvas: ICanvas, resolution?: number): Rectangle;
`,hm=`import EventEmitter from 'eventemitter3';
/**
 * Regexp for data URI.
 * Based on: {@link https://github.com/ragingwind/data-uri-regex}
 * @static
 * @type {RegExp}
 * @default /(?:^data:image\\/([\\w+]+);(?:[\\w=]+|charset=[\\w-]+)?(?:;base64)?,)/i
 * @example
 * import { DATA_URI } from 'pixi.js';
 *
 * DATA_URI.test('data:image/png;base64,foobar'); // => true
 * @memberof utils
 */
export declare const DATA_URI: RegExp;
export { EventEmitter };
/** The current version of PixiJS. This is automatically replaced by the build process. */
export declare const VERSION = "$_VERSION";
`,fm=`type TypedArray = Float32Array | Uint32Array | Int32Array | Uint8Array;
/**
 * Flexible wrapper around \`ArrayBuffer\` that also provides typed array views on demand.
 * @memberof utils
 */
export declare class ViewableBuffer {
    /** The size of the buffer in bytes. */
    size: number;
    /** Underlying \`ArrayBuffer\` that holds all the data and is of capacity \`this.size\`. */
    rawBinaryData: ArrayBuffer;
    /** View on the raw binary data as a \`Uint32Array\`. */
    uint32View: Uint32Array;
    /** View on the raw binary data as a \`Float32Array\`. */
    float32View: Float32Array;
    uint16View: Uint16Array;
    private _int8View;
    private _uint8View;
    private _int16View;
    private _int32View;
    private _float64Array;
    private _bigUint64Array;
    /**
     * @param length - The size of the buffer in bytes.
     */
    constructor(length: number);
    /**
     * @param arrayBuffer - The source array buffer.
     */
    constructor(arrayBuffer: ArrayBuffer);
    /** View on the raw binary data as a \`Int8Array\`. */
    get int8View(): Int8Array;
    /** View on the raw binary data as a \`Uint8Array\`. */
    get uint8View(): Uint8Array;
    /**  View on the raw binary data as a \`Int16Array\`. */
    get int16View(): Int16Array;
    /** View on the raw binary data as a \`Int32Array\`. */
    get int32View(): Int32Array;
    /** View on the raw binary data as a \`Float64Array\`. */
    get float64View(): Float64Array;
    /** View on the raw binary data as a \`BigUint64Array\`. */
    get bigUint64View(): BigUint64Array;
    /**
     * Returns the view of the given type.
     * @param type - One of \`int8\`, \`uint8\`, \`int16\`,
     *    \`uint16\`, \`int32\`, \`uint32\`, and \`float32\`.
     * @returns - typed array of given type
     */
    view(type: string): TypedArray;
    /** Destroys all buffer references. Do not use after calling this. */
    destroy(): void;
    /**
     * Returns the size of the given type in bytes.
     * @param type - One of \`int8\`, \`uint8\`, \`int16\`,
     *   \`uint16\`, \`int32\`, \`uint32\`, and \`float32\`.
     * @returns - size of the type in bytes
     */
    static sizeOf(type: string): number;
}
export {};
`,bm=`/**
 * Takes a hash and removes all the \`undefined\`/\`null\` values from it.
 * In PixiJS, we tend to null properties instead of using 'delete' for performance reasons.
 * However, in some cases, this could be a problem if the hash grows too large over time,
 * this function can be used to clean a hash.
 * @param hash - The hash to clean.
 * @returns A new hash with all the \`undefined\`/\`null\` values removed.
 * @memberof utils
 */
export declare function cleanHash<T>(hash: Record<string, T>): Record<string, T>;
/**
 * Removes all \`undefined\`/\`null\` elements from the given array and compacts the array.
 *
 * This function iterates through the array, shifting non-undefined elements to the left
 * to fill gaps created by \`undefined\` elements. The length of the array is then adjusted
 * to remove the trailing \`undefined\` elements.
 * @param arr - The array to be cleaned.
 * @returns The cleaned array with all \`undefined\` elements removed.
 * @example
 * // Example usage:
 * const arr = [1, undefined, 2, undefined, 3];
 * const cleanedArr = cleanArray(arr);
 * console.log(cleanedArr); // Output: [1, 2, 3]
 * @memberof utils
 */
export declare function cleanArray<T>(arr: T[]): T[];
`,gm=`/**
 * Remove items from a javascript array without generating garbage
 * @function removeItems
 * @memberof utils
 * @param {Array<any>} arr - Array to remove elements from
 * @param {number} startIdx - starting index
 * @param {number} removeCount - how many to remove
 */
export declare function removeItems(arr: any[], startIdx: number, removeCount: number): void;
`,ym=`type UIDNames = 'default' | 'resource' | 'texture' | 'textureSource' | 'textureResource' | 'batcher' | 'graphicsContext' | 'graphicsView' | 'graphicsPath' | 'fillGradient' | 'fillPattern' | 'meshView' | 'renderable' | 'buffer' | 'bufferResource' | 'geometry' | 'instructionSet' | 'renderTarget' | 'uniform' | 'spriteView' | 'textView' | 'tilingSpriteView' | 'shader';
/**
 * Gets the next unique identifier
 * @param name - The name of the identifier.
 * @function uid
 * @returns {number} The next unique identifier to use.
 * @memberof utils
 */
export declare function uid(name?: UIDNames): number;
/** Resets the next unique identifier to 0. This is used for some tests, dont touch or things WILL explode :) */
export declare function resetUids(): void;
export {};
`,xm=`import type { ObservablePoint } from '../../maths/point/ObservablePoint';
import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { BoundsData } from '../../scene/container/bounds/Bounds';
/**
 * Updates the bounds of a quad (a rectangular area) based on the provided texture and anchor point.
 *
 * This function calculates the minimum and maximum x and y coordinates of the bounds, taking into
 * account the texture's original dimensions and any trimming that may have been applied to it.
 * @param {BoundsData} bounds - The bounds object to be updated. It contains minX, maxX, minY, and maxY properties.
 * @param {ObservablePoint} anchor - The anchor point of the texture, which affects the positioning of the bounds.
 * @param {Texture} texture - The texture whose dimensions and trimming information are used to update the bounds.
 */
export declare function updateQuadBounds(bounds: BoundsData, anchor: ObservablePoint, texture: Texture): void;
`,vm=`import { type ExtensionMetadata, ExtensionType } from '../../extensions/Extensions';
import type { Application } from '../../app/Application';
import type { System } from '../../rendering/renderers/shared/system/System';
import type { Renderer } from '../../rendering/renderers/types';
declare global {
    var __PIXI_APP_INIT__: undefined | ((arg: Application | Renderer, version: string) => void);
    var __PIXI_RENDERER_INIT__: undefined | ((arg: Application | Renderer, version: string) => void);
}
/**
 * Calls global __PIXI_APP_INIT__ hook with the application instance, after the application is initialized.
 * @memberof app
 */
export declare class ApplicationInitHook {
    /** @ignore */
    static extension: ExtensionMetadata;
    static init(): void;
    static destroy(): void;
}
/**
 * Calls global __PIXI_RENDERER_INIT__ hook with the renderer instance, after the renderer is initialized.
 * @memberof rendering
 */
export declare class RendererInitHook implements System {
    /** @ignore */
    static extension: {
        readonly type: readonly [ExtensionType.WebGLSystem, ExtensionType.WebGPUSystem];
        readonly name: "initHook";
        readonly priority: -10;
    };
    private _renderer;
    constructor(renderer: Renderer);
    init(): void;
    destroy(): void;
}
`,Tm=`export * from './browser/detectVideoAlphaMode';
export * from './browser/isMobile';
export * from './browser/isSafari';
export * from './browser/isWebGLSupported';
export * from './browser/isWebGPUSupported';
export * from './browser/unsafeEvalSupported';
export * from './canvas/getCanvasBoundingBox';
export * from './const';
export * from './data/clean';
export * from './data/removeItems';
export * from './data/uid';
export * from './data/updateQuadBounds';
export * from './data/ViewableBuffer';
export * from './global/globalHooks';
export * from './logging/deprecation';
export * from './logging/logDebugTexture';
export * from './logging/logScene';
export * from './logging/warn';
export * from './misc/NOOP';
export * from './misc/Transform';
export * from './network/getResolutionOfUrl';
export * from './path';
export * from './pool/Pool';
export * from './pool/PoolGroup';
export * from './sayHello';
export * from './types';
export * from './utils';
`,Sm=`/**
 * deprecation name for version 8.0.0
 * @ignore
 */
export declare const v8_0_0 = "8.0.0";
export declare const v8_3_4 = "8.3.4";
/**
 * Helper for warning developers about deprecated features & settings.
 * A stack track for warnings is given; useful for tracking-down where
 * deprecated methods/properties/classes are being used within the code.
 * @memberof utils
 * @ignore
 * @function deprecation
 * @param {string} version - The version where the feature became deprecated
 * @param {string} message - Message should include what is deprecated, where, and the new solution
 * @param {number} [ignoreDepth=3] - The number of steps to ignore at the top of the error stack
 *        this is mostly to ignore internal deprecation calls.
 */
export declare function deprecation(version: string, message: string, ignoreDepth?: number): void;
`,wm=`import type { Texture } from '../../rendering/renderers/shared/texture/Texture';
import type { Renderer } from '../../rendering/renderers/types';
/**
 * Logs a texture to the console as a base64 image.
 * This can be very useful for debugging issues with rendering.
 * @param texture - The texture to log
 * @param renderer - The renderer to use
 * @param size - The size of the texture to log in the console
 * @ignore
 */
export declare function logDebugTexture(texture: Texture, renderer: Renderer, size?: number): Promise<void>;
`,_m=`import type { Container } from '../../scene/container/Container';
import type { RenderGroup } from '../../scene/container/RenderGroup';
export declare function logScene(container: Container, depth?: number, data?: {
    color?: string;
}): void;
export declare function logRenderGroupScene(renderGroup: RenderGroup, depth?: number, data?: {
    index: number;
    color?: string;
}): void;
`,Em=`/**
 * Logs a PixiJS warning message to the console. Stops logging after 500 warnings have been logged.
 * @param args - The warning message(s) to log
 * @returns {void}
 * @memberof utils
 * @ignore
 */
export declare function warn(...args: any[]): void;
`,Pm=`export declare const NOOP: () => void;
`,Am=`import { Matrix } from '../../maths/matrix/Matrix';
import { ObservablePoint } from '../../maths/point/ObservablePoint';
import type { Observer } from '../../maths/point/ObservablePoint';
/**
 * Options for the {@link utils.Transform} constructor.
 * @memberof utils.Transform
 */
export interface TransformOptions {
    /** The matrix to use. */
    matrix?: Matrix;
    /** The observer to use. */
    observer?: {
        _onUpdate: (transform: Transform) => void;
    };
}
/**
 * The Transform class facilitates the manipulation of a 2D transformation matrix through
 * user-friendly properties: position, scale, rotation, skew, and pivot.
 * @memberof utils
 */
export declare class Transform {
    /**
     * The local transformation matrix.
     * @internal
     * @private
     */
    _matrix: Matrix;
    /** The coordinate of the object relative to the local coordinates of the parent. */
    position: ObservablePoint;
    /** The scale factor of the object. */
    scale: ObservablePoint;
    /** The pivot point of the container that it rotates around. */
    pivot: ObservablePoint;
    /** The skew amount, on the x and y axis. */
    skew: ObservablePoint;
    /** The rotation amount. */
    protected _rotation: number;
    /**
     * The X-coordinate value of the normalized local X axis,
     * the first column of the local transformation matrix without a scale.
     */
    protected _cx: number;
    /**
     * The Y-coordinate value of the normalized local X axis,
     * the first column of the local transformation matrix without a scale.
     */
    protected _sx: number;
    /**
     * The X-coordinate value of the normalized local Y axis,
     * the second column of the local transformation matrix without a scale.
     */
    protected _cy: number;
    /**
     * The Y-coordinate value of the normalized local Y axis,
     * the second column of the local transformation matrix without a scale.
     */
    protected _sy: number;
    protected dirty: boolean;
    protected observer: Observer<Transform>;
    /**
     * @param options - Options for the transform.
     * @param options.matrix - The matrix to use.
     * @param options.observer - The observer to use.
     */
    constructor({ matrix, observer }?: TransformOptions);
    /**
     * This matrix is computed by combining this Transforms position, scale, rotation, skew, and pivot
     * properties into a single matrix.
     * @readonly
     */
    get matrix(): Matrix;
    /**
     * Called when a value changes.
     * @param point
     * @internal
     * @private
     */
    _onUpdate(point?: ObservablePoint): void;
    /** Called when the skew or the rotation changes. */
    protected updateSkew(): void;
    toString(): string;
    /**
     * Decomposes a matrix and sets the transforms properties based on it.
     * @param matrix - The matrix to decompose
     */
    setFromMatrix(matrix: Matrix): void;
    /** The rotation of the object in radians. */
    get rotation(): number;
    set rotation(value: number);
}
`,Cm=`/**
 * get the resolution / device pixel ratio of an asset by looking for the prefix
 * used by spritesheets and image urls
 * @memberof utils
 * @function getResolutionOfUrl
 * @param {string} url - the image path
 * @param {number} [defaultValue=1] - the defaultValue if no filename prefix is set.
 * @returns {number} resolution / device pixel ratio of an asset
 */
export declare function getResolutionOfUrl(url: string, defaultValue?: number): number;
`,Rm=`/**
 * Path utilities for working with URLs and file paths in a cross-platform way.
 * All paths that are passed in will become normalized to have posix separators.
 * \`\`\`js
 * import { path } from 'pixi.js';
 *
 * path.normalize('http://www.example.com/foo/bar/../baz'); // http://www.example.com/foo/baz
 * \`\`\`
 * @memberof utils
 */
export interface Path {
    /**
     * Converts a path to posix format.
     * @param path - The path to convert to posix
     */
    toPosix: (path: string) => string;
    /**
     * Checks if the path is a URL e.g. http://, https://
     * @param path - The path to check
     */
    isUrl: (path: string) => boolean;
    /**
     * Checks if the path is a data URL
     * @param path - The path to check
     */
    isDataUrl: (path: string) => boolean;
    /**
     * Checks if the path is a blob URL
     * @param path - The path to check
     */
    isBlobUrl: (path: string) => boolean;
    /**
     * Checks if the path has a protocol e.g. http://, https://, file:///, data:, blob:, C:/
     * This will return true for windows file paths
     * @param path - The path to check
     */
    hasProtocol: (path: string) => boolean;
    /**
     * Returns the protocol of the path e.g. http://, https://, file:///, data:, blob:, C:/
     * @param path - The path to get the protocol from
     */
    getProtocol: (path: string) => string;
    /**
     * Converts URL to an absolute path.
     * When loading from a Web Worker, we must use absolute paths.
     * If the URL is already absolute we return it as is
     * If it's not, we convert it
     * @param url - The URL to test
     * @param customBaseUrl - The base URL to use
     * @param customRootUrl - The root URL to use
     */
    toAbsolute: (url: string, baseUrl?: string, rootUrl?: string) => string;
    /**
     * Normalizes the given path, resolving '..' and '.' segments
     * @param path - The path to normalize
     */
    normalize: (path: string) => string;
    /**
     * Determines if path is an absolute path.
     * Absolute paths can be urls, data urls, or paths on disk
     * @param path - The path to test
     */
    isAbsolute: (path: string) => boolean;
    /**
     * Joins all given path segments together using the platform-specific separator as a delimiter,
     * then normalizes the resulting path
     * @param segments - The segments of the path to join
     */
    join: (...paths: string[]) => string;
    /**
     * Returns the directory name of a path
     * @param path - The path to parse
     */
    dirname: (path: string) => string;
    /**
     * Returns the root of the path e.g. /, C:/, file:///, http://domain.com/
     * @param path - The path to parse
     */
    rootname: (path: string) => string;
    /**
     * Returns the last portion of a path
     * @param path - The path to test
     * @param ext - Optional extension to remove
     */
    basename: (path: string, ext?: string) => string;
    /**
     * Returns the extension of the path, from the last occurrence of the . (period) character to end of string in the last
     * portion of the path. If there is no . in the last portion of the path, or if there are no . characters other than
     * the first character of the basename of path, an empty string is returned.
     * @param path - The path to parse
     */
    extname: (path: string) => string;
    /**
     * Parses a path into an object containing the 'root', \`dir\`, \`base\`, \`ext\`, and \`name\` properties.
     * @param path - The path to parse
     */
    parse: (path: string) => {
        root?: string;
        dir?: string;
        base?: string;
        ext?: string;
        name?: string;
    };
    sep: string;
    delimiter: string;
    joinExtensions: string[];
}
/**
 * Path utilities for working with URLs and file paths in a cross-platform way.
 * All paths that are passed in will become normalized to have posix separators.
 * \`\`\`js
 * import { path } from 'pixi.js';
 *
 * path.normalize('http://www.example.com/foo/bar/../baz'); // http://www.example.com/foo/baz
 * \`\`\`
 * @see {@link utils.Path}
 * @memberof utils
 */
export declare const path: Path;
`,Gm=`/**
 * A generic class for managing a pool of items.
 * @template T The type of items in the pool. Must implement {@link utils.PoolItem}.
 * @memberof utils
 */
export declare class Pool<T extends PoolItem> {
    readonly _classType: PoolItemConstructor<T>;
    private readonly _pool;
    private _count;
    private _index;
    /**
     * Constructs a new Pool.
     * @param ClassType - The constructor of the items in the pool.
     * @param {number} [initialSize] - The initial size of the pool.
     */
    constructor(ClassType: PoolItemConstructor<T>, initialSize?: number);
    /**
     * Prepopulates the pool with a given number of items.
     * @param total - The number of items to add to the pool.
     */
    prepopulate(total: number): void;
    /**
     * Gets an item from the pool. Calls the item's \`init\` method if it exists.
     * If there are no items left in the pool, a new one will be created.
     * @param {unknown} [data] - Optional data to pass to the item's constructor.
     * @returns {T} The item from the pool.
     */
    get(data?: unknown): T;
    /**
     * Returns an item to the pool. Calls the item's \`reset\` method if it exists.
     * @param {T} item - The item to return to the pool.
     */
    return(item: T): void;
    /**
     * Gets the number of items in the pool.
     * @readonly
     * @member {number}
     */
    get totalSize(): number;
    /**
     * Gets the number of items in the pool that are free to use without needing to create more.
     * @readonly
     * @member {number}
     */
    get totalFree(): number;
    /**
     * Gets the number of items in the pool that are currently in use.
     * @readonly
     * @member {number}
     */
    get totalUsed(): number;
    /** clears the pool - mainly used for debugging! */
    clear(): void;
}
/**
 * An object that can be stored in a {@link utils.Pool}.
 * @memberof utils
 */
export type PoolItem = {
    init?: (data?: any) => void;
    reset?: () => void;
    [key: string]: any;
};
/**
 * The constructor of an object that can be stored in a {@link utils.Pool}.
 * @typeParam K - The type of the object that can be stored in a {@link utils.Pool}.
 * @memberof utils
 */
export type PoolItemConstructor<K extends PoolItem> = new () => K;
`,Mm=`import { Pool } from './Pool';
import type { PoolItem, PoolItemConstructor } from './Pool';
/**
 * A type alias for a constructor of a Pool.
 * @template T The type of items in the pool. Must extend PoolItem.
 * @memberof utils
 */
export type PoolConstructor<T extends PoolItem> = new () => Pool<T>;
/**
 * A group of pools that can be used to store objects of different types.
 * @memberof utils
 */
export declare class PoolGroupClass {
    /**
     * A map to store the pools by their class type.
     * @private
     */
    private readonly _poolsByClass;
    /**
     * Prepopulates a specific pool with a given number of items.
     * @template T The type of items in the pool. Must extend PoolItem.
     * @param {PoolItemConstructor<T>} Class - The constructor of the items in the pool.
     * @param {number} total - The number of items to add to the pool.
     */
    prepopulate<T extends PoolItem>(Class: PoolItemConstructor<T>, total: number): void;
    /**
     * Gets an item from a specific pool.
     * @template T The type of items in the pool. Must extend PoolItem.
     * @param {PoolItemConstructor<T>} Class - The constructor of the items in the pool.
     * @param {unknown} [data] - Optional data to pass to the item's constructor.
     * @returns {T} The item from the pool.
     */
    get<T extends PoolItem>(Class: PoolItemConstructor<T>, data?: unknown): T;
    /**
     * Returns an item to its respective pool.
     * @param {PoolItem} item - The item to return to the pool.
     */
    return(item: PoolItem): void;
    /**
     * Gets a specific pool based on the class type.
     * @template T The type of items in the pool. Must extend PoolItem.
     * @param {PoolItemConstructor<T>} ClassType - The constructor of the items in the pool.
     * @returns {Pool<T>} The pool of the given class type.
     */
    getPool<T extends PoolItem>(ClassType: PoolItemConstructor<T>): Pool<T>;
    /** gets the usage stats of each pool in the system */
    stats(): Record<string, {
        free: number;
        used: number;
        size: number;
    }>;
}
export declare const BigPool: PoolGroupClass;
`,km=`/**
 * Prints out the version and renderer information for this running instance of PixiJS.
 * @param type - The name of the renderer this instance is using.
 * @returns {void}
 */
export declare function sayHello(type: string): void;
`,Fm=`export type ArrayFixed<T, L extends number> = [T, ...Array<T>] & {
    length: L;
};
export type Dict<T> = {
    [key: string]: T;
};
/**
 * A collection of utility functions used by Pixi, but also handy for your games and applications.
 *
 * \`\`\`js
 * import { isWebGLSupported } from 'pixi.js';
 *
 * if (isWebGLSupported()) {
 *    // WebGL is supported, proceed!
 * }
 * \`\`\`
 * @namespace utils
 */
`,Om=`/**
 * A high performance event emitter
 * @see {@link https://github.com/primus/eventemitter3}
 * @class EventEmitter
 * @memberof utils
 */
export { default as EventEmitter } from 'eventemitter3';
/**
 * A polygon triangulation library
 * @see {@link https://github.com/mapbox/earcut}
 * @method earcut
 * @param {number[]} vertices - A flat array of vertex coordinates
 * @param {number[]} [holes] - An array of hole indices
 * @param {number} [dimensions=2] - The number of coordinates per vertex in the input array
 * @returns {number[]} Triangulated polygon
 * @memberof utils
 */
export { default as earcut } from 'earcut';
`;function Im(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function M(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter(function(o){return Object.getOwnPropertyDescriptor(e,o).enumerable})),t.push.apply(t,r)}return t}function k(e){for(var n=1;n<arguments.length;n++){var t=arguments[n]!=null?arguments[n]:{};n%2?M(Object(t),!0).forEach(function(r){Im(e,r,t[r])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):M(Object(t)).forEach(function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))})}return e}function Lm(e,n){if(e==null)return{};var t={},r=Object.keys(e),o,a;for(a=0;a<r.length;a++)o=r[a],!(n.indexOf(o)>=0)&&(t[o]=e[o]);return t}function Bm(e,n){if(e==null)return{};var t=Lm(e,n),r,o;if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)r=a[o],!(n.indexOf(r)>=0)&&Object.prototype.propertyIsEnumerable.call(e,r)&&(t[r]=e[r])}return t}function Dm(e,n){return Um(e)||jm(e,n)||Wm(e,n)||Hm()}function Um(e){if(Array.isArray(e))return e}function jm(e,n){if(!(typeof Symbol>"u"||!(Symbol.iterator in Object(e)))){var t=[],r=!0,o=!1,a=void 0;try{for(var i=e[Symbol.iterator](),l;!(r=(l=i.next()).done)&&(t.push(l.value),!(n&&t.length===n));r=!0);}catch(s){o=!0,a=s}finally{try{!r&&i.return!=null&&i.return()}finally{if(o)throw a}}return t}}function Wm(e,n){if(e){if(typeof e=="string")return F(e,n);var t=Object.prototype.toString.call(e).slice(8,-1);if(t==="Object"&&e.constructor&&(t=e.constructor.name),t==="Map"||t==="Set")return Array.from(e);if(t==="Arguments"||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t))return F(e,n)}}function F(e,n){(n==null||n>e.length)&&(n=e.length);for(var t=0,r=new Array(n);t<n;t++)r[t]=e[t];return r}function Hm(){throw new TypeError(`Invalid attempt to destructure non-iterable instance.
In order to be iterable, non-array objects must have a [Symbol.iterator]() method.`)}function Vm(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function O(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter(function(o){return Object.getOwnPropertyDescriptor(e,o).enumerable})),t.push.apply(t,r)}return t}function I(e){for(var n=1;n<arguments.length;n++){var t=arguments[n]!=null?arguments[n]:{};n%2?O(Object(t),!0).forEach(function(r){Vm(e,r,t[r])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):O(Object(t)).forEach(function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))})}return e}function Nm(){for(var e=arguments.length,n=new Array(e),t=0;t<e;t++)n[t]=arguments[t];return function(r){return n.reduceRight(function(o,a){return a(o)},r)}}function y(e){return function n(){for(var t=this,r=arguments.length,o=new Array(r),a=0;a<r;a++)o[a]=arguments[a];return o.length>=e.length?e.apply(this,o):function(){for(var i=arguments.length,l=new Array(i),s=0;s<i;s++)l[s]=arguments[s];return n.apply(t,[].concat(o,l))}}}function E(e){return{}.toString.call(e).includes("Object")}function zm(e){return!Object.keys(e).length}function T(e){return typeof e=="function"}function Xm(e,n){return Object.prototype.hasOwnProperty.call(e,n)}function Km(e,n){return E(n)||p("changeType"),Object.keys(n).some(function(t){return!Xm(e,t)})&&p("changeField"),n}function qm(e){T(e)||p("selectorType")}function Ym(e){T(e)||E(e)||p("handlerType"),E(e)&&Object.values(e).some(function(n){return!T(n)})&&p("handlersType")}function Jm(e){e||p("initialIsRequired"),E(e)||p("initialType"),zm(e)&&p("initialContent")}function $m(e,n){throw new Error(e[n]||e.default)}var Qm={initialIsRequired:"initial state is required",initialType:"initial state should be an object",initialContent:"initial state shouldn't be an empty object",handlerType:"handler should be an object or a function",handlersType:"all handlers should be a functions",selectorType:"selector should be a function",changeType:"provided value of changes should be an object",changeField:'it seams you want to change a field in the state which is not specified in the "initial" state',default:"an unknown error accured in `state-local` package"},p=y($m)(Qm),w={changes:Km,selector:qm,handler:Ym,initial:Jm};function Zm(e){var n=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};w.initial(e),w.handler(n);var t={current:e},r=y(th)(t,n),o=y(nh)(t),a=y(w.changes)(e),i=y(eh)(t);function l(){var d=arguments.length>0&&arguments[0]!==void 0?arguments[0]:function(c){return c};return w.selector(d),d(t.current)}function s(d){Nm(r,o,a,i)(d)}return[l,s]}function eh(e,n){return T(n)?n(e.current):n}function nh(e,n){return e.current=I(I({},e.current),n),n}function th(e,n,t){return T(n)?n(e.current):Object.keys(t).forEach(function(r){var o;return(o=n[r])===null||o===void 0?void 0:o.call(n,e.current[r])}),t}var rh={create:Zm},oh={paths:{vs:"https://cdn.jsdelivr.net/npm/monaco-editor@0.52.2/min/vs"}};function ah(e){return function n(){for(var t=this,r=arguments.length,o=new Array(r),a=0;a<r;a++)o[a]=arguments[a];return o.length>=e.length?e.apply(this,o):function(){for(var i=arguments.length,l=new Array(i),s=0;s<i;s++)l[s]=arguments[s];return n.apply(t,[].concat(o,l))}}}function ih(e){return{}.toString.call(e).includes("Object")}function sh(e){return e||L("configIsRequired"),ih(e)||L("configType"),e.urls?(lh(),{paths:{vs:e.urls.monacoBase}}):e}function lh(){console.warn(j.deprecation)}function dh(e,n){throw new Error(e[n]||e.default)}var j={configIsRequired:"the configuration object is required",configType:"the configuration object should be an object",default:"an unknown error accured in `@monaco-editor/loader` package",deprecation:`Deprecation warning!
    You are using deprecated way of configuration.

    Instead of using
      monaco.config({ urls: { monacoBase: '...' } })
    use
      monaco.config({ paths: { vs: '...' } })

    For more please check the link https://github.com/suren-atoyan/monaco-loader#config
  `},L=ah(dh)(j),ph={config:sh},ch=function(){for(var n=arguments.length,t=new Array(n),r=0;r<n;r++)t[r]=arguments[r];return function(o){return t.reduceRight(function(a,i){return i(a)},o)}};function W(e,n){return Object.keys(n).forEach(function(t){n[t]instanceof Object&&e[t]&&Object.assign(n[t],W(e[t],n[t]))}),k(k({},e),n)}var uh={type:"cancelation",msg:"operation is manually canceled"};function A(e){var n=!1,t=new Promise(function(r,o){e.then(function(a){return n?o(uh):r(a)}),e.catch(o)});return t.cancel=function(){return n=!0},t}var mh=rh.create({config:oh,isInitialized:!1,resolve:null,reject:null,monaco:null}),H=Dm(mh,2),S=H[0],P=H[1];function hh(e){var n=ph.config(e),t=n.monaco,r=Bm(n,["monaco"]);P(function(o){return{config:W(o.config,r),monaco:t}})}function fh(){var e=S(function(n){var t=n.monaco,r=n.isInitialized,o=n.resolve;return{monaco:t,isInitialized:r,resolve:o}});if(!e.isInitialized){if(P({isInitialized:!0}),e.monaco)return e.resolve(e.monaco),A(C);if(window.monaco&&window.monaco.editor)return V(window.monaco),e.resolve(window.monaco),A(C);ch(bh,yh)(xh)}return A(C)}function bh(e){return document.body.appendChild(e)}function gh(e){var n=document.createElement("script");return e&&(n.src=e),n}function yh(e){var n=S(function(r){var o=r.config,a=r.reject;return{config:o,reject:a}}),t=gh("".concat(n.config.paths.vs,"/loader.js"));return t.onload=function(){return e()},t.onerror=n.reject,t}function xh(){var e=S(function(t){var r=t.config,o=t.resolve,a=t.reject;return{config:r,resolve:o,reject:a}}),n=window.require;n.config(e.config),n(["vs/editor/editor.main"],function(t){V(t),e.resolve(t)},function(t){e.reject(t)})}function V(e){S().monaco||P({monaco:e})}function vh(){return S(function(e){var n=e.monaco;return n})}var C=new Promise(function(e,n){return P({resolve:e,reject:n})}),Th={config:hh,init:fh,__getMonacoInstance:vh},Sh=J("<div>");const B=Object.assign({"../../types/Cont.d.ts":te,"../../types/TypeSchema.d.ts":re,"../../types/components/AnimatedComponent.d.ts":oe,"../../types/components/CameraComponent.d.ts":ae,"../../types/components/FlipXComponent.d.ts":ie,"../../types/components/LevelRefComponent.d.ts":se,"../../types/components/OnGroundComponent.d.ts":le,"../../types/components/ScaleComponent.d.ts":de,"../../types/components/SpriteComponent.d.ts":pe,"../../types/components/TileCollisionComponent.d.ts":ce,"../../types/components/Transform2DComponent.d.ts":ue,"../../types/components/Velocity2DComponent.d.ts":me,"../../types/components/registry.d.ts":he,"../../types/cont-do.d.ts":fe,"../../types/coroutine-dsl.d.ts":be,"../../types/ecs/EcsComponent.d.ts":ge,"../../types/ecs/EcsRegistry.d.ts":ye,"../../types/ecs/EcsWorld.d.ts":xe,"../../types/ecs/EcsWorldAutomergeProjection.d.ts":ve,"../../types/ecs/IEcsWorld.d.ts":Te,"../../types/ecs/components/ChildrenComponent.d.ts":Se,"../../types/ecs/components/ParentComponent.d.ts":we,"../../types/ecs/components/SortOrderIndexComponent.d.ts":_e,"../../types/ecs/components/registry.d.ts":Ee,"../../types/ecs/systems/AutomergeEcsSyncSystem.d.ts":Pe,"../../types/index.d.ts":Ae,"../../types/index.html.d.ts":Ce,"../../types/lib.d.ts":Re,"../../types/math/Complex.d.ts":Ge,"../../types/math/Transform2D.d.ts":Me,"../../types/math/Vec2.d.ts":ke,"../../types/pixi-js.d.ts":Fe,"../../types/solid-js-store.d.ts":Oe,"../../types/solid-js.d.ts":Ie,"../../types/solid.js.d.ts":Le,"../../types/systems/AnimationSystem.d.ts":Be,"../../types/systems/CollisionResolutionSystem.d.ts":De,"../../types/systems/CollisionSystem.d.ts":Ue,"../../types/systems/GmeSystem.d.ts":je,"../../types/systems/MonsterLogicSystem.d.ts":We,"../../types/systems/PixiRenderSystem.d.ts":He,"../../types/systems/SpawnSystem.d.ts":Ve,"../../types/systems/VirtualDPadSystem.d.ts":Ne}),N={};for(let e in B)N["prelude/"+e.slice(12)]=B[e];const D=Object.assign({"../../node_modules/solid-js/h/jsx-runtime/types/index.d.ts":ze,"../../node_modules/solid-js/h/jsx-runtime/types/jsx.d.ts":Xe,"../../node_modules/solid-js/h/types/hyperscript.d.ts":Ke,"../../node_modules/solid-js/h/types/index.d.ts":qe,"../../node_modules/solid-js/html/types/index.d.ts":Ye,"../../node_modules/solid-js/html/types/lit.d.ts":Je,"../../node_modules/solid-js/jsx-runtime.d.ts":$e,"../../node_modules/solid-js/store/types/index.d.ts":Qe,"../../node_modules/solid-js/store/types/modifiers.d.ts":Ze,"../../node_modules/solid-js/store/types/mutable.d.ts":en,"../../node_modules/solid-js/store/types/server.d.ts":nn,"../../node_modules/solid-js/store/types/store.d.ts":tn,"../../node_modules/solid-js/types/index.d.ts":rn,"../../node_modules/solid-js/types/jsx.d.ts":on,"../../node_modules/solid-js/types/reactive/array.d.ts":an,"../../node_modules/solid-js/types/reactive/observable.d.ts":sn,"../../node_modules/solid-js/types/reactive/scheduler.d.ts":ln,"../../node_modules/solid-js/types/reactive/signal.d.ts":dn,"../../node_modules/solid-js/types/render/Suspense.d.ts":pn,"../../node_modules/solid-js/types/render/component.d.ts":cn,"../../node_modules/solid-js/types/render/flow.d.ts":un,"../../node_modules/solid-js/types/render/hydration.d.ts":mn,"../../node_modules/solid-js/types/render/index.d.ts":hn,"../../node_modules/solid-js/types/server/index.d.ts":fn,"../../node_modules/solid-js/types/server/reactive.d.ts":bn,"../../node_modules/solid-js/types/server/rendering.d.ts":gn,"../../node_modules/solid-js/universal/types/index.d.ts":yn,"../../node_modules/solid-js/universal/types/universal.d.ts":xn,"../../node_modules/solid-js/web/storage/types/index.d.ts":vn,"../../node_modules/solid-js/web/types/client.d.ts":Tn,"../../node_modules/solid-js/web/types/core.d.ts":Sn,"../../node_modules/solid-js/web/types/index.d.ts":wn,"../../node_modules/solid-js/web/types/jsx.d.ts":_n,"../../node_modules/solid-js/web/types/server-mock.d.ts":En,"../../node_modules/solid-js/web/types/server.d.ts":Pn}),z={};for(let e in D)z["prelude/"+e.slice(19)]=D[e];const U=Object.assign({"../../node_modules/pixi.js/dist/pixi.js.d.ts":An,"../../node_modules/pixi.js/lib/Shaders.d.ts":Cn,"../../node_modules/pixi.js/lib/accessibility/AccessibilityMixins.d.ts":Rn,"../../node_modules/pixi.js/lib/accessibility/AccessibilitySystem.d.ts":Gn,"../../node_modules/pixi.js/lib/accessibility/accessibilityTarget.d.ts":Mn,"../../node_modules/pixi.js/lib/accessibility/index.d.ts":kn,"../../node_modules/pixi.js/lib/accessibility/init.d.ts":Fn,"../../node_modules/pixi.js/lib/advanced-blend-modes/ColorBlend.d.ts":On,"../../node_modules/pixi.js/lib/advanced-blend-modes/ColorBurnBlend.d.ts":In,"../../node_modules/pixi.js/lib/advanced-blend-modes/ColorDodgeBlend.d.ts":Ln,"../../node_modules/pixi.js/lib/advanced-blend-modes/DarkenBlend.d.ts":Bn,"../../node_modules/pixi.js/lib/advanced-blend-modes/DifferenceBlend.d.ts":Dn,"../../node_modules/pixi.js/lib/advanced-blend-modes/DivideBlend.d.ts":Un,"../../node_modules/pixi.js/lib/advanced-blend-modes/ExclusionBlend.d.ts":jn,"../../node_modules/pixi.js/lib/advanced-blend-modes/HardLightBlend.d.ts":Wn,"../../node_modules/pixi.js/lib/advanced-blend-modes/HardMixBlend.d.ts":Hn,"../../node_modules/pixi.js/lib/advanced-blend-modes/LightenBlend.d.ts":Vn,"../../node_modules/pixi.js/lib/advanced-blend-modes/LinearBurnBlend.d.ts":Nn,"../../node_modules/pixi.js/lib/advanced-blend-modes/LinearDodgeBlend.d.ts":zn,"../../node_modules/pixi.js/lib/advanced-blend-modes/LinearLightBlend.d.ts":Xn,"../../node_modules/pixi.js/lib/advanced-blend-modes/LuminosityBlend.d.ts":Kn,"../../node_modules/pixi.js/lib/advanced-blend-modes/NegationBlend.d.ts":qn,"../../node_modules/pixi.js/lib/advanced-blend-modes/OverlayBlend.d.ts":Yn,"../../node_modules/pixi.js/lib/advanced-blend-modes/PinLightBlend.d.ts":Jn,"../../node_modules/pixi.js/lib/advanced-blend-modes/SaturationBlend.d.ts":$n,"../../node_modules/pixi.js/lib/advanced-blend-modes/SoftLightBlend.d.ts":Qn,"../../node_modules/pixi.js/lib/advanced-blend-modes/SubtractBlend.d.ts":Zn,"../../node_modules/pixi.js/lib/advanced-blend-modes/VividLightBlend.d.ts":et,"../../node_modules/pixi.js/lib/advanced-blend-modes/index.d.ts":nt,"../../node_modules/pixi.js/lib/advanced-blend-modes/init.d.ts":tt,"../../node_modules/pixi.js/lib/app/Application.d.ts":rt,"../../node_modules/pixi.js/lib/app/ApplicationMixins.d.ts":ot,"../../node_modules/pixi.js/lib/app/ResizePlugin.d.ts":at,"../../node_modules/pixi.js/lib/app/TickerPlugin.d.ts":it,"../../node_modules/pixi.js/lib/app/index.d.ts":st,"../../node_modules/pixi.js/lib/app/init.d.ts":lt,"../../node_modules/pixi.js/lib/assets/AssetExtension.d.ts":dt,"../../node_modules/pixi.js/lib/assets/Assets.d.ts":pt,"../../node_modules/pixi.js/lib/assets/AssetsMixins.d.ts":ct,"../../node_modules/pixi.js/lib/assets/BackgroundLoader.d.ts":ut,"../../node_modules/pixi.js/lib/assets/cache/Cache.d.ts":mt,"../../node_modules/pixi.js/lib/assets/cache/CacheParser.d.ts":ht,"../../node_modules/pixi.js/lib/assets/cache/parsers/cacheTextureArray.d.ts":ft,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectAvif.d.ts":bt,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectDefaults.d.ts":gt,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectMp4.d.ts":yt,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectOgv.d.ts":xt,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectWebm.d.ts":vt,"../../node_modules/pixi.js/lib/assets/detections/parsers/detectWebp.d.ts":Tt,"../../node_modules/pixi.js/lib/assets/detections/types.d.ts":St,"../../node_modules/pixi.js/lib/assets/detections/utils/testImageFormat.d.ts":wt,"../../node_modules/pixi.js/lib/assets/detections/utils/testVideoFormat.d.ts":_t,"../../node_modules/pixi.js/lib/assets/index.d.ts":Et,"../../node_modules/pixi.js/lib/assets/loader/Loader.d.ts":Pt,"../../node_modules/pixi.js/lib/assets/loader/parsers/LoaderParser.d.ts":At,"../../node_modules/pixi.js/lib/assets/loader/parsers/loadJson.d.ts":Ct,"../../node_modules/pixi.js/lib/assets/loader/parsers/loadTxt.d.ts":Rt,"../../node_modules/pixi.js/lib/assets/loader/parsers/loadWebFont.d.ts":Gt,"../../node_modules/pixi.js/lib/assets/loader/parsers/textures/loadSVG.d.ts":Mt,"../../node_modules/pixi.js/lib/assets/loader/parsers/textures/loadTextures.d.ts":kt,"../../node_modules/pixi.js/lib/assets/loader/parsers/textures/loadVideoTextures.d.ts":Ft,"../../node_modules/pixi.js/lib/assets/loader/parsers/textures/utils/createTexture.d.ts":Ot,"../../node_modules/pixi.js/lib/assets/loader/types.d.ts":It,"../../node_modules/pixi.js/lib/assets/loader/workers/WorkerManager.d.ts":Lt,"../../node_modules/pixi.js/lib/assets/loader/workers/checkImageBitmap.worker.d.ts":Bt,"../../node_modules/pixi.js/lib/assets/loader/workers/loadImageBitmap.worker.d.ts":Dt,"../../node_modules/pixi.js/lib/assets/resolver/Resolver.d.ts":Ut,"../../node_modules/pixi.js/lib/assets/resolver/parsers/resolveJsonUrl.d.ts":jt,"../../node_modules/pixi.js/lib/assets/resolver/parsers/resolveTextureUrl.d.ts":Wt,"../../node_modules/pixi.js/lib/assets/resolver/types.d.ts":Ht,"../../node_modules/pixi.js/lib/assets/types.d.ts":Vt,"../../node_modules/pixi.js/lib/assets/utils/checkDataUrl.d.ts":Nt,"../../node_modules/pixi.js/lib/assets/utils/checkExtension.d.ts":zt,"../../node_modules/pixi.js/lib/assets/utils/convertToList.d.ts":Xt,"../../node_modules/pixi.js/lib/assets/utils/copySearchParams.d.ts":Kt,"../../node_modules/pixi.js/lib/assets/utils/createStringVariations.d.ts":qt,"../../node_modules/pixi.js/lib/assets/utils/isSingleItem.d.ts":Yt,"../../node_modules/pixi.js/lib/color/Color.d.ts":Jt,"../../node_modules/pixi.js/lib/color/index.d.ts":$t,"../../node_modules/pixi.js/lib/compressed-textures/basis/detectBasis.d.ts":Qt,"../../node_modules/pixi.js/lib/compressed-textures/basis/init.d.ts":Zt,"../../node_modules/pixi.js/lib/compressed-textures/basis/loadBasis.d.ts":er,"../../node_modules/pixi.js/lib/compressed-textures/basis/types.d.ts":nr,"../../node_modules/pixi.js/lib/compressed-textures/basis/utils/createLevelBuffers.d.ts":tr,"../../node_modules/pixi.js/lib/compressed-textures/basis/utils/gpuFormatToBasisTranscoderFormat.d.ts":rr,"../../node_modules/pixi.js/lib/compressed-textures/basis/utils/setBasisTranscoderPath.d.ts":or,"../../node_modules/pixi.js/lib/compressed-textures/basis/worker/basis.worker.d.ts":ar,"../../node_modules/pixi.js/lib/compressed-textures/basis/worker/loadBasisOnWorker.d.ts":ir,"../../node_modules/pixi.js/lib/compressed-textures/dds/const.d.ts":sr,"../../node_modules/pixi.js/lib/compressed-textures/dds/init.d.ts":lr,"../../node_modules/pixi.js/lib/compressed-textures/dds/loadDDS.d.ts":dr,"../../node_modules/pixi.js/lib/compressed-textures/dds/parseDDS.d.ts":pr,"../../node_modules/pixi.js/lib/compressed-textures/index.d.ts":cr,"../../node_modules/pixi.js/lib/compressed-textures/ktx/init.d.ts":ur,"../../node_modules/pixi.js/lib/compressed-textures/ktx/loadKTX.d.ts":mr,"../../node_modules/pixi.js/lib/compressed-textures/ktx/parseKTX.d.ts":hr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/const.d.ts":fr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/init.d.ts":br,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/loadKTX2.d.ts":gr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/types.d.ts":yr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/convertFormatIfRequired.d.ts":xr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/createLevelBuffersFromKTX.d.ts":vr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/getTextureFormatFromKTXTexture.d.ts":Tr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/glFormatToGPUFormat.d.ts":Sr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/gpuFormatToKTXBasisTranscoderFormat.d.ts":wr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/setKTXTranscoderPath.d.ts":_r,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/utils/vkFormatToGPUFormat.d.ts":Er,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/worker/ktx.worker.d.ts":Pr,"../../node_modules/pixi.js/lib/compressed-textures/ktx2/worker/loadKTX2onWorker.d.ts":Ar,"../../node_modules/pixi.js/lib/compressed-textures/shared/detectCompressed.d.ts":Cr,"../../node_modules/pixi.js/lib/compressed-textures/shared/resolveCompressedTextureUrl.d.ts":Rr,"../../node_modules/pixi.js/lib/culling/Culler.d.ts":Gr,"../../node_modules/pixi.js/lib/culling/CullerPlugin.d.ts":Mr,"../../node_modules/pixi.js/lib/culling/CullingMixins.d.ts":kr,"../../node_modules/pixi.js/lib/culling/cullingMixin.d.ts":Fr,"../../node_modules/pixi.js/lib/culling/index.d.ts":Or,"../../node_modules/pixi.js/lib/dom/DOMContainer.d.ts":Ir,"../../node_modules/pixi.js/lib/dom/DOMMixins.d.ts":Lr,"../../node_modules/pixi.js/lib/dom/DOMPipe.d.ts":Br,"../../node_modules/pixi.js/lib/dom/index.d.ts":Dr,"../../node_modules/pixi.js/lib/dom/init.d.ts":Ur,"../../node_modules/pixi.js/lib/environment-browser/BrowserAdapter.d.ts":jr,"../../node_modules/pixi.js/lib/environment-browser/browserAll.d.ts":Wr,"../../node_modules/pixi.js/lib/environment-browser/browserExt.d.ts":Hr,"../../node_modules/pixi.js/lib/environment-browser/index.d.ts":Vr,"../../node_modules/pixi.js/lib/environment-webworker/WebWorkerAdapter.d.ts":Nr,"../../node_modules/pixi.js/lib/environment-webworker/index.d.ts":zr,"../../node_modules/pixi.js/lib/environment-webworker/webworkerAll.d.ts":Xr,"../../node_modules/pixi.js/lib/environment-webworker/webworkerExt.d.ts":Kr,"../../node_modules/pixi.js/lib/environment/adapter.d.ts":qr,"../../node_modules/pixi.js/lib/environment/autoDetectEnvironment.d.ts":Yr,"../../node_modules/pixi.js/lib/environment/canvas/ICanvas.d.ts":Jr,"../../node_modules/pixi.js/lib/environment/canvas/ICanvasRenderingContext2D.d.ts":$r,"../../node_modules/pixi.js/lib/environment/index.d.ts":Qr,"../../node_modules/pixi.js/lib/events/EventBoundary.d.ts":Zr,"../../node_modules/pixi.js/lib/events/EventBoundaryTypes.d.ts":eo,"../../node_modules/pixi.js/lib/events/EventSystem.d.ts":no,"../../node_modules/pixi.js/lib/events/EventTicker.d.ts":to,"../../node_modules/pixi.js/lib/events/EventsMixins.d.ts":ro,"../../node_modules/pixi.js/lib/events/FederatedEvent.d.ts":oo,"../../node_modules/pixi.js/lib/events/FederatedEventMap.d.ts":ao,"../../node_modules/pixi.js/lib/events/FederatedEventTarget.d.ts":io,"../../node_modules/pixi.js/lib/events/FederatedMouseEvent.d.ts":so,"../../node_modules/pixi.js/lib/events/FederatedPointerEvent.d.ts":lo,"../../node_modules/pixi.js/lib/events/FederatedWheelEvent.d.ts":po,"../../node_modules/pixi.js/lib/events/deprecatedTypes.d.ts":co,"../../node_modules/pixi.js/lib/events/index.d.ts":uo,"../../node_modules/pixi.js/lib/events/init.d.ts":mo,"../../node_modules/pixi.js/lib/extensions/Extensions.d.ts":ho,"../../node_modules/pixi.js/lib/extensions/index.d.ts":fo,"../../node_modules/pixi.js/lib/filters/Filter.d.ts":bo,"../../node_modules/pixi.js/lib/filters/FilterEffect.d.ts":go,"../../node_modules/pixi.js/lib/filters/FilterMixins.d.ts":yo,"../../node_modules/pixi.js/lib/filters/FilterPipe.d.ts":xo,"../../node_modules/pixi.js/lib/filters/FilterSystem.d.ts":vo,"../../node_modules/pixi.js/lib/filters/blend-modes/BlendModeFilter.d.ts":To,"../../node_modules/pixi.js/lib/filters/blend-modes/hls/GLhls.d.ts":So,"../../node_modules/pixi.js/lib/filters/blend-modes/hls/GPUhls.d.ts":wo,"../../node_modules/pixi.js/lib/filters/defaults/alpha/AlphaFilter.d.ts":_o,"../../node_modules/pixi.js/lib/filters/defaults/blur/BlurFilter.d.ts":Eo,"../../node_modules/pixi.js/lib/filters/defaults/blur/BlurFilterPass.d.ts":Po,"../../node_modules/pixi.js/lib/filters/defaults/blur/const.d.ts":Ao,"../../node_modules/pixi.js/lib/filters/defaults/blur/gl/generateBlurFragSource.d.ts":Co,"../../node_modules/pixi.js/lib/filters/defaults/blur/gl/generateBlurGlProgram.d.ts":Ro,"../../node_modules/pixi.js/lib/filters/defaults/blur/gl/generateBlurVertSource.d.ts":Go,"../../node_modules/pixi.js/lib/filters/defaults/blur/gpu/generateBlurProgram.d.ts":Mo,"../../node_modules/pixi.js/lib/filters/defaults/color-matrix/ColorMatrixFilter.d.ts":ko,"../../node_modules/pixi.js/lib/filters/defaults/displacement/DisplacementFilter.d.ts":Fo,"../../node_modules/pixi.js/lib/filters/defaults/noise/NoiseFilter.d.ts":Oo,"../../node_modules/pixi.js/lib/filters/index.d.ts":Io,"../../node_modules/pixi.js/lib/filters/init.d.ts":Lo,"../../node_modules/pixi.js/lib/filters/mask/MaskFilter.d.ts":Bo,"../../node_modules/pixi.js/lib/gif/GifAsset.d.ts":Do,"../../node_modules/pixi.js/lib/gif/GifSource.d.ts":Uo,"../../node_modules/pixi.js/lib/gif/GifSprite.d.ts":jo,"../../node_modules/pixi.js/lib/gif/index.d.ts":Wo,"../../node_modules/pixi.js/lib/gif/init.d.ts":Ho,"../../node_modules/pixi.js/lib/index.d.ts":Vo,"../../node_modules/pixi.js/lib/math-extras/MathExtraMixins.d.ts":No,"../../node_modules/pixi.js/lib/math-extras/index.d.ts":zo,"../../node_modules/pixi.js/lib/math-extras/init.d.ts":Xo,"../../node_modules/pixi.js/lib/math-extras/pointExtras.d.ts":Ko,"../../node_modules/pixi.js/lib/math-extras/rectangleExtras.d.ts":qo,"../../node_modules/pixi.js/lib/math-extras/util.d.ts":Yo,"../../node_modules/pixi.js/lib/maths/index.d.ts":Jo,"../../node_modules/pixi.js/lib/maths/matrix/Matrix.d.ts":$o,"../../node_modules/pixi.js/lib/maths/matrix/groupD8.d.ts":Qo,"../../node_modules/pixi.js/lib/maths/misc/Size.d.ts":Zo,"../../node_modules/pixi.js/lib/maths/misc/const.d.ts":ea,"../../node_modules/pixi.js/lib/maths/misc/pow2.d.ts":na,"../../node_modules/pixi.js/lib/maths/misc/squaredDistanceToLineSegment.d.ts":ta,"../../node_modules/pixi.js/lib/maths/point/ObservablePoint.d.ts":ra,"../../node_modules/pixi.js/lib/maths/point/Point.d.ts":oa,"../../node_modules/pixi.js/lib/maths/point/PointData.d.ts":aa,"../../node_modules/pixi.js/lib/maths/point/PointLike.d.ts":ia,"../../node_modules/pixi.js/lib/maths/point/pointInTriangle.d.ts":sa,"../../node_modules/pixi.js/lib/maths/shapes/Circle.d.ts":la,"../../node_modules/pixi.js/lib/maths/shapes/Ellipse.d.ts":da,"../../node_modules/pixi.js/lib/maths/shapes/Polygon.d.ts":pa,"../../node_modules/pixi.js/lib/maths/shapes/Rectangle.d.ts":ca,"../../node_modules/pixi.js/lib/maths/shapes/RoundedRectangle.d.ts":ua,"../../node_modules/pixi.js/lib/maths/shapes/ShapePrimitive.d.ts":ma,"../../node_modules/pixi.js/lib/maths/shapes/Triangle.d.ts":ha,"../../node_modules/pixi.js/lib/prepare/PrepareBase.d.ts":fa,"../../node_modules/pixi.js/lib/prepare/PrepareMixins.d.ts":ba,"../../node_modules/pixi.js/lib/prepare/PrepareQueue.d.ts":ga,"../../node_modules/pixi.js/lib/prepare/PrepareSystem.d.ts":ya,"../../node_modules/pixi.js/lib/prepare/PrepareUpload.d.ts":xa,"../../node_modules/pixi.js/lib/prepare/index.d.ts":va,"../../node_modules/pixi.js/lib/prepare/init.d.ts":Ta,"../../node_modules/pixi.js/lib/rendering/RenderingMixins.d.ts":Sa,"../../node_modules/pixi.js/lib/rendering/batcher/gl/GlBatchAdaptor.d.ts":wa,"../../node_modules/pixi.js/lib/rendering/batcher/gl/utils/checkMaxIfStatementsInShader.d.ts":_a,"../../node_modules/pixi.js/lib/rendering/batcher/gl/utils/maxRecommendedTextures.d.ts":Ea,"../../node_modules/pixi.js/lib/rendering/batcher/gpu/GpuBatchAdaptor.d.ts":Pa,"../../node_modules/pixi.js/lib/rendering/batcher/gpu/generateGPULayout.d.ts":Aa,"../../node_modules/pixi.js/lib/rendering/batcher/gpu/generateLayout.d.ts":Ca,"../../node_modules/pixi.js/lib/rendering/batcher/gpu/getTextureBatchBindGroup.d.ts":Ra,"../../node_modules/pixi.js/lib/rendering/batcher/shared/BatchGeometry.d.ts":Ga,"../../node_modules/pixi.js/lib/rendering/batcher/shared/BatchTextureArray.d.ts":Ma,"../../node_modules/pixi.js/lib/rendering/batcher/shared/Batcher.d.ts":ka,"../../node_modules/pixi.js/lib/rendering/batcher/shared/BatcherPipe.d.ts":Fa,"../../node_modules/pixi.js/lib/rendering/batcher/shared/DefaultBatcher.d.ts":Oa,"../../node_modules/pixi.js/lib/rendering/batcher/shared/DefaultShader.d.ts":Ia,"../../node_modules/pixi.js/lib/rendering/high-shader/compileHighShaderToProgram.d.ts":La,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/compileHighShader.d.ts":Ba,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/types.d.ts":Da,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/addBits.d.ts":Ua,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/compileHooks.d.ts":ja,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/compileInputs.d.ts":Wa,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/compileOutputs.d.ts":Ha,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/formatShader.d.ts":Va,"../../node_modules/pixi.js/lib/rendering/high-shader/compiler/utils/injectBits.d.ts":Na,"../../node_modules/pixi.js/lib/rendering/high-shader/defaultProgramTemplate.d.ts":za,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/colorBit.d.ts":Xa,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/generateTextureBatchBit.d.ts":Ka,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/globalUniformsBit.d.ts":qa,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/localUniformBit.d.ts":Ya,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/roundPixelsBit.d.ts":Ja,"../../node_modules/pixi.js/lib/rendering/high-shader/shader-bits/textureBit.d.ts":$a,"../../node_modules/pixi.js/lib/rendering/index.d.ts":Qa,"../../node_modules/pixi.js/lib/rendering/init.d.ts":Za,"../../node_modules/pixi.js/lib/rendering/mask/MaskEffectManager.d.ts":ei,"../../node_modules/pixi.js/lib/rendering/mask/alpha/AlphaMask.d.ts":ni,"../../node_modules/pixi.js/lib/rendering/mask/alpha/AlphaMaskPipe.d.ts":ti,"../../node_modules/pixi.js/lib/rendering/mask/color/ColorMask.d.ts":ri,"../../node_modules/pixi.js/lib/rendering/mask/color/ColorMaskPipe.d.ts":oi,"../../node_modules/pixi.js/lib/rendering/mask/scissor/ScissorMask.d.ts":ai,"../../node_modules/pixi.js/lib/rendering/mask/stencil/StencilMask.d.ts":ii,"../../node_modules/pixi.js/lib/rendering/mask/stencil/StencilMaskPipe.d.ts":si,"../../node_modules/pixi.js/lib/rendering/mask/utils/addMaskBounds.d.ts":li,"../../node_modules/pixi.js/lib/rendering/mask/utils/addMaskLocalBounds.d.ts":di,"../../node_modules/pixi.js/lib/rendering/renderers/autoDetectRenderer.d.ts":pi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlBackBufferSystem.d.ts":ci,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlColorMaskSystem.d.ts":ui,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlEncoderSystem.d.ts":mi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlRenderTarget.d.ts":hi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlStencilSystem.d.ts":fi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/GlUboSystem.d.ts":bi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/WebGLRenderer.d.ts":gi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/buffer/GlBuffer.d.ts":yi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/buffer/GlBufferSystem.d.ts":xi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/buffer/const.d.ts":vi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/const.d.ts":Ti,"../../node_modules/pixi.js/lib/rendering/renderers/gl/context/GlContextSystem.d.ts":Si,"../../node_modules/pixi.js/lib/rendering/renderers/gl/context/GlRenderingContext.d.ts":wi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/context/WebGLExtensions.d.ts":_i,"../../node_modules/pixi.js/lib/rendering/renderers/gl/geometry/GlGeometrySystem.d.ts":Ei,"../../node_modules/pixi.js/lib/rendering/renderers/gl/geometry/utils/getGlTypeFromFormat.d.ts":Pi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/renderTarget/GlRenderTargetAdaptor.d.ts":Ai,"../../node_modules/pixi.js/lib/rendering/renderers/gl/renderTarget/GlRenderTargetSystem.d.ts":Ci,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/GenerateShaderSyncCode.d.ts":Ri,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/GlProgram.d.ts":Gi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/GlProgramData.d.ts":Mi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/GlShaderSystem.d.ts":ki,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/GlUniformGroupSystem.d.ts":Fi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/const.d.ts":Oi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/getBatchSamplersUniformGroup.d.ts":Ii,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/migrateFragmentFromV7toV8.d.ts":Li,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/compileShader.d.ts":Bi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/defaultValue.d.ts":Di,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/ensureAttributes.d.ts":Ui,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/extractAttributesFromGlProgram.d.ts":ji,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/generateProgram.d.ts":Wi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/getMaxFragmentPrecision.d.ts":Hi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/getTestContext.d.ts":Vi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/getUboData.d.ts":Ni,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/getUniformData.d.ts":zi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/logProgramError.d.ts":Xi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/mapSize.d.ts":Ki,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/mapType.d.ts":qi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/preprocessors/addProgramDefines.d.ts":Yi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/preprocessors/ensurePrecision.d.ts":Ji,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/preprocessors/insertVersion.d.ts":$i,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/preprocessors/setProgramName.d.ts":Qi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/program/preprocessors/stripVersion.d.ts":Zi,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/utils/createUboElementsSTD40.d.ts":es,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/utils/createUboSyncSTD40.d.ts":ns,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/utils/generateArraySyncSTD40.d.ts":ts,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/utils/generateUniformsSync.d.ts":rs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/shader/utils/generateUniformsSyncTypes.d.ts":os,"../../node_modules/pixi.js/lib/rendering/renderers/gl/state/GlStateSystem.d.ts":as,"../../node_modules/pixi.js/lib/rendering/renderers/gl/state/mapWebGLBlendModesToPixi.d.ts":is,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/GlTexture.d.ts":ss,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/GlTextureSystem.d.ts":ls,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/const.d.ts":ds,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/uploaders/GLTextureUploader.d.ts":ps,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/uploaders/glUploadBufferImageResource.d.ts":cs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/uploaders/glUploadCompressedTextureResource.d.ts":us,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/uploaders/glUploadImageResource.d.ts":ms,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/uploaders/glUploadVideoResource.d.ts":hs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/applyStyleParams.d.ts":fs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/getSupportedGlCompressedTextureFormats.d.ts":bs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/mapFormatToGlFormat.d.ts":gs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/mapFormatToGlInternalFormat.d.ts":ys,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/mapFormatToGlType.d.ts":xs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/pixiToGlMaps.d.ts":vs,"../../node_modules/pixi.js/lib/rendering/renderers/gl/texture/utils/unpremultiplyAlpha.d.ts":Ts,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/BindGroupSystem.d.ts":Ss,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuColorMaskSystem.d.ts":ws,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuDeviceSystem.d.ts":_s,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuEncoderSystem.d.ts":Es,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuStencilSystem.d.ts":Ps,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuUboSystem.d.ts":As,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/GpuUniformBatchPipe.d.ts":Cs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/WebGPURenderer.d.ts":Rs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/buffer/GpuBufferSystem.d.ts":Gs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/buffer/GpuReadBuffer.d.ts":Ms,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/buffer/UboBatch.d.ts":ks,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/pipeline/PipelineSystem.d.ts":Fs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/renderTarget/GpuRenderTarget.d.ts":Os,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/renderTarget/GpuRenderTargetAdaptor.d.ts":Is,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/renderTarget/GpuRenderTargetSystem.d.ts":Ls,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/renderTarget/calculateProjection.d.ts":Bs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/BindGroup.d.ts":Ds,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/BindResource.d.ts":Us,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/GpuProgram.d.ts":js,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/GpuShaderSystem.d.ts":Ws,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/createUboElementsWGSL.d.ts":Hs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/createUboSyncFunctionWGSL.d.ts":Vs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/extractAttributesFromGpuProgram.d.ts":Ns,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/extractStructAndGroups.d.ts":zs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/generateArraySyncWGSL.d.ts":Xs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/generateGpuLayoutGroups.d.ts":Ks,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/generateLayoutHash.d.ts":qs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/shader/utils/removeStructAndGroupDuplicates.d.ts":Ys,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/state/GpuBlendModesToPixi.d.ts":Js,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/state/GpuStateSystem.d.ts":$s,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/state/GpuStencilModesToPixi.d.ts":Qs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/GpuTextureSystem.d.ts":Zs,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/uploaders/GpuTextureUploader.d.ts":el,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/uploaders/gpuUploadBufferImageResource.d.ts":nl,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/uploaders/gpuUploadCompressedTextureResource.d.ts":tl,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/uploaders/gpuUploadImageSource.d.ts":rl,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/uploaders/gpuUploadVideoSource.d.ts":ol,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/utils/GpuMipmapGenerator.d.ts":al,"../../node_modules/pixi.js/lib/rendering/renderers/gpu/texture/utils/getSupportedGPUCompressedTextureFormats.d.ts":il,"../../node_modules/pixi.js/lib/rendering/renderers/shared/Renderable.d.ts":sl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/SchedulerSystem.d.ts":ll,"../../node_modules/pixi.js/lib/rendering/renderers/shared/background/BackgroundSystem.d.ts":dl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/blendModes/BlendModePipe.d.ts":pl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/buffer/Buffer.d.ts":cl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/buffer/BufferResource.d.ts":ul,"../../node_modules/pixi.js/lib/rendering/renderers/shared/buffer/const.d.ts":ml,"../../node_modules/pixi.js/lib/rendering/renderers/shared/buffer/utils/fastCopy.d.ts":hl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/extract/ExtractSystem.d.ts":fl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/extract/GenerateTextureSystem.d.ts":bl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/Geometry.d.ts":gl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/const.d.ts":yl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/utils/buildUvs.d.ts":xl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/utils/ensureIsBuffer.d.ts":vl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/utils/getAttributeInfoFromFormat.d.ts":Tl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/utils/getGeometryBounds.d.ts":Sl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/geometry/utils/transformVertices.d.ts":wl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/instructions/Instruction.d.ts":_l,"../../node_modules/pixi.js/lib/rendering/renderers/shared/instructions/InstructionSet.d.ts":El,"../../node_modules/pixi.js/lib/rendering/renderers/shared/instructions/RenderPipe.d.ts":Pl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/renderTarget/GlobalUniformSystem.d.ts":Al,"../../node_modules/pixi.js/lib/rendering/renderers/shared/renderTarget/RenderTarget.d.ts":Cl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/renderTarget/RenderTargetSystem.d.ts":Rl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/renderTarget/isRenderingToScreen.d.ts":Gl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/renderTarget/viewportFromFrame.d.ts":Ml,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/Shader.d.ts":kl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/ShaderSystem.d.ts":Fl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/UboSystem.d.ts":Ol,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/UniformGroup.d.ts":Il,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/const.d.ts":Ll,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/types.d.ts":Bl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/utils/createUboSyncFunction.d.ts":Dl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/utils/getDefaultUniformValue.d.ts":Ul,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/utils/uboSyncFunctions.d.ts":jl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/shader/utils/uniformParsers.d.ts":Wl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/startup/HelloSystem.d.ts":Hl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/state/State.d.ts":Vl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/state/const.d.ts":Nl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/state/getAdjustedBlendModeBlend.d.ts":zl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/system/AbstractRenderer.d.ts":Xl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/system/SharedSystems.d.ts":Kl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/system/System.d.ts":ql,"../../node_modules/pixi.js/lib/rendering/renderers/shared/system/SystemRunner.d.ts":Yl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/system/utils/typeUtils.d.ts":Jl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/CanvasPool.d.ts":$l,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/GenerateCanvas.d.ts":Ql,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/RenderTexture.d.ts":Zl,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/RenderableGCSystem.d.ts":ed,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/Texture.d.ts":nd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/TextureGCSystem.d.ts":td,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/TextureMatrix.d.ts":rd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/TexturePool.d.ts":od,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/TextureStyle.d.ts":ad,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/TextureUvs.d.ts":id,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/const.d.ts":sd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/BufferImageSource.d.ts":ld,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/CanvasSource.d.ts":dd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/CompressedSource.d.ts":pd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/ImageSource.d.ts":cd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/TextureSource.d.ts":ud,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/sources/VideoSource.d.ts":md,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/utils/generateUID.d.ts":hd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/utils/getCanvasTexture.d.ts":fd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/utils/getSupportedCompressedTextureFormats.d.ts":bd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/utils/getSupportedTextureFormats.d.ts":gd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/texture/utils/textureFrom.d.ts":yd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/utils/createIdFromString.d.ts":xd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/utils/parseFunctionBody.d.ts":vd,"../../node_modules/pixi.js/lib/rendering/renderers/shared/view/View.d.ts":Td,"../../node_modules/pixi.js/lib/rendering/renderers/shared/view/ViewSystem.d.ts":Sd,"../../node_modules/pixi.js/lib/rendering/renderers/types.d.ts":wd,"../../node_modules/pixi.js/lib/scene/SceneMixins.d.ts":_d,"../../node_modules/pixi.js/lib/scene/container/Container.d.ts":Ed,"../../node_modules/pixi.js/lib/scene/container/CustomRenderPipe.d.ts":Pd,"../../node_modules/pixi.js/lib/scene/container/Effect.d.ts":Ad,"../../node_modules/pixi.js/lib/scene/container/RenderContainer.d.ts":Cd,"../../node_modules/pixi.js/lib/scene/container/RenderGroup.d.ts":Rd,"../../node_modules/pixi.js/lib/scene/container/RenderGroupPipe.d.ts":Gd,"../../node_modules/pixi.js/lib/scene/container/RenderGroupSystem.d.ts":Md,"../../node_modules/pixi.js/lib/scene/container/bounds/Bounds.d.ts":kd,"../../node_modules/pixi.js/lib/scene/container/bounds/getFastGlobalBounds.d.ts":Fd,"../../node_modules/pixi.js/lib/scene/container/bounds/getGlobalBounds.d.ts":Od,"../../node_modules/pixi.js/lib/scene/container/bounds/getLocalBounds.d.ts":Id,"../../node_modules/pixi.js/lib/scene/container/bounds/getRenderableBounds.d.ts":Ld,"../../node_modules/pixi.js/lib/scene/container/bounds/utils/matrixAndBoundsPool.d.ts":Bd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/cacheAsTextureMixin.d.ts":Dd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/childrenHelperMixin.d.ts":Ud,"../../node_modules/pixi.js/lib/scene/container/container-mixins/collectRenderablesMixin.d.ts":jd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/effectsMixin.d.ts":Wd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/findMixin.d.ts":Hd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/getFastGlobalBoundsMixin.d.ts":Vd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/getGlobalMixin.d.ts":Nd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/measureMixin.d.ts":zd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/onRenderMixin.d.ts":Xd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/sortMixin.d.ts":Kd,"../../node_modules/pixi.js/lib/scene/container/container-mixins/toLocalGlobalMixin.d.ts":qd,"../../node_modules/pixi.js/lib/scene/container/destroyTypes.d.ts":Yd,"../../node_modules/pixi.js/lib/scene/container/utils/assignWithIgnore.d.ts":Jd,"../../node_modules/pixi.js/lib/scene/container/utils/checkChildrenDidChange.d.ts":$d,"../../node_modules/pixi.js/lib/scene/container/utils/clearList.d.ts":Qd,"../../node_modules/pixi.js/lib/scene/container/utils/collectAllRenderables.d.ts":Zd,"../../node_modules/pixi.js/lib/scene/container/utils/definedProps.d.ts":ep,"../../node_modules/pixi.js/lib/scene/container/utils/executeInstructions.d.ts":np,"../../node_modules/pixi.js/lib/scene/container/utils/mixHexColors.d.ts":tp,"../../node_modules/pixi.js/lib/scene/container/utils/multiplyColors.d.ts":rp,"../../node_modules/pixi.js/lib/scene/container/utils/multiplyHexColors.d.ts":op,"../../node_modules/pixi.js/lib/scene/container/utils/updateLocalTransform.d.ts":ap,"../../node_modules/pixi.js/lib/scene/container/utils/updateRenderGroupTransforms.d.ts":ip,"../../node_modules/pixi.js/lib/scene/container/utils/updateWorldTransform.d.ts":sp,"../../node_modules/pixi.js/lib/scene/container/utils/validateRenderables.d.ts":lp,"../../node_modules/pixi.js/lib/scene/graphics/GraphicsMixins.d.ts":dp,"../../node_modules/pixi.js/lib/scene/graphics/gl/GlGraphicsAdaptor.d.ts":pp,"../../node_modules/pixi.js/lib/scene/graphics/gpu/GpuGraphicsAdaptor.d.ts":cp,"../../node_modules/pixi.js/lib/scene/graphics/gpu/colorToUniform.d.ts":up,"../../node_modules/pixi.js/lib/scene/graphics/init.d.ts":mp,"../../node_modules/pixi.js/lib/scene/graphics/shared/BatchableGraphics.d.ts":hp,"../../node_modules/pixi.js/lib/scene/graphics/shared/FillTypes.d.ts":fp,"../../node_modules/pixi.js/lib/scene/graphics/shared/Graphics.d.ts":bp,"../../node_modules/pixi.js/lib/scene/graphics/shared/GraphicsContext.d.ts":gp,"../../node_modules/pixi.js/lib/scene/graphics/shared/GraphicsContextSystem.d.ts":yp,"../../node_modules/pixi.js/lib/scene/graphics/shared/GraphicsPipe.d.ts":xp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/ShapeBuildCommand.d.ts":vp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildAdaptiveBezier.d.ts":Tp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildAdaptiveQuadratic.d.ts":Sp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildArc.d.ts":wp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildArcTo.d.ts":_p,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildArcToSvg.d.ts":Ep,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildCircle.d.ts":Pp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildLine.d.ts":Ap,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildPixelLine.d.ts":Cp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildPolygon.d.ts":Rp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildRectangle.d.ts":Gp,"../../node_modules/pixi.js/lib/scene/graphics/shared/buildCommands/buildTriangle.d.ts":Mp,"../../node_modules/pixi.js/lib/scene/graphics/shared/const.d.ts":kp,"../../node_modules/pixi.js/lib/scene/graphics/shared/fill/FillGradient.d.ts":Fp,"../../node_modules/pixi.js/lib/scene/graphics/shared/fill/FillPattern.d.ts":Op,"../../node_modules/pixi.js/lib/scene/graphics/shared/path/GraphicsPath.d.ts":Ip,"../../node_modules/pixi.js/lib/scene/graphics/shared/path/ShapePath.d.ts":Lp,"../../node_modules/pixi.js/lib/scene/graphics/shared/path/roundShape.d.ts":Bp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/SVGParser.d.ts":Dp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/parseSVGDefinitions.d.ts":Up,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/parseSVGFloatAttribute.d.ts":jp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/parseSVGPath.d.ts":Wp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/parseSVGStyle.d.ts":Hp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/utils/extractSvgUrlId.d.ts":Vp,"../../node_modules/pixi.js/lib/scene/graphics/shared/svg/utils/parse-svg-path.d.ts":Np,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/buildContextBatches.d.ts":zp,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/buildGeometryFromPath.d.ts":Xp,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/convertFillInputToFillStyle.d.ts":Kp,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/generateTextureFillMatrix.d.ts":qp,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/getOrientationOfPoints.d.ts":Yp,"../../node_modules/pixi.js/lib/scene/graphics/shared/utils/triangulateWithHoles.d.ts":Jp,"../../node_modules/pixi.js/lib/scene/index.d.ts":$p,"../../node_modules/pixi.js/lib/scene/layers/RenderLayer.d.ts":Qp,"../../node_modules/pixi.js/lib/scene/mesh-perspective/PerspectiveMesh.d.ts":Zp,"../../node_modules/pixi.js/lib/scene/mesh-perspective/PerspectivePlaneGeometry.d.ts":ec,"../../node_modules/pixi.js/lib/scene/mesh-perspective/utils/applyProjectiveTransformationToPlane.d.ts":nc,"../../node_modules/pixi.js/lib/scene/mesh-perspective/utils/compute2DProjections.d.ts":tc,"../../node_modules/pixi.js/lib/scene/mesh-plane/MeshPlane.d.ts":rc,"../../node_modules/pixi.js/lib/scene/mesh-plane/PlaneGeometry.d.ts":oc,"../../node_modules/pixi.js/lib/scene/mesh-simple/MeshRope.d.ts":ac,"../../node_modules/pixi.js/lib/scene/mesh-simple/MeshSimple.d.ts":ic,"../../node_modules/pixi.js/lib/scene/mesh-simple/RopeGeometry.d.ts":sc,"../../node_modules/pixi.js/lib/scene/mesh/MeshMixins.d.ts":lc,"../../node_modules/pixi.js/lib/scene/mesh/gl/GlMeshAdaptor.d.ts":dc,"../../node_modules/pixi.js/lib/scene/mesh/gpu/GpuMeshAdapter.d.ts":pc,"../../node_modules/pixi.js/lib/scene/mesh/init.d.ts":cc,"../../node_modules/pixi.js/lib/scene/mesh/shared/BatchableMesh.d.ts":uc,"../../node_modules/pixi.js/lib/scene/mesh/shared/Mesh.d.ts":mc,"../../node_modules/pixi.js/lib/scene/mesh/shared/MeshGeometry.d.ts":hc,"../../node_modules/pixi.js/lib/scene/mesh/shared/MeshPipe.d.ts":fc,"../../node_modules/pixi.js/lib/scene/mesh/shared/getTextureDefaultMatrix.d.ts":bc,"../../node_modules/pixi.js/lib/scene/particle-container/ParticleMixins.d.ts":gc,"../../node_modules/pixi.js/lib/scene/particle-container/gl/GlParticleContainerAdaptor.d.ts":yc,"../../node_modules/pixi.js/lib/scene/particle-container/gpu/GpuParticleContainerAdaptor.d.ts":xc,"../../node_modules/pixi.js/lib/scene/particle-container/init.d.ts":vc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/GlParticleContainerPipe.d.ts":Tc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/GpuParticleContainerPipe.d.ts":Sc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/Particle.d.ts":wc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/ParticleBuffer.d.ts":_c,"../../node_modules/pixi.js/lib/scene/particle-container/shared/ParticleContainer.d.ts":Ec,"../../node_modules/pixi.js/lib/scene/particle-container/shared/ParticleContainerPipe.d.ts":Pc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/particleData.d.ts":Ac,"../../node_modules/pixi.js/lib/scene/particle-container/shared/shader/ParticleShader.d.ts":Cc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/utils/createIndicesForQuads.d.ts":Rc,"../../node_modules/pixi.js/lib/scene/particle-container/shared/utils/generateParticleUpdateFunction.d.ts":Gc,"../../node_modules/pixi.js/lib/scene/sprite-animated/AnimatedSprite.d.ts":Mc,"../../node_modules/pixi.js/lib/scene/sprite-nine-slice/NineSliceGeometry.d.ts":kc,"../../node_modules/pixi.js/lib/scene/sprite-nine-slice/NineSliceSprite.d.ts":Fc,"../../node_modules/pixi.js/lib/scene/sprite-nine-slice/NineSliceSpriteMixins.d.ts":Oc,"../../node_modules/pixi.js/lib/scene/sprite-nine-slice/NineSliceSpritePipe.d.ts":Ic,"../../node_modules/pixi.js/lib/scene/sprite-nine-slice/init.d.ts":Lc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/TilingSprite.d.ts":Bc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/TilingSpriteMixins.d.ts":Dc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/TilingSpritePipe.d.ts":Uc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/init.d.ts":jc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/shader/TilingSpriteShader.d.ts":Wc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/shader/tilingBit.d.ts":Hc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/utils/QuadGeometry.d.ts":Vc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/utils/applyMatrix.d.ts":Nc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/utils/setPositions.d.ts":zc,"../../node_modules/pixi.js/lib/scene/sprite-tiling/utils/setUvs.d.ts":Xc,"../../node_modules/pixi.js/lib/scene/sprite/BatchableSprite.d.ts":Kc,"../../node_modules/pixi.js/lib/scene/sprite/Sprite.d.ts":qc,"../../node_modules/pixi.js/lib/scene/sprite/SpritePipe.d.ts":Yc,"../../node_modules/pixi.js/lib/scene/text-bitmap/AbstractBitmapFont.d.ts":Jc,"../../node_modules/pixi.js/lib/scene/text-bitmap/BitmapFont.d.ts":$c,"../../node_modules/pixi.js/lib/scene/text-bitmap/BitmapFontManager.d.ts":Qc,"../../node_modules/pixi.js/lib/scene/text-bitmap/BitmapText.d.ts":Zc,"../../node_modules/pixi.js/lib/scene/text-bitmap/BitmapTextPipe.d.ts":eu,"../../node_modules/pixi.js/lib/scene/text-bitmap/DynamicBitmapFont.d.ts":nu,"../../node_modules/pixi.js/lib/scene/text-bitmap/TextBitmapMixins.d.ts":tu,"../../node_modules/pixi.js/lib/scene/text-bitmap/asset/bitmapFontTextParser.d.ts":ru,"../../node_modules/pixi.js/lib/scene/text-bitmap/asset/bitmapFontXMLParser.d.ts":ou,"../../node_modules/pixi.js/lib/scene/text-bitmap/asset/bitmapFontXMLStringParser.d.ts":au,"../../node_modules/pixi.js/lib/scene/text-bitmap/asset/loadBitmapFont.d.ts":iu,"../../node_modules/pixi.js/lib/scene/text-bitmap/init.d.ts":su,"../../node_modules/pixi.js/lib/scene/text-bitmap/utils/getBitmapTextLayout.d.ts":lu,"../../node_modules/pixi.js/lib/scene/text-bitmap/utils/resolveCharacters.d.ts":du,"../../node_modules/pixi.js/lib/scene/text-html/HTMLText.d.ts":pu,"../../node_modules/pixi.js/lib/scene/text-html/HTMLTextPipe.d.ts":cu,"../../node_modules/pixi.js/lib/scene/text-html/HTMLTextRenderData.d.ts":uu,"../../node_modules/pixi.js/lib/scene/text-html/HTMLTextStyle.d.ts":mu,"../../node_modules/pixi.js/lib/scene/text-html/HTMLTextSystem.d.ts":hu,"../../node_modules/pixi.js/lib/scene/text-html/TextHTMLMixins.d.ts":fu,"../../node_modules/pixi.js/lib/scene/text-html/init.d.ts":bu,"../../node_modules/pixi.js/lib/scene/text-html/utils/extractFontFamilies.d.ts":gu,"../../node_modules/pixi.js/lib/scene/text-html/utils/getFontCss.d.ts":yu,"../../node_modules/pixi.js/lib/scene/text-html/utils/getSVGUrl.d.ts":xu,"../../node_modules/pixi.js/lib/scene/text-html/utils/getTemporaryCanvasFromImage.d.ts":vu,"../../node_modules/pixi.js/lib/scene/text-html/utils/loadFontAsBase64.d.ts":Tu,"../../node_modules/pixi.js/lib/scene/text-html/utils/loadFontCSS.d.ts":Su,"../../node_modules/pixi.js/lib/scene/text-html/utils/loadSVGImage.d.ts":wu,"../../node_modules/pixi.js/lib/scene/text-html/utils/measureHtmlText.d.ts":_u,"../../node_modules/pixi.js/lib/scene/text-html/utils/textStyleToCSS.d.ts":Eu,"../../node_modules/pixi.js/lib/scene/text/AbstractText.d.ts":Pu,"../../node_modules/pixi.js/lib/scene/text/Text.d.ts":Au,"../../node_modules/pixi.js/lib/scene/text/TextMixins.d.ts":Cu,"../../node_modules/pixi.js/lib/scene/text/TextStyle.d.ts":Ru,"../../node_modules/pixi.js/lib/scene/text/canvas/CanvasTextMetrics.d.ts":Gu,"../../node_modules/pixi.js/lib/scene/text/canvas/CanvasTextPipe.d.ts":Mu,"../../node_modules/pixi.js/lib/scene/text/canvas/CanvasTextSystem.d.ts":ku,"../../node_modules/pixi.js/lib/scene/text/canvas/utils/fontStringFromTextStyle.d.ts":Fu,"../../node_modules/pixi.js/lib/scene/text/canvas/utils/getCanvasFillStyle.d.ts":Ou,"../../node_modules/pixi.js/lib/scene/text/init.d.ts":Iu,"../../node_modules/pixi.js/lib/scene/text/sdfShader/SdfShader.d.ts":Lu,"../../node_modules/pixi.js/lib/scene/text/sdfShader/shader-bits/localUniformMSDFBit.d.ts":Bu,"../../node_modules/pixi.js/lib/scene/text/sdfShader/shader-bits/mSDFBit.d.ts":Du,"../../node_modules/pixi.js/lib/scene/text/utils/ensureTextStyle.d.ts":Uu,"../../node_modules/pixi.js/lib/scene/text/utils/generateTextStyleKey.d.ts":ju,"../../node_modules/pixi.js/lib/scene/text/utils/getPo2TextureFromSource.d.ts":Wu,"../../node_modules/pixi.js/lib/scene/text/utils/updateTextBounds.d.ts":Hu,"../../node_modules/pixi.js/lib/scene/view/ViewContainer.d.ts":Vu,"../../node_modules/pixi.js/lib/spritesheet/Spritesheet.d.ts":Nu,"../../node_modules/pixi.js/lib/spritesheet/index.d.ts":zu,"../../node_modules/pixi.js/lib/spritesheet/init.d.ts":Xu,"../../node_modules/pixi.js/lib/spritesheet/spritesheetAsset.d.ts":Ku,"../../node_modules/pixi.js/lib/ticker/Ticker.d.ts":qu,"../../node_modules/pixi.js/lib/ticker/TickerListener.d.ts":Yu,"../../node_modules/pixi.js/lib/ticker/const.d.ts":Ju,"../../node_modules/pixi.js/lib/ticker/index.d.ts":$u,"../../node_modules/pixi.js/lib/unsafe-eval/index.d.ts":Qu,"../../node_modules/pixi.js/lib/unsafe-eval/init.d.ts":Zu,"../../node_modules/pixi.js/lib/unsafe-eval/particle/generateParticleUpdatePolyfill.d.ts":em,"../../node_modules/pixi.js/lib/unsafe-eval/particle/particleUpdateFunctions.d.ts":nm,"../../node_modules/pixi.js/lib/unsafe-eval/shader/generateShaderSyncPolyfill.d.ts":tm,"../../node_modules/pixi.js/lib/unsafe-eval/ubo/generateUboSyncPolyfill.d.ts":rm,"../../node_modules/pixi.js/lib/unsafe-eval/ubo/uboSyncFunctions.d.ts":om,"../../node_modules/pixi.js/lib/unsafe-eval/uniforms/generateUniformsSyncPolyfill.d.ts":am,"../../node_modules/pixi.js/lib/unsafe-eval/uniforms/uniformSyncFunctions.d.ts":im,"../../node_modules/pixi.js/lib/utils/browser/detectVideoAlphaMode.d.ts":sm,"../../node_modules/pixi.js/lib/utils/browser/isMobile.d.ts":lm,"../../node_modules/pixi.js/lib/utils/browser/isSafari.d.ts":dm,"../../node_modules/pixi.js/lib/utils/browser/isWebGLSupported.d.ts":pm,"../../node_modules/pixi.js/lib/utils/browser/isWebGPUSupported.d.ts":cm,"../../node_modules/pixi.js/lib/utils/browser/unsafeEvalSupported.d.ts":um,"../../node_modules/pixi.js/lib/utils/canvas/getCanvasBoundingBox.d.ts":mm,"../../node_modules/pixi.js/lib/utils/const.d.ts":hm,"../../node_modules/pixi.js/lib/utils/data/ViewableBuffer.d.ts":fm,"../../node_modules/pixi.js/lib/utils/data/clean.d.ts":bm,"../../node_modules/pixi.js/lib/utils/data/removeItems.d.ts":gm,"../../node_modules/pixi.js/lib/utils/data/uid.d.ts":ym,"../../node_modules/pixi.js/lib/utils/data/updateQuadBounds.d.ts":xm,"../../node_modules/pixi.js/lib/utils/global/globalHooks.d.ts":vm,"../../node_modules/pixi.js/lib/utils/index.d.ts":Tm,"../../node_modules/pixi.js/lib/utils/logging/deprecation.d.ts":Sm,"../../node_modules/pixi.js/lib/utils/logging/logDebugTexture.d.ts":wm,"../../node_modules/pixi.js/lib/utils/logging/logScene.d.ts":_m,"../../node_modules/pixi.js/lib/utils/logging/warn.d.ts":Em,"../../node_modules/pixi.js/lib/utils/misc/NOOP.d.ts":Pm,"../../node_modules/pixi.js/lib/utils/misc/Transform.d.ts":Am,"../../node_modules/pixi.js/lib/utils/network/getResolutionOfUrl.d.ts":Cm,"../../node_modules/pixi.js/lib/utils/path.d.ts":Rm,"../../node_modules/pixi.js/lib/utils/pool/Pool.d.ts":Gm,"../../node_modules/pixi.js/lib/utils/pool/PoolGroup.d.ts":Mm,"../../node_modules/pixi.js/lib/utils/sayHello.d.ts":km,"../../node_modules/pixi.js/lib/utils/types.d.ts":Fm,"../../node_modules/pixi.js/lib/utils/utils.d.ts":Om});let X={};for(let e in U)X["prelude/"+e.slice(19)]=U[e];const wh={...N,...z,...X};let x=await Th.init();const f=navigator&&/android/i.test(navigator.userAgent);let _=new q;function Ch(e){for(let[t,r]of Object.entries(wh)){let o=x.languages.typescript.typescriptDefaults.addExtraLib(r,t);R(()=>o.dispose())}x.languages.typescript.typescriptDefaults.setCompilerOptions({paths:{prelude:["./prelude/lib.js"],"prelude/solid-js":["./prelude/solid-js/types/index.js"],"prelude/solid-js/store":["./prelude/solid-js/store/types/index.js"],"prelude/pixi.js":["./prelude/pixi.js/lib/index.js"]}});let n=(t,r,o)=>{m(Z(()=>o.contents,a=>m(()=>{switch(a.type){case"File":{let i=a.id,l=t+a.name,s=r+a.name,d=o.openFileById(i);m(v(d,c=>{if(c.type!="Success")return;let u=c.value,b=x.editor.createModel(ee(()=>u.doc.source),"typescript",x.Uri.parse(s));m(v(()=>u.doc.source,h=>{b.setValue(h)},{defer:!0}));let g={model:b,file:u};_.set(l,g),R(()=>{b.dispose(),_.get(l)===g&&_.delete(l)})}));break}case"Folder":{let i=a.id,l=o.openFolderById(i);m(v(l,s=>{if(s.type!="Success")return;let d=s.value;n(t+a.name+"/",r+a.name+"/",d)}));break}}})))};n("","file:///",e)}const Rh=e=>{let[n,t]=G(),[r,o]=G();return Q(()=>{let a=n();if(a==null)return;let i=x.editor.create(a,{language:"typescript",quickSuggestions:{other:!f,comments:!f,strings:!f},automaticLayout:!0,acceptSuggestionOnCommitCharacter:!f,acceptSuggestionOnEnter:f?"off":"on",accessibilitySupport:f?"off":"on",theme:"vs-dark"});o(i);let l=ne(()=>{if(e.path!=null)return _.get(e.path)});m(v(l,s=>{if(s==null)return;let d=s.model,c=s.file;i.setModel(d);let u=!1,b=()=>{if(u)return;let h=r()?.getModel()?.getValue();h!=null&&c.docHandle.change(K=>{$(K,["source"],h)})},g=d?.onDidChangeContent(b);R(()=>{g?.dispose()}),m(v(()=>c.doc.source,h=>{u=!0;try{d.setValue(h)}finally{u=!1}}))}))}),(()=>{var a=Sh(),i=t;return typeof i=="function"?Y(i,a):t=a,a.style.setProperty("width","100%"),a.style.setProperty("height","100%"),a.style.setProperty("overflow","hidden"),a})()};export{Rh as default,Ch as mountAutomergeFolderToMonacoVfsWhileMounted};
